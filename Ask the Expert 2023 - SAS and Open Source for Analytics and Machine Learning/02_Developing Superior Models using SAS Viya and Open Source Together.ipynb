{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ask the Expert Special Edition - Developing Superior Models using SAS Viya and Open Source Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "def display_image(img):\n",
    "    ''' Display images for presentation'''\n",
    "    return Image(url=r'https://raw.githubusercontent.com/pestyld/Python-Integration-to-SAS-Viya/master/images/' + img, embed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 404: Not Found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdisplay_image\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMR_01_title.png\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m, in \u001b[0;36mdisplay_image\u001b[1;34m(img)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdisplay_image\u001b[39m(img):\n\u001b[0;32m      3\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m''' Display images for presentation'''\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mImage\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttps://raw.githubusercontent.com/pestyld/Python-Integration-to-SAS-Viya/master/images/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\IPython\\core\\display.py:970\u001b[0m, in \u001b[0;36mImage.__init__\u001b[1;34m(self, data, url, filename, format, embed, width, height, retina, unconfined, metadata, alt)\u001b[0m\n\u001b[0;32m    968\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munconfined \u001b[38;5;241m=\u001b[39m unconfined\n\u001b[0;32m    969\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malt \u001b[38;5;241m=\u001b[39m alt\n\u001b[1;32m--> 970\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mImage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwidth\u001b[39m\u001b[38;5;124m'\u001b[39m, {}):\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth \u001b[38;5;241m=\u001b[39m metadata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwidth\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\IPython\\core\\display.py:327\u001b[0m, in \u001b[0;36mDisplayObject.__init__\u001b[1;34m(self, data, url, filename, metadata)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 327\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    328\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_data()\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\IPython\\core\\display.py:1005\u001b[0m, in \u001b[0;36mImage.reload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1003\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[39;00m\n\u001b[0;32m   1004\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed:\n\u001b[1;32m-> 1005\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mImage\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1006\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretina:\n\u001b[0;32m   1007\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retina_shape()\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\IPython\\core\\display.py:358\u001b[0m, in \u001b[0;36mDisplayObject.reload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    355\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    356\u001b[0m     \u001b[38;5;66;03m# Deferred import\u001b[39;00m\n\u001b[0;32m    357\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01murllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrequest\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m urlopen\n\u001b[1;32m--> 358\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    359\u001b[0m     data \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m    360\u001b[0m     \u001b[38;5;66;03m# extract encoding from header, if there is one:\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py:222\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    221\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[1;32m--> 222\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py:531\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    529\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_response\u001b[38;5;241m.\u001b[39mget(protocol, []):\n\u001b[0;32m    530\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[1;32m--> 531\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    533\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py:640\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[1;34m(self, request, response)\u001b[0m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[0;32m    639\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[1;32m--> 640\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    641\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    643\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py:569\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[1;34m(self, proto, *args)\u001b[0m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[0;32m    568\u001b[0m     args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_error_default\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m orig_args\n\u001b[1;32m--> 569\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py:502\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    500\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[0;32m    501\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 502\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    503\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py:649\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[1;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[0;32m    648\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[1;32m--> 649\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req\u001b[38;5;241m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[1;31mHTTPError\u001b[0m: HTTP Error 404: Not Found"
     ]
    }
   ],
   "source": [
    "display_image('MR_01_title.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agenda\n",
    "\n",
    "Today we will go through the steps of predictive modeling using CAS Actionsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Visual Modeling and Model Studio Pipelines \n",
    "2. Introduction to using Actionsets for Predictive Modeling\n",
    "3. Connect to CAS and Load the Data\n",
    "4. Explore Data\n",
    "5. Partition Data\n",
    "6. Run a Decision Tree and Gradient Boosting Model\n",
    "7. Run a Python Gradient Boosting Model\n",
    "8. Introduce the Data Science Automated Machine Learning Pipeline\n",
    "9. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](images/MR_02_pipeline.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](images/MR_03_pipeline_nodes.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect to CAS and load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import the swat (SAS Wrapper for Analytic Transfer) package and connect to CAS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import swat\n",
    "from pprint import pprint\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import sys\n",
    "import collections\n",
    "%matplotlib inline\n",
    "\n",
    "# Host, port, username, password\n",
    "conn = swat.CAS(\"http://server.demo.sas.com/cas-shared-default-http/\", username='sasdemo', password=\"Orion123\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](images/MR_04_ActionSets.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: Added action set 'cardinality'.\n",
      "NOTE: Added action set 'sampling'.\n",
      "NOTE: Added action set 'decisionTree'.\n",
      "NOTE: Added action set 'percentile'.\n",
      "NOTE: Added action set 'autotune'.\n",
      "NOTE: Added action set 'dataSciencePilot'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[actionset]\n",
       " \n",
       "  'cardinality'\n",
       " \n",
       " + Elapsed: 0.000501s, user: 0.000365s, sys: 0.000116s, mem: 0.222mb,\n",
       " [actionset]\n",
       " \n",
       "  'sampling'\n",
       " \n",
       " + Elapsed: 0.00202s, sys: 0.002s, mem: 0.262mb,\n",
       " [actionset]\n",
       " \n",
       "  'decisionTree'\n",
       " \n",
       " + Elapsed: 0.00141s, user: 0.00104s, sys: 0.000348s, mem: 0.239mb,\n",
       " [actionset]\n",
       " \n",
       "  'percentile'\n",
       " \n",
       " + Elapsed: 0.000283s, user: 0.000181s, sys: 8.4e-05s, mem: 0.221mb,\n",
       " [actionset]\n",
       " \n",
       "  'autotune'\n",
       " \n",
       " + Elapsed: 0.000975s, user: 8.3e-05s, sys: 0.000874s, mem: 0.241mb,\n",
       " [actionset]\n",
       " \n",
       "  'dataSciencePilot'\n",
       " \n",
       " + Elapsed: 0.0011s, user: 0.000745s, sys: 0.000336s, mem: 0.222mb]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load actionsets for analysis (for data prep, modeling, assessing)\n",
    "actionsets = ['cardinality', 'sampling', 'decisionTree', 'percentile', 'autotune', 'dataSciencePilot']\n",
    "[conn.builtins.loadactionset(i) for i in actionsets]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload data into CAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: Cloud Analytic Services made the file home_equity_final.sashdat available as table HOME_EQUITY_FINAL in caslib CASUSER(sasdemo).\n"
     ]
    }
   ],
   "source": [
    "conn.loadTable(path = 'home_equity_final.sashdat', caslib = 'public',\n",
    "              casout = {\n",
    "                  'name':'home_equity_final',\n",
    "                  'caslib':'casuser',\n",
    "                  'replace':True\n",
    "              })\n",
    "Home_Equity = conn.CASTable('home_equity_final', caslib = 'casuser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"cas-results-key\"><b>&#167; ColumnInfo</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"Column\">Column</th>\n",
       "      <th title=\"Label\">Label</th>\n",
       "      <th title=\"ID\">ID</th>\n",
       "      <th title=\"Type\">Type</th>\n",
       "      <th title=\"RawLength\">RawLength</th>\n",
       "      <th title=\"FormattedLength\">FormattedLength</th>\n",
       "      <th title=\"Format\">Format</th>\n",
       "      <th title=\"NFL\">NFL</th>\n",
       "      <th title=\"NFD\">NFD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>BAD</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>double</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>LOAN</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>double</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>MORTDUE</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>double</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>VALUE</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>double</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>REASON</td>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td>varchar</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>JOB</td>\n",
       "      <td></td>\n",
       "      <td>6</td>\n",
       "      <td>varchar</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>YOJ</td>\n",
       "      <td></td>\n",
       "      <td>7</td>\n",
       "      <td>double</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>DEROG</td>\n",
       "      <td></td>\n",
       "      <td>8</td>\n",
       "      <td>double</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>DELINQ</td>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>double</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>CLAGE</td>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>double</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>NINQ</td>\n",
       "      <td></td>\n",
       "      <td>11</td>\n",
       "      <td>double</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>CLNO</td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>double</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>DEBTINC</td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>double</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>APPDATE</td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>double</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>MMDDYY</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>CITY</td>\n",
       "      <td></td>\n",
       "      <td>15</td>\n",
       "      <td>varchar</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>STATE</td>\n",
       "      <td></td>\n",
       "      <td>16</td>\n",
       "      <td>varchar</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>DIVISION</td>\n",
       "      <td></td>\n",
       "      <td>17</td>\n",
       "      <td>varchar</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>REGION</td>\n",
       "      <td></td>\n",
       "      <td>18</td>\n",
       "      <td>varchar</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>IMP_CLAGE</td>\n",
       "      <td></td>\n",
       "      <td>19</td>\n",
       "      <td>double</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>IMP_CLNO</td>\n",
       "      <td></td>\n",
       "      <td>20</td>\n",
       "      <td>double</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>IMP_DEBTINC</td>\n",
       "      <td></td>\n",
       "      <td>21</td>\n",
       "      <td>double</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>IMP_DELINQ</td>\n",
       "      <td></td>\n",
       "      <td>22</td>\n",
       "      <td>double</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>IMP_DEROG</td>\n",
       "      <td></td>\n",
       "      <td>23</td>\n",
       "      <td>double</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>IMP_MORTDUE</td>\n",
       "      <td></td>\n",
       "      <td>24</td>\n",
       "      <td>double</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>IMP_NINQ</td>\n",
       "      <td></td>\n",
       "      <td>25</td>\n",
       "      <td>double</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>IMP_VALUE</td>\n",
       "      <td></td>\n",
       "      <td>26</td>\n",
       "      <td>double</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>IMP_YOJ</td>\n",
       "      <td></td>\n",
       "      <td>27</td>\n",
       "      <td>double</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>IMP_CITY</td>\n",
       "      <td></td>\n",
       "      <td>28</td>\n",
       "      <td>varchar</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>IMP_JOB</td>\n",
       "      <td></td>\n",
       "      <td>29</td>\n",
       "      <td>varchar</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>IMP_REASON</td>\n",
       "      <td></td>\n",
       "      <td>30</td>\n",
       "      <td>varchar</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>YEAR</td>\n",
       "      <td></td>\n",
       "      <td>31</td>\n",
       "      <td>double</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>QTR</td>\n",
       "      <td></td>\n",
       "      <td>32</td>\n",
       "      <td>double</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>DATE_SINCE_LAST_APP</td>\n",
       "      <td></td>\n",
       "      <td>33</td>\n",
       "      <td>double</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-output-area\"></div>\n",
       "<p class=\"cas-results-performance\"><small><span class=\"cas-elapsed\">elapsed 0.000535s</span> &#183; <span class=\"cas-user\">user 0.000343s</span> &#183; <span class=\"cas-sys\">sys 0.000171s</span> &#183; <span class=\"cas-memory\">mem 0.83MB</span></small></p>"
      ],
      "text/plain": [
       "[ColumnInfo]\n",
       "\n",
       "                  Column Label  ID     Type  RawLength  FormattedLength  Format  NFL  NFD\n",
       " 0                   BAD         1   double          8               12            0    0\n",
       " 1                  LOAN         2   double          8               12            0    0\n",
       " 2               MORTDUE         3   double          8               12            0    0\n",
       " 3                 VALUE         4   double          8               12            0    0\n",
       " 4                REASON         5  varchar          7                7            0    0\n",
       " 5                   JOB         6  varchar          7                7            0    0\n",
       " 6                   YOJ         7   double          8               12            0    0\n",
       " 7                 DEROG         8   double          8               12            0    0\n",
       " 8                DELINQ         9   double          8               12            0    0\n",
       " 9                 CLAGE        10   double          8               12            0    0\n",
       " 10                 NINQ        11   double          8               12            0    0\n",
       " 11                 CLNO        12   double          8               12            0    0\n",
       " 12              DEBTINC        13   double          8               12            0    0\n",
       " 13              APPDATE        14   double          8               12  MMDDYY   10    0\n",
       " 14                 CITY        15  varchar         19               19            0    0\n",
       " 15                STATE        16  varchar         20               20            0    0\n",
       " 16             DIVISION        17  varchar         18               18            0    0\n",
       " 17               REGION        18  varchar          9                9            0    0\n",
       " 18            IMP_CLAGE        19   double          8               12            0    0\n",
       " 19             IMP_CLNO        20   double          8               12            0    0\n",
       " 20          IMP_DEBTINC        21   double          8               12            0    0\n",
       " 21           IMP_DELINQ        22   double          8               12            0    0\n",
       " 22            IMP_DEROG        23   double          8               12            0    0\n",
       " 23          IMP_MORTDUE        24   double          8               12            0    0\n",
       " 24             IMP_NINQ        25   double          8               12            0    0\n",
       " 25            IMP_VALUE        26   double          8               12            0    0\n",
       " 26              IMP_YOJ        27   double          8               12            0    0\n",
       " 27             IMP_CITY        28  varchar         19               19            0    0\n",
       " 28              IMP_JOB        29  varchar          7                7            0    0\n",
       " 29           IMP_REASON        30  varchar          7                7            0    0\n",
       " 30                 YEAR        31   double          8               12            0    0\n",
       " 31                  QTR        32   double          8               12            0    0\n",
       " 32  DATE_SINCE_LAST_APP        33   double          8               12            0    0\n",
       "\n",
       "+ Elapsed: 0.000535s, user: 0.000343s, sys: 0.000171s, mem: 0.83mb"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Home_Equity.table.columnInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><caption>Selected Rows from Table HOME_EQUITY_FINAL</caption>\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"BAD\">BAD</th>\n",
       "      <th title=\"LOAN\">LOAN</th>\n",
       "      <th title=\"MORTDUE\">MORTDUE</th>\n",
       "      <th title=\"VALUE\">VALUE</th>\n",
       "      <th title=\"REASON\">REASON</th>\n",
       "      <th title=\"JOB\">JOB</th>\n",
       "      <th title=\"YOJ\">YOJ</th>\n",
       "      <th title=\"DEROG\">DEROG</th>\n",
       "      <th title=\"DELINQ\">DELINQ</th>\n",
       "      <th title=\"CLAGE\">CLAGE</th>\n",
       "      <th title=\"IMP_MORTDUE\">IMP_MORTDUE</th>\n",
       "      <th title=\"IMP_NINQ\">IMP_NINQ</th>\n",
       "      <th title=\"IMP_VALUE\">IMP_VALUE</th>\n",
       "      <th title=\"IMP_YOJ\">IMP_YOJ</th>\n",
       "      <th title=\"IMP_CITY\">IMP_CITY</th>\n",
       "      <th title=\"IMP_JOB\">IMP_JOB</th>\n",
       "      <th title=\"IMP_REASON\">IMP_REASON</th>\n",
       "      <th title=\"YEAR\">YEAR</th>\n",
       "      <th title=\"QTR\">QTR</th>\n",
       "      <th title=\"DATE_SINCE_LAST_APP\">DATE_SINCE_LAST_APP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>25860.0</td>\n",
       "      <td>39025.0</td>\n",
       "      <td>HOMEIMP</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>10.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>25860.0000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>39025.000000</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>HOMEIMP</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1105.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>70053.0</td>\n",
       "      <td>68400.0</td>\n",
       "      <td>HOMEIMP</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>70053.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>68400.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>Churchton</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>HOMEIMP</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>916.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>13500.0</td>\n",
       "      <td>16700.0</td>\n",
       "      <td>HOMEIMP</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>13500.0000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16700.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>Orcas</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>HOMEIMP</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1749.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73760.8172</td>\n",
       "      <td>1.186055</td>\n",
       "      <td>101776.048741</td>\n",
       "      <td>8.922268</td>\n",
       "      <td>Hastings</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>DEBTCON</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>932.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>97800.0</td>\n",
       "      <td>112000.0</td>\n",
       "      <td>HOMEIMP</td>\n",
       "      <td>OFFICE</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>97800.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>112000.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>Wilmington</td>\n",
       "      <td>OFFICE</td>\n",
       "      <td>HOMEIMP</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>816.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Selected Rows from Table HOME_EQUITY_FINAL\n",
       "\n",
       "   BAD    LOAN  MORTDUE     VALUE   REASON     JOB   YOJ  DEROG  DELINQ  CLAGE  NINQ  CLNO  DEBTINC     APPDATE        CITY       STATE            DIVISION   REGION   IMP_CLAGE   IMP_CLNO  IMP_DEBTINC  IMP_DELINQ  IMP_DEROG  IMP_MORTDUE  IMP_NINQ      IMP_VALUE    IMP_YOJ    IMP_CITY IMP_JOB IMP_REASON    YEAR  QTR  DATE_SINCE_LAST_APP\n",
       "0  1.0  1100.0  25860.0   39025.0  HOMEIMP   OTHER  10.5    0.0     0.0   94.0   1.0   9.0      NaN  2020-05-05      Oregon   Wisconsin  East North Central  Midwest   94.000000   9.000000    33.779915    0.000000    0.00000   25860.0000  1.000000   39025.000000  10.500000      Oregon   OTHER    HOMEIMP  2020.0  2.0               1105.0\n",
       "1  1.0  1300.0  70053.0   68400.0  HOMEIMP   OTHER   7.0    0.0     2.0  122.0   0.0  14.0      NaN  2020-11-10   Churchton    Maryland      South Atlantic    South  122.000000  14.000000    33.779915    2.000000    0.00000   70053.0000  0.000000   68400.000000   7.000000   Churchton   OTHER    HOMEIMP  2020.0  4.0                916.0\n",
       "2  1.0  1500.0  13500.0   16700.0  HOMEIMP   OTHER   4.0    0.0     0.0  149.0   1.0  10.0      NaN  2018-07-31       Orcas  Washington             Pacific     West  149.000000  10.000000    33.779915    0.000000    0.00000   13500.0000  1.000000   16700.000000   4.000000       Orcas   OTHER    HOMEIMP  2018.0  3.0               1749.0\n",
       "3  1.0  1500.0      NaN       NaN                    NaN    NaN     NaN    NaN   NaN   NaN      NaN  2020-10-25    Hastings     Florida      South Atlantic    South  179.771762  21.296096    33.779915    0.449442    0.25457   73760.8172  1.186055  101776.048741   8.922268    Hastings   OTHER    DEBTCON  2020.0  4.0                932.0\n",
       "4  0.0  1700.0  97800.0  112000.0  HOMEIMP  OFFICE   3.0    0.0     0.0   93.0   0.0  14.0      NaN  2021-02-18  Wilmington  California             Pacific     West   93.000000  14.000000    33.779915    0.000000    0.00000   97800.0000  0.000000  112000.000000   3.000000  Wilmington  OFFICE    HOMEIMP  2021.0  1.0                816.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Home_Equity.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for missing look at descriptive statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"cas-results-key\"><b>&#167; Summary</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><caption>Descriptive Statistics for HOME_EQUITY_FINAL</caption>\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"Analysis Variable\">Column</th>\n",
       "      <th title=\"Minimum\">Min</th>\n",
       "      <th title=\"Maximum\">Max</th>\n",
       "      <th title=\"N\">N</th>\n",
       "      <th title=\"N Miss\">NMiss</th>\n",
       "      <th title=\"Mean\">Mean</th>\n",
       "      <th title=\"Sum\">Sum</th>\n",
       "      <th title=\"Std Dev\">Std</th>\n",
       "      <th title=\"Std Error\">StdErr</th>\n",
       "      <th title=\"Variance\">Var</th>\n",
       "      <th title=\"USS\">USS</th>\n",
       "      <th title=\"Corrected SS\">CSS</th>\n",
       "      <th title=\"Coeff of Variation\">CV</th>\n",
       "      <th title=\"t Value\">TValue</th>\n",
       "      <th title=\"Pr &gt; |t|\">ProbT</th>\n",
       "      <th title=\"Skewness\">Skewness</th>\n",
       "      <th title=\"Kurtosis\">Kurtosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>BAD</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5960.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.199497</td>\n",
       "      <td>1.189000e+03</td>\n",
       "      <td>0.399656</td>\n",
       "      <td>0.005177</td>\n",
       "      <td>1.597245e-01</td>\n",
       "      <td>1.189000e+03</td>\n",
       "      <td>9.517985e+02</td>\n",
       "      <td>200.331950</td>\n",
       "      <td>38.536557</td>\n",
       "      <td>2.720203e-290</td>\n",
       "      <td>1.504317</td>\n",
       "      <td>0.263057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>LOAN</td>\n",
       "      <td>1100.000000</td>\n",
       "      <td>89900.000000</td>\n",
       "      <td>5960.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18607.969799</td>\n",
       "      <td>1.109035e+08</td>\n",
       "      <td>11207.480417</td>\n",
       "      <td>145.172668</td>\n",
       "      <td>1.256076e+08</td>\n",
       "      <td>2.812185e+12</td>\n",
       "      <td>7.484958e+11</td>\n",
       "      <td>60.229464</td>\n",
       "      <td>128.178190</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.023781</td>\n",
       "      <td>6.932590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>MORTDUE</td>\n",
       "      <td>2063.000000</td>\n",
       "      <td>399550.000000</td>\n",
       "      <td>5442.0</td>\n",
       "      <td>518.0</td>\n",
       "      <td>73760.817200</td>\n",
       "      <td>4.014064e+08</td>\n",
       "      <td>44457.609458</td>\n",
       "      <td>602.652327</td>\n",
       "      <td>1.976479e+09</td>\n",
       "      <td>4.036208e+13</td>\n",
       "      <td>1.075402e+13</td>\n",
       "      <td>60.272664</td>\n",
       "      <td>122.393649</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.814481</td>\n",
       "      <td>6.481866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>VALUE</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>855909.000000</td>\n",
       "      <td>5848.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>101776.048741</td>\n",
       "      <td>5.951863e+08</td>\n",
       "      <td>57385.775334</td>\n",
       "      <td>750.413385</td>\n",
       "      <td>3.293127e+09</td>\n",
       "      <td>7.983063e+13</td>\n",
       "      <td>1.925491e+13</td>\n",
       "      <td>56.384362</td>\n",
       "      <td>135.626644</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.053344</td>\n",
       "      <td>24.362805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>YOJ</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>5445.0</td>\n",
       "      <td>515.0</td>\n",
       "      <td>8.922268</td>\n",
       "      <td>4.858175e+04</td>\n",
       "      <td>7.573982</td>\n",
       "      <td>0.102642</td>\n",
       "      <td>5.736521e+01</td>\n",
       "      <td>7.457556e+05</td>\n",
       "      <td>3.122962e+05</td>\n",
       "      <td>84.888530</td>\n",
       "      <td>86.926047</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.988460</td>\n",
       "      <td>0.372072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>DEROG</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5252.0</td>\n",
       "      <td>708.0</td>\n",
       "      <td>0.254570</td>\n",
       "      <td>1.337000e+03</td>\n",
       "      <td>0.846047</td>\n",
       "      <td>0.011674</td>\n",
       "      <td>7.157951e-01</td>\n",
       "      <td>4.099000e+03</td>\n",
       "      <td>3.758640e+03</td>\n",
       "      <td>332.343880</td>\n",
       "      <td>21.805933</td>\n",
       "      <td>5.478603e-101</td>\n",
       "      <td>5.320870</td>\n",
       "      <td>36.872763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>DELINQ</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>5380.0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>0.449442</td>\n",
       "      <td>2.418000e+03</td>\n",
       "      <td>1.127266</td>\n",
       "      <td>0.015369</td>\n",
       "      <td>1.270728e+00</td>\n",
       "      <td>7.922000e+03</td>\n",
       "      <td>6.835248e+03</td>\n",
       "      <td>250.814336</td>\n",
       "      <td>29.244135</td>\n",
       "      <td>1.326786e-174</td>\n",
       "      <td>4.023150</td>\n",
       "      <td>23.565449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>CLAGE</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1168.000000</td>\n",
       "      <td>5652.0</td>\n",
       "      <td>308.0</td>\n",
       "      <td>179.771762</td>\n",
       "      <td>1.016070e+06</td>\n",
       "      <td>85.809396</td>\n",
       "      <td>1.141389</td>\n",
       "      <td>7.363252e+03</td>\n",
       "      <td>2.242704e+08</td>\n",
       "      <td>4.160974e+07</td>\n",
       "      <td>47.732411</td>\n",
       "      <td>157.502593</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.343188</td>\n",
       "      <td>7.599865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>NINQ</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>5450.0</td>\n",
       "      <td>510.0</td>\n",
       "      <td>1.186055</td>\n",
       "      <td>6.464000e+03</td>\n",
       "      <td>1.728675</td>\n",
       "      <td>0.023416</td>\n",
       "      <td>2.988317e+00</td>\n",
       "      <td>2.395000e+04</td>\n",
       "      <td>1.628334e+04</td>\n",
       "      <td>145.749978</td>\n",
       "      <td>50.651202</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.621984</td>\n",
       "      <td>9.786507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>CLNO</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>5738.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>21.296096</td>\n",
       "      <td>1.221970e+05</td>\n",
       "      <td>10.138933</td>\n",
       "      <td>0.133848</td>\n",
       "      <td>1.027980e+02</td>\n",
       "      <td>3.192071e+06</td>\n",
       "      <td>5.897519e+05</td>\n",
       "      <td>47.609351</td>\n",
       "      <td>159.106532</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.775052</td>\n",
       "      <td>1.157673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>DEBTINC</td>\n",
       "      <td>0.524499</td>\n",
       "      <td>203.312149</td>\n",
       "      <td>4693.0</td>\n",
       "      <td>1267.0</td>\n",
       "      <td>33.779915</td>\n",
       "      <td>1.585291e+05</td>\n",
       "      <td>8.601746</td>\n",
       "      <td>0.125563</td>\n",
       "      <td>7.399004e+01</td>\n",
       "      <td>5.702262e+06</td>\n",
       "      <td>3.471613e+05</td>\n",
       "      <td>25.464084</td>\n",
       "      <td>269.027831</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.852353</td>\n",
       "      <td>50.504042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>APPDATE</td>\n",
       "      <td>20820.000000</td>\n",
       "      <td>22645.000000</td>\n",
       "      <td>5960.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21657.131208</td>\n",
       "      <td>1.290765e+08</td>\n",
       "      <td>519.756837</td>\n",
       "      <td>6.732511</td>\n",
       "      <td>2.701472e+05</td>\n",
       "      <td>2.797037e+12</td>\n",
       "      <td>1.609807e+09</td>\n",
       "      <td>2.399934</td>\n",
       "      <td>3216.798420</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.164909</td>\n",
       "      <td>-1.143734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>IMP_CLAGE</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1168.000000</td>\n",
       "      <td>5960.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>179.771762</td>\n",
       "      <td>1.071440e+06</td>\n",
       "      <td>83.562381</td>\n",
       "      <td>1.082400</td>\n",
       "      <td>6.982672e+03</td>\n",
       "      <td>2.342243e+08</td>\n",
       "      <td>4.160974e+07</td>\n",
       "      <td>46.482484</td>\n",
       "      <td>166.086296</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.379282</td>\n",
       "      <td>8.177152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>IMP_CLNO</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>5960.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.296096</td>\n",
       "      <td>1.269247e+05</td>\n",
       "      <td>9.948280</td>\n",
       "      <td>0.128862</td>\n",
       "      <td>9.896827e+01</td>\n",
       "      <td>3.292753e+06</td>\n",
       "      <td>5.897519e+05</td>\n",
       "      <td>46.714101</td>\n",
       "      <td>165.262811</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.789895</td>\n",
       "      <td>1.318510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>IMP_DEBTINC</td>\n",
       "      <td>0.524499</td>\n",
       "      <td>203.312149</td>\n",
       "      <td>5960.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.779915</td>\n",
       "      <td>2.013283e+05</td>\n",
       "      <td>7.632713</td>\n",
       "      <td>0.098868</td>\n",
       "      <td>5.825831e+01</td>\n",
       "      <td>7.148014e+06</td>\n",
       "      <td>3.471613e+05</td>\n",
       "      <td>22.595418</td>\n",
       "      <td>341.666780</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.214191</td>\n",
       "      <td>64.934410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>IMP_DELINQ</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>5960.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.449442</td>\n",
       "      <td>2.678677e+03</td>\n",
       "      <td>1.071002</td>\n",
       "      <td>0.013873</td>\n",
       "      <td>1.147046e+00</td>\n",
       "      <td>8.039159e+03</td>\n",
       "      <td>6.835248e+03</td>\n",
       "      <td>238.295826</td>\n",
       "      <td>32.397142</td>\n",
       "      <td>3.173991e-212</td>\n",
       "      <td>4.234346</td>\n",
       "      <td>26.427063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>IMP_DEROG</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5960.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.254570</td>\n",
       "      <td>1.517235e+03</td>\n",
       "      <td>0.794198</td>\n",
       "      <td>0.010287</td>\n",
       "      <td>6.307502e-01</td>\n",
       "      <td>4.144882e+03</td>\n",
       "      <td>3.758640e+03</td>\n",
       "      <td>311.976587</td>\n",
       "      <td>24.745779</td>\n",
       "      <td>9.025600e-129</td>\n",
       "      <td>5.667985</td>\n",
       "      <td>42.243159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>IMP_MORTDUE</td>\n",
       "      <td>2063.000000</td>\n",
       "      <td>399550.000000</td>\n",
       "      <td>5960.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73760.817200</td>\n",
       "      <td>4.396145e+08</td>\n",
       "      <td>42481.395689</td>\n",
       "      <td>550.269760</td>\n",
       "      <td>1.804669e+09</td>\n",
       "      <td>4.318035e+13</td>\n",
       "      <td>1.075402e+13</td>\n",
       "      <td>57.593445</td>\n",
       "      <td>134.044831</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.898829</td>\n",
       "      <td>7.383875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>IMP_NINQ</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>5960.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.186055</td>\n",
       "      <td>7.068888e+03</td>\n",
       "      <td>1.653046</td>\n",
       "      <td>0.021412</td>\n",
       "      <td>2.732563e+00</td>\n",
       "      <td>2.466743e+04</td>\n",
       "      <td>1.628334e+04</td>\n",
       "      <td>139.373501</td>\n",
       "      <td>55.391474</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.741856</td>\n",
       "      <td>10.982241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>IMP_VALUE</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>855909.000000</td>\n",
       "      <td>5960.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101776.048741</td>\n",
       "      <td>6.065853e+08</td>\n",
       "      <td>56843.931566</td>\n",
       "      <td>736.310474</td>\n",
       "      <td>3.231233e+09</td>\n",
       "      <td>8.099076e+13</td>\n",
       "      <td>1.925491e+13</td>\n",
       "      <td>55.851973</td>\n",
       "      <td>138.224366</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.082429</td>\n",
       "      <td>24.886463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>IMP_YOJ</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>5960.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.922268</td>\n",
       "      <td>5.317672e+04</td>\n",
       "      <td>7.239301</td>\n",
       "      <td>0.093772</td>\n",
       "      <td>5.240748e+01</td>\n",
       "      <td>7.867531e+05</td>\n",
       "      <td>3.122962e+05</td>\n",
       "      <td>81.137454</td>\n",
       "      <td>95.148457</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.034125</td>\n",
       "      <td>0.691017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>YEAR</td>\n",
       "      <td>2017.000000</td>\n",
       "      <td>2021.000000</td>\n",
       "      <td>5960.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018.804195</td>\n",
       "      <td>1.203207e+07</td>\n",
       "      <td>1.394767</td>\n",
       "      <td>0.018067</td>\n",
       "      <td>1.945376e+00</td>\n",
       "      <td>2.429041e+10</td>\n",
       "      <td>1.159250e+04</td>\n",
       "      <td>0.069089</td>\n",
       "      <td>111741.773481</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.174429</td>\n",
       "      <td>-1.242641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>QTR</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5960.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.469799</td>\n",
       "      <td>1.472000e+04</td>\n",
       "      <td>1.117720</td>\n",
       "      <td>0.014478</td>\n",
       "      <td>1.249297e+00</td>\n",
       "      <td>4.380000e+04</td>\n",
       "      <td>7.444564e+03</td>\n",
       "      <td>45.255502</td>\n",
       "      <td>170.589284</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.036748</td>\n",
       "      <td>-1.358147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>DATE_SINCE_LAST_APP</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>2325.000000</td>\n",
       "      <td>5960.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1487.868792</td>\n",
       "      <td>8.867698e+06</td>\n",
       "      <td>519.756837</td>\n",
       "      <td>6.732511</td>\n",
       "      <td>2.701472e+05</td>\n",
       "      <td>1.480378e+10</td>\n",
       "      <td>1.609807e+09</td>\n",
       "      <td>34.932975</td>\n",
       "      <td>220.997598</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.164909</td>\n",
       "      <td>-1.143734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-output-area\"></div>\n",
       "<p class=\"cas-results-performance\"><small><span class=\"cas-elapsed\">elapsed 0.0046s</span> &#183; <span class=\"cas-user\">user 0.00881s</span> &#183; <span class=\"cas-memory\">mem 4.53MB</span></small></p>"
      ],
      "text/plain": [
       "[Summary]\n",
       "\n",
       " Descriptive Statistics for HOME_EQUITY_FINAL\n",
       " \n",
       "                  Column           Min            Max       N   NMiss           Mean           Sum           Std      StdErr           Var           USS           CSS          CV         TValue          ProbT  Skewness   Kurtosis\n",
       " 0                   BAD      0.000000       1.000000  5960.0     0.0       0.199497  1.189000e+03      0.399656    0.005177  1.597245e-01  1.189000e+03  9.517985e+02  200.331950      38.536557  2.720203e-290  1.504317   0.263057\n",
       " 1                  LOAN   1100.000000   89900.000000  5960.0     0.0   18607.969799  1.109035e+08  11207.480417  145.172668  1.256076e+08  2.812185e+12  7.484958e+11   60.229464     128.178190   0.000000e+00  2.023781   6.932590\n",
       " 2               MORTDUE   2063.000000  399550.000000  5442.0   518.0   73760.817200  4.014064e+08  44457.609458  602.652327  1.976479e+09  4.036208e+13  1.075402e+13   60.272664     122.393649   0.000000e+00  1.814481   6.481866\n",
       " 3                 VALUE   8000.000000  855909.000000  5848.0   112.0  101776.048741  5.951863e+08  57385.775334  750.413385  3.293127e+09  7.983063e+13  1.925491e+13   56.384362     135.626644   0.000000e+00  3.053344  24.362805\n",
       " 4                   YOJ      0.000000      41.000000  5445.0   515.0       8.922268  4.858175e+04      7.573982    0.102642  5.736521e+01  7.457556e+05  3.122962e+05   84.888530      86.926047   0.000000e+00  0.988460   0.372072\n",
       " 5                 DEROG      0.000000      10.000000  5252.0   708.0       0.254570  1.337000e+03      0.846047    0.011674  7.157951e-01  4.099000e+03  3.758640e+03  332.343880      21.805933  5.478603e-101  5.320870  36.872763\n",
       " 6                DELINQ      0.000000      15.000000  5380.0   580.0       0.449442  2.418000e+03      1.127266    0.015369  1.270728e+00  7.922000e+03  6.835248e+03  250.814336      29.244135  1.326786e-174  4.023150  23.565449\n",
       " 7                 CLAGE      0.000000    1168.000000  5652.0   308.0     179.771762  1.016070e+06     85.809396    1.141389  7.363252e+03  2.242704e+08  4.160974e+07   47.732411     157.502593   0.000000e+00  1.343188   7.599865\n",
       " 8                  NINQ      0.000000      17.000000  5450.0   510.0       1.186055  6.464000e+03      1.728675    0.023416  2.988317e+00  2.395000e+04  1.628334e+04  145.749978      50.651202   0.000000e+00  2.621984   9.786507\n",
       " 9                  CLNO      0.000000      71.000000  5738.0   222.0      21.296096  1.221970e+05     10.138933    0.133848  1.027980e+02  3.192071e+06  5.897519e+05   47.609351     159.106532   0.000000e+00  0.775052   1.157673\n",
       " 10              DEBTINC      0.524499     203.312149  4693.0  1267.0      33.779915  1.585291e+05      8.601746    0.125563  7.399004e+01  5.702262e+06  3.471613e+05   25.464084     269.027831   0.000000e+00  2.852353  50.504042\n",
       " 11              APPDATE  20820.000000   22645.000000  5960.0     0.0   21657.131208  1.290765e+08    519.756837    6.732511  2.701472e+05  2.797037e+12  1.609807e+09    2.399934    3216.798420   0.000000e+00  0.164909  -1.143734\n",
       " 12            IMP_CLAGE      0.000000    1168.000000  5960.0     0.0     179.771762  1.071440e+06     83.562381    1.082400  6.982672e+03  2.342243e+08  4.160974e+07   46.482484     166.086296   0.000000e+00  1.379282   8.177152\n",
       " 13             IMP_CLNO      0.000000      71.000000  5960.0     0.0      21.296096  1.269247e+05      9.948280    0.128862  9.896827e+01  3.292753e+06  5.897519e+05   46.714101     165.262811   0.000000e+00  0.789895   1.318510\n",
       " 14          IMP_DEBTINC      0.524499     203.312149  5960.0     0.0      33.779915  2.013283e+05      7.632713    0.098868  5.825831e+01  7.148014e+06  3.471613e+05   22.595418     341.666780   0.000000e+00  3.214191  64.934410\n",
       " 15           IMP_DELINQ      0.000000      15.000000  5960.0     0.0       0.449442  2.678677e+03      1.071002    0.013873  1.147046e+00  8.039159e+03  6.835248e+03  238.295826      32.397142  3.173991e-212  4.234346  26.427063\n",
       " 16            IMP_DEROG      0.000000      10.000000  5960.0     0.0       0.254570  1.517235e+03      0.794198    0.010287  6.307502e-01  4.144882e+03  3.758640e+03  311.976587      24.745779  9.025600e-129  5.667985  42.243159\n",
       " 17          IMP_MORTDUE   2063.000000  399550.000000  5960.0     0.0   73760.817200  4.396145e+08  42481.395689  550.269760  1.804669e+09  4.318035e+13  1.075402e+13   57.593445     134.044831   0.000000e+00  1.898829   7.383875\n",
       " 18             IMP_NINQ      0.000000      17.000000  5960.0     0.0       1.186055  7.068888e+03      1.653046    0.021412  2.732563e+00  2.466743e+04  1.628334e+04  139.373501      55.391474   0.000000e+00  2.741856  10.982241\n",
       " 19            IMP_VALUE   8000.000000  855909.000000  5960.0     0.0  101776.048741  6.065853e+08  56843.931566  736.310474  3.231233e+09  8.099076e+13  1.925491e+13   55.851973     138.224366   0.000000e+00  3.082429  24.886463\n",
       " 20              IMP_YOJ      0.000000      41.000000  5960.0     0.0       8.922268  5.317672e+04      7.239301    0.093772  5.240748e+01  7.867531e+05  3.122962e+05   81.137454      95.148457   0.000000e+00  1.034125   0.691017\n",
       " 21                 YEAR   2017.000000    2021.000000  5960.0     0.0    2018.804195  1.203207e+07      1.394767    0.018067  1.945376e+00  2.429041e+10  1.159250e+04    0.069089  111741.773481   0.000000e+00  0.174429  -1.242641\n",
       " 22                  QTR      1.000000       4.000000  5960.0     0.0       2.469799  1.472000e+04      1.117720    0.014478  1.249297e+00  4.380000e+04  7.444564e+03   45.255502     170.589284   0.000000e+00  0.036748  -1.358147\n",
       " 23  DATE_SINCE_LAST_APP    500.000000    2325.000000  5960.0     0.0    1487.868792  8.867698e+06    519.756837    6.732511  2.701472e+05  1.480378e+10  1.609807e+09   34.932975     220.997598   0.000000e+00 -0.164909  -1.143734\n",
       "\n",
       "+ Elapsed: 0.0046s, user: 0.00881s, mem: 4.53mb"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Home_Equity.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 25 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use the built in hist() method to plot the distribution of every variable\n",
    "# Hist method using a random sample of 10,000 rows by default. Options are available for sampling method and sample size.\n",
    "Home_Equity.hist(figsize = (20, 20));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Variable Shortcuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set variables for later use by models\n",
    "## For models that can handle missing values\n",
    "target              = \"BAD\"\n",
    "class_inputs        = [\"REASON\", \"JOB\", \"REGION\"]\n",
    "interval_inputs     = [\"CLAGE\", \"CLNO\", \"DEBTINC\", \"LOAN\", \"MORTDUE\", \"VALUE\", \"YOJ\", \"NINQ\", \"DEROG\", \"DELINQ\", \"DATE_SINCE_LAST_APP\"]\n",
    "class_vars          = [target] + class_inputs\n",
    "all_inputs          = interval_inputs + class_inputs\n",
    "\n",
    "## For models that can't handle missing values\n",
    "imp_class_inputs    = [\"IMP_REASON\",\"IMP_JOB\", \"REGION\"]\n",
    "imp_interval_inputs = [\"IMP_CLAGE\", \"IMP_CLNO\", \"IMP_DEBTINC\", \"LOAN\", \"IMP_MORTDUE\", \"IMP_VALUE\", \"IMP_YOJ\", \"IMP_NINQ\", \"IMP_DEROG\", \"IMP_DELINQ\", \"DATE_SINCE_LAST_APP\"]\n",
    "imp_class_vars      = [target] + imp_class_inputs\n",
    "imp_all_inputs      = imp_interval_inputs + imp_class_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partition data into training and validation data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: Stratified sampling is in effect.\n",
      "NOTE: Using SEED=1234 for sampling.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"cas-results-key\"><b>&#167; OutputCasTables</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"CAS Library\">casLib</th>\n",
       "      <th title=\"Name\">Name</th>\n",
       "      <th title=\"Label\">Label</th>\n",
       "      <th title=\"Number of Rows\">Rows</th>\n",
       "      <th title=\"Number of Columns\">Columns</th>\n",
       "      <th title=\"Table\">casTable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>CASUSER(sasdemo)</td>\n",
       "      <td>Home_Equity_p</td>\n",
       "      <td></td>\n",
       "      <td>5960</td>\n",
       "      <td>34</td>\n",
       "      <td>CASTable('Home_Equity_p', caslib='CASUSER(sasd...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-results-key\"><hr/><b>&#167; STRAFreq</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><caption>Frequencies</caption>\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"Index\">ByGrpID</th>\n",
       "      <th title=\"BAD\">BAD</th>\n",
       "      <th title=\"Number of Obs\">NObs</th>\n",
       "      <th title=\"Number of Samples\">NSamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4771</td>\n",
       "      <td>3340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1189</td>\n",
       "      <td>832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-output-area\"></div>\n",
       "<p class=\"cas-results-performance\"><small><span class=\"cas-elapsed\">elapsed 0.195s</span> &#183; <span class=\"cas-user\">user 0.197s</span> &#183; <span class=\"cas-sys\">sys 0.0153s</span> &#183; <span class=\"cas-memory\">mem 91.1MB</span></small></p>"
      ],
      "text/plain": [
       "[OutputCasTables]\n",
       "\n",
       "              casLib           Name Label  Rows  Columns                                           casTable\n",
       " 0  CASUSER(sasdemo)  Home_Equity_p        5960       34  CASTable('Home_Equity_p', caslib='CASUSER(sasd...\n",
       "\n",
       "[STRAFreq]\n",
       "\n",
       " Frequencies\n",
       " \n",
       "    ByGrpID           BAD  NObs  NSamp\n",
       " 0        0             0  4771   3340\n",
       " 1        1             1  1189    832\n",
       "\n",
       "+ Elapsed: 0.195s, user: 0.197s, sys: 0.0153s, mem: 91.1mb"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create training data set to be 70% of the data and validation 30%\n",
    "conn.sampling.stratified(\n",
    "  table={\"name\":\"Home_Equity_final\", \"groupBy\":target},\n",
    "  output={\"casOut\":{\"name\":\"Home_Equity_p\", \"replace\":True}, \"copyVars\":\"ALL\"},\n",
    "  samppct=70,\n",
    "  seed=1234,\n",
    "  partind=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Home_Equity_p = conn.CASTable(\"Home_Equity_p\", caslib=\"CASUSER\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run a Decision Tree & Gradient Boosting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: Character values have been converted to numeric values at the places given by: (Line):(Column).\n",
      "      0:79    0:176\n",
      "NOTE: Duplicate messages output by DATA step:\n",
      "NOTE: Character values have been converted to numeric values at the places given by: (Line):(Column).  (occurred 32 times)\n",
      "      0:79    0:176  (occurred 32 times)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"cas-results-key\"><b>&#167; InputCasTables</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"CAS Library\">casLib</th>\n",
       "      <th title=\"Name\">Name</th>\n",
       "      <th title=\"Number of Rows\">Rows</th>\n",
       "      <th title=\"Number of Columns\">Columns</th>\n",
       "      <th title=\"Table\">casTable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>CASUSER(sasdemo)</td>\n",
       "      <td>_scored_tree</td>\n",
       "      <td>5960</td>\n",
       "      <td>14</td>\n",
       "      <td>CASTable('_scored_tree', caslib='CASUSER(sasde...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-results-key\"><hr/><b>&#167; OutputCasTables</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"CAS Library\">casLib</th>\n",
       "      <th title=\"Name\">Name</th>\n",
       "      <th title=\"Number of Rows\">Rows</th>\n",
       "      <th title=\"Number of Columns\">Columns</th>\n",
       "      <th title=\"Number of Rows Appended\">Append</th>\n",
       "      <th title=\"Promoted\">Promoted</th>\n",
       "      <th title=\"Table\">casTable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>CASUSER(sasdemo)</td>\n",
       "      <td>_scored_tree</td>\n",
       "      <td>5960</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>CASTable('_scored_tree', caslib='CASUSER(sasde...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-output-area\"></div>\n",
       "<p class=\"cas-results-performance\"><small><span class=\"cas-elapsed\">elapsed 0.0152s</span> &#183; <span class=\"cas-user\">user 0.028s</span> &#183; <span class=\"cas-sys\">sys 0.0333s</span> &#183; <span class=\"cas-memory\">mem 21.2MB</span></small></p>"
      ],
      "text/plain": [
       "[InputCasTables]\n",
       "\n",
       "              casLib          Name  Rows  Columns                                           casTable\n",
       " 0  CASUSER(sasdemo)  _scored_tree  5960       14  CASTable('_scored_tree', caslib='CASUSER(sasde...\n",
       "\n",
       "[OutputCasTables]\n",
       "\n",
       "              casLib          Name  Rows  Columns  Append Promoted                                           casTable\n",
       " 0  CASUSER(sasdemo)  _scored_tree  5960       16     NaN        N  CASTable('_scored_tree', caslib='CASUSER(sasde...\n",
       "\n",
       "+ Elapsed: 0.0152s, user: 0.028s, sys: 0.0333s, mem: 21.2mb"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Decision Tree\n",
    "conn.decisionTree.dtreeTrain(\n",
    "  table={\n",
    "    \"name\":\"Home_Equity_p\",\n",
    "    \"where\":\"strip(put(_partind_, best.))='1'\"\n",
    "  },\n",
    "  inputs=all_inputs,\n",
    "  target=\"bad\",\n",
    "  nominals=class_vars,\n",
    "  crit=\"GAIN\",\n",
    "  prune=True,\n",
    "  varImp=True,\n",
    "  missing=\"USEINSEARCH\",\n",
    "  casOut={\"name\":\"tree_model\", \"replace\":True}\n",
    ")\n",
    "\n",
    "# Score \n",
    "conn.decisionTree.dtreeScore(\n",
    "  table={\"name\":\"Home_Equity_p\"},\n",
    "  modelTable={\"name\":\"tree_model\"},\n",
    "  casOut={\"name\":\"_scored_tree\", \"replace\":True},\n",
    "  copyVars={\"bad\", \"_partind_\"}\n",
    ")\n",
    "\n",
    "# Create p_bad0 and p_bad1 as _dt_predp_ is the probability of event in _dt_predname_\n",
    "conn.dataStep.runCode(code = \"\"\"\n",
    "data _scored_tree; \n",
    "    length p_bad1 p_bad0 8.;\n",
    "    set _scored_tree; \n",
    "    if _dt_predname_=1 then do; \n",
    "        p_bad1=_dt_predp_; \n",
    "        p_bad0=1-p_bad1; \n",
    "    end; \n",
    "    if _dt_predname_=0 then do; \n",
    "        p_bad0=_dt_predp_; \n",
    "        p_bad1=1-p_bad0; \n",
    "    end; \n",
    "run;\n",
    "\"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: Character values have been converted to numeric values at the places given by: (Line):(Column).\n",
      "      0:45    0:136\n",
      "NOTE: Duplicate messages output by DATA step:\n",
      "NOTE: Character values have been converted to numeric values at the places given by: (Line):(Column).  (occurred 32 times)\n",
      "      0:45    0:136  (occurred 32 times)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"cas-results-key\"><b>&#167; InputCasTables</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"CAS Library\">casLib</th>\n",
       "      <th title=\"Name\">Name</th>\n",
       "      <th title=\"Number of Rows\">Rows</th>\n",
       "      <th title=\"Number of Columns\">Columns</th>\n",
       "      <th title=\"Table\">casTable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>CASUSER(sasdemo)</td>\n",
       "      <td>_scored_gb</td>\n",
       "      <td>5960</td>\n",
       "      <td>6</td>\n",
       "      <td>CASTable('_scored_gb', caslib='CASUSER(sasdemo)')</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-results-key\"><hr/><b>&#167; OutputCasTables</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"CAS Library\">casLib</th>\n",
       "      <th title=\"Name\">Name</th>\n",
       "      <th title=\"Number of Rows\">Rows</th>\n",
       "      <th title=\"Number of Columns\">Columns</th>\n",
       "      <th title=\"Number of Rows Appended\">Append</th>\n",
       "      <th title=\"Promoted\">Promoted</th>\n",
       "      <th title=\"Table\">casTable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>CASUSER(sasdemo)</td>\n",
       "      <td>_scored_gb</td>\n",
       "      <td>5960</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>CASTable('_scored_gb', caslib='CASUSER(sasdemo)')</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-output-area\"></div>\n",
       "<p class=\"cas-results-performance\"><small><span class=\"cas-elapsed\">elapsed 0.014s</span> &#183; <span class=\"cas-user\">user 0.0555s</span> &#183; <span class=\"cas-memory\">mem 22.2MB</span></small></p>"
      ],
      "text/plain": [
       "[InputCasTables]\n",
       "\n",
       "              casLib        Name  Rows  Columns                                           casTable\n",
       " 0  CASUSER(sasdemo)  _scored_gb  5960        6  CASTable('_scored_gb', caslib='CASUSER(sasdemo)')\n",
       "\n",
       "[OutputCasTables]\n",
       "\n",
       "              casLib        Name  Rows  Columns  Append Promoted                                           casTable\n",
       " 0  CASUSER(sasdemo)  _scored_gb  5960        8     NaN        N  CASTable('_scored_gb', caslib='CASUSER(sasdemo)')\n",
       "\n",
       "+ Elapsed: 0.014s, user: 0.0555s, mem: 22.2mb"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Gradient Boosting\n",
    "conn.decisionTree.gbtreeTrain(\n",
    "  table={\n",
    "    \"name\":\"Home_Equity_p\",\n",
    "    \"where\":\"strip(put(_partind_, best.))='1'\"\n",
    "  },\n",
    "  inputs=all_inputs,\n",
    "  nominals=class_vars,\n",
    "  target=target,\n",
    "  nTree=10,\n",
    "  nBins=20,\n",
    "  maxLevel=6,\n",
    "  varImp=True,\n",
    "  missing=\"USEINSEARCH\",\n",
    "  casOut={\"name\":\"gb_model\", \"replace\":True}\n",
    ")\n",
    "\n",
    "# Score \n",
    "conn.decisionTree.gbtreeScore(\n",
    "  table={\"name\":\"Home_Equity_p\"},\n",
    "  modelTable={\"name\":\"gb_model\"},\n",
    "  casOut={\"name\":\"_scored_gb\", \"replace\":True},\n",
    "  copyVars={ target, \"_partind_\"}\n",
    ")\n",
    "\n",
    "# Create p_bad0 and p_bad1 as _gbt_predp_ is the probability of event in _gbt_predname_\n",
    "conn.dataStep.runCode(\n",
    "  code=\"\"\"data _scored_gb; \n",
    "    set _scored_gb; \n",
    "    if _gbt_predname_=1 then do; \n",
    "    p_bad1=_gbt_predp_; \n",
    "    p_bad0=1-p_bad1; \n",
    "    end; \n",
    "    if _gbt_predname_=0 then do; \n",
    "    p_bad0=_gbt_predp_; \n",
    "    p_bad1=1-p_bad0; \n",
    "    end; \n",
    "    run;\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assess the Performance - CAS/Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access the two Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_model(prefix):\n",
    "    return conn.percentile.assess(\n",
    "      table={\n",
    "        \"name\":\"_scored_\" + prefix, \n",
    "        \"where\": \"strip(put(_partind_, best.))='0'\"\n",
    "      },\n",
    "      inputs=[{\"name\":\"p_bad1\"}],      \n",
    "      response=\"bad\",\n",
    "      event=\"1\",\n",
    "      pVar={\"p_bad0\"},\n",
    "      pEvent={\"0\"}      \n",
    "    )\n",
    "\n",
    "treeAssess=assess_model(prefix=\"tree\")    \n",
    "tree_fitstat =treeAssess.FitStat\n",
    "tree_rocinfo =treeAssess.ROCInfo\n",
    "tree_liftinfo=treeAssess.LIFTInfo\n",
    "\n",
    "gbAssess=assess_model(prefix=\"gb\")    \n",
    "gb_fitstat =gbAssess.FitStat\n",
    "gb_rocinfo =gbAssess.ROCInfo\n",
    "gb_liftinfo=gbAssess.LIFTInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new variable to indicate type of model\n",
    "tree_liftinfo[\"model\"]=\"DecisionTree\"\n",
    "tree_rocinfo[\"model\"]=\"DecisionTree\"\n",
    "gb_liftinfo[\"model\"]=\"GradientBoosting\"\n",
    "gb_rocinfo[\"model\"]=\"GradientBoosting\"\n",
    "\n",
    "# Append data\n",
    "all_liftinfo=gb_liftinfo.append(tree_liftinfo, ignore_index=True)\n",
    "all_rocinfo=gb_rocinfo.append(tree_rocinfo, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Confusion Matrix Information       \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><caption>ROC Information for _SCORED_GB</caption>\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"model\">model</th>\n",
       "      <th title=\"True Positive\">TP</th>\n",
       "      <th title=\"False Positive\">FP</th>\n",
       "      <th title=\"False Negative\">FN</th>\n",
       "      <th title=\"True Negative\">TN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>145.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>1412.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>241.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>1365.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "ROC Information for _SCORED_GB\n",
       "\n",
       "              model     TP    FP     FN      TN\n",
       "0  GradientBoosting  145.0  19.0  212.0  1412.0\n",
       "1      DecisionTree  241.0  66.0  116.0  1365.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display stacked confusion matrix using Python\n",
    "print('\\n', 'Confusion Matrix Information'.center(42, ' '))\n",
    "all_rocinfo[round(all_rocinfo['CutOff'], 2) == 0.5][['model', 'TP', 'FP', 'FN', 'TN']].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   Misclassification Rate Comparison  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><caption>ROC Information for _SCORED_GB</caption>\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"model\">model</th>\n",
       "      <th title=\"Misclassification\">Misclassification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.101790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>0.129195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "ROC Information for _SCORED_GB\n",
       "\n",
       "              model  Misclassification\n",
       "1      DecisionTree           0.101790\n",
       "0  GradientBoosting           0.129195"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_rocinfo['Misclassification'] = 1 - all_rocinfo['ACC']\n",
    "\n",
    "print('\\n', 'Misclassification Rate Comparison'.center(37, ' '))\n",
    "miss = all_rocinfo[round(all_rocinfo['CutOff'], 2) == 0.5][['model', 'Misclassification']].reset_index(drop = True)\n",
    "miss.sort_values('Misclassification')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draw ROC and lift plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------AUC (using validation data)---------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><caption>ROC Information for _SCORED_GB</caption>\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"model\">model</th>\n",
       "      <th title=\"Area Under ROC\">C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>0.920532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.883477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "ROC Information for _SCORED_GB\n",
       "\n",
       "                model         C\n",
       "0    GradientBoosting  0.920532\n",
       "100      DecisionTree  0.883477"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print Area under the ROC Curve\n",
    "print(\"AUC (using validation data)\".center(80, '-'))\n",
    "all_rocinfo[[\"model\", \"C\"]].drop_duplicates(keep=\"first\").sort_values(by=\"C\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create ROC and Lift plots (using validation data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAABQr0lEQVR4nO3dd3gUVdvA4d+TTjolCb3XRCQ0EQuCCGIFFVFEkPYiiliwYUOwFz4LVVEBeS34ioCoCCoQAUHpNRQBKaGm97JJzvfHTMISk7AJ2Wyye+7r2mvLnJ15JgvnmTlz5hxRSqFpmqa5LjdHB6BpmqY5lk4EmqZpLk4nAk3TNBenE4GmaZqL04lA0zTNxelEoGma5uJ0ItCcioj0FZGlFbCeNBFpXgEhVRgROSoiN5ivnxeRT20pW47tXCsiB8obZxm3Ve44bVj3YhHpZ491OxudCKop8z9QpllhnRGR+SLiX6TMVSKyWkRSRSRZRH4QkfAiZQJF5AMROW6u65D5vk4J2xUReVRE9ohIuojEiMi3ItLenvtbBm8Ab13qSpRS/kqpIxUQj10opd5QSo2uiHWJiBKRllbrXqeUalMR665IReO0wVvA6/aKx5noRFC93aaU8gcigY7AcwULRKQ78AvwPVAfaAbsBP4oONIVES9gFRAB9AMCgauAeOCKErb5IfAY8ChQC2gNLAVuKWvwIuJR1u9cZH1dgSCl1J8VuV6telJKbQICRaSLo2Op8pRS+lENH8BR4Aar9+8AP1m9XwfMKuZ7PwMLzNejgbOAv43bbAXkAVeUUiYKGG31fjiw3uq9AsYBfwP/AB8BU4us43tggvm6PvAdEGuWf7SUbU8CPrV639Tcnkdx8QEtgd+BZCAO+KZInC3N1/OBmcBPQCrwF9DCqmxf4IC5nlnmOkcXE199IBOoZfVZR3PbnkALYDVGIo4DvgSCi/vNgcnAF1bLhgLHzO++UKTsFcBGIAk4DcwAvMxla819TQfSgHuAnkCM1brbmX+3JGAvcLvVslL/NsX8DSoyzprAj+a/jUTzdcMi2/sEeNnR/1+r+kOfETgBEWkI3AQcMt/7YhzZf1tM8f8BfczXNwArlFJpNm6qN0YFsenSImYA0A0IB74C7hERARCRmhgV60IRcQN+wDiTaWBu/3ERubGE9bbHqJBt9SrGWVNNoCEwvZSyg4EpZtlDmE0OZhPaIoyzsdrm9q8qbgVKqVMYFd1dVh/fByxSSlkAAd7ESBjtgEYYFX6pzOa+2RiVbH0zjoZWRfKAJ4A6QHeMv+PDZkw9zDIdlNEc9k2RdXti/Aa/AKHAeOBLEbFuOir2b1MJcboB84AmQGOMJDujyGb3AR2Ki0c7TyeC6m2piKQCJ4BzwMvm57UwftvTxXznNMZ/NDD+IxZXpiRlLV+SN5VSCUqpTIwzFwVcay4bCGw0K82uQIhS6hWlVI4y2uw/Ae4tYb3BGEeltrJgVCL1lVJZSqn1pZRdrJTapJTKxThSjzQ/vxnYq5RabC6bBpwpZT1fYVScmMnvXvMzlFKHlFK/KqWylVKxwHvAdTbsx0DgR6XUWqVUNvASkF+wUCm1VSn1p1IqVyl1FPjYxvUCXAn4A2+Zv8FqjCPvwVZlSvrb2DVOpVS8Uuo7pVSGUioVIwEVLZ+K8e9CK4VOBNXbAKVUAMapfFvOV/CJGP/B6hXznXoYzQ5gnJ4XV6YkZS1fkhMFL5Rx/r6Q8xXLfRiVCZiVtIgkFTyA54GwEtabCASUIY5nMI7CN4nIXhEZWUpZ68o9A6NyBOPItuj+xJSynkVAdxGpD/TASILrAEQkVEQWishJEUkBvuD8b1qaojGkY/xWmOttLSI/mp0KUjAuqNuy3sJ1K6XyrT47hnGGVqCkv41d4xQRXxH5WESOmeXXAsEi4m5VLACjqUkrhU4ETkAp9TtGW+1U8306RhPE3cUUH4RxgRjgN+BGEfGzcVOrgIYXufiWDvhava9bXMhF3n8NDBSRJhhNRt+Zn58A/lFKBVs9ApRSN5ew7V0YF6+tY6GkeJRSZ5RS/1FK1QceBGaVsVcKGGdIhc0b5lF+w5IKK6WSMJpZBmEkva/N5AFGs5ACLldKBQL3YyQqW2JoZBWDL8bZW4HZwH6glbne521cL8ApoJHZTFegMXDSxu/bM84ngTZAN7N8QfOR9XfaYTQtaqXQicB5fAD0EZFI8/1E4AGzq2eAiNQUkdcw2l6nmGX+i1HZficibUXETURqm33U/1XZKqX+xrgY+rWI9BQRLxHxEZF7RWSiWWwHcKd5tNYSGHWxwJVS2zEu+H0KrDQrS4BNQIqIPCsiNUTEXUQuM3sHFWc5Vk0DZvPKSeB+87sjMS7IAiAid5vXV8A4m1AY7dRl8RPQXkQGmL2gxlF88rP2FTAM41rBV1afB2BcCE0SkQbA0zbGsAi4VUSuMXuCvcKF/7cDgBQgTUTaAg8V+f5ZoKR7Jv7CSKjPiIiniPQEbsM4iyurio4zAOO6QJKI1OJ806i16zA6SGil0InASZiV3gKMdlfM9u4bgTsxjsSOYfRQucas0DHbaW/AOAr7FeM/4SaM0/G/StjUoxgX5GZinHIfBu7AuKAI8D6Qg/Gf9nPON/NczNdmLIUVo1IqD6PSicToMRSHkSyCSvgbbAOSRaSb1cf/wahQ4zG6yW6wWtYV+EtE0oBlwGNKqX9sjLdgm3EYZ17vmNsIB7YA2aV8bRlGD6yzSinro9UpQCeM3kc/AYttjGEvRgL6CuO3TuTC5qmnMM4+UjGusXxTZBWTgc/N5rdBRdadA9yO0RkhDuNAYJhSar8tsdk5zg+AGmZcfwIrrAubBwzpFdC5wenJ+bNSTav+RKQv8LBSaoCDtu+GUbkNUUqtcUQMmkFEvgM+U0otd3QsVZ1OBJp2iczurH9hNFM8jXHU29zsFaVpVZ5uGtK0S9cdo4ksDqMpa4BOAlp1os8INE3TXJw+I9A0TXNxFTroV2WoU6eOatq0abm+m56ejp+frV3mnYPeZ9eg99k1XMo+b926NU4pFVLcsmqXCJo2bcqWLVvK9d2oqCh69uxZsQFVcXqfXYPeZ9dwKfssIsdKWqabhjRN01ycTgSapmkuTicCTdM0F6cTgaZpmovTiUDTNM3F2S0RiMhcETknIntKWC4iMk2MydJ3iUgne8WiaZqmlcyeZwTzMSZEL8lNGCMwtgLGYIxFrmmaplUyu91HoJRaKyJNSynSH2MSdQX8KSLBIlJPKVURUyFqmqZVbfl5YMmAnAzj2ZKJykknKzON9NQUMtJTycxIIzszlczUFI7FnMK7fjjGhIQVy5E3lDXAato6jKF7G1DMnLgiMgbjrIGwsDCioqLKtcG0tLRyf7e60vvsGvQ+VzCVj1u+Bfe8LNzys3HPyzZf55TwWTZu+Vnms7HMLS8LcrMhNxvJy8bdXO6hcvDMz8KT3H9tVjAmWKhh9dn203mMXZbJuXTF9KcH2WWfHZkIipuCrtgR8JRSc4A5AF26dFHlvbNO34noGvQ+O7H8PLBkQm42G9etpnv7doXvyc2C3EywZBmfWdLN54KjbvN1weNfn1mVzS374LG5eJAl3mTiTYbyIj3fm0y8yFDeZOFX+DoTb3LEm3xPX9w8a+Dm7Y+7ty9ePn54+vrjUyMAXz9/3Dy9+fKLr1gw/3Nq1a7DjE9nUCs0xC6/syMTQQxW85dizPN6ykGxaJpmK6UgL8eqAraqiC1ZZoVc8Miu2HL554+iu4MxL5lNBLz8UJ6+5Hv4kOteA4ubDzniQ5YEkOkWQoanF2keXqR6epKS50lSrieJOe7E53iSlu9pVOT4kKW8jMoebzKVF27efvjU8CPQz5dgX09q+npR09eTYPO5pp8Xwb5ehJnLgn098ff2wJjeumT9+vVj5cqVjBgxgv/7v/+jZs2adjsDcmQiWAY8IiILMSYsT9bXBzStDPLzCitL76w4iD98vsK0WFWwBRXrBUfOl1IuixJO3m3j5gEePuDhDR41jGdP89nDB3yCjWdPnxLLKXdv9h46Tv0WbUnL8yQl150UizvJFnez8nYnLtud2Cx3zmW5cS4DEjMtpKb8uzmmgIebnK+8/b0KK/VgP0+aXlC5G8uCfT0JruGFl0fF9blJTU3F09MTHx8fJk6cyJNPPkmfPn0qbP0lsVsiEJGvMa5q1BGRGIyJpT0BlFIfYUw0fjNwCMgARtgrFk2zm4KjY3sc/RZXzrqSzrcUhlG2o2NTYSXrc/5hXfn6BP27ki6uXHGVebGfmQ/3C6ud3Lx8kjItJGXkkJhhITE954L3SRk5JCZaSMzIISnj/HNOXiMotnM6+Hu7n6/IfT2JrFP8UXrNMh6l29PKlSsZM2YM999/P6+//nqlNvXZs9fQ4IssVxhT+mla1aYUpJyE2APGI67g+SBkJHBJR8fiblVZWlWaBRWtT9D5CreUcgcOH6NNRIeLljv/8IYKrvSUUmTk5J2vsFOtKvL0RPNzq8/MSj01y8ajdF8vmtT2JbJRMMF+niSePkHn9m0JqmFduVf8Ubq9JSQkMGHCBD7//HPatm3LLbfcUukxVLthqDXNbvLzIPHohZV9QYWfk3a+XI2aENIW2t4K/mE2VL6lVMjuFfNf8HRmFG069KyQdUEJR+lmxZ2YYSE5M4fE9OKO0vNLXKe/t8cFR+lNavtd0lF6VNRZenZtXGH77AirVq1iyJAhxMfH88ILL/Diiy/i4+NT6XHoRKC5ntxsoz29aGUf9zfkZZ8vF1APQtpA5BDjOaQN1GkDfnUq/GjaEc6lZhF9KoV9p1OJPp3C8fj0Sz5KD65RXBNM9TtKryyhoaE0a9aMFStWEBkZ6bA4dCLQnFdOulHBW1f2sfsh4R9QeWYhgZpNjAq+RS/jSL9OGwhpbTTLOIHcvHz+iUsn+nSK8TiVwr7TKcSl5RSWaRBcg+Yhfpd8lK6VTinF559/zrZt25g2bRrt27dnw4YNDv976kSgVX+ZiRdU9u0PbIDt4yH5+Pkybh5QqwWEtoOIO8zKvg3Ubglevo6LvYKlZlnYfya1sLKPPp3CgTOpZOcaTTae7kKr0AB6tgklvF4g7eoFEl4vkCBfTwdH7vz++ecfHnzwQX799VeuvfZaMjMzqVGjhsOTAOhEoFUXSkHaOeOIvuDIvqDyTz93vpyHD14+9aBZN6gz7HyTTq3m4O48lZ1SilPJRtNO9KkU1u7OYtKmNRxPyCgsU9PXk3b1Ahl6ZRPC6xuVfosQf91EU8ny8vKYOXMmzz33HG5ubsyaNYsHH3wQN7eq8zvoRKBVPdmpELMZzu69sKdOVvL5Mt6BRgXfqq9V+31rCG7M1rXrnOou2+zcPA6dSzMq/dPmkf6pFFLMdnwRCK0hdG4RyKAuDQsr/bqBPlXiaNPVxcXFMWnSJK677jo++ugjGjeuehe4dSLQHC/tHBzfCMc2Gs9ndoEye5/4hRjNOJfdZbbftzaeA+o6xQXbohLTcwqbdAoq/kPn0sjNN7qo+ni60bZuILdcXp/w+kazTtu6AWzeuJ6ePTs7OHqtgMVi4csvv2TYsGGEhYWxbds2mjVrVmUTs04EWuVSChKOXFjxJxw2lnnUgIZd4NqnoPGVUL8j+NZybLx2kp+vOJaQUXh0X3Ckfzo5q7BMaIA34fUD6dXWaM8Prx9I09p+uLtVzcpEM2zdupWRI0eya9cu6tWrx4033kjz5s0dHVapdCLQ7Cs/D87shuN/wvENxnPaWWNZjZrQuDt0Hm481+sAHl4ODdceMnPy2H+moJtmMtGnUth/JpWMHKPnkrub0CLEj27NahkXb82mnTr+3g6OXCuLzMxMpkyZwtSpUwkNDWXJkiXceOONjg7LJjoRaBXLkgknt5pH+xvgxGbISTWWBTWG5j2No/3GVxnNPFXogtmlUkoRm5rNXqt2/OjTKRyNS8ds2SHA24N29QIZ1KUR7eoFEF4viFZh/vh4ujs2eO2SDRgwgF9++YXRo0fz7rvvEhwc7OiQbKYTgVZ+6fFwdo9xUffsXji7G85Gnx8DJzQcLh8ETa4yKv+gho6NtwLl5uVzJC79gm6axfXND68fyG2X16ddvUAi6gfSsGbV6C6oVYyUlBS8vLzw8fHh+eef55lnnqF3796ODqvMdCLQLi7PYtx1W1jZmxV/qtVgsX6hEBYB3R82jvYbdzOafpxASpaF/adTiT6VXHgX7oGzqeSYffO93N1oFeZPrzahhc067erqvvnObvny5YwdO5b777+fN954g+uuu87RIZWbTgTahTIT4dQOqyP9PUb3zTzzSNfN0+i107ynUfGHRUDYZeAf6sioK4RSipNJmRd20zydwomE85OU1PT1JLx+IA90v7Bvvqe78zRxaaWLi4vjiSee4IsvviA8PJzbb7/d0SFdMp0INENOBmyYBus/OD87k39dqHsZtLjeqOzDLoM6rZzixqzs3Dz+Ppt2wZAL+05f2De/WW0/Lm8QzL1dGxfehRsW6K2bdlzYr7/+ypAhQ0hMTGTSpEk8//zzeHtX/4v6OhG4OqVg72L4ZRKkxBjDL3QeblT6fnUcHV2FSCjom291pG/dN7+Gpztt6wVwa4f6hd0024QF4Oet/3toF6pXrx6tW7dm9uzZtG/f3tHhVBj9L92Vnd4JP080evfUbQ93zoGmVzs6qnLLz1ccjU9n05lcNq/cXziy5pmU833zwwK9Ca8XyPVtQwtvyGqi++ZrJVBK8dlnn7F9+3ZmzpzJZZddxrp165zurFAnAleUFgurX4VtC4wbtm77EDoOBbfq04UxIyeX/WdSLzjSP3BB3/wjtAzxp3uL2oXdNNvVC6C27puv2ejIkSP85z//YfXq1fTs2bNKDRJX0XQicAX5ecYF31Pb4OQ22P0tWDLgyofhumegRrCjIyyRUopzqdmFlX1B084/cemogr75Puf75ofXCyTj1EHuvbmn7puvlUteXh7Tpk3jhRdewMPDg48//pjRo0dXqUHiKppOBM6mYAiHk9vg1HYi962BP44aFT+AVwA0vw56v2yMuV+FWPLyORKbTvRps5umeRE3Pv183/xGtWrQrm4gt3eoXziEctG++VFRh3US0MotLi6OKVOm0Lt3b2bPnk3Dhs5z/0tJdCJwFvGHYefXsPOb8+Pwe/ggvk2g0zBj3J76nYzx96vAkU1KloV9RbppHjybdr5vvocbrcP86d3u/Lj5besFElSj+vdY0qqenJwcvvjiC4YPH05YWBg7duygSZMmTtkMVBydCKozSxbs+gZ2fAkn/gJxM/r393gSGnSGkHZsX7feoUMyK6WIScy8oJtm9OkUYhLP982v5edFeL1Ahl/VtLDSbx7ip/vma5Vi8+bNjBw5kj179tCwYUP69u1L06ZNHR1WpdKJoDrKyYCt8+CPaZB2xhim+YbJcPk9EFjfYWFlWS4cN7/gaD/Vum9+HT86NApm8BWNC3vthAbovvla5cvIyGDSpEm8//771KtXj2XLltG3b19Hh+UQOhFUN3uXwk9PQkYcNL3W6PLZrEelj80fn5Z9wWia+06ncig2jTyzb76vlztt6wZwe4fz4+a3qRuAr5f+J6dVDf379+e3335jzJgxvPPOOwQFOccc1eWh/1dWJ/t+gEUjoX4k3PulMZCbneWZffOL3pB1NiW7sEzdQB/C6wdyQ3go4fWCCK8fSJNavrjpvvlaFZOcnIy3tzc+Pj689NJLPP/88/Tq1cvRYTmcTgTVQX4+7PkOlj5ktP0PXQzeARW+mfRsq775ZoW//3QqmRajb76Hm9Ay1J+rW9S5YNz8Wn7ON4eA5nx+/PFHxo4dy9ChQ3nzzTfp0aOHo0OqMnQiqMry8yD6e1g7Fc7tNXr9DPn2kpOAUoqzKdn/6qb5T/yFffPD6wVy7xWNCrtptgrzx9tDd8vUqpfY2Fgee+wxvv76a9q3b8+dd97p6JCqHJ0Iqoo8C/zyEhxeff6z7BRjqOc6reGOOca8ve7l+8nOJGex5sA5Vu8/x9ZjiSRY9c1vXMuXdvUC6B/ZwLgLt34gDYKd8w5KzbX88ssvDBkyhOTkZKZMmcLEiRPx8tJnsEXpRFAVZCXD/x6AI2ugZR/w8jM+d3OHtrdCeP8yD/+Ql6/YGZPEd3/n8M7OdUSfTgGgfpAPvduGclmDILNvfgCBPrpvvuacGjRoQLt27Zg9ezYRERGODqfK0onAkfJy4fAq+G0yxB2E/jOh4/3lXl1ypoW1B2NZs/8cUQdjSUjPQYAuTf15pl8brm8bSpuwAH2krzmt/Px8Pv30U7Zv315Y+a9du9bRYVV5OhE4QsI/sP0L2PEVpJ4C/zAYsghalK33glKKv8+lsXr/+SafvHxFsK8n17UO4fq2obifO8itfa+y045oWtVx6NAh/vOf/xAVFUWvXr0KB4nTLk4ngsp0YhOs+z84uMK4C7jlDXDzO9C6n82TvWRZ8th4JJ41ZuVfcIdu27oBPNijOde3DaVj45qFwypHRf1tt93RtKogLy+PDz74gJdeeglPT08++eQTRo0apc98y8CuiUBE+gEfAu7Ap0qpt4osDwK+ABqbsUxVSs2zZ0wOkZkEi8fA3yuNeXyve9YY/8fGydxPJWWyev851uw/xx+H48iy5OPj6cY1LevwUM8W9GoTSv1gfeSjuaa4uDhee+01+vTpw6xZs2jQoIGjQ6p27JYIRMQdmAn0AWKAzSKyTCkVbVVsHBCtlLpNREKAAyLypVIqp5hVVk9Jx+HLQRD/N9wwBbqOBm//Ur+Sm5fP9hNJhZX//jOpADSsWYN7ujSiV9tQrmxeW4+wqbms7OxsfvzxR3r06FE4SFzjxo31WUA52fOM4ArgkFLqCICILAT6A9aJQAEBYvx6/kACkGvHmCpP0nFjLKDt/wV3b7h/sTH8c0nFM3L4/WAsq/ad4/eDsSRnWnB3E7o0qclzN7Xl+rahtAz11//QNZf3119/MWrUKPbu3Uvfvn3p27cvTZo0cXRY1ZqogjuIKnrFIgOBfkqp0eb7oUA3pdQjVmUCgGVAWyAAuEcp9VMx6xoDjAEICwvrvHDhwnLFlJaWhr9/6Ufjl0wpGpxcTovDcwE4G9aTY03uJqtG3SLFFDFpip3nctkZm8ehpHwjK3rB5XU86BDiTkQdd/w8L63ir5R9rmL0PjunzMxM5s6dy3fffUedOnV4+OGHHTqyriNcyu/cq1evrUqpLsUts+cZQXE1WNGscyOwA7geaAH8KiLrlFIpF3xJqTnAHIAuXbqo8v74UVFR9v2HY8mC78fBoUXGBeBb/o96QQ2pV6RYcqaFkfM3s/VYIgCXNQhkfKdQerUNpUPD4Aodo8fu+1wF6X12Tn369OG3337joYce4q233mLbtm1Ov89F2et3tmciiAEaWb1vCJwqUmYE8JYyTksOicg/GGcHm+wYl31kJMDC++D4Rug9Ca6ZUOyIoClZFobN3UT0qWQm3RrOLZfXIyzQxwEBa1rVl5SUhLe3NzVq1GDSpEm89NJLeowgO7DnzB+bgVYi0kxEvIB7MZqBrB0HegOISBjQBjhix5jsZ+ULcHIrDJwL1z5ZbBJIy85l+NxN7D2ZzMz7OjHymmY6CWhaCZYtW0ZERARTpkwB4Nprr9VJwE7slgiUUrnAI8BKYB/wP6XUXhEZKyJjzWKvAleJyG5gFfCsUirOXjHZTeJRY6awrqON8YCKkZ6dy4h5m9gZk8yM+zrSN6JuseU0zdWdO3eOe++9l/79+1OnTh0GDhzo6JCcnl3vI1BKLQeWF/nsI6vXp4DqPSVQXi78/KwxFtBV44stkpGTy4j5m9l2PIlp93ak32VFrxpomgawYsUKhgwZQlpaGq+++irPPvssnp56LCx703cWX4q8XPjpCeNO4ZunFjtNZGZOHqPmb2HL0QQ+uLcjt1yuk4CmlaRRo0a0b9+eWbNmER4e7uhwXIZOBOV1bh8seRBO7zSuCVzxn38VybLk8Z8FW/jzn3jeHxTJ7R0cN5+wplVF+fn5fPzxx+zYsYOPP/6YiIgIoqKiHB2Wy7HnxWLnlZtt3C2ccgoGLTB6CRVRkAT+OBzH1IEdGNBR3/auadYOHjxIz549efjhh/nnn3/IyspydEguSyeC8ti2AJKPwx0fG3MFFJGdm8fYL7ay7u843r7rcu7qbNuYQprmCnJzc3n77be5/PLL2b17N/PmzWPlypX4+OgedI6im4bKKjsVfn8bmlwNLa7/1+Kc3Hwe/mIbUQdiefPO9gzq0qiYlWia64qPj+ftt9/m5ptvZubMmdSrp6+bOZo+IyirDdMhPRb6vPqvewVycvMZ99U2Vu0/x2sDLmPwFY0dFKSmVS3Z2dl8/PHH5OfnExYWxs6dO1m8eLFOAlWETgRlkXLaSAQRd0DDzhcssuTl8+jX2/k1+iyv9I/g/iv1IFiaBrBx40Y6duzI2LFjWb3amJO7USN9plyV6ERQFr+/ZUwyX+TisCUvn8cX7mDF3jNMujWcYd2bOiY+TatC0tLSePzxx7n66qtJT09nxYoV3HDDDY4OSyuGvkZgq+QY2P4ldH4AajUv/Dj6VArPfLeTPSdTePGWdoy8ppkDg9S0qmPAgAGsWrWKRx55hDfeeIOAgABHh6SVQCcCW22YDii4+jHA6Bk0Y/UhZkcdJtjXk1lDOnFze93eqbm2xMREfHx8qFGjBpMnT2by5Mlcc801jg5Luwibm4ZExM+egVR5h9dAi94Q3JitxxK5Zdp6pq8+xO2R9fn1iet0EtBc3uLFiwkPD2fy5MkAXHPNNToJVBMXTQQicpWIRGMMHIeIdBCRWXaPrKrJiCcvoB6v/BDNwI82kJGdy7wRXXlvUCQ1/bwcHZ2mOcyZM2cYOHAgd911F3Xr1uXee+91dEhaGdnSNPQ+xgQyywCUUjtFxLXGgs3Ph8xEdid4MHf/P9x/ZWMm3tQOf2/dsqa5tp9//pkhQ4aQkZHBG2+8wVNPPaUHiauGbKrJlFInisyVm2efcKqo1FOg8lh1ypNOjYN5bUB7R0ekaVVCkyZN6NixIzNnzqRt27aODkcrJ1uuEZwQkasAJSJeIvIUZjORy4g7CMDmtNoMv1r3CtJcV35+PjNmzOA//zEGWQwPD2fVqlU6CVRztiSCscA4oAHG9JORwMN2jKnqiTUSQbJvU266TE8oo7mmAwcO0KNHD8aPH8+JEyf0IHFOxJZE0EYpNUQpFaaUClVK3Q+0s3dgVUnKse3EqwD6deuAp7u+B09zLRaLhTfffJMOHToQHR3N/Pnz+fnnn/UgcU7Ellptuo2fOaW8fEX8oS3sU00ZfKUeO0hzPYmJibz77rvcdtttREdH88ADDyDFzMmtVV8lXiwWke7AVUCIiEywWhQIuNs7sKpi3b6TXJXzD5kthhEaoI+ANNeQlZXF3LlzGTt2LKGhoezatYuGDfVw6s6qtDMCL8AfI1kEWD1SAJeZTTr98Aa8JI8mkT0dHYqmVYr169fToUMHxo0bVzhInE4Czq3EMwKl1O/A7yIyXyl1rBJjqlICY9ZgwR2/tr0dHYqm2VVqairPPfccM2fOpGnTpvzyyy96kDgXYct9BBki8i4QARS2jSil/j0rixNqlriBvZ6XEemtB8zSnNuAAQNYs2YNjz32GK+99hr+/v6ODkmrJLYkgi+Bb4BbMbqSPgDE2jOoKiPpBA0tR9lU5yEiHR2LptlBQkICPj4++Pr68uqrryIidO/e3dFhaZXMll5DtZVSnwEWpdTvSqmRwJV2jsvxlCL/x8fJV0JCw16OjkbTKtyiRYto165d4SBxV111lU4CLsqWRGAxn0+LyC0i0hFw/itHqadxO/Qb0/PuILBBuKOj0bQKc/r0ae68807uvvtuGjVqxJAhQxwdkuZgtjQNvSYiQcCTGPcPBAKP2zOoKuH0LgDW5rXnmdq+Dg5G0yrGTz/9xP33309WVhZvv/02EyZMwMNDD57o6i76L0Ap9aP5MhnoBSAiV9szqCrhzC4Uwj7VhCa1XXsqBs15NG/enK5duzJjxgxat27t6HC0KqLEpiERcReRwSLylIhcZn52q4hsAGZUWoSOcnonCT6NyPPwJTTA29HRaFq55OXl8eGHHzJq1CgA2rVrxy+//KKTgHaB0s4IPgMaAZuAaSJyDOgOTFRKLa2E2Bzr9C4Ou7egSW1f3Nz07fRa9RMdHc3o0aPZuHEjN998M1lZWXp8IK1YpSWCLsDlSql8EfEB4oCWSqkzlROaA236BJKPs92nD41DdbOQVr3k5OTwzjvv8OqrrxIQEMAXX3zBfffdp8cH0kpUWq+hHKVUPoBSKgs4WNYkICL9ROSAiBwSkYkllOkpIjtEZK+I/F6W9dvFqldh+VOo1v34KP06mugLxVo1k5SUxPvvv88dd9xBdHQ0Q4YM0UlAK1VpZwRtRWSX+VqAFuZ7AZRS6vLSViwi7sBMoA/GPAabRWSZUiraqkwwMAvop5Q6LiKh5d+VCpCbDev+DyLuILbPTBJ3RelEoFUL2dnZzJgxg4cffpjQ0FB2795N/fr1HR2WVk2Ulggudc6BK4BDSqkjACKyEOgPRFuVuQ9YrJQ6DqCUOneJ27w0SScABa1u5GhiNoDuMaRVeWvXrmX06NHExMTQrl07evfurZOAVialDTp3qQPNNQBOWL2PAboVKdMa8BSRKIyRTT9USi0ouiIRGQOMAQgLCyMqKqpcAaWlpZX63ZoJ2+gAbD+awMq0rQCc+Xs3Uaeq72Q0F9tnZ+Qq+5yens6cOXNYtmwZYWFhTJ06FXd3d5fYd3Cd39mavfbZnneSFNcoqYrZfmegN1AD2CgifyqlDl7wJaXmAHMAunTponr27FmugKKioij1u1uOwC7o2GsAq/9Kw93tMHf261mtZyW76D47IVfZ5+uvv56oqCieeOIJ+vTpw0033eTokCqVq/zO1uy1z/ZMBDEY3U8LNAROFVMmTimVDqSLyFqgA3AQR0g8Bm6eEFCXo/G7aBBco1onAc35xMXF4evri6+vL6+//joiwpVXXulyR8ZaxbKplhORGiLSpozr3gy0EpFmIuIF3AssK1Lme+BaEfEQEV+MpqN9ZdxOxTm7B2q3BDd3jsen6wvFWpWhlGLhwoW0a9eOl19+GYDu3btz5ZXOP/6jZn8XTQQichuwA1hhvo8UkaIV+r8opXKBR4CVGJX7/5RSe0VkrIiMNcvsM9e7C+PGtU+VUnvKuS+XJj8Pjm2EptcAcCwhg8a1dCLQHO/kyZMMGDCAwYMH06xZM4YNG+bokDQnY0vT0GSMHkBRAEqpHSLS1JaVK6WWA8uLfPZRkffvAu/asj67yk4BSzrUak5yhoWkDAtNdY8hzcF+/PFHhgwZgsViYerUqTz++OO4u7vMlOFaJbElEeQqpZKd/oaUnAzj2cuXYwnpADTWTUOag7Vs2ZKrrrqK6dOn07JlS0eHozkpW64R7BGR+wB3EWklItOBDXaOq/JZzETg6cexeOO1vkagVba8vDzef/99hg8fDkDbtm35+eefdRLQ7MqWRDAeY77ibOArjOGoH7djTI6RY5wF4OXL8QQjEehrBFpl2rt3L1dffTUTJkwgLi6OrKwsR4ekuQhbEkEbpdQLSqmu5uNFc+wh51KQCDx9ORqXTmiAN75eesIOzf5ycnJ45ZVX6NixI4cPH+arr77ihx9+0COFapXGlkTwnojsF5FXRSTC7hE5SuJR4zm4MccSMnSzkFZpkpKSmDZtGnfffTfR0dEMHjxYDxKnVaqLJgKlVC+gJxALzBGR3SLyor0Dq3TnosHDB2o25Xh8Bo1r6R5Dmv1kZGTw4YcfkpeXVzhI3JdffklISIijQ9NckE03lCmlziilpgFjMe4pmGTPoBzi3D6o05qsPDiTkkVTfUag2cmaNWto3749jz/+eOEdwfXq1XNsUJpLs+WGsnYiMllE9mBMUbkBY7gI5xK7H0Lbnb9QrBOBVsGSk5N58MEHuf766xER1qxZQ+/evR0dlqbZdB/BPOBroK9SquhYQc4hMxFSTkJIW6uuo7ppSKtYAwYMYO3atTz99NNMnjwZX199sKFVDRdNBEop5x/M5MRm47lBZ46dNHoP6aYhrSLExsbi5+eHr68vb775Ju7u7nTt2tXRYWnaBUpsGhKR/5nPu0Vkl9Vjt9XMZc7h+AZw84CGXTkWn0GgjwfBvl6OjkqrxpRSfPXVVxcMEnfllVfqJKBVSaWdETxmPt9aGYE41LENUL+jObxEhm4W0i5JTEwMDz30ED/++CPdunUrvEtY06qqEs8IlFKnzZcPK6WOWT+AhysnvEpgyYST26DJVQAcj0/XF4q1clu2bBnh4eGsXr2a999/nz/++IOICOe9/UZzDrZ0H+1TzGfOMxXSuX2Qb4EGXcjNyycmMVNfH9DKrXXr1lxzzTXs3r1bjxSqVRslNg2JyEMYR/7Ni1wTCAD+sHdglSbJnJq5VnNOJWWRm69oom8m02yUm5vLBx98wK5du1iwYAFt27Zl+fLlF/+iplUhpV0j+Ar4GXgTmGj1eapSKsGuUVWmRDMRBDfm2Ak9/LRmu127djFq1Ci2bNlC//79ycrK0uMDadVSaU1DSil1FBgHpFo9EJFa9g+tkiTHgE8Q+ARy1LyHQE9Io5UmOzubl19+mc6dO3P8+HH+97//sWTJEp0EtGrrYmcEtwJbAQVYj4KlgOZ2jKvy5KSDdyBgXCj29nAjNMDbwUFpVVlKSgqzZs1i8ODBvP/++9SuXdvRIWnaJSkxESilbjWfm1VeOA6Qm2kMNgccizfmKXZz0yM/ahdKT09nzpw5PProo4SEhLBnzx7CwsIcHZamVQhbxhq6WkT8zNf3i8h7ItLY/qFVEksWeBqJ4Li+h0ArxqpVq2jfvj0TJkzg999/B9BJQHMqtnQfnQ1kiEgH4BngGPBfu0ZVmXIzwaMGSimOxet5CLTzkpKSGD16NDfccAMeHh78/vvvXH/99Y4OS9MqnC2JIFcppYD+wIdKqQ8xupA6B0sWeHgTm5pNpiVPJwKt0B133MH8+fN59tln2blzJz169HB0SJpmF7aMPpoqIs8BQ4FrRcQd8LRvWJUoMwFqNeeYnqdYA86ePYu/vz9+fn689dZbeHh40LlzZ0eHpWl2ZcsZwT0YE9ePVEqdARoA79o1qspyZg/EHYTmvTgaVzDqqL5G4IqUUvz3v/8lPDy8cJC4bt266SSguQRbpqo8A3wJBInIrUCWUmqB3SOrDDu/BncvuHwQxxMycHcTGtSs4eiotEp2/PhxbrnlFoYNG0abNm0YNWqUo0PStEplS6+hQcAm4G5gEPCXiAy0d2CVIvEo1G4FvrU4Fp9B/WAfPN1tmr1TcxLff/89ERERrF27lmnTprFu3TratWvn6LA0rVLZco3gBaCrUuocgIiEAL8Bi+wZWKXISQcv45rAsfh03SzkQpRSiAht27alZ8+eTJ8+naZNmzo6LE1zCFsOf90KkoAp3sbvVX2WDPA0E0FChr5Q7AJyc3N5++23GTp0KABt2rThhx9+0ElAc2m2VOgrRGSliAwXkeHAT4BzDK+YkwFefiRnWkjKsOiuo05u586ddOvWjYkTJ5KRkUFWVpajQ9K0KsGWi8VPAx8DlwMdgDlKqWftHVilsKSDpy/H9YT1Ti0rK4sXX3yRLl26cPLkSRYtWsTixYv1IHGaZiptPoJWwFSgBbAbeEopdbKyArO7/DxIPgltb+FovNF1VJ8ROKfU1FQ+/vhjhgwZwnvvvUetWs4zeK6mVYTSzgjmAj8Cd2GMQDq9rCsXkX4ickBEDonIxFLKdRWRvErtjZR8AvKyoXYrjuubyZxOWloaU6dOJS8vj5CQEKKjo5k/f75OAppWjNJ6DQUopT4xXx8QkW1lWbF5B/JMjKkuY4DNIrJMKRVdTLm3gZVlWf8liz1oPNdpxbF/0gkJ8MbXy5ZOVFpVt3nzZoYPH87x48fp3LkzvXr1IiQkxNFhaVqVVdoZgY+IdBSRTiLSCahR5P3FXAEcUkodUUrlAAsxxisqajzwHXCumGX2c8acfTM0nKPxGXqeYieQkJDAiBEjeOaZZ/Dx8WHdunX06tXL0WFpWpVX2iHwaeA9q/dnrN4r4GLDMDYATli9jwG6WRcQkQbAHea6upa0IhEZA4wBY/jfqKioi2y6eGlpaYXfDd+7igCfuvz11w7+PpVBeG33cq+3KrPeZ2f32GOPsWfPHu6++25Gjx6NxWJxmX13pd+5gN7nilPaxDSXeihV3Owuqsj7D4BnlVJ5IiVPBqOUmgPMAejSpYvq2bNnuQKKioqi8Lu7noBmV3Dl1deSuGIF3SKa07Nnq3Kttyq7YJ+d0JkzZwgICMDPz49PPvkELy8vkpKSnHqfi+Psv3Nx9D5XHHveGBYDNLJ63xA4VaRMF2ChiBwFBgKzRGSAHWM6LyMBAuoWXijWPYaqF6UU8+fPJzw8nEmTJgFwxRVXEBkZ6djANK0asmci2Ay0EpFmIuIF3Asssy6glGqmlGqqlGqKMWTFw0qppXaMqQjhmL6HoNo5evQo/fr1Y8SIEURERDBmzBhHh6Rp1ZrduskopXJF5BGM3kDuwFyl1F4RGWsu/8he2y6LYwX3EOiuo9XCkiVLGDp0KCLCjBkzeOihh3Bzc44RTzTNUS6aCMRovB8CNFdKvWLOV1xXKbXpYt9VSi2nyHAUJSUApdRwmyKuYMfiMwj08SDY13nm2nFGBYPERUREcMMNN/Dhhx/SpEkTR4elaU7BlkOpWUB3YLD5PhXj/oBqzrhufcycsL60i9Wa41gsFt544w2GDBkCQOvWrVm6dKlOAppWgWxJBN2UUuOALAClVCLgZdeo7C03B7JSwCeI4/HpNNYXiqukbdu2ccUVV/DCCy+Ql5dHdna2o0PSNKdkSyKwmHf/KiicjyDfrlHZW9JxQJEX3ISYxEx9M1kVk5mZyXPPPccVV1zBmTNnWLJkCd988w3e3t6ODk3TnJItiWAasAQIFZHXgfXAG3aNyt7O7gbgXI2W5OYrmtTSPYaqkvT0dD777DMeeOABoqOjGTBggKND0jSndtGLxUqpL0VkK9Ab4yaxAUqpfXaPzJ7O7AY3D6bvNnb/sgZBDg5IS01NZfbs2Tz55JPUqVOH6Oho6tSp4+iwNM0l2DJncWMgA/gB4z6AdPOz6ivlFHn+dflq21lGXt2M8PqBjo7Ipa1YsYLLLruMiRMnsm7dOgCdBDStEtlyH8FPGNcHBPABmgEHgAg7xmVf6XFYvI3hiCMbBzs2FhcWHx/PhAkTWLBgAe3ateOPP/6ge/fujg5L01yOLU1D7a3fmyOPPmi3iCpDRhzZXkYiCKqh7x9wlDvvvJMNGzbw0ksv8cILL+iLwZrmIGW+s1gptU1EShwptFpIjyejptEPPVgngkp1+vRpAgIC8Pf3Z+rUqXh5edGhQwdHh6VpLs2WO4snWL11AzoBsXaLqDJkxJFaOxhA31FcSZRSzJs3jwkTJjBy5Ejee+89unat3scTmuYsbOk+GmD18Ma4ZlDcBDPVQ04GWDJIdjN6CgXXqN73xlUHR44coW/fvowaNYoOHTowduxYR4ekaZqVUs8IzBvJ/JVST1dSPPaXEQdAAoGIQICPnp7SnhYvXszQoUNxd3dn9uzZjBkzRg8Sp2lVTIm1oIh4mCOI2jItZfWRZsyIGZcfQKCPJ25ueowheygYJK59+/b069ePDz74gEaNGl38i5qmVbrSDoc3YVwP2CEiy4BvgfSChUqpxXaOzT7iDwNwTIXp6wN2kJOTwzvvvMPevXv56quvaNWqFd99952jw9I0rRS2nKPXAuIx5hW+FbjNfK6e4g6CuHMoN0R3Ha1gW7ZsoWvXrrz00kuAkRQ0Tav6SjsjCDV7DO3h/A1lBYrOPVx9JByB4MYkZOl7CCpKZmYmL7/8Mv/3f/9H3bp1+f7777n99tsdHZamaTYq7YzAHfA3HwFWrwse1VNyDAQ3IjnTQrCv7jFUEdLT05k/fz6jRo1i7969OgloWjVT2hnBaaXUK5UWSWVJOQnNriPpWI6+mewSpKSkMGvWLJ5++mnq1KnDvn37qF27tqPD0jStHEo7I3C67jSSnwepp1GBDUjOtOimoXL66aefiIiI4IUXXigcJE4nAU2rvkpLBL0rLYpK4pWTACqfLL965Ct9V3FZxcbGMmTIEG699VaCgoLYsGEDPXv2dHRYmqZdohKbhpRSCZUZSGXwzjZuJkvzCgP0xeKyuuuuu/jzzz+ZPHkyzz33HF5e+hqLpjkDl7qt1ifLGCIp0TMMOKcvFtvg5MmTBAUF4e/vz/vvv4+3tzeXXXaZo8PSNK0CudS9/t7Z8QDEuxuTnugzgpIppfjkk08IDw9n0qRJAHTu3FknAU1zQq6XCLwCiM81xr3X1wiKd/jwYXr37s2YMWPo3Lkz48aNc3RImqbZkUslAq+ceAisR1KGBdBzERRn0aJFtG/fnq1btzJnzhxWrVpFixYtHB2Wpml25FLXCNzyLeDpQ3KmkQgCdSIoVDBIXIcOHbjlllt4//33adiwoaPD0jStErjUGUGB5EwLPp5u+Hi6OzoUh8vJyWHKlCnce++9KKVo1aoV3377rU4CmuZCXDIRJGXk6AlpgE2bNtG5c2cmT56Mh4eHHiRO01yUiyYCi0tfKM7IyOCpp56ie/fuJCYm8sMPP/Dll1/qyeM1zUW5ZiLItLj09YHMzEy++OILxowZQ3R0NLfeWn1HFdc07dLZNRGISD8ROSAih0RkYjHLh4jILvOxQUQ62DOeAimZFpfrMZScnMzrr79Obm4utWvXZt++fcyePZvAwEBHh6ZpmoPZLRGY8x3PBG4CwoHBIhJepNg/wHVKqcuBV4E59orHmqs1Df3www+FN4atX78egJo1azo4Kk3Tqgp7nhFcARxSSh1RSuUAC4H+1gWUUhuUUonm2z+BSumqkpSZ4xLDS8TGxvLqq69y++23U7t2bf766y89SJymaf9iz/sIGgAnrN7HAN1KKT8K+Lm4BSIyBhgDEBYWRlRUVLkCapubR0pWGlmWfOJPnyAq6my51lNdPPbYY0RHRzNixAgGDx5MWlpauf921Ymr7Kc1vc+uwV77bM9EUNx8BsVOcSkivTASwTXFLVdKzcFsNurSpYsq71Ft3O7XqOHtB/HQMaINPa9sUq71VGUxMTEEBwfj7+/PvHnz2LlzJyNGjHB0WJUqKirK5c589D67Bnvtsz2bhmKARlbvGwKnihYSkcuBT4H+Sql4O8YDQF6+kYuc7RpBfn4+H3/8MeHh4YWTx3fq1IlmzZo5ODJN06o6eyaCzUArEWkmIl7AvcAy6wIi0hhYDAxVSh20YyyFChOBE91Q9vfff3P99dczduxYrrjiCsaPH+/okDRNq0bs1jSklMoVkUeAlYA7MFcptVdExprLPwImAbWBWSICkKuU6mKvmOB8InCWIai//fZbhg0bhre3N5999hkjRozA/FtqmqbZxK6DzimllgPLi3z2kdXr0cBoe8ZgzdOSRraHH1D9m4YKBonr2LEj/fv357333qN+/fqODkvTtGrIpe4s9sk6R6JXPQCCqmkiyM7OZtKkSQwaNAilFC1btmThwoU6CWiaVm6ukwhys/HKSeCcR1083IQA7+o3Aveff/5Jp06dePXVV6lRo4YeJE7TtArhOokgPRZBcU7VJNjXs1q1o6enp/PEE09w1VVXkZqayvLly1mwYIEeJE7TtArhOolAGReJ0yyq2t1VnJWVxcKFC3n44YfZu3cvN910k6ND0jTNiVS/9pFLlJGTS81qcH0gKSmJ6dOn89xzzxUOEhccHOzosDRNc0Kuc0ZgysjOq/JnBEuXLiU8PJwpU6awYcMGAJ0ENE2zG31GUIWcPXuW8ePH8+2339KhQwd++OEHOnfu7OiwNCdhsViIiYkhKyvL0aFUiKCgIPbt2+foMCqVLfvs4+NDw4YN8fS0vZ5zuUSQnpNHzSp6RjBw4EA2bdrEa6+9xjPPPFOmH1LTLiYmJoaAgACaNm1arTpLlCQ1NZWAgABHh1GpLrbPSini4+OJiYkp0/AyLpcIcvOr1sXi48ePU7NmTQICApg2bRre3t6EhxedtkHTLl1WVpbTJAGteCJC7dq1iY2NLdP3XO4aAVAlmoby8/OZOXMmERERTJo0CYCOHTvqJKDZlU4Czq88v7FLJgJHnxEcOHCA6667jkceeYTu3bvz2GOPOTQeTdNcm0smAkeeEfzvf/+jQ4cO7Nmzh3nz5rFy5UqaNm3qsHg0rTK5u7sTGRlJREQEHTp04L333iM/P79c63rttdf47bffSlz+0UcfsWDBgjKvd+XKlURGRhIZGYm/vz9t2rQhMjKSYcOGlSvO6sDlrhEA1PKr/DOCgkHiOnfuzJ133sl7771H3bp1Kz0OTXOkGjVqsGPHDgDOnTvHfffdR3JyMlOmTCnzul588cVSL5yOHTu2XDHeeOON3HjjjQD07NmTqVOn0qXLhYMi5+Xl4e7uXq71V0UumQgqs2koKyuLV199lf3797No0SJatGjBV199VWnb17TiTPlhL9GnUip0neH1A3n5tgiby4eGhjJnzhy6du3K5MmTyc/PZ+LEiURFRZGdnc24ceN48MEHAXjnnXf473//i5ubGzfddBNvvfUWY8eO5Y477mDgwIFMnDiRZcuW4eHhQd++fZk6dSqTJ0/G39+fp556ih07djB27FgyMjJo0aIFc+fOpWbNmvTs2ZNu3bqxZs0akpKS+Oyzz7j22muLjbdp06aMHDmSX375hUceeYRatWrx8ssvk52dTYsWLZg3bx7+/v5s3bqVCRMmkJaWRp06dZg/fz716tWrkL+xvbhoIqicpqENGzYwatQo9u/fzwMPPEBOTo4eH0jTrDRv3pz8/HzOnTvH999/T1BQEJs3byY7O5urr76avn37sn//fpYuXcpff/2Fr68vCQkJF6wjISGBJUuWsH//fkSEpKSkf21n2LBhTJ8+neuuu45JkyYxZcoUPvjgAwByc3PZtGkTy5cvZ8qUKaU2N/n4+LB+/Xri4uK48847+e233/Dz8+Ptt9/mvffe47nnnmP8+PF8//33hISE8M033/DCCy8wd+7civyzVTiXSwQ+Hm54utv30khaWhrPP/88M2bMoFGjRqxYsaLwVFPTqoKyHLnbmzLHAfvll1/YtWsXixYtAiA5OZm///6b3377jREjRuDr6wtArVq1Lvh+YGAgPj4+jB49mltuuYVbb731guXJyckkJSVx3XXXAfDAAw9w9913Fy6/8847AejcuTNHjx4tNdZ77rkHMEYCjo6O5uqrrwYgJyeH7t27c+DAAfbs2UOfPn0Aowmpqp8NgAsmAl9v+7fr5eTksGjRIsaNG8cbb7zhcje9aJqtjhw5gru7O6GhoSilmD59+r8OmlasWFFql0gPDw82bdrEqlWrWLhwITNmzGD16tU2x1Bwlu7u7k5ubm6pZf38jImtlFL06dOHr7/++oLlu3fvJiIigo0bN9q8/arA5XoN+XraJxEkJCQwefJkcnNzqVWrFvv27WP69Ok6CWhaCWJjYxk7diyPPPIIIsKNN97I7NmzsVgsABw8eJD09HT69u3L3LlzycjIAPhX01BaWhrJycncfPPNfPDBB4UXowsEBQVRs2ZN1q1bB8B///vfwrOD8rryyiv5448/OHToEAAZGRkcPHiQNm3aEBsbW5gILBYLe/fuvaRtVQaXOyPw8qj4RPDdd98xbtw44uLiuP766+nRowdBQUEVvh1Nq+4yMzOJjIzEYrHg4eHB0KFDmTBhAgCjR4/m6NGjdOrUCaUUISEhLF26lH79+rFjxw66dOmCl5cXN998M2+88UbhOlNTU+nfvz9ZWVkopXj//ff/td3PP/+88GJx8+bNmTdv3iXtR0hICPPnz2fw4MFkZ2cDRnfW1q1bs2jRIh599FGSk5PJzc3l8ccfJyKi6jTFFUspVa0enTt3VuWSeFyplwPVZ9OmlO/7xTh16pS68847FaA6duyotm/fXmHrrihr1qxxdAiVTu9z8aKjo+0fSCVKSUlxdAiVztZ9Lu63BraoEupV1zsjqMALxYMGDWLz5s289dZbPPnkk3h4uNyfU9M0J+ByNZenx6UlgmPHjlGrVi0CAgKYPn06NWrUoE2bNhUUnaZpWuVzuYvF3uVMBPn5+UyfPp2IiAheeuklACIjI3US0DSt2nO5M4LyNA3t37+f0aNH88cff9CvXz+eeOIJO0SmaZrmGC5zRpBrDmzlVcYzgoULF9KhQwf27dvHggULWL58OU2aNLFHiJqmaQ7hMokg01K2RFAwImLXrl25++67iY6OZujQoXo8d03TnI7rJIKcPAC8LjJiYGZmJhMnTuSuu+5CKUWLFi344osvCAsLq4wwNc2pnT17lvvuu4/mzZvTuXNnunfvzpIlS8q9vsmTJzN16lQAJk2aVOo4QaXZsWMHy5cvL3w/f/58QkJCCofMHjhwYOENbRWh6PaWLVvGW2+9VWHrLyvXSQQWIxF4e5Z8RL9u3ToiIyN5++23qV27duEdjpqmXTqlFAMGDKBHjx4cOXKErVu3snDhQmJiYi4od7FhHkryyiuvcMMNN5Tru0UrZjDGFdqxYwd79+7Fy8uLb775plzrtmV7t99+OxMnTqyw9ZeVy1wszjLv/vMspq9/amoqEydOZNasWTRr1oxff/213P+gNK1a+HkinNldseus2x5uKvmodvXq1Xh5eV0wT0CTJk0YP3488+fP56effiIrK4v09HSWLVtG//79SUxMxGKx8Nprr9G/f38AXn/9dRYsWED9+vWpW7cunTt3BmD48OHceuutDBw4sMShoIsbdrpbt25MmjSJzMxM1q9fz3PPPXdB3Lm5uaSnp1OzZk3A6EI+cuRIYmNjCQkJYd68eTRu3LjEz7/99lumTJmCu7s7QUFB/Pbbb//aXmZmJlu2bGHGjBkMHz6cwMBAtmzZwpkzZ3jnnXcYOHAg+fn5PPHEE2zcuJFmzZqRn5/PyJEjGThw4CX/dC5zRpCTYYy97u7z76EfLBYLS5cu5fHHH2f37t06CWiaHezdu5dOnTqVuHzjxo18/vnnrF69Gh8fH5YsWcK2bdtYs2YNTz75JEqpwrOI7du388UXX7B58+Z/rcdisTB+/HgWLVrE1q1bGTlyJC+88ELh8oJhpz/44AOmTJmCl5cXr7zySuEZQMEIo9988w2RkZE0aNCAhIQEbrvtNgAeeeQRhg0bxq5duxgyZAiPPvpoqZ+/8sorrFy5kp07d7Js2bISt2ft9OnTrF+/nh9//LHwTGHx4sUcP36c3bt38+mnn1bowHYuc0aQm5EMgIdvIADx8fF8+OGHTJo0iVq1arF//349QJzmOko5cq8s48aNY/369Xh5eTFu3Dj69OlTOMS0Uornn3+etWvX4ubmxsmTJzl79izr1q3jjjvuwNfXl7y8PG6//fZ/rfdiQ0HbOuz0Pffcw4wZM1BKMW7cON59910mTpzIxo0bWbx4MQBDhw7lmWeeASjx86uvvprhw4czaNCgwm1fzIABA3BzcyM8PJyzZ88CsH79eu644w7c3NyoW7cuvXr1smldtrDrGYGI9BORAyJySET+1QAmhmnm8l0iUvLhwiXKyzTOCDxqBPDtt98SHh7Om2++WZhVdRLQNPuKiIhg27Zthe9nzpzJqlWriI2NBc4P8Qzw5ZdfEhsby9atW9mxYwdhYWFkZWUBXLTnnlKKiIgIduzYwY4dO9i9eze//PJL4fKyDDtdsL3bbruNtWvXlri8tM8/+ugjXnvtNU6cOEFkZCTx8fEX3ab1BFbKnK+h4Nke7JYIRMQdmAncBIQDg0UkvEixm4BW5mMMMNte8TQMgFOp+Tz67CsMGjSIRo0asWXLlhKnpdM0rWJdf/31ZGVlMXv2+f/mJfXESU5OJjQ0FE9PT9asWcOxY8cA6NGjB0uWLCEzM5PU1FR++OGHf323PENBBwQEkJqaWuLy9evX06JFCwCuuuoqFi5cCBgJ65prrin188OHD9OtWzdeeeUV6tSpw4kTJy66veJcc801fP/99+Tn53P27FmioqLK9P3S2LNp6ArgkFLqCICILAT6A9FWZfoDC8yR8f4UkWARqaeUOl3RwdQN9OGabzPZGruBd955hyeeeEIPEqdplUhEWLp0KU888QTvvPMOISEhhdM8ZmZmXlB2yJAh3HbbbXTp0oXIyEjatm0LQKdOnbjnnnsK2+6LO5Dz8vIq81DQvXr14q233iIyMrLwYvE333zD+vXryc/Pp2HDhsyfPx+AadOmMXLkSN59993Ci8Klff7000/z999/o5Sid+/edOjQgcaNG/9rexdz1113sWLFCi677DJat25Nt27dKmy4e7HX6YaIDAT6KaVGm++HAt2UUo9YlfkReEsptd58vwp4Vim1pci6xmCcMRAWFta5IOuWRWDyfuL/mE9C68GEtexQ3t2qdtLS0vD393d0GJVK73PxgoKCaNmyZSVFZH95eXm4X+S+IGeTnJxMUFAQ8fHx9OrVi19//bXYe5wOHTpEcnLyBZ/16tVrq1KqS3HrtechcXENZ0Wzji1lUErNAeYAdOnSRfXs2bMc4fQkKqgt95Tru9VXVFQU5ft7VV96n4u3b98+p7oWlpqa6lT7Y4ubb76Z1NRUcnJyePnll0tM7D4+PnTs2NHm9dozEcQAjazeNwROlaOMpmmaBixfvtwuyc+evYY2A61EpJmIeAH3AsuKlFkGDDN7D10JJNvj+oCmaQZ79jzRqoby/MZ2OyNQSuWKyCPASsAdmKuU2isiY83lHwHLgZuBQ0AGMMJe8Wiaq/Px8SE+Pp7atWvrwROdlFKK+Ph4fHx8yvQ9u3abUUotx6jsrT/7yOq1AsbZMwZN0wwNGzYkJiamsN9+dZeVlVXmCq+6s2WffXx8aNiwYZnWq/tPapqL8PT0pFmzZo4Oo8JERUWV6YKoM7DXPrvMWEOapmla8XQi0DRNc3E6EWiaprk4u91ZbC8iEgscK+fX6wBxFRhOdaD32TXofXYNl7LPTZRSIcUtqHaJ4FKIyJaSbrF2VnqfXYPeZ9dgr33WTUOapmkuTicCTdM0F+dqiWCOowNwAL3PrkHvs2uwyz671DUCTdM07d9c7YxA0zRNK0InAk3TNBfnlIlARPqJyAEROSQiE4tZLiIyzVy+S0Q6OSLOimTDPg8x93WXiGwQkWo/TdvF9tmqXFcRyTNnzavWbNlnEekpIjtEZK+I/F7ZMVY0G/5tB4nIDyKy09znaj2KsYjMFZFzIrKnhOUVX38ppZzqgTHk9WGgOeAF7ATCi5S5GfgZY4a0K4G/HB13JezzVUBN8/VNrrDPVuVWY4yCO9DRcVfC7xyMMS94Y/N9qKPjroR9fh5423wdAiQAXo6O/RL2uQfQCdhTwvIKr7+c8YzgCuCQUuqIUioHWAj0L1KmP7BAGf4EgkWkXmUHWoEuus9KqQ1KqUTz7Z8Ys8FVZ7b8zgDjge+Ac5UZnJ3Yss/3AYuVUscBlFLVfb9t2WcFBIgxyYI/RiLIrdwwK45Sai3GPpSkwusvZ0wEDYATVu9jzM/KWqY6Kev+jMI4oqjOLrrPItIAuAP4COdgy+/cGqgpIlEislVEhlVadPZhyz7PANphTHO7G3hMKZVfOeE5RIXXX844H0FxUy8V7SNrS5nqxOb9EZFeGIngGrtGZH+27PMHwLNKqTwnmZHLln32ADoDvYEawEYR+VMpddDewdmJLft8I7ADuB5oAfwqIuuUUil2js1RKrz+csZEEAM0snrfEONIoaxlqhOb9kdELgc+BW5SSsVXUmz2Yss+dwEWmkmgDnCziOQqpZZWSoQVz9Z/23FKqXQgXUTWAh2A6poIbNnnEcBbymhAPyQi/wBtgU2VE2Klq/D6yxmbhjYDrUSkmYh4AfcCy4qUWQYMM6++XwkkK6VOV3agFeii+ywijYHFwNBqfHRo7aL7rJRqppRqqpRqCiwCHq7GSQBs+7f9PXCtiHiIiC/QDdhXyXFWJFv2+TjGGRAiEga0AY5UapSVq8LrL6c7I1BK5YrII8BKjB4Hc5VSe0VkrLn8I4weJDcDh4AMjCOKasvGfZ4E1AZmmUfIuaoaj9xo4z47FVv2WSm1T0RWALuAfOBTpVSx3RCrAxt/51eB+SKyG6PZ5FmlVLUdnlpEvgZ6AnVEJAZ4GfAE+9VfeogJTdM0F+eMTUOapmlaGehEoGma5uJ0ItA0TXNxOhFomqa5OJ0INE3TXJxOBFqVZI4WusPq0bSUsmkVsL35IvKPua1tItK9HOt43Oy7X/B+uYgEl1K+vogsKuM2Cv4ue8wRN0tcv1k+UkRuLss2NNeju49qVZKIpCml/Cu6bCnrmA/8qJRaJCJ9galKqcvLuI6jQBd79mG33lcR+Rw4qJR6vZTyw82YHrFXTFr1p88ItGpBRPxFZJV5tL5bRP410qiI1BORtVZHzNean/cVkY3md78VkYsljbVAS/O7E8x17RGRx83P/ETkJzHGv98jIveIyKNAfWCNiKwxyx0VkToi8raIPGwV52QReVJEmoo55ryIuIvIuyKyWYwx5h+04c+yEXOwMRG5Qox5Jrabz23MO3FfAe4x/yb3mLHPNbezvbi/o+aCHD32tn7oR3EPIA9jILEdwBKMu+ADzWV1MO6qLDijTTOfnwReMF+7AwFm2bWAn/n5s8CkYrY3H3O+AuBu4C+Mwdt2A34YwxvvBToCdwGfWH03yHw+CtSx+vyouf2OwO9Wn0cDjYGmmGPOA2OAF83X3sAWoFkxcaZZ7d+3QD/zfSDgYb6+AfjOfD0cmGH1/TeA+83XwRhjEPk5+vfWD8c+nG6ICc1pZCqlIgveiIgn8IaI9MAYOqEBEAacsfrOZmCuWXapUmqHiFwHhAN/mENreGEcSRfnXRF5EYjFGKG1N7BEGQO4ISKLgWuBFcBUEXkbozlpXWk7opTaLiKhIlIfY+KURKXU8SLXPfoCl8v5WdSCgFbAP0VWV0NEdmAkka3Ar1blPxeRVhgjUXqWEE5f4HYRecp874ORlKrzeETaJdKJQKsuhmBUop2VUhazPd7HuoBSaq2ZKG4B/isi7wKJwK9KqcE2bONppVThxVsRuaG4QkqpgyLSGWO8lzdF5Bel1CsXWfciYCBQF2NylaIEGK+UWnmR9WQqpSJFJAj4ERgHTMMYb2eNUuoOM8FElfB9Ae5SSh24yHY0F6KvEWjVRRBwzkwCvYAmRQuISBOzzCfAZxjT/f0JXC0iBW3+viLS2sZtrgUGmN/xw5jkZp15ZJ+hlPoCmGpuByAVozmqOAsxRs4ciJEUiloJPGSezSAirc1tFksplQw8CjxlficIOGkuHm5VtGhMK4HxYp4eiUjHkrahuQ6dCLTq4kugi4hswTg72F9MmZ7ADhHZjtGO/6FSKhajYvxaRHZhJIa2tmxQKbUN49rBJoxrBp8qpbYD7YFNZhPNC8Br5lfmAD8XXCwusq69GBXySVX8kMGfYlw72GZeQP6Yi5yxm7HsxEgw72CcnfyBcf2gwBogvOBiMcaZgyewy9zOqxf7O2jOT3cf1TRNc3H6jEDTNM3F6USgaZrm4nQi0DRNc3E6EWiaprk4nQg0TdNcnE4EmqZpLk4nAk3TNBf3/5QiRU/+WdgKAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEWCAYAAABsY4yMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAA3/UlEQVR4nO3dd3xUVdrA8d+TSW+0FDokSG+BIE0poetiB7viqou6lt11dW1rgdf11V1f117QRSwoKAqii4IoiCg1gPReAwFCSUhCes77xx0gCenJ5GZmnu/ncz8zc9t5zk3yzM25554rxhiUUkp5Hh+7A1BKKeUamuCVUspDaYJXSikPpQleKaU8lCZ4pZTyUJrglVLKQ2mCd2MiMkhEthX53FFE1opIuog8UEtl7BWREbWxryqW+4uI9KrhPh4XkfdqK6baICK3icjSIp8zRCS2MutWo6xvRWRCdbevQjk1irOCffcQkV9dsW9voAneDZSVZI0xPxtjOhaZ9TdgsTEmzBjzamWSs4iEi8jLIrLfmWx2Oj9H1HY9nOUtFpE7K1jnMiDdGLO2JmUZY54zxpRblt2MMaHGmN013Y+IPCMiH5fY9yXGmA9quu/aVFqc5THGrAdSnb8Tqoo0wXuWNsCmyq4sIv7AD0BXYAwQDgwEjgN9azMwsVT29+1u4KPaLF+5tenAXXYH4ZaMMTrV8wnYC4woZf5QIMn5/kegAMgGMoBPgUIgy/n5b6VsfydwBAitoOyHgPVAGjATCHQuawR8A6QAJ53vWxbZdjHwD+AXZxzTS8T4einl+TvXLbqfacCzpdXb+fkR4CCQDmwDhjvnPwN87HzfFjDABGA/cAx4osg+goAPnPXYgvXfUFIZx+Rt4MUS874CHnS+fxTY5YxnM3BVkfVuA5YW+WyAC5zvmwBzgVPASuB/Sqz7CnDAuTwRGOScPwbIBfKcx/W3Isf/Tud7H+DvwD7gKPAh0KAyx6aU+td2nL93HvN0YDdwV4nyWjh/JwLs/lt0t8n2AHSqxA+pEgne+fnsH3R52xVZPgP4oBJlrwSaA42df4h3O5c1Aa4BgoEw4HNgTol49mP9h+AL+JWMsZTyugKZJeZNo4wED3R0JpPmzs9tgXbO989wfoJ/FyuZ9wRygM7O5c8DP2F9abXE+kIrK8EPdpYpzs+NnAnoTAzjncfLB7gOyASaOZfdRtkJfgbwGRACdMP60iq67s3OY+4L/BU4zLkv27N1Le33Abgd2AnEAqHAl8BHlTk2Zfze1GacvwPaAQIMAU4DvUuscwroYfffortN2kTj3ZoAyZVY71VjzCFjzAngayAOwBhz3BjzhTHmtDEmHetsfUiJbacZYzYZY/KNMXmVKKsh1plcZRUAAUAXEfEzxuw1xuwqZ/1JxpgsY8xvwG9YyQzgWuA5Y8xJY0wS8Go5+/gZKyEOcn4eBywzxhwCMMZ87jxehcaYmcAOKmjyEhEH1pflU8aYTGPMRqz/KM4yxnzsPOb5xpj/c9a7Yym7K81NwEvGmN3GmAzgMeB6EfEtsk5Zx8alcRpj/muM2WUsPwELOHdsz0jH+t1QVaAJ3rsdB5pVYr3DRd6fxjoDRESCReQdEdknIqeAJUBDZxI440AVYzqJ9d9ApRhjdgJ/xjozPCoiM0SkeTmblFoXrDPuorGWGbexTilnADc4Z92I1fwEgIjcKiLrRCRVRFKxznIrumgdiXXGW7TcfUVXEJG/isgWEUlz7rdBJfZ7RvMS+9vnLC+6yLyyjo1L4xSRS0RkuYiccK5/aSnrhwGpZe1DlU4TvGeraKjQhcBoEQmp5v7/inVm1s8YE47VdAHWv9plxVBRTDuwrsm2KDIvE6sZ6IymxXZozCfGmIuxLjIb4IXKhV9MMlbTzBmtKlj/U2CciLQB+gFfYAXeBqup4z6giTGmIbCR4sekNClAfolyW595IyKDsK41XAs0cu43rch+Kzquh7COT9F952Ndg6mKWo1TRAKwjt2LQLRz/XlF1sf5he2PdX1FVYEmePfhJyKBRSbfijfhCFaba1k+wjoT+0JEOomIj4g0cfYfv7QS+w/DantOFZHGwNM1jcnZjLOQ4k0964BLRaSxiDTFOmMHzvb9H+ZMFNnOeAoqEUdJnwGPiUgj55fLfeWtbKwunCnAe8B8Y0yqc1EIVhJLccb3e6wz+HIZYwqw2sWfcf5n1AXroucZYViJNQXwFZGnsHo9nXEEaFtOT6VPgb+ISIyIhALPATONMfkVxebiOP2xmnBSgHwRuQQYVaLYocCPxpicqsSqNMG7k3lYyevM9Ewltvlf4O/OpoKHSi50/sGMALYC33OuV0QEsKIS+38Z66LcMWA58F0ltnkF68z3pIiU1c79DnBLkc8fYbUJ78Vqn51ZZFkA1gXSY1hNDFHA45WIo6TJQBKwB+sLZhbWhcbyfIp1/D45M8MYsxn4P2AZVjLrjtWLqDLuw2oWOYx1Yfn9IsvmA98C27GaRLIp3kzyufP1uIisKWXfU7GO4xKsOmYD91cyLpfF6bx28wDWF+xJrOauuSXKuwmr55KqojO9AJSqV5x3Rt5vanizUw3Kvwe43hhT8qKxqkMi0h2YYowZYHcs7kgTvFKAiDTDajpaBrQH/ovVT/9lO+NSqiYq046rlDfwx2oaisHqrTEDeNPOgJSqKT2DV0opD6UXWZVSykPVqyaaiIgI07ZtW7vDsEVmZiYhIdXtju7+tP5af61/9eqfmJh4zBgTWdqyepXg27Zty+rVq+0OwxaLFy9m6NChdodhG62/1l/rP7Ra24rIvrKWuTTBi8herDEkCoB8Y0wfV5anlFLqnLo4g08wxhyrg3KUUkoVoRdZlVLKQ7m0m6SI7MG6/dgA7xhjppSyzkRgIkB0dHT8jBkzXBZPfZaRkUFoaGmD93kHrX/16y8ihISE4HA4Kl65njLGIFLReGyeqzL1LygoIDMzk5I5OyEhIbGs5m9XJ/jmxphDIhKFNdbJ/caYJWWt36dPH6MXWb2T1r/69d+zZw9hYWE0adLEbZNkeno6YWGVHiXa41RUf2MMx48fJz09nZiYmGLLRKTMBO/SJpoiD0A4Csymlp/zqZSC7Oxst07uqmIiQpMmTcjOzq7Sdi5L8CISIiJhZ95jDQG60VXlKeXNNLl7vur8jF15Bh8NLBWR37CGoP2vMaYyw8lWTV4W/PIq7Pm51netlFLuzGUJ3vnsx57Oqasx5h8uKUgcsOwNWPqSS3avlKqYw+EgLi6Orl270rNnT1566SUKCwurta+nnnqKhQsXlrn87bff5sMPP6zyfufPn09cXBxxcXGEhobSsWNH4uLiuPXWW6sVpzuoV3eyVouvP/T9A/z4P3B0C0R1tjsipbxOUFAQ69atA+Do0aPceOONpKWlMWnSpCrva/LkyeUuv/vuu6sTIqNHj2b06NEADB06lBdffJE+fYpfmywoKHDr3kgleUY/+D63g28QLNfRXZWyW1RUFFOmTOH111/HGENBQQEPP/wwF154IT169OCdd945u+4///lPunfvzsCBA3n00UcBuO2225g1axYAjz76KF26dKFHjx489JD1ULJnnnmGF198EYB169bRv39/evTowVVXXcXJkycBK4E/8sgj9O3blw4dOvDzz2U34bZt25bJkydz8cUX8/nnn7NgwQIGDBhA7969GT9+PBkZGQAkJiYyZMgQ4uPjGT16NMnJybV/8GqZ+5/BAwQ3hp7Xw7pPYPjTEFLZB80r5Vkmfb2JzYdO1eo+uzQP5+nLulZpm9jYWAoLCzl69ChfffUVDRo0YNWqVeTk5HDRRRcxatQotm7dypw5c1ixYgUFBQXk5eUV28eJEyeYPXs2W7duRURITU09r5xbb72V1157jSFDhvDUU08xadIkXn75ZQDy8/NZuXIl8+bNY9KkSeU2+wQGBrJ06VKOHTvG1VdfzcKFCwkJCeGFF17gpZde4rHHHuP+++/nq6++IjIykpkzZ/LEE08wderUKh2XuuYZCR6g/z2Q+D6sngpD/mZ3NEp5vTP32CxYsID169efPStPS0tjx44dLFy4kN///vcEBweTnp5O48aNi20fHh5OYGAgd955J7/73e8YO3ZsseVpaWmkpqYyZIj1VMUJEyYwfvz4s8uvvvpqAOLj49m7d2+5sV533XUALF++nM2bN3PRRRcBkJuby4ABA9i2bRsbN25k5MiRgNWU06xZs+ocljrlOQk+siNcMAJWvgsX/Ql8A+yOSKk6V9UzbVfZvXs3DoeDqKgojDG89tprZ9u/z/juu+/K7frn6+vLypUr+eGHH5gxYwavv/46P/74Y6VjCAiwcoDD4SA/P7/cdc8M1WuMYeTIkXz66afFlm/YsIGuXbuybNmySpdfH3hGG/wZ/f8ImUdh45d2R6KU10pJSeHuu+/mvvvuQ0QYPXo0b7311tkmmO3bt5OZmcmoUaOYOnUqp0+fBqwmmaIyMjJIS0vj0ksv5eWXXz57EfeMBg0a0KhRo7Pt6x999NHZs/nq6t+/P7/88gs7d+4E4PTp02zfvp2OHTuSkpJyNsHn5eWxadOmGpVVFzznDB6g3TCI7AzL37Da5PXmD6XqRFZWFnFxceTl5eHr68stt9zCgw8+CMCdd97J3r176d27N8YYIiMjmTNnDmPGjGHdunX06dMHX19fxo4dy3PPPXd2n+np6VxxxRVkZ2djjOHf//73eeV+8MEH3H333Zw+fZrY2Fjef//9GtUjMjKSadOmccMNN5CTkwPAs88+S4cOHZg1axYPPPAAaWlp5Ofn8+c//5muXevHf0xlqVfPZK2VsWgSP4CvH4AJ30DMoNoJrA7oWCxa/+rWf8uWLXTu7N7dg3UsmsrVv7SftW1j0diix7UQ3ES7TCqlvJ7nJXi/IKtf/LZv4fguu6NRSinbeF6CB7jwTvDxhRXvVLyuUkp5KM9M8GFNofs4WPsxZKXaHY1SStnCMxM8WF0m8zJhTdUHJVJKKU/guQm+WQ9oOwhWToGC8m9yUEopT+S5CR6s4QvSDsCWuXZHopTHO3LkCDfeeCOxsbHEx8czYMAAZs+eXe39FR1UrKIhhMuzbt065s2bd/bztGnTiIyMPDu88bhx487ebFUbSpY3d+5cnn/++Vrbf1V4doLvMAYaxWiXSaVczBjDlVdeyeDBg9m9ezeJiYnMmDGDpKSkYutVNGRAWSZPnsyIESOqtW3JhAvW2DPr1q1j06ZN+Pv7M3PmzGrtuzLlXX755WdHyqxrnp3gfRzWWXzSKjiwyu5olPJYP/74I/7+/sXGam/Tpg33338/06ZNY/z48Vx22WWMGjWKjIwMhg8fTu/evenevTtfffXV2W3+8Y9/0LFjR0aMGMG2bdvOzi86hHBZw/aWNkRwbm4uTz31FDNnziQuLu68RJ6fn09mZiaNGjUCYN++fQwfPpwePXowfPhw9u/fX+78zz//nG7dutGzZ08GDx5cannTpk3jvvvuO1uPBx54gIEDBxIbG3u2ToWFhfzxj3+ka9eujB07lksvvfTssprwrKEKShN3E/z4D+ssvlXNbmNWqt779lE4vKF299m0O1xSfhPDpk2b6N27d5nLly1bxvr162ncuDH5+fnMnj2b8PBwjh07Rv/+/VmzZs3Zs/61a9eSn59P7969iY+PL7afvLy8coftLW2I4MmTJ7N69Wpef/11wGqimTlzJkuXLiU5OZkOHTpw2WWXAXDfffdx6623MmHCBKZOncoDDzzAnDlzypw/efJk5s+fT4sWLUhNTcXf37/U8opKTk5m6dKlbN26lcsvv5xx48Yxd+5c9u7dy4YNGzh69CidO3fm9ttvr9KPqTSefQYPEBAK8bfC5q8g9YDd0SjlFe6991569uzJhRdeCMDIkSPPDgdsjOHxxx+nR48ejBgxgoMHD3L06FF+/vlnrrrqKoKDgwkPD+fyyy8/b79Fh+2Ni4vj2WefLdYMVNkhgs800Rw+fJju3bvzr3/9C7C+iG688UYAbrnlFpYuXVru/IsuuojbbruNd999l4KCgkodmyuvvBIfHx+6dOnCkSNHzu5//Pjx+Pj40LRpUxISEiq1r4p4/hk8QN+J1nNbV06BUf9jdzRKuU4FZ9qu0rVrV7744ouzn9944w2OHTt29pF4Z4bjBZg+fTopKSkkJibi5+dH27Ztyc7OBih3+GCwvhzKG7a3KkMEnynvsssu47XXXiu1nbyseM7Mf/vtt1mxYgX//e9/iYuLO2/Ey/JihHNj5rtqTDCPOINPSc8p/wA1bA2dL7cGIsvJqLvAlPISw4YNIzs7m7feeuvsvLJ6pqSlpREVFYWfnx+LFi1i3759AAwePJjZs2eTlZVFeno6X3/99XnbVmfY3rCwMNLT08tcvnTpUtq1awfAwIEDmTFjBmB9EV188cXlzt+1axf9+vVj8uTJREREcODAgQrLK82AAQP44osvKCws5MiRIyxevLhK25fF7RP8ycxcrnh9KY/P3kBBYTlJfsC9kJNmPdZPKVWrRIQ5c+bw008/ERMTQ9++fZkwYQIvvPDCeevedNNNrF69mj59+jB9+nQ6deoEQO/evbnuuuuIi4vjmmuuYdCg80eD9ff3Z9asWTzyyCP07NmTuLg4fv3113JjS0hIYPPmzcUusp65CNqjRw/Wrl3Lk08+CcCrr77K+++/T48ePfjoo4945ZVXyp3/8MMP0717d7p168bgwYPp2bNnqeVV5IorrqBly5Z069aNu+66i379+tGgQYNKbVsuY0y9meLj401VFRYWmhfnbzVtHvnG3Ds90eTmF5S98pRhxrwSZ0xBOevYZNGiRXaHYCut/6Jqb7t58+baC8Qmp06dsjsEW506dcqkp6cbY4w5duyYiY2NNcnJyeetV9rPGlhtysipbt8GLyL8dVRHwgJ9eW7eVk7nFvDmTb0J9HOcv/KAP8Ks22HHfOh4Sd0Hq5RSZRg7diypqank5uby5JNP0rRp0xrv0+0T/BkTB7cjNMCPJ+ZsYMLUlbw3oQ9hgX7FV+p8OYS3sC64aoJXStUjtdXuXpTbt8EXdWO/1rx8XRyJ+05y83srOJmZW3wFh5/Vo2bvz5C83p4glXIBU4+ezKZcozo/Y49K8ABXxLXgnVvi2XI4neumLOPIqeziK8RPAL9gWP5W6TtQys0EBgZy/PhxTfIezBjD8ePHCQwMrNJ2HtNEU9TwztFM+/2F/OGD1Yx/exnT7+xHq8bB1sKgRtbdrWs+gBHPQFi0rbEqVVMtW7YkKSmJlJQUu0Optuzs7ConL09SmfoHBgbSsmXLKu3XIxM8wMB2EUz/Q38mTF3JuLd/5eM7+tE+2vlQ2/73wKp3YfV/IOFxewNVqob8/PyIiYmxO4waWbx4Mb169bI7DNu4qv4e10RTVFyrhnx21wAKDVz7zjI2JKVZC5q0s0aaXPUfyMsufydKKeWmPDrBA3RsGsbndw0g2N+XG99dzso9J6wF/f8Ip4/Bhs/sDVAppVzE4xM8QNuIEGbdM4Co8ABunbqCxduOQsxgiO4Gy94EvTillPJALk/wIuIQkbUi8o2ryypPswZBfHbXANpFhvKHD1czb+Nh6yw+ZQvsXmRnaEop5RJ1cQb/J2BLHZRToSahAXzyh/70bNmQ+z5Zw6zc/hASqV0mlVIeyaUJXkRaAr8D3nNlOVXRIMiPD+/oy0UXRPDQ7K2sib4GdiyAlO12h6aUUrVKXHlzhIjMAv4XCAMeMsaMLWWdicBEgOjo6PgzQ3K6Wl6h4e3fcth75ATLAx8grUkcG7s9DmLPZYmMjAxCQ0NtKbs+0Ppr/bX+1at/QkJCojGmT6kLyxqFrKYTMBZ40/l+KPBNRdtUZzTJmsjLLzB/mbnWPPP4vcY8HW7Sv3++TssvSkdTXGR3CLbS+i+yOwRb1aT+lDOapCtPVy8CLheRvcAMYJiIfOzC8qrM1+HDi+N6Ej7kfr4pHEDQz//L/LmfkF9QaHdoSilVYy5L8MaYx4wxLY0xbYHrgR+NMTe7qrzq8vER/jKqI13v/pBD/m24MPFhbn/lS1btPWF3aEopVSNe0Q++MmKaR9Hyri8I84PH0p/j5rd/4sHP1pGSnmN3aEopVS11kuCNMYtNKRdY6xuJuAC/cVPobHbxWevZfP3bIYa9uJj3f9mjzTZKKbejZ/AldfodDPorPY9+xa+jkohr3ZBJX29m7GtLzw1zoJRSbkATfGkSnoDYBCKXPMGHo315++bepGfnc+07y3hw5jqOpusAZUqp+k8TfGl8HHDNfyA0Gvl8AmNi/Pn+wcHcm9COr9cfYviLP2mzjVKq3tMEX5aQJnDth5BxFL64nWBf4eHRnZj/58HabKOUcgua4MvTojf87kXYvRh+fBaA2MhQPry973nNNuc9/1UppWzmsU90qjW9b4Wk1bD0JWgRD53HIiKM6daMwR0ieWPRTqYs2Y2I8H/X9rQ7WqWUOkvP4Cvjkn9C814w5x44tvPs7GB/Xx4e3YnLe7bg+82HydM2eaVUPaIJvjL8AuHaj8DHF2beBDkZxRaP7hrNqex8VuzW9nilVP2hCb6yGraCcVPh2HaYe3+xp0ANah9JoJ8PCzYftjFApZQqThN8VbRLgGFPwqYvYfmbZ2cH+TsY0iGSBZuOUFioj/9TStUPmuCr6uK/QKexsOBJ2PvL2dmjuzbl8KlsNhxMszE4pZQ6RxN8VYnAlW9B4xj4/DY4lQzAsE5ROHyE+Zu0mUYpVT9ogq+OwHC47mPIzYTPJ0B+Lg2D/ekf21gTvFKq3tAEX11RneGK1+HACljwBACjujRlV0omO49mVLCxUkq5nib4muh2NQy4D1ZOgQ2zGNklGkB70yil6gVN8DU14hlo3hsW/J3mwYYeLRuwYNMRu6NSSilN8DXm8IPR/4D0ZFj+JqO7NmXdgVQOp+mQwkope2mCrw1tBkKHS+CXV7gk1g+A77foWbxSyl6a4GvLiGcgN4OYzW8RGxHCAu1No5SymSb42hLVCeJuQla9x/h2hSzbdZy003l2R6WU8mKa4GtTwuPg48t16dPILzQs2nbU7oiUUl5ME3xtCm8O/e+h8e6vGBR6UG96UkrZShN8bbvoTxDUiKcDZ/LT9hSy8wrsjkgp5aU0wde2oIYw+GEuyFhN7/x1LN1xzO6IlFJeShO8K1x4J6ZBax73n8GCjYfsjkYp5aU0wbuCbwAy/Em6sAffLV+Sr4/yU0rZQBO8q3QbR1rDLtxT8CmJu/Viq1Kq7mmCdxUfH/zHTKaVTwqpP71ldzRKKS+kCd6FgjqNZFNgPP2TpmKyTtodjlLKy2iCd7GDff5GAzI4Nv9fdoeilPIymuBdLL5/Al8VDKTh+vfglPaoUUrVHZcleBEJFJGVIvKbiGwSkUmuKqs+axIawIKmEzGFBbDoObvDUUp5EVeewecAw4wxPYE4YIyI9HdhefVWrx49+Sh/JGbddDi61e5wlFJewmUJ3ljOPJzUzzkZV5VXn43u2pTX868gzycYFj5jdzhKKS8hxrgu54qIA0gELgDeMMY8Uso6E4GJANHR0fEzZsxwWTx2evKXLH5v5nB7/gzWxj1HWsOuxZZnZGQQGhpqU3T20/pr/bX+1at/QkJCojGmT2nLXJrgzxYi0hCYDdxvjNlY1np9+vQxq1evdnk8dnh54Xbe+WEjG5s8hqNhK7jjexA5u3zx4sUMHTrUvgBtpvXX+mv9h1ZrWxEpM8HXSS8aY0wqsBgYUxfl1UejujQlywSwOuZuSFoFW762OySllIdzZS+aSOeZOyISBIwAvPYKY+dmYbRqHMSUtP4Q0RF+mAQF+sQnpZTruPIMvhmwSETWA6uA740x37iwvHpNRBjdpSk/70rl9JC/w/GdsOZDu8NSSnkwV/aiWW+M6WWM6WGM6WaMmeyqstzFqK5NyS0o5MfCeGg9ABY/DzkZFW+olFLVoHey1qH4No1oEuLP/M1HYeRkyDwKy96wOyyllIfSBF+HHD7CiM7RLNp6lJxm8dD5Mvj1VchIsTs0pZQH0gRfx0Z3iyYjJ59lu47D8KchLwuW/NPusJRSHkgTfB0b2C6CEH8H8zcdgYj20PtWWD2VoNPJdoemlPIwmuDrWKCfg6Edo/h+8xEKCw0MfRQc/rQ6MNvu0JRSHkYTvA1GdY3mWEYOaw+chLCmEJtAo5Pr7A5LKeVhNMHbIKFTFH4OYcGmI9aM2CEEZR+Bk3ttjUsp5Vk0wdsgPNCPAe0imL/pMMYYiBliLdj9k72BKaU8iiZ4m4zqEs3e46fZfiQDIjuS498I9iyxOyyllAfRBG+TUV2iAViw6TCIkNqwu5Xg62B0T6WUd9AEb5Oo8EB6tW7I/M2HATjZqKd1Z+vRLTZHppTyFJrgbTS6a1M2HjzFwdQsTjbqYc3co+3wSqnaUakELyJ/qsw8VTWjuzYFrGaanMAoaBSjF1qVUrWmsmfwE0qZd1stxuGVYiJCaB8VWqy7JPt+gYJ8ewNTSnmEchO8iNwgIl8DsSIyt8i0CDheNyF6ttFdm7Jy7wkycg3EDIacU5C8zu6wlFIewLeC5cuBZCAC+L8i89OB9a4KypuM6hrN64t2svZoPmMvOtMffjG0LPURi0opVWkVJfhZxph4ETltjNHGYRfo3qIBLRoGsepwLoREQHQ360Lr4IfsDk0p5eYqSvA+IvI00EFEHiy50BjzkmvC8h4iwuVxzXnnp12kpOcQGTMEVr1nDSPsF2R3eEopN1bRRdbrgWysL4KwUiZVC67u1YJCA3N/O2RdaC3IgQMr7A5LKeXmyj2DN8ZsA14QkfXGmG/rKCav0z46jLbhPny5Jok77hoIPr5Wd8nYoXaHppRyY+UmeBG52RjzMdBFRDqXXK5NNLVnYHNfPtl6iu2p0KFFvI5Lo5SqsYqaaEKcr6Gc3zwT6sK4vE7/Zr44fIQv1xy0ukseWgPZaXaHpZRyY+UmeGPMO87XSSUn4FSdROglwgOEIR0imbP2IAVtB4MphL2/2B2WUsqN1WQsmvN61aiaubp3Cw6fymZFXjvwDdJxaZRSNVKTBC+1FoUCYETnaMICfPnit2PQur+OS6OUqpGaJHgduLyWBfo5uLR7M77dmExum0GQsgXSj9gdllLKTVU0Fk26iJwqZUoHmtdRjF7l6t4tOJ1bwK8F3awZ2ptGKVVNFV1kDTPGhJcyhRljKroLVlXDhW0b06JhEFN3h0FgA22HV0pVmz7wo57x8RGu7t2CpbtOktNioCZ4pVS1aYKvh65yDl2w2tEDUvfDiT12h6SUckOa4Ouh2MhQerZqyLTkNtYMPYtXSlWDJvh66preLfg+pQF5wVHaXVIpVS0uS/Ai0kpEFonIFhHZpM9wrZqxPZrj6+PD1qDeVk+awkK7Q1JKuRlXnsHnA381xnQG+gP3ikgXF5bnURqH+JPQKYovU9vB6WNWn3illKoClyV4Y0yyMWaN8306sAVo4aryPNHVvVowP7Oj9UGbaZRSVSTGuP6GVBFpCywBuhljTpVYNhGYCBAdHR0/Y8YMl8dTH2VkZBAaWnyAzrxCw59+PM0P/g/i16gVG7v/3aboXK+0+nsTrb/Wv7r1T0hISDTGlPoQZ5ffrCQiocAXwJ9LJncAY8wUYApAnz59zNChQ10dUr20ePFiSqv7lWkb+GltN65LX87QQReDwzPvLyur/t5C66/1d0X9XdqLRkT8sJL7dGPMl64sy1Nd3asFS/K7ILkZ1hjxSilVSa7sRSPAf4At+uSn6otv04gDDZz/fWk7vFKqClx5Bn8RcAswTETWOadLXVieRxIRhvXuzKbCNuTs+NHucJRSbsRlDbrGmKXomPG14qpeLfj+p650Ovg95GWBX5DdISml3IDeyeoG2kaEcDSiHw6Th9m/3O5wlFJuQhO8m2jXZzR5xsGx9QvsDkUp5SY0wbuJMb3bsd5cQO6ORXaHopRyE5rg3UTDYH+Sm/Sj6elt5GeetDscpZQb0ATvRqJ6jsJBIVuWz7M7FKWUG9AE70biBowkC3+Ob1hodyhKKTegCd6N+AcEkhQWR4uTK0nPzrM7HKVUPacJ3s0EdxxGe0li0aoNdoeilKrnNMG7mea9xgCwL/FbmyNRStV3muDdjDTrQbZvONHHVpB08rTd4Sil6jFN8O7Gx0Fhm4sZ6NjEV2sP2h2NUqoe0wTvhoI7DqOlHGN54mrq4oEtSin3pAneHcUMAaBl6io2HEyzORilVH2lCd4dRbSnMLQpgxyb+HKNNtMopUqnCd4dieATO5RBflv4el0SeQWFdkeklKqHNMG7q9ghhBWkEZW1i5+2pdgdjVKqHtIE766c7fAjA7cyW3vTKKVKoQneXTVoAU0uYGzYdr7fcoS0LB26QClVnCZ4dxYzmHZZ6ynMz2XehmS7o1FK1TOa4N1ZzBAceZmMbZLMR8v2aZ94pVQxmuDdWcxgQLizxQE2J5/il53H7Y5IKVWPaIJ3Z8GNoWl3umSvJSosgHeW7LI7IqVUPaIJ3t3FDsHn4Cru7B/NzzuOsemQ3tmqlLJognd3MUOhIJebmiUT4u/g3SW77Y5IKVVPaIJ3d20GgI8vIbvmcUPf1ny9PlmHEVZKAZrg3Z9/CPS6BRLf595GKxBg6tK9dkellKoHNMF7gkv+CbEJNPrhIR5qd5AZq/aTdlpvfFLK22mC9wS+/nDthxDZmT8cfpq2ebv4eMU+u6NSStlME7ynCAyHmz7DEdSI6cEv8u3SlWTnFdgdlVLKRprgPUl4c7h5FmE+efw771n+u3Kz3REppWykCd7TRHXGceMntPU5wgU/3kVhbrbdESmlbOKyBC8iU0XkqIhsdFUZqnQSM5j1fZ6nZ8Emjnz0eyjUB4Io5Y1ceQY/DRjjwv2rcvS85A7e9L2VZgfmwcKn7Q5HKWUDlyV4Y8wS4ISr9q/K5+vwIXjoX/ggfyT8+iqseMfukJRSdUxcOcSsiLQFvjHGdCtnnYnARIDo6Oj4GTNmuCye+iwjI4PQ0NBa3WdOvuGhnzJ4L+Bl+uYnsqnrIxyLHFCrZdQWV9TfnWj9tf7VrX9CQkKiMaZPact8axRVLTDGTAGmAPTp08cMHTrU3oBssnjxYlxR942F27ht0b2sbf0a3ba9DP2HQ6u+tV5OTbmq/u5C66/1d0X9tReNh5swsC0FjiBebDLJ6kb5yXVwbKfdYSml6oAmeA8XERrAuPiWfLg+k+NXfQriA9OvgYwUu0NTSrmYK7tJfgosAzqKSJKI3OGqslT5/jAolryCQt7fLHDjZ5B+BD65FnIz7Q5NKeVCruxFc4Mxppkxxs8Y09IY8x9XlaXKFxMRwqgu0Xy0fB+ZkT1h3FRIXgezboeCfLvDU0q5iDbReIm7hrQjLSuPz1YfgE6XwqUvwvbvYN5DoA/rVsojaYL3Er1bN+LCto147+c95BcUwoV3wMV/gcT3YelLdoenlHIBTfBeZOLgdhxMzeK/G5KtGcOegu7Xwg+T4dfXtLlGKQ+jCd6LDO8URbvIEKYs2Y0xBnx84Io3oMMlsODv8PbFsHOh3WEqpWqJJngv4uMjTBwcy6ZDp/hl53Frpq8/3PApXDcd8rPh42tg+nhI2WZvsEqpGtME72Wu7NWCyLAA3lmy69xMEeg8Fu5dAaOehf0r4M0BMO9hOK3DCSnlrjTBe5kAXwe3DWzLzzuOsfnQqeILfQNg4P3wwBqIvw1WvQevxsGyNyA/145wlVI1oAneC93crw0h/g6mFD2LLyokAsa+BPf8Ci3iYf7j8GZ/2DpPu1Qq5UY0wXuhBsF+XN+3NV+vT+ZgalbZK0Z1hpu/hBs/Bx8HzLgBPrwcDuszXJRyB5rgvdTtF8cAMHXpnvJXFIEOo6yz+Uv+BYc3wDuDYO4DkHG0DiJVSlWXJngv1aJhEJf3bM6nK/eTdjqv4g0cftBvIjywFvrdA+umw6u94eeXIE+f+6pUfWT7ePDKPn8YFMvstQf5eMU+7k24oHIbBTWCMc9Bn9vh+yfhh0nW3bCdxgJS7VgiT4WAGWL9x6CUqhWa4L1Yl+bhDGofwbRf93LnoBgCfB2V3zjiAqv//O7FsPAZWPNR9QMpzKdrfha8/zOMeR6ax1V/X0qpszTBe7m7h7TjpvdW8NScTfSNaUyzhoE0bxBE0waBBPpVIuHHDoWJi2sWRGEB22Y8ScekmTBlKPS+xRpGITSyZvtVystpgvdyA9s1YUTnaGauPsDM1QeKLWsc4k+zBoE0axBE84bFX5s1CCQ6PBB/31q4jOPjILn5KDpe9TdY8i9Y8TZsmgNDHoG+E627bZVSVaYJ3suJCO9N6EN2XgHJadkkp2ZxqOhrWhYHTpxm5Z7jnMrOL7Gt9cSo5g0C6dmqIZd0a0bfmMY4fKrZjh7UEEb/w7rJ6rvHYMETVvv+6P+1evIopapEE7wCINDPQUxECDERIWWuk5GTz+G0LA6lWon/zOvB1Cw+W32AD5ftIyLUn1Fdm/K77s3oF9MYX0c1zvAj2sPNs2D7Apj/GHwyHtqPgtHPWcuUUpWiCV5VWmiALxdEhXFBVNh5y07n5rN4WwrzNiQzZ+1BPlmxn0bBfozu2pRLujdjYLsm+FU12XcYZbXxr5wCP71g3U3b724Y8jcIbFA7lVLKg2mCV7Ui2N+XS7s349LuzcjKLeCn7Sl8uzGZb9YnM2PVARoE+TGySzS/696Miy6IqHzbva8/DLwPelwLP/6PNS7ObzNg+FPQ62brDtuqyM20RspM2QYpW89NeVnWl0ZAOASGl3gtMv+8dZyfHfqnpOof/a1UtS7I38GYbk0Z060p2XkFLN1xjHkbkpm/6TCzEpMIC/RlZOdoLunejEHtIyrXWyc0Ci5/DfrcAd89Cl8/YA2GdskL0Gbg+evnpEPK9uJJPGUrpO4/t47DH5q0h+a9ISAUsk9BzinrNS3p3Oe80xXHF9UV+t8D3ceDX2DlD5ZSLqQJXrlUoJ+DEV2iGdElmpz8An7deZx5G5JZsPkIX649SIi/g+Gdo/HPymULZQx+VkwYxLzOBSELGLD7ZULfv4QdkaNIatyfRpl7aHx6F40ydxOWc/jsFgXix8ngtpwM6cyJtmM5GRLDyZB2pAW2xPgU+RMIL71En8I8/AoyCchPxz8/4+wUUOB8zT9FTMqPRMy9j9PfPsXGFteyqfl4sv0bVfo47d5d2fq7RqvGQYzoHF25L1vlNjTBqzoT4OsgoVMUCZ2ieK6gkGW7jvPtxmTmbzrCicw82L61CntrQyDPc7fv19x99Gvapywgx/ix0zRnjYllR+FgdpgW7DAt2W+iKMhywPGi22cDO6tRCwHCnFNRgxnos4k7Cr5l+N636bnnP3xZcDFTCy5hh2lZuV1Xqf61LyzQl8t6NmdcfEt6tWqI6F3Fbk8TvLKFn8OHwR0iGdwhkn9caVi4aDGDBw+uxp6ugMxj5OSkYRq2pZ2Pg3bAmNoOuFIuAR4i59h2HCvf5voNM7ghfxEFscMo6PdHCmMSyhyKYcmSJdWsf80ZA2v3n2RWYhJfrknikxX7aRcZwrj4VlzVqwVNG2iTk7vSBK9s5+Mj+Duk+s0DDaOB6FqNqUaadYYrXoERT0HiVBwr38Xx6TiI7AwD/mg96LxEO32N6l8LBl4QwcALIph0RVfmbUhmVmISL3y3lX/N38qg9pGMi2/JyC7ahONuNMEr5SohTWDwwzDwAdj4pdUDaO79sHASXHinNdWz4RjCAv247sLWXHdha/Ycy+SLxCS+WJPE/Z+uJTzQl8vjmjMuvhU9WzbQJhw3oAleKVfzDYC4G6Dn9bBnCSx/E356Hpb+2+r+OeBeuyMsVUxECA+N7shfRnZg2a7jfJ54gM9XJ/Hx8v1cEBXKuPiWXN2rBVHh2oRTX2mCV6quiEDsEGs6tsNK9Os+hbUfER/aDjKGQLM4azTNyM71Zgweh49wcfsILm4fwansPP673mrCef7brfzzu60M6RDJ8M7RtGocTIuGQbRsFKRNOfWEJnil7BDRHsb+G4Y9CYnvk5/4JWyYBaunWssd/hDd1Znwe9WbpB8e6McNfVtzQ9/W7ErJ4IvEJL5cc5BF21KKrRcR6k+LhkG0aBRkvTYMomWjYOtzoyDCA/1sqoF30QSvlJ2CG8Ogv/JbQTxDBw+Gk3vg0FpIXgeH1llt94nvW+sWS/px1mtUF9uSfrvIUP42phMPjepI8qlskk6c5mBqFgdPWuMTHUzNYmtyOgu3HCU3v7DYtmGBvmfP9ls2Cib1aC6/5e+wpR61wdchBPs7CPH3JTjA+ervICSg+Guwv2/1B+OrTlx1VpJSqnw+PtCknTV1H2fNKyysOOlHdYEmF1ijcQY2PP81sMG59wFhtf7ULB8fOXuWXprCQsOxzJxzid/5mnQyiwMnsli++wQZOfmwc3utxlVfBfk5CAmwkv2Z5C/Z2QwdWvtlaYJXqj4rLekbAyd2n0v4yevgYCJkp0J2GpjCsvcnjiIJv8G5L4KGraH1AGjVz/qvolarIESFBRIVFkiv1uff3WuMYdHixQwdMrRWy3UJUwgFeVCQW+Q1l7zCQrILHWQW+nI630FGgYPTeZCZW0BmTj6ZufmczimwXp3zir1muSZcTfBKuRuRc0m/2zXFlxUWQm6GleyzUkt5TTt/XtoB2PIN/PKKtY/IztBmgJXwWw+Ahq1cXB3BRwSf6jZd5GVBxlFrzKC805B72pqXl+l8f2bKsgaby8sqse5pyM8ukbTzSk3kmIJSQwhwTsXGOBUfcARYTWiOAKs3lcP//NfAAA7nFeCK2/NcmuBFZAzwCuAA3jPGPO/K8pTyej4+zlEvw62z8srKy7L+C9i/DPYtg/Wfn7vgG96yeMKP7GSVU5dyM+HEHus/lxO7nK974PguSD9U+f34BoJfEPiFWK/+wdZ7/1Ar2Tr8nK+lvfcrex2A/BzrS6DYaw7k55Z4LbHe6Uz8c0v/4qgplyV4EXEAbwAjgSRglYjMNcZsdlWZSqlq8guCthdbE0BhARzZCPuXw75frf77Gz63lgU2hNb9zyX85r1q50JvToYzce8uksidST09ufi6IZHQONZ6XkDjWAhvBn7B4B9SSgI/MwVVfXjpOrJ+8WKGumC/rjyD7wvsNMbsBhCRGcAVgCZ4peo7Hwc062lN/e6y2v1P7jmX8Pcvh+3fWev6BkLDNjW6eDsg7QgsPll8Zmi0lbzbDbNei06BZQz9qYoRY4xrdiwyDhhjjLnT+fkWoJ8x5r4S600EJgJER0fHz5gxwyXx1HcZGRmEhobaHYZttP7uV3+/3FQapG2hQdpmAnKO1Whf2YV+5Ie3JiuomXNqSoFvcC1FWv/V5OefkJCQaIzpU9oyV57Bl/Z1ft63iTFmCjAFoE+fPmaoK/oKuYHFixfjrXUHrb/71v/KWtmL+9a/driq/q68UpIEFL383hKowtUQpZRSNeHKBL8KaC8iMSLiD1wPzHVheUoppYpwWRONMSZfRO4D5mN1k5xqjNnkqvKUUkoV59J+8MaYecA8V5ahlFKqdHV8t4JSSqm6ogleKaU8lCZ4pZTyUJrglVLKQ7nsTtbqEJEUYJ/dcdgkAqjZ7YDuTeuv9df6V08bY0ypT2+vVwnem4nI6rJuN/YGWn+tv9a/9uuvTTRKKeWhNMErpZSH0gRff0yxOwCbaf29m9bfBbQNXimlPJSewSullIfSBK+UUh5KE3wdE5FWIrJIRLaIyCYR+ZNzfmMR+V5EdjhfG9kdqyuJiENE1orIN87PXlN/EWkoIrNEZKvz92CAl9X/L87f/Y0i8qmIBHp6/UVkqogcFZGNReaVWWcReUxEdorINhEZXd1yNcHXvXzgr8aYzkB/4F4R6QI8CvxgjGkP/OD87Mn+BGwp8tmb6v8K8J0xphPQE+s4eEX9RaQF8ADQxxjTDWso8evx/PpPA8aUmFdqnZ354Hqgq3ObN0Wkek8LN8boZOMEfAWMBLYBzZzzmgHb7I7NhXVu6fyFHgZ845znFfUHwoE9ODs4FJnvLfVvARwAGmMNV/4NMMob6g+0BTZW9DMHHgMeK7LefGBAdcrUM3gbiUhboBewAog2xiQDOF+jbAzN1V4G/gYUFpnnLfWPBVKA951NVO+JSAheUn9jzEHgRWA/kAykGWMW4CX1L6GsOp/5EjwjyTmvyjTB20REQoEvgD8bY07ZHU9dEZGxwFFjTKLdsdjEF+gNvGWM6QVk4nnNEWVytjNfAcQAzYEQEbnZ3qjqHSllXrX6s2uCt4GI+GEl9+nGmC+ds4+ISDPn8mbAUbvic7GLgMtFZC8wAxgmIh/jPfVPApKMMSucn2dhJXxvqf8IYI8xJsUYkwd8CQzEe+pfVFl1TgJaFVmvJXCoOgVogq9jIiLAf4AtxpiXiiyaC0xwvp+A1TbvcYwxjxljWhpj2mJdSPrRGHMz3lP/w8ABEenonDUc2IyX1B+raaa/iAQ7/xaGY11k9pb6F1VWnecC14tIgIjEAO2BldUpQO9krWMicjHwM7CBc23Qj2O1w38GtMb6IxhvjDlhS5B1RESGAg8ZY8aKSBO8pP4iEge8B/gDu4HfY51seUv9JwHXYfUoWwvcCYTiwfUXkU+BoVjDAh8BngbmUEadReQJ4HasY/RnY8y31SpXE7xSSnkmbaJRSikPpQleKaU8lCZ4pZTyUJrglVLKQ2mCV0opD6UJXnkVESkQkXXO0Qx/E5EHRaTafwci8niR922LjhaolN00wStvk2WMiTPGdMUa5O1SrD7J1fV4xasoZQ9N8MprGWOOAhOB+8TiEJF/icgqEVkvIneBdUOWiCwRkdkisllE3hYRHxF5Hghy/kcw3blbh4i86/wPYYGIBNlVP6U0wSuvZozZjfV3EAXcgTW64YXAhcAfnLeKA/QF/gp0B9oBVxtjHuXcfwQ3OddrD7zh/A8hFbimziqjVAma4JU6N3rfKOBWEVmHNXREE6yEDbDSGLPbGFMAfApcXMa+9hhj1jnfJ2KNAa6ULXztDkApO4lILFCANZKfAPcbY+aXWGco5w/XWtYYHzlF3hcA2kSjbKNn8MpriUgk8DbwurEGZZoP3OMczhkR6eB8GAdAXxGJcfa4uQ5Y6pyfd2Z9peobPYNX3ibI2QTjhzVS30fAmWGb38NqUlnjHMo2BbjSuWwZ8DxWG/wSYLZz/hRgvYisAZ5wffhKVZ6OJqlUBYoOa2xzKEpViTbRKKWUh9IzeKWU8lB6Bq+UUh5KE7xSSnkoTfBKKeWhNMErpZSH0gSvlFIe6v8BJuzAH/A9S7MAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#/* Draw ROC charts */ \n",
    "plt.figure()\n",
    "for key, grp in all_rocinfo.groupby([\"model\"]):\n",
    "    plt.plot(grp[\"FPR\"], grp[\"Sensitivity\"], label=key)\n",
    "plt.plot([0,1], [0,1], \"k--\")\n",
    "plt.xlabel(\"False Postivie Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.grid(True)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.title(\"ROC Curve (using validation data)\")\n",
    "plt.show()\n",
    "\n",
    "#/* Draw lift charts */\n",
    "plt.figure()\n",
    "for key, grp in all_liftinfo.groupby([\"model\"]):\n",
    "    plt.plot(grp[\"Depth\"], grp[\"Lift\"], label=key)\n",
    "plt.xlabel(\"Depth\")\n",
    "plt.ylabel(\"Lift\")\n",
    "plt.grid(True)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.title(\"Lift Chart (using validation data)\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Gradient Boosting in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sasmwr\\Anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      " [[1395   36]\n",
      " [ 139  218]] \n",
      "\n",
      "Misclassification Rate\n",
      "  0.09787472035794187\n"
     ]
    }
   ],
   "source": [
    "# Bring specified columns to the client (note: Python models must be run locally)\n",
    "local_inputs = [target, '_PartInd_'] + imp_all_inputs\n",
    "local = Home_Equity_p[local_inputs].to_frame()\n",
    "\n",
    "# Create dummy variables for class inputs (note: scikit-learn cannot have character variables)\n",
    "local = pd.concat([local, pd.get_dummies(local[imp_class_inputs])], axis = 1).drop(imp_class_inputs, axis = 1)\n",
    "\n",
    "# Split into training and validation\n",
    "train = local[local['_PartInd_'] == 1]\n",
    "valid = local[local['_PartInd_'] == 0]\n",
    "\n",
    "# Split target and inputs and remove unnecessary variables (note: scikit-learn Gradient Boosting can't handle missing values)\n",
    "X_train = train.drop(target, axis = 1)\n",
    "X_valid = valid.drop(target, axis = 1)\n",
    "y_train = train[target]\n",
    "y_valid = valid[target]\n",
    "\n",
    "# Build scikit-learn gradient boosting model using default values\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics  import confusion_matrix, accuracy_score\n",
    "gb = GradientBoostingClassifier()\n",
    "gb.fit(X_train, y_train)\n",
    "df = pd.DataFrame(dict(actual = y_valid, pred = gb.predict_proba(X_valid)[:,1])) # put results in pandas dataframe\n",
    "\n",
    "# Predict and assess model\n",
    "gb_y_score           = gb.predict(X_valid)\n",
    "gb_misclassification = 1 - accuracy_score(y_valid, gb_y_score)\n",
    "gb_confusion_matrix  = confusion_matrix(y_valid, gb_y_score)\n",
    "\n",
    "print('Confusion Matrix\\n', gb_confusion_matrix, '\\n') # note: scikit-learn reverses True Positives and True Negatives\n",
    "print('Misclassification Rate\\n ', gb_misclassification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Gradient Boosting - Python to our SAS Gradient Boosting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: Cloud Analytic Services made the uploaded file available as table PYTHON in caslib CASUSER(sasdemo).\n",
      "NOTE: The table PYTHON has been created in caslib CASUSER(sasdemo) from binary data uploaded to Cloud Analytic Services.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"cas-results-key\"><b>&#167; Fetch</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><caption>Selected Rows from Table PYTHON</caption>\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"actual\">actual</th>\n",
       "      <th title=\"pred\">pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.389005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.744539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.735353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.407900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.968085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-output-area\"></div>\n",
       "<p class=\"cas-results-performance\"><small><span class=\"cas-elapsed\">elapsed 0.000643s</span> &#183; <span class=\"cas-user\">user 0.000123s</span> &#183; <span class=\"cas-sys\">sys 0.000502s</span> &#183; <span class=\"cas-memory\">mem 0.979MB</span></small></p>"
      ],
      "text/plain": [
       "[Fetch]\n",
       "\n",
       " Selected Rows from Table PYTHON\n",
       " \n",
       "    actual      pred\n",
       " 0     0.0  0.389005\n",
       " 1     1.0  0.744539\n",
       " 2     0.0  0.735353\n",
       " 3     1.0  0.407900\n",
       " 4     1.0  0.968085\n",
       "\n",
       "+ Elapsed: 0.000643s, user: 0.000123s, sys: 0.000502s, mem: 0.979mb"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytbl = conn.upload_frame(df, casout=dict(name='Python', replace=True))\n",
    "\n",
    "# Verify that the Python actuals vs. predicted are in CAS\n",
    "pytbl.fetch(to = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   Misclassification Rate Comparison  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"model\">model</th>\n",
       "      <th title=\"Misclassification\">Misclassification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>GradientBoosting - Python</td>\n",
       "      <td>0.097875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>GradientBoosting - CAS</td>\n",
       "      <td>0.129195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       model  Misclassification\n",
       "1  GradientBoosting - Python           0.097875\n",
       "0     GradientBoosting - CAS           0.129195"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assess the Python model using CAS\n",
    "python_assess = pytbl.percentile.assess(\n",
    "    inputs   = 'pred',      \n",
    "    response = 'actual',\n",
    "    event    = '1',   \n",
    ")\n",
    "python_assess.ROCInfo['model'] = 'GradientBoosting - Python'\n",
    "\n",
    "all_rocinfo['model'] = all_rocinfo['model'] + ' - CAS'\n",
    "roc_df = pd.concat([all_rocinfo.query('model == \"GradientBoosting - CAS\"'), python_assess.ROCInfo])\n",
    "roc_df['Misclassification'] = 1 - roc_df['ACC']\n",
    "\n",
    "print('\\n', 'Misclassification Rate Comparison'.center(37, ' '))\n",
    "miss = roc_df[round(roc_df['CutOff'], 2) == 0.5][['model', 'Misclassification']].reset_index(drop = True)\n",
    "miss.sort_values('Misclassification')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoTune the Decision Tree & Gradient Boosting Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](images/MR_05_autotuning.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](images/MR_06_autotuning2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: Autotune is started for 'Decision Tree' model.\n",
      "NOTE: Autotune option SEARCHMETHOD='GA'.\n",
      "NOTE: Autotune option MAXTIME=36000 (sec.).\n",
      "NOTE: Autotune option SEED=1876970011.\n",
      "NOTE: Autotune objective is 'Misclassification Error Percentage'.\n",
      "NOTE: Autotune number of parallel evaluations is set to 4, each using 0 worker nodes.\n",
      "         Iteration       Evals     Best Objective  Elapsed Time\n",
      "                 0           1             13.255          0.33\n",
      "                 1          17             11.242          3.35\n",
      "                 2          32              10.57          5.77\n",
      "                 3          46              10.57          7.81\n",
      "                 4          59              10.57          9.46\n",
      "                 5          71              10.57         11.46\n",
      "NOTE: Data was partitioned during tuning, to tune based on validation score; the final model is trained and scored on all data.\n",
      "NOTE: Autotune time is 12.30 seconds.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"cas-results-key\"><b>&#167; BestConfiguration</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><caption>Best Configuration</caption>\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"Parameter\">Parameter</th>\n",
       "      <th title=\"Internal Name\">Name</th>\n",
       "      <th title=\"Value\">Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Evaluation</td>\n",
       "      <td>Evaluation</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Maximum Tree Levels</td>\n",
       "      <td>MAXLEVEL</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Maximum Bins</td>\n",
       "      <td>NBINS</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Criterion</td>\n",
       "      <td>CRIT</td>\n",
       "      <td>GAINRATIO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Misclassification Error Percentage</td>\n",
       "      <td>Objective</td>\n",
       "      <td>10.57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-results-key\"><hr/><b>&#167; DTreeVarImpInfo</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><caption>Decision Tree for HOME_EQUITY_P_AUTOTUNE_DATA_11FA4B25-9848-604F-9F45-7E73830B6354</caption>\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"Analysis Variable\">Variable</th>\n",
       "      <th title=\"Importance\">Importance</th>\n",
       "      <th title=\"Std\">Std</th>\n",
       "      <th title=\"Count\">Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>DEBTINC</td>\n",
       "      <td>642.097725</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>VALUE</td>\n",
       "      <td>131.927995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>DELINQ</td>\n",
       "      <td>81.481774</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>CLAGE</td>\n",
       "      <td>66.352486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>DEROG</td>\n",
       "      <td>52.426890</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>CLNO</td>\n",
       "      <td>38.648586</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>YOJ</td>\n",
       "      <td>33.386225</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>JOB</td>\n",
       "      <td>31.846041</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>NINQ</td>\n",
       "      <td>21.344958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>LOAN</td>\n",
       "      <td>10.315714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>MORTDUE</td>\n",
       "      <td>8.665758</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>REGION</td>\n",
       "      <td>6.025108</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>DATE_SINCE_LAST_APP</td>\n",
       "      <td>1.576300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-results-key\"><hr/><b>&#167; EncodedName</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"BAD\">LEVNAME</th>\n",
       "      <th title=\"LEVINDEX\">LEVINDEX</th>\n",
       "      <th title=\"Name\">VARNAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>P_BAD1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>P_BAD0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-results-key\"><hr/><b>&#167; EncodedTargetName</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"BAD\">LEVNAME</th>\n",
       "      <th title=\"LEVINDEX\">LEVINDEX</th>\n",
       "      <th title=\"Name\">VARNAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>I_BAD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-results-key\"><hr/><b>&#167; EvaluationHistory</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><caption>Tuner Evaluation History</caption>\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"Evaluation\">Evaluation</th>\n",
       "      <th title=\"Iteration\">Iteration</th>\n",
       "      <th title=\"MAXLEVEL\">MAXLEVEL</th>\n",
       "      <th title=\"NBINS\">NBINS</th>\n",
       "      <th title=\"CRIT\">CRIT</th>\n",
       "      <th title=\"Misclassification Error Percentage\">MisclassErr</th>\n",
       "      <th title=\"Evaluation Time in Seconds\">EvaluationTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>GAIN</td>\n",
       "      <td>13.255034</td>\n",
       "      <td>0.325845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>CHISQUARE</td>\n",
       "      <td>12.416107</td>\n",
       "      <td>0.586283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>100</td>\n",
       "      <td>GAIN</td>\n",
       "      <td>12.472036</td>\n",
       "      <td>0.491589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>80</td>\n",
       "      <td>GAINRATIO</td>\n",
       "      <td>11.409396</td>\n",
       "      <td>0.917100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>60</td>\n",
       "      <td>GAIN</td>\n",
       "      <td>12.360179</td>\n",
       "      <td>0.505119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>104</td>\n",
       "      <td>GAIN</td>\n",
       "      <td>12.639821</td>\n",
       "      <td>0.579900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>68</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>69</td>\n",
       "      <td>GAINRATIO</td>\n",
       "      <td>11.017897</td>\n",
       "      <td>0.902059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>69</td>\n",
       "      <td>GAINRATIO</td>\n",
       "      <td>10.682327</td>\n",
       "      <td>0.881478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>92</td>\n",
       "      <td>GAINRATIO</td>\n",
       "      <td>11.800895</td>\n",
       "      <td>0.909713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>47</td>\n",
       "      <td>GAINRATIO</td>\n",
       "      <td>12.304251</td>\n",
       "      <td>0.724634</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows  7 columns</p>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-results-key\"><hr/><b>&#167; FitStat</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><caption>Fit Statistics for _AUTOTUNE_DEFAULT_SCORE_TABLE_</caption>\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"Number of Observations\">NOBS</th>\n",
       "      <th title=\"Average Squared Error\">ASE</th>\n",
       "      <th title=\"Divisor for ASE\">DIV</th>\n",
       "      <th title=\"Root Average Squared Error\">RASE</th>\n",
       "      <th title=\"Misclassification (MCE)\">MCE</th>\n",
       "      <th title=\"Multi-Class Log Loss\">MCLL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5960.0</td>\n",
       "      <td>0.065227</td>\n",
       "      <td>5960.0</td>\n",
       "      <td>0.255395</td>\n",
       "      <td>0.082383</td>\n",
       "      <td>0.234067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-results-key\"><hr/><b>&#167; HyperparameterImportance</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><caption>Hyperparameter Importance</caption>\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"Hyperparameter\">Hyperparameter</th>\n",
       "      <th title=\"Relative Importance\">RelImportance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>MAXLEVEL</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>NBINS</td>\n",
       "      <td>0.699811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>CRIT</td>\n",
       "      <td>0.439128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-results-key\"><hr/><b>&#167; IterationHistory</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><caption>Tuner Iteration History</caption>\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"Iteration\">Iteration</th>\n",
       "      <th title=\"Evaluations\">Evaluations</th>\n",
       "      <th title=\"Best Objective\">Best_obj</th>\n",
       "      <th title=\"Elapsed Time\">Time_sec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13.255034</td>\n",
       "      <td>0.325845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>11.241611</td>\n",
       "      <td>3.672138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>10.570470</td>\n",
       "      <td>6.094000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>46</td>\n",
       "      <td>10.570470</td>\n",
       "      <td>8.133851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>59</td>\n",
       "      <td>10.570470</td>\n",
       "      <td>9.785020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>71</td>\n",
       "      <td>10.570470</td>\n",
       "      <td>11.784207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-results-key\"><hr/><b>&#167; ModelInfo</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><caption>Decision Tree for HOME_EQUITY_P_AUTOTUNE_DATA_11FA4B25-9848-604F-9F45-7E73830B6354</caption>\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"Descr\">Descr</th>\n",
       "      <th title=\"Value\">Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Number of Tree Nodes</td>\n",
       "      <td>135.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Max Number of Branches</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Number of Levels</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Number of Leaves</td>\n",
       "      <td>68.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Number of Bins</td>\n",
       "      <td>69.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Minimum Size of Leaves</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Maximum Size of Leaves</td>\n",
       "      <td>3901.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Number of Variables</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Confidence Level for Pruning</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Number of Observations Used</td>\n",
       "      <td>5960.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>Misclassification Error (%)</td>\n",
       "      <td>8.238255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-results-key\"><hr/><b>&#167; ROCInfo</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><caption>ROC Information for _AUTOTUNE_DEFAULT_SCORE_TABLE_</caption>\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"Analysis Variable\">Variable</th>\n",
       "      <th title=\"Event\">Event</th>\n",
       "      <th title=\"CutOff\">CutOff</th>\n",
       "      <th title=\"True Positive\">TP</th>\n",
       "      <th title=\"False Positive\">FP</th>\n",
       "      <th title=\"False Negative\">FN</th>\n",
       "      <th title=\"True Negative\">TN</th>\n",
       "      <th title=\"Sensitivity\">Sensitivity</th>\n",
       "      <th title=\"Specificity\">Specificity</th>\n",
       "      <th title=\"KS Cutoff\">KS</th>\n",
       "      <th title=\"False Positive Rate\">FPR</th>\n",
       "      <th title=\"Accuracy\">ACC</th>\n",
       "      <th title=\"False Discovery Rate\">FDR</th>\n",
       "      <th title=\"F1 Score\">F1</th>\n",
       "      <th title=\"Area Under ROC\">C</th>\n",
       "      <th title=\"Gini Coefficient\">Gini</th>\n",
       "      <th title=\"Gamma\">Gamma</th>\n",
       "      <th title=\"Tau\">Tau</th>\n",
       "      <th title=\"Misclassification (Event)\">MISCEVENT</th>\n",
       "      <th title=\"False Negative Rate\">FNR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>P_BAD0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4771.0</td>\n",
       "      <td>1189.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800503</td>\n",
       "      <td>0.199497</td>\n",
       "      <td>0.889200</td>\n",
       "      <td>0.906464</td>\n",
       "      <td>0.812927</td>\n",
       "      <td>0.919858</td>\n",
       "      <td>0.259689</td>\n",
       "      <td>0.199497</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>P_BAD0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4771.0</td>\n",
       "      <td>823.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>366.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.307822</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.692178</td>\n",
       "      <td>0.861913</td>\n",
       "      <td>0.147122</td>\n",
       "      <td>0.920598</td>\n",
       "      <td>0.906464</td>\n",
       "      <td>0.812927</td>\n",
       "      <td>0.919858</td>\n",
       "      <td>0.259689</td>\n",
       "      <td>0.138087</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>P_BAD0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>4771.0</td>\n",
       "      <td>823.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>366.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.307822</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.692178</td>\n",
       "      <td>0.861913</td>\n",
       "      <td>0.147122</td>\n",
       "      <td>0.920598</td>\n",
       "      <td>0.906464</td>\n",
       "      <td>0.812927</td>\n",
       "      <td>0.919858</td>\n",
       "      <td>0.259689</td>\n",
       "      <td>0.138087</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>P_BAD0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>4771.0</td>\n",
       "      <td>823.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>366.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.307822</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.692178</td>\n",
       "      <td>0.861913</td>\n",
       "      <td>0.147122</td>\n",
       "      <td>0.920598</td>\n",
       "      <td>0.906464</td>\n",
       "      <td>0.812927</td>\n",
       "      <td>0.919858</td>\n",
       "      <td>0.259689</td>\n",
       "      <td>0.138087</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>P_BAD0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>4769.0</td>\n",
       "      <td>771.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>418.0</td>\n",
       "      <td>0.999581</td>\n",
       "      <td>0.351556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.648444</td>\n",
       "      <td>0.870302</td>\n",
       "      <td>0.139170</td>\n",
       "      <td>0.925032</td>\n",
       "      <td>0.906464</td>\n",
       "      <td>0.812927</td>\n",
       "      <td>0.919858</td>\n",
       "      <td>0.259689</td>\n",
       "      <td>0.129698</td>\n",
       "      <td>0.000419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>P_BAD0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>3918.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>853.0</td>\n",
       "      <td>1031.0</td>\n",
       "      <td>0.821211</td>\n",
       "      <td>0.867115</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.132885</td>\n",
       "      <td>0.830369</td>\n",
       "      <td>0.038763</td>\n",
       "      <td>0.885724</td>\n",
       "      <td>0.906464</td>\n",
       "      <td>0.812927</td>\n",
       "      <td>0.919858</td>\n",
       "      <td>0.259689</td>\n",
       "      <td>0.169631</td>\n",
       "      <td>0.178789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>P_BAD0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.96</td>\n",
       "      <td>3918.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>853.0</td>\n",
       "      <td>1031.0</td>\n",
       "      <td>0.821211</td>\n",
       "      <td>0.867115</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.132885</td>\n",
       "      <td>0.830369</td>\n",
       "      <td>0.038763</td>\n",
       "      <td>0.885724</td>\n",
       "      <td>0.906464</td>\n",
       "      <td>0.812927</td>\n",
       "      <td>0.919858</td>\n",
       "      <td>0.259689</td>\n",
       "      <td>0.169631</td>\n",
       "      <td>0.178789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>P_BAD0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.97</td>\n",
       "      <td>124.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4647.0</td>\n",
       "      <td>1188.0</td>\n",
       "      <td>0.025990</td>\n",
       "      <td>0.999159</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000841</td>\n",
       "      <td>0.220134</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>0.050654</td>\n",
       "      <td>0.906464</td>\n",
       "      <td>0.812927</td>\n",
       "      <td>0.919858</td>\n",
       "      <td>0.259689</td>\n",
       "      <td>0.779866</td>\n",
       "      <td>0.974010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>P_BAD0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.98</td>\n",
       "      <td>124.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4647.0</td>\n",
       "      <td>1188.0</td>\n",
       "      <td>0.025990</td>\n",
       "      <td>0.999159</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000841</td>\n",
       "      <td>0.220134</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>0.050654</td>\n",
       "      <td>0.906464</td>\n",
       "      <td>0.812927</td>\n",
       "      <td>0.919858</td>\n",
       "      <td>0.259689</td>\n",
       "      <td>0.779866</td>\n",
       "      <td>0.974010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>P_BAD0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4705.0</td>\n",
       "      <td>1189.0</td>\n",
       "      <td>0.013834</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.210570</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.906464</td>\n",
       "      <td>0.812927</td>\n",
       "      <td>0.919858</td>\n",
       "      <td>0.259689</td>\n",
       "      <td>0.789430</td>\n",
       "      <td>0.986166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows  22 columns</p>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-results-key\"><hr/><b>&#167; ScoreInfo</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"Descr\">Descr</th>\n",
       "      <th title=\"Value\">Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Number of Observations Read</td>\n",
       "      <td>5960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Number of Observations Used</td>\n",
       "      <td>5960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Misclassification Error (%)</td>\n",
       "      <td>8.2382550336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-results-key\"><hr/><b>&#167; TunerCasOutputTables</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><caption>Tuner CAS Output Tables</caption>\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"CAS Library\">CAS_Library</th>\n",
       "      <th title=\"Name\">Name</th>\n",
       "      <th title=\"Number of Rows\">Rows</th>\n",
       "      <th title=\"Number of Columns\">Columns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>CASUSER(sasdemo)</td>\n",
       "      <td>tree_model_at</td>\n",
       "      <td>135</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-results-key\"><hr/><b>&#167; TunerInfo</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><caption>Tuner Information</caption>\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"Parameter\">Parameter</th>\n",
       "      <th title=\"Value\">Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Model Type</td>\n",
       "      <td>Decision Tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Tuner Objective Function</td>\n",
       "      <td>Misclassification Error Percentage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Search Method</td>\n",
       "      <td>GA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Population Size</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Maximum Iterations</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Maximum Tuning Time in Seconds</td>\n",
       "      <td>36000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Validation Type</td>\n",
       "      <td>Single Partition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Validation Partition Fraction</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Log Level</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Seed</td>\n",
       "      <td>1876970011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>Number of Parallel Evaluations</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>Number of Workers per Subsession</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-results-key\"><hr/><b>&#167; TunerResults</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><caption>Tuner Results</caption>\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"Evaluation\">Evaluation</th>\n",
       "      <th title=\"MAXLEVEL\">MAXLEVEL</th>\n",
       "      <th title=\"NBINS\">NBINS</th>\n",
       "      <th title=\"CRIT\">CRIT</th>\n",
       "      <th title=\"Misclassification Error Percentage\">MisclassErr</th>\n",
       "      <th title=\"Evaluation Time in Seconds\">EvaluationTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>GAIN</td>\n",
       "      <td>13.255034</td>\n",
       "      <td>0.325845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>69</td>\n",
       "      <td>GAINRATIO</td>\n",
       "      <td>10.570470</td>\n",
       "      <td>0.867248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>69</td>\n",
       "      <td>18</td>\n",
       "      <td>69</td>\n",
       "      <td>GAINRATIO</td>\n",
       "      <td>10.682327</td>\n",
       "      <td>0.881478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>44</td>\n",
       "      <td>20</td>\n",
       "      <td>69</td>\n",
       "      <td>GAINRATIO</td>\n",
       "      <td>10.961969</td>\n",
       "      <td>0.903958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>68</td>\n",
       "      <td>14</td>\n",
       "      <td>69</td>\n",
       "      <td>GAINRATIO</td>\n",
       "      <td>11.017897</td>\n",
       "      <td>0.902059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>53</td>\n",
       "      <td>15</td>\n",
       "      <td>77</td>\n",
       "      <td>GAINRATIO</td>\n",
       "      <td>11.129754</td>\n",
       "      <td>0.591072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>120</td>\n",
       "      <td>GINI</td>\n",
       "      <td>11.241611</td>\n",
       "      <td>0.613608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>8</td>\n",
       "      <td>131</td>\n",
       "      <td>GINI</td>\n",
       "      <td>11.297539</td>\n",
       "      <td>0.315831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>46</td>\n",
       "      <td>16</td>\n",
       "      <td>159</td>\n",
       "      <td>GAINRATIO</td>\n",
       "      <td>11.297539</td>\n",
       "      <td>0.188161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>58</td>\n",
       "      <td>16</td>\n",
       "      <td>114</td>\n",
       "      <td>GAINRATIO</td>\n",
       "      <td>11.297539</td>\n",
       "      <td>0.497017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>144</td>\n",
       "      <td>CHISQUARE</td>\n",
       "      <td>11.297539</td>\n",
       "      <td>0.508096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-results-key\"><hr/><b>&#167; TunerSummary</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><caption>Tuner Summary</caption>\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"Parameter\">Parameter</th>\n",
       "      <th title=\"Value\">Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Initial Configuration Objective Value</td>\n",
       "      <td>13.255034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Best Configuration Objective Value</td>\n",
       "      <td>10.570470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Worst Configuration Objective Value</td>\n",
       "      <td>15.492170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Initial Configuration Evaluation Time in Seconds</td>\n",
       "      <td>0.325845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Best Configuration Evaluation Time in Seconds</td>\n",
       "      <td>0.867237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Number of Improved Configurations</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Number of Evaluated Configurations</td>\n",
       "      <td>71.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Total Tuning Time in Seconds</td>\n",
       "      <td>12.299052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Parallel Tuning Speedup</td>\n",
       "      <td>3.366582</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-results-key\"><hr/><b>&#167; TunerTiming</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><caption>Tuner Task Timing</caption>\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"Task\">Task</th>\n",
       "      <th title=\"Seconds\">Time_sec</th>\n",
       "      <th title=\"Percent\">Time_percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Model Training</td>\n",
       "      <td>35.370924</td>\n",
       "      <td>85.425110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Model Scoring</td>\n",
       "      <td>4.093047</td>\n",
       "      <td>9.885210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Total Objective Evaluations</td>\n",
       "      <td>39.967290</td>\n",
       "      <td>96.525895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Tuner</td>\n",
       "      <td>1.438480</td>\n",
       "      <td>3.474105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Total CPU Time</td>\n",
       "      <td>41.405770</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-output-area\"></div>\n",
       "<p class=\"cas-results-performance\"><small><span class=\"cas-elapsed\">elapsed 12.4s</span> &#183; <span class=\"cas-user\">user 0.295s</span> &#183; <span class=\"cas-sys\">sys 0.135s</span> &#183; <span class=\"cas-memory\">mem 0.276MB</span></small></p>"
      ],
      "text/plain": [
       "[BestConfiguration]\n",
       "\n",
       " Best Configuration\n",
       " \n",
       "                             Parameter        Name      Value\n",
       " 0                          Evaluation  Evaluation         20\n",
       " 1                 Maximum Tree Levels    MAXLEVEL         16\n",
       " 2                        Maximum Bins       NBINS         69\n",
       " 3                           Criterion        CRIT  GAINRATIO\n",
       " 4  Misclassification Error Percentage   Objective      10.57\n",
       "\n",
       "[DTreeVarImpInfo]\n",
       "\n",
       " Decision Tree for HOME_EQUITY_P_AUTOTUNE_DATA_11FA4B25-9848-604F-9F45-7E73830B6354\n",
       " \n",
       "                Variable  Importance  Std  Count\n",
       " 0               DEBTINC  642.097725  NaN    6.0\n",
       " 1                 VALUE  131.927995  NaN    3.0\n",
       " 2                DELINQ   81.481774  NaN    6.0\n",
       " 3                 CLAGE   66.352486  NaN    7.0\n",
       " 4                 DEROG   52.426890  NaN    8.0\n",
       " 5                  CLNO   38.648586  NaN    9.0\n",
       " 6                   YOJ   33.386225  NaN    5.0\n",
       " 7                   JOB   31.846041  NaN    7.0\n",
       " 8                  NINQ   21.344958  NaN    5.0\n",
       " 9                  LOAN   10.315714  NaN    3.0\n",
       " 10              MORTDUE    8.665758  NaN    4.0\n",
       " 11               REGION    6.025108  NaN    3.0\n",
       " 12  DATE_SINCE_LAST_APP    1.576300  NaN    1.0\n",
       "\n",
       "[EncodedName]\n",
       "\n",
       "         LEVNAME  LEVINDEX VARNAME\n",
       " 0             1         0  P_BAD1\n",
       " 1             0         1  P_BAD0\n",
       "\n",
       "[EncodedTargetName]\n",
       "\n",
       "   LEVNAME  LEVINDEX VARNAME\n",
       " 0                 0   I_BAD\n",
       "\n",
       "[EvaluationHistory]\n",
       "\n",
       " Tuner Evaluation History\n",
       " \n",
       "     Evaluation  Iteration  MAXLEVEL  NBINS       CRIT  MisclassErr  EvaluationTime\n",
       " 0            0          0        11     20       GAIN    13.255034        0.325845\n",
       " 1            1          1         6     20  CHISQUARE    12.416107        0.586283\n",
       " 2            2          1        14    100       GAIN    12.472036        0.491589\n",
       " 3            3          1        18     80  GAINRATIO    11.409396        0.917100\n",
       " 4            4          1        20     60       GAIN    12.360179        0.505119\n",
       " 5            5          1         8    160  GAINRATIO    14.373602        0.411325\n",
       " 6            6          1        12    200  CHISQUARE    12.248322        0.605058\n",
       " 7            7          1        10    120       GINI    11.241611        0.613608\n",
       " 8            8          1         4    180       GINI    11.744966        0.599673\n",
       " 9            9          1        16     40      CHAID    13.814318        0.975242\n",
       " 10          10          1        11     20       GAIN    13.255034        0.000000\n",
       " 11          11          1        11    110       GINI    11.744966        0.791423\n",
       " 12          12          1        20    110       GINI    11.689038        0.886191\n",
       " 13          13          1         2    110       GINI    14.205817        0.510701\n",
       " 14          14          1        11    200       GINI    11.968680        0.714583\n",
       " 15          15          1        11     20       GINI    13.255034        0.225882\n",
       " 16          16          1        11    110      CHAID    13.143177        1.005801\n",
       " 17          17          1        11    110       GAIN    12.136465        0.533706\n",
       " 18          18          2        20     20       GAIN    12.639821        0.665407\n",
       " 19          19          2        17     96  GAINRATIO    11.744966        0.864420\n",
       " 20          20          2        16     69  GAINRATIO    10.570470        0.867248\n",
       " 21          21          2        20    111       GINI    11.521253        0.971629\n",
       " 22          22          2        15     51  GAINRATIO    11.968680        0.342898\n",
       " 23          23          2         2    200      CHAID    15.492170        0.568740\n",
       " 24          24          2         6    164       GINI    11.689038        0.322406\n",
       " 25          25          2         8    131       GINI    11.297539        0.315831\n",
       " 26          26          2        16     91  GAINRATIO    11.800895        0.382040\n",
       " 27          27          2        10    200       GINI    11.912752        0.485457\n",
       " 28          28          2        10     30       GINI    11.689038        0.203403\n",
       " 29          29          2        10    120      CHAID    13.310962        1.031208\n",
       " 30          30          2        10    120       GAIN    11.633110        0.446901\n",
       " 31          31          2        19    120       GINI    12.583893        0.677706\n",
       " 32          32          2         2    120       GINI    14.149888        0.417702\n",
       " 33          33          3         4    125       GINI    11.744966        0.241575\n",
       " 34          34          3        14    116       GINI    11.968680        0.378714\n",
       " 35          35          3        10     20       GINI    13.310962        0.151509\n",
       " 36          36          3         2    146       GINI    14.149888        0.251344\n",
       " 37          37          3        11    126       GINI    11.465324        0.704371\n",
       " 38          38          3        12    110  GAINRATIO    12.863535        0.621595\n",
       " 39          39          3        16     60  GAINRATIO    11.577181        0.611217\n",
       " 40          40          3        17     87  GAINRATIO    12.248322        0.598303\n",
       " 41          41          3        16     20  GAINRATIO    13.143177        0.220380\n",
       " 42          42          3        16     69  CHISQUARE    12.807606        0.988744\n",
       " 43          43          3        16     69       GAIN    12.080537        1.001446\n",
       " 44          44          3        20     69  GAINRATIO    10.961969        0.903958\n",
       " 45          45          3         7     69  GAINRATIO    13.982103        0.779565\n",
       " 46          46          3        16    159  GAINRATIO    11.297539        0.188161\n",
       " 47          47          4        18     47  GAINRATIO    12.248322        0.526300\n",
       " 48          48          4         6    112       GINI    11.968680        0.515051\n",
       " 49          49          4        10     22       GINI    12.919463        0.422111\n",
       " 50          50          4         3    147       GINI    14.149888        0.507484\n",
       " 51          51          4         9     42       GINI    12.695749        0.382953\n",
       " 52          52          4        19     36  GAINRATIO    12.527964        0.523057\n",
       " 53          53          4        15     77  GAINRATIO    11.129754        0.591072\n",
       " 54          54          4         6    158  CHISQUARE    11.633110        0.578928\n",
       " 55          55          4        12    119       GINI    11.353468        0.635894\n",
       " 56          56          4        16     69       GINI    12.863535        0.485402\n",
       " 57          57          4        12     69  GAINRATIO    11.353468        0.407911\n",
       " 58          58          4        16    114  GAINRATIO    11.297539        0.497017\n",
       " 59          59          4        16     24  GAINRATIO    12.472036        0.208952\n",
       " 60          60          5        15     75  GAINRATIO    11.521253        0.659044\n",
       " 61          61          5         6    110       GINI    11.968680        0.550632\n",
       " 62          62          5        15     82  GAINRATIO    11.465324        0.672967\n",
       " 63          63          5        14    105       GINI    11.577181        0.693537\n",
       " 64          64          5         8    144  CHISQUARE    11.297539        0.508096\n",
       " 65          65          5        17     67  GAINRATIO    11.689038        0.411090\n",
       " 66          66          5         7    110       GINI    12.304251        0.396534\n",
       " 67          67          5        20    104       GAIN    12.639821        0.579900\n",
       " 68          68          5        14     69  GAINRATIO    11.017897        0.902059\n",
       " 69          69          5        18     69  GAINRATIO    10.682327        0.881478\n",
       " 70          70          5        16     92  GAINRATIO    11.800895        0.909713\n",
       " 71          71          5        16     47  GAINRATIO    12.304251        0.724634\n",
       "\n",
       "[FitStat]\n",
       "\n",
       " Fit Statistics for _AUTOTUNE_DEFAULT_SCORE_TABLE_\n",
       " \n",
       "      NOBS       ASE     DIV      RASE       MCE      MCLL\n",
       " 0  5960.0  0.065227  5960.0  0.255395  0.082383  0.234067\n",
       "\n",
       "[HyperparameterImportance]\n",
       "\n",
       " Hyperparameter Importance\n",
       " \n",
       "   Hyperparameter  RelImportance\n",
       " 0       MAXLEVEL       1.000000\n",
       " 1          NBINS       0.699811\n",
       " 2           CRIT       0.439128\n",
       "\n",
       "[IterationHistory]\n",
       "\n",
       " Tuner Iteration History\n",
       " \n",
       "    Iteration  Evaluations   Best_obj   Time_sec\n",
       " 0          0            1  13.255034   0.325845\n",
       " 1          1           17  11.241611   3.672138\n",
       " 2          2           32  10.570470   6.094000\n",
       " 3          3           46  10.570470   8.133851\n",
       " 4          4           59  10.570470   9.785020\n",
       " 5          5           71  10.570470  11.784207\n",
       "\n",
       "[ModelInfo]\n",
       "\n",
       " Decision Tree for HOME_EQUITY_P_AUTOTUNE_DATA_11FA4B25-9848-604F-9F45-7E73830B6354\n",
       " \n",
       "                            Descr        Value\n",
       " 0           Number of Tree Nodes   135.000000\n",
       " 1         Max Number of Branches     2.000000\n",
       " 2               Number of Levels    16.000000\n",
       " 3               Number of Leaves    68.000000\n",
       " 4                 Number of Bins    69.000000\n",
       " 5         Minimum Size of Leaves     5.000000\n",
       " 6         Maximum Size of Leaves  3901.000000\n",
       " 7            Number of Variables    14.000000\n",
       " 8   Confidence Level for Pruning     0.250000\n",
       " 9    Number of Observations Used  5960.000000\n",
       " 10   Misclassification Error (%)     8.238255\n",
       "\n",
       "[ROCInfo]\n",
       "\n",
       " ROC Information for _AUTOTUNE_DEFAULT_SCORE_TABLE_\n",
       " \n",
       "    Variable Event  CutOff      TP      FP      FN      TN  Sensitivity  Specificity   KS       KS2    F_HALF       FPR       ACC       FDR        F1         C      Gini     Gamma       Tau  MISCEVENT       FNR\n",
       " 0    P_BAD0     0    0.00  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.906464  0.812927  0.919858  0.259689   0.199497  0.000000\n",
       " 1    P_BAD0     0    0.01  4771.0   823.0     0.0   366.0     1.000000     0.307822  0.0  0.307822  0.878734  0.692178  0.861913  0.147122  0.920598  0.906464  0.812927  0.919858  0.259689   0.138087  0.000000\n",
       " 2    P_BAD0     0    0.02  4771.0   823.0     0.0   366.0     1.000000     0.307822  0.0  0.307822  0.878734  0.692178  0.861913  0.147122  0.920598  0.906464  0.812927  0.919858  0.259689   0.138087  0.000000\n",
       " 3    P_BAD0     0    0.03  4771.0   823.0     0.0   366.0     1.000000     0.307822  0.0  0.307822  0.878734  0.692178  0.861913  0.147122  0.920598  0.906464  0.812927  0.919858  0.259689   0.138087  0.000000\n",
       " 4    P_BAD0     0    0.04  4769.0   771.0     2.0   418.0     0.999581     0.351556  0.0  0.351137  0.885411  0.648444  0.870302  0.139170  0.925032  0.906464  0.812927  0.919858  0.259689   0.129698  0.000419\n",
       " 5    P_BAD0     0    0.05  4769.0   771.0     2.0   418.0     0.999581     0.351556  0.0  0.351137  0.885411  0.648444  0.870302  0.139170  0.925032  0.906464  0.812927  0.919858  0.259689   0.129698  0.000419\n",
       " 6    P_BAD0     0    0.06  4769.0   771.0     2.0   418.0     0.999581     0.351556  0.0  0.351137  0.885411  0.648444  0.870302  0.139170  0.925032  0.906464  0.812927  0.919858  0.259689   0.129698  0.000419\n",
       " 7    P_BAD0     0    0.07  4769.0   771.0     2.0   418.0     0.999581     0.351556  0.0  0.351137  0.885411  0.648444  0.870302  0.139170  0.925032  0.906464  0.812927  0.919858  0.259689   0.129698  0.000419\n",
       " 8    P_BAD0     0    0.08  4767.0   745.0     4.0   444.0     0.999162     0.373423  0.0  0.372585  0.888736  0.626577  0.874329  0.135160  0.927161  0.906464  0.812927  0.919858  0.259689   0.125671  0.000838\n",
       " 9    P_BAD0     0    0.09  4761.0   684.0    10.0   505.0     0.997904     0.424727  0.0  0.422631  0.896576  0.575273  0.883557  0.125620  0.932067  0.906464  0.812927  0.919858  0.259689   0.116443  0.002096\n",
       " 10   P_BAD0     0    0.10  4761.0   684.0    10.0   505.0     0.997904     0.424727  0.0  0.422631  0.896576  0.575273  0.883557  0.125620  0.932067  0.906464  0.812927  0.919858  0.259689   0.116443  0.002096\n",
       " 11   P_BAD0     0    0.11  4761.0   684.0    10.0   505.0     0.997904     0.424727  0.0  0.422631  0.896576  0.575273  0.883557  0.125620  0.932067  0.906464  0.812927  0.919858  0.259689   0.116443  0.002096\n",
       " 12   P_BAD0     0    0.12  4761.0   684.0    10.0   505.0     0.997904     0.424727  0.0  0.422631  0.896576  0.575273  0.883557  0.125620  0.932067  0.906464  0.812927  0.919858  0.259689   0.116443  0.002096\n",
       " 13   P_BAD0     0    0.13  4761.0   684.0    10.0   505.0     0.997904     0.424727  0.0  0.422631  0.896576  0.575273  0.883557  0.125620  0.932067  0.906464  0.812927  0.919858  0.259689   0.116443  0.002096\n",
       " 14   P_BAD0     0    0.14  4761.0   684.0    10.0   505.0     0.997904     0.424727  0.0  0.422631  0.896576  0.575273  0.883557  0.125620  0.932067  0.906464  0.812927  0.919858  0.259689   0.116443  0.002096\n",
       " 15   P_BAD0     0    0.15  4760.0   678.0    11.0   511.0     0.997694     0.429773  0.0  0.427467  0.897334  0.570227  0.884396  0.124678  0.932511  0.906464  0.812927  0.919858  0.259689   0.115604  0.002306\n",
       " 16   P_BAD0     0    0.16  4760.0   678.0    11.0   511.0     0.997694     0.429773  0.0  0.427467  0.897334  0.570227  0.884396  0.124678  0.932511  0.906464  0.812927  0.919858  0.259689   0.115604  0.002306\n",
       " 17   P_BAD0     0    0.17  4757.0   663.0    14.0   526.0     0.997066     0.442389  0.0  0.439454  0.899210  0.557611  0.886409  0.122325  0.933569  0.906464  0.812927  0.919858  0.259689   0.113591  0.002934\n",
       " 18   P_BAD0     0    0.18  4757.0   663.0    14.0   526.0     0.997066     0.442389  0.0  0.439454  0.899210  0.557611  0.886409  0.122325  0.933569  0.906464  0.812927  0.919858  0.259689   0.113591  0.002934\n",
       " 19   P_BAD0     0    0.19  4755.0   654.0    16.0   535.0     0.996646     0.449958  0.0  0.446604  0.900329  0.550042  0.887584  0.120910  0.934185  0.906464  0.812927  0.919858  0.259689   0.112416  0.003354\n",
       " 20   P_BAD0     0    0.20  4755.0   654.0    16.0   535.0     0.996646     0.449958  0.0  0.446604  0.900329  0.550042  0.887584  0.120910  0.934185  0.906464  0.812927  0.919858  0.259689   0.112416  0.003354\n",
       " 21   P_BAD0     0    0.21  4751.0   638.0    20.0   551.0     0.995808     0.463415  0.0  0.459223  0.902306  0.536585  0.889597  0.118389  0.935236  0.906464  0.812927  0.919858  0.259689   0.110403  0.004192\n",
       " 22   P_BAD0     0    0.22  4751.0   638.0    20.0   551.0     0.995808     0.463415  0.0  0.459223  0.902306  0.536585  0.889597  0.118389  0.935236  0.906464  0.812927  0.919858  0.259689   0.110403  0.004192\n",
       " 23   P_BAD0     0    0.23  4751.0   638.0    20.0   551.0     0.995808     0.463415  0.0  0.459223  0.902306  0.536585  0.889597  0.118389  0.935236  0.906464  0.812927  0.919858  0.259689   0.110403  0.004192\n",
       " 24   P_BAD0     0    0.24  4751.0   638.0    20.0   551.0     0.995808     0.463415  0.0  0.459223  0.902306  0.536585  0.889597  0.118389  0.935236  0.906464  0.812927  0.919858  0.259689   0.110403  0.004192\n",
       " 25   P_BAD0     0    0.25  4751.0   638.0    20.0   551.0     0.995808     0.463415  0.0  0.459223  0.902306  0.536585  0.889597  0.118389  0.935236  0.906464  0.812927  0.919858  0.259689   0.110403  0.004192\n",
       " 26   P_BAD0     0    0.26  4730.0   577.0    41.0   612.0     0.991406     0.514718  0.0  0.506125  0.909650  0.485282  0.896309  0.108724  0.938678  0.906464  0.812927  0.919858  0.259689   0.103691  0.008594\n",
       " 27   P_BAD0     0    0.27  4730.0   577.0    41.0   612.0     0.991406     0.514718  0.0  0.506125  0.909650  0.485282  0.896309  0.108724  0.938678  0.906464  0.812927  0.919858  0.259689   0.103691  0.008594\n",
       " 28   P_BAD0     0    0.28  4730.0   577.0    41.0   612.0     0.991406     0.514718  0.0  0.506125  0.909650  0.485282  0.896309  0.108724  0.938678  0.906464  0.812927  0.919858  0.259689   0.103691  0.008594\n",
       " 29   P_BAD0     0    0.29  4730.0   577.0    41.0   612.0     0.991406     0.514718  0.0  0.506125  0.909650  0.485282  0.896309  0.108724  0.938678  0.906464  0.812927  0.919858  0.259689   0.103691  0.008594\n",
       " 30   P_BAD0     0    0.30  4730.0   577.0    41.0   612.0     0.991406     0.514718  0.0  0.506125  0.909650  0.485282  0.896309  0.108724  0.938678  0.906464  0.812927  0.919858  0.259689   0.103691  0.008594\n",
       " 31   P_BAD0     0    0.31  4730.0   577.0    41.0   612.0     0.991406     0.514718  0.0  0.506125  0.909650  0.485282  0.896309  0.108724  0.938678  0.906464  0.812927  0.919858  0.259689   0.103691  0.008594\n",
       " 32   P_BAD0     0    0.32  4730.0   577.0    41.0   612.0     0.991406     0.514718  0.0  0.506125  0.909650  0.485282  0.896309  0.108724  0.938678  0.906464  0.812927  0.919858  0.259689   0.103691  0.008594\n",
       " 33   P_BAD0     0    0.33  4730.0   577.0    41.0   612.0     0.991406     0.514718  0.0  0.506125  0.909650  0.485282  0.896309  0.108724  0.938678  0.906464  0.812927  0.919858  0.259689   0.103691  0.008594\n",
       " 34   P_BAD0     0    0.34  4723.0   563.0    48.0   626.0     0.989939     0.526493  0.0  0.516432  0.911248  0.473507  0.897483  0.106508  0.939246  0.906464  0.812927  0.919858  0.259689   0.102517  0.010061\n",
       " 35   P_BAD0     0    0.35  4723.0   563.0    48.0   626.0     0.989939     0.526493  0.0  0.516432  0.911248  0.473507  0.897483  0.106508  0.939246  0.906464  0.812927  0.919858  0.259689   0.102517  0.010061\n",
       " 36   P_BAD0     0    0.36  4723.0   563.0    48.0   626.0     0.989939     0.526493  0.0  0.516432  0.911248  0.473507  0.897483  0.106508  0.939246  0.906464  0.812927  0.919858  0.259689   0.102517  0.010061\n",
       " 37   P_BAD0     0    0.37  4723.0   563.0    48.0   626.0     0.989939     0.526493  0.0  0.516432  0.911248  0.473507  0.897483  0.106508  0.939246  0.906464  0.812927  0.919858  0.259689   0.102517  0.010061\n",
       " 38   P_BAD0     0    0.38  4553.0   276.0   218.0   913.0     0.954307     0.767872  0.0  0.722179  0.945116  0.232128  0.917114  0.057155  0.948542  0.906464  0.812927  0.919858  0.259689   0.082886  0.045693\n",
       " 39   P_BAD0     0    0.39  4553.0   276.0   218.0   913.0     0.954307     0.767872  0.0  0.722179  0.945116  0.232128  0.917114  0.057155  0.948542  0.906464  0.812927  0.919858  0.259689   0.082886  0.045693\n",
       " 40   P_BAD0     0    0.40  4553.0   276.0   218.0   913.0     0.954307     0.767872  0.0  0.722179  0.945116  0.232128  0.917114  0.057155  0.948542  0.906464  0.812927  0.919858  0.259689   0.082886  0.045693\n",
       " 41   P_BAD0     0    0.41  4551.0   273.0   220.0   916.0     0.953888     0.770395  0.0  0.724283  0.945486  0.229605  0.917282  0.056592  0.948619  0.906464  0.812927  0.919858  0.259689   0.082718  0.046112\n",
       " 42   P_BAD0     0    0.42  4551.0   273.0   220.0   916.0     0.953888     0.770395  0.0  0.724283  0.945486  0.229605  0.917282  0.056592  0.948619  0.906464  0.812927  0.919858  0.259689   0.082718  0.046112\n",
       " 43   P_BAD0     0    0.43  4551.0   273.0   220.0   916.0     0.953888     0.770395  0.0  0.724283  0.945486  0.229605  0.917282  0.056592  0.948619  0.906464  0.812927  0.919858  0.259689   0.082718  0.046112\n",
       " 44   P_BAD0     0    0.44  4544.0   264.0   227.0   925.0     0.952421     0.777965  0.0  0.730386  0.946548  0.222035  0.917617  0.054908  0.948742  0.906464  0.812927  0.919858  0.259689   0.082383  0.047579\n",
       " 45   P_BAD0     0    0.45  4544.0   264.0   227.0   925.0     0.952421     0.777965  0.0  0.730386  0.946548  0.222035  0.917617  0.054908  0.948742  0.906464  0.812927  0.919858  0.259689   0.082383  0.047579\n",
       " 46   P_BAD0     0    0.46  4544.0   264.0   227.0   925.0     0.952421     0.777965  0.0  0.730386  0.946548  0.222035  0.917617  0.054908  0.948742  0.906464  0.812927  0.919858  0.259689   0.082383  0.047579\n",
       " 47   P_BAD0     0    0.47  4544.0   264.0   227.0   925.0     0.952421     0.777965  0.0  0.730386  0.946548  0.222035  0.917617  0.054908  0.948742  0.906464  0.812927  0.919858  0.259689   0.082383  0.047579\n",
       " 48   P_BAD0     0    0.48  4544.0   264.0   227.0   925.0     0.952421     0.777965  0.0  0.730386  0.946548  0.222035  0.917617  0.054908  0.948742  0.906464  0.812927  0.919858  0.259689   0.082383  0.047579\n",
       " 49   P_BAD0     0    0.49  4544.0   264.0   227.0   925.0     0.952421     0.777965  0.0  0.730386  0.946548  0.222035  0.917617  0.054908  0.948742  0.906464  0.812927  0.919858  0.259689   0.082383  0.047579\n",
       " 50   P_BAD0     0    0.50  4544.0   264.0   227.0   925.0     0.952421     0.777965  0.0  0.730386  0.946548  0.222035  0.917617  0.054908  0.948742  0.906464  0.812927  0.919858  0.259689   0.082383  0.047579\n",
       " 51   P_BAD0     0    0.51  4544.0   264.0   227.0   925.0     0.952421     0.777965  0.0  0.730386  0.946548  0.222035  0.917617  0.054908  0.948742  0.906464  0.812927  0.919858  0.259689   0.082383  0.047579\n",
       " 52   P_BAD0     0    0.52  4544.0   264.0   227.0   925.0     0.952421     0.777965  0.0  0.730386  0.946548  0.222035  0.917617  0.054908  0.948742  0.906464  0.812927  0.919858  0.259689   0.082383  0.047579\n",
       " 53   P_BAD0     0    0.53  4544.0   264.0   227.0   925.0     0.952421     0.777965  0.0  0.730386  0.946548  0.222035  0.917617  0.054908  0.948742  0.906464  0.812927  0.919858  0.259689   0.082383  0.047579\n",
       " 54   P_BAD0     0    0.54  4544.0   264.0   227.0   925.0     0.952421     0.777965  0.0  0.730386  0.946548  0.222035  0.917617  0.054908  0.948742  0.906464  0.812927  0.919858  0.259689   0.082383  0.047579\n",
       " 55   P_BAD0     0    0.55  4544.0   264.0   227.0   925.0     0.952421     0.777965  0.0  0.730386  0.946548  0.222035  0.917617  0.054908  0.948742  0.906464  0.812927  0.919858  0.259689   0.082383  0.047579\n",
       " 56   P_BAD0     0    0.56  4544.0   264.0   227.0   925.0     0.952421     0.777965  0.0  0.730386  0.946548  0.222035  0.917617  0.054908  0.948742  0.906464  0.812927  0.919858  0.259689   0.082383  0.047579\n",
       " 57   P_BAD0     0    0.57  4544.0   264.0   227.0   925.0     0.952421     0.777965  0.0  0.730386  0.946548  0.222035  0.917617  0.054908  0.948742  0.906464  0.812927  0.919858  0.259689   0.082383  0.047579\n",
       " 58   P_BAD0     0    0.58  4540.0   261.0   231.0   928.0     0.951582     0.780488  0.0  0.732070  0.946820  0.219512  0.917450  0.054364  0.948600  0.906464  0.812927  0.919858  0.259689   0.082550  0.048418\n",
       " 59   P_BAD0     0    0.59  4540.0   261.0   231.0   928.0     0.951582     0.780488  0.0  0.732070  0.946820  0.219512  0.917450  0.054364  0.948600  0.906464  0.812927  0.919858  0.259689   0.082550  0.048418\n",
       " 60   P_BAD0     0    0.60  4540.0   261.0   231.0   928.0     0.951582     0.780488  0.0  0.732070  0.946820  0.219512  0.917450  0.054364  0.948600  0.906464  0.812927  0.919858  0.259689   0.082550  0.048418\n",
       " 61   P_BAD0     0    0.61  4528.0   253.0   243.0   936.0     0.949067     0.787216  0.0  0.736283  0.947479  0.212784  0.916779  0.052918  0.948074  0.906464  0.812927  0.919858  0.259689   0.083221  0.050933\n",
       " 62   P_BAD0     0    0.62  4528.0   253.0   243.0   936.0     0.949067     0.787216  0.0  0.736283  0.947479  0.212784  0.916779  0.052918  0.948074  0.906464  0.812927  0.919858  0.259689   0.083221  0.050933\n",
       " 63   P_BAD0     0    0.63  4528.0   253.0   243.0   936.0     0.949067     0.787216  0.0  0.736283  0.947479  0.212784  0.916779  0.052918  0.948074  0.906464  0.812927  0.919858  0.259689   0.083221  0.050933\n",
       " 64   P_BAD0     0    0.64  4528.0   253.0   243.0   936.0     0.949067     0.787216  0.0  0.736283  0.947479  0.212784  0.916779  0.052918  0.948074  0.906464  0.812927  0.919858  0.259689   0.083221  0.050933\n",
       " 65   P_BAD0     0    0.65  4528.0   253.0   243.0   936.0     0.949067     0.787216  0.0  0.736283  0.947479  0.212784  0.916779  0.052918  0.948074  0.906464  0.812927  0.919858  0.259689   0.083221  0.050933\n",
       " 66   P_BAD0     0    0.66  4528.0   253.0   243.0   936.0     0.949067     0.787216  0.0  0.736283  0.947479  0.212784  0.916779  0.052918  0.948074  0.906464  0.812927  0.919858  0.259689   0.083221  0.050933\n",
       " 67   P_BAD0     0    0.67  4524.0   251.0   247.0   938.0     0.948229     0.788898  0.0  0.737127  0.947593  0.211102  0.916443  0.052565  0.947832  0.906464  0.812927  0.919858  0.259689   0.083557  0.051771\n",
       " 68   P_BAD0     0    0.68  4524.0   251.0   247.0   938.0     0.948229     0.788898  0.0  0.737127  0.947593  0.211102  0.916443  0.052565  0.947832  0.906464  0.812927  0.919858  0.259689   0.083557  0.051771\n",
       " 69   P_BAD0     0    0.69  4524.0   251.0   247.0   938.0     0.948229     0.788898  0.0  0.737127  0.947593  0.211102  0.916443  0.052565  0.947832  0.906464  0.812927  0.919858  0.259689   0.083557  0.051771\n",
       " 70   P_BAD0     0    0.70  4524.0   251.0   247.0   938.0     0.948229     0.788898  0.0  0.737127  0.947593  0.211102  0.916443  0.052565  0.947832  0.906464  0.812927  0.919858  0.259689   0.083557  0.051771\n",
       " 71   P_BAD0     0    0.71  4512.0   246.0   259.0   943.0     0.945714     0.793103  1.0  0.738817  0.947780  0.206897  0.915268  0.051702  0.947004  0.906464  0.812927  0.919858  0.259689   0.084732  0.054286\n",
       " 72   P_BAD0     0    0.72  4512.0   246.0   259.0   943.0     0.945714     0.793103  0.0  0.738817  0.947780  0.206897  0.915268  0.051702  0.947004  0.906464  0.812927  0.919858  0.259689   0.084732  0.054286\n",
       " 73   P_BAD0     0    0.73  4512.0   246.0   259.0   943.0     0.945714     0.793103  0.0  0.738817  0.947780  0.206897  0.915268  0.051702  0.947004  0.906464  0.812927  0.919858  0.259689   0.084732  0.054286\n",
       " 74   P_BAD0     0    0.74  4512.0   246.0   259.0   943.0     0.945714     0.793103  0.0  0.738817  0.947780  0.206897  0.915268  0.051702  0.947004  0.906464  0.812927  0.919858  0.259689   0.084732  0.054286\n",
       " 75   P_BAD0     0    0.75  4512.0   246.0   259.0   943.0     0.945714     0.793103  0.0  0.738817  0.947780  0.206897  0.915268  0.051702  0.947004  0.906464  0.812927  0.919858  0.259689   0.084732  0.054286\n",
       " 76   P_BAD0     0    0.76  4512.0   246.0   259.0   943.0     0.945714     0.793103  0.0  0.738817  0.947780  0.206897  0.915268  0.051702  0.947004  0.906464  0.812927  0.919858  0.259689   0.084732  0.054286\n",
       " 77   P_BAD0     0    0.77  4512.0   246.0   259.0   943.0     0.945714     0.793103  0.0  0.738817  0.947780  0.206897  0.915268  0.051702  0.947004  0.906464  0.812927  0.919858  0.259689   0.084732  0.054286\n",
       " 78   P_BAD0     0    0.78  4512.0   246.0   259.0   943.0     0.945714     0.793103  0.0  0.738817  0.947780  0.206897  0.915268  0.051702  0.947004  0.906464  0.812927  0.919858  0.259689   0.084732  0.054286\n",
       " 79   P_BAD0     0    0.79  4512.0   246.0   259.0   943.0     0.945714     0.793103  0.0  0.738817  0.947780  0.206897  0.915268  0.051702  0.947004  0.906464  0.812927  0.919858  0.259689   0.084732  0.054286\n",
       " 80   P_BAD0     0    0.80  4512.0   246.0   259.0   943.0     0.945714     0.793103  0.0  0.738817  0.947780  0.206897  0.915268  0.051702  0.947004  0.906464  0.812927  0.919858  0.259689   0.084732  0.054286\n",
       " 81   P_BAD0     0    0.81  4487.0   240.0   284.0   949.0     0.940474     0.798150  0.0  0.738623  0.947464  0.201850  0.912081  0.050772  0.944830  0.906464  0.812927  0.919858  0.259689   0.087919  0.059526\n",
       " 82   P_BAD0     0    0.82  4478.0   238.0   293.0   951.0     0.938587     0.799832  0.0  0.738419  0.947324  0.200168  0.910906  0.050466  0.944029  0.906464  0.812927  0.919858  0.259689   0.089094  0.061413\n",
       " 83   P_BAD0     0    0.83  4478.0   238.0   293.0   951.0     0.938587     0.799832  0.0  0.738419  0.947324  0.200168  0.910906  0.050466  0.944029  0.906464  0.812927  0.919858  0.259689   0.089094  0.061413\n",
       " 84   P_BAD0     0    0.84  4478.0   238.0   293.0   951.0     0.938587     0.799832  0.0  0.738419  0.947324  0.200168  0.910906  0.050466  0.944029  0.906464  0.812927  0.919858  0.259689   0.089094  0.061413\n",
       " 85   P_BAD0     0    0.85  4478.0   238.0   293.0   951.0     0.938587     0.799832  0.0  0.738419  0.947324  0.200168  0.910906  0.050466  0.944029  0.906464  0.812927  0.919858  0.259689   0.089094  0.061413\n",
       " 86   P_BAD0     0    0.86  4272.0   203.0   499.0   986.0     0.895410     0.829268  0.0  0.724678  0.942173  0.170732  0.882215  0.045363  0.924075  0.906464  0.812927  0.919858  0.259689   0.117785  0.104590\n",
       " 87   P_BAD0     0    0.87  4105.0   176.0   666.0  1013.0     0.860407     0.851976  0.0  0.712383  0.937429  0.148024  0.858725  0.041112  0.906982  0.906464  0.812927  0.919858  0.259689   0.141275  0.139593\n",
       " 88   P_BAD0     0    0.88  4091.0   174.0   680.0  1015.0     0.857472     0.853659  0.0  0.711131  0.936970  0.146341  0.856711  0.040797  0.905489  0.906464  0.812927  0.919858  0.259689   0.143289  0.142528\n",
       " 89   P_BAD0     0    0.89  4091.0   174.0   680.0  1015.0     0.857472     0.853659  0.0  0.711131  0.936970  0.146341  0.856711  0.040797  0.905489  0.906464  0.812927  0.919858  0.259689   0.143289  0.142528\n",
       " 90   P_BAD0     0    0.90  4056.0   170.0   715.0  1019.0     0.850136     0.857023  0.0  0.707159  0.935640  0.142977  0.851510  0.040227  0.901634  0.906464  0.812927  0.919858  0.259689   0.148490  0.149864\n",
       " 91   P_BAD0     0    0.91  4047.0   169.0   724.0  1020.0     0.848250     0.857864  0.0  0.706114  0.935290  0.142136  0.850168  0.040085  0.900634  0.906464  0.812927  0.919858  0.259689   0.149832  0.151750\n",
       " 92   P_BAD0     0    0.92  3994.0   164.0   777.0  1025.0     0.837141     0.862069  0.0  0.699210  0.933047  0.137931  0.842114  0.039442  0.894613  0.906464  0.812927  0.919858  0.259689   0.157886  0.162859\n",
       " 93   P_BAD0     0    0.93  3932.0   159.0   839.0  1030.0     0.824146     0.866274  0.0  0.690420  0.930211  0.133726  0.832550  0.038866  0.887384  0.906464  0.812927  0.919858  0.259689   0.167450  0.175854\n",
       " 94   P_BAD0     0    0.94  3918.0   158.0   853.0  1031.0     0.821211     0.867115  0.0  0.688327  0.929537  0.132885  0.830369  0.038763  0.885724  0.906464  0.812927  0.919858  0.259689   0.169631  0.178789\n",
       " 95   P_BAD0     0    0.95  3918.0   158.0   853.0  1031.0     0.821211     0.867115  0.0  0.688327  0.929537  0.132885  0.830369  0.038763  0.885724  0.906464  0.812927  0.919858  0.259689   0.169631  0.178789\n",
       " 96   P_BAD0     0    0.96  3918.0   158.0   853.0  1031.0     0.821211     0.867115  0.0  0.688327  0.929537  0.132885  0.830369  0.038763  0.885724  0.906464  0.812927  0.919858  0.259689   0.169631  0.178789\n",
       " 97   P_BAD0     0    0.97   124.0     1.0  4647.0  1188.0     0.025990     0.999159  0.0  0.025149  0.117625  0.000841  0.220134  0.008000  0.050654  0.906464  0.812927  0.919858  0.259689   0.779866  0.974010\n",
       " 98   P_BAD0     0    0.98   124.0     1.0  4647.0  1188.0     0.025990     0.999159  0.0  0.025149  0.117625  0.000841  0.220134  0.008000  0.050654  0.906464  0.812927  0.919858  0.259689   0.779866  0.974010\n",
       " 99   P_BAD0     0    0.99    66.0     0.0  4705.0  1189.0     0.013834     1.000000  0.0  0.013834  0.065541  0.000000  0.210570  0.000000  0.027290  0.906464  0.812927  0.919858  0.259689   0.789430  0.986166\n",
       "\n",
       "[ScoreInfo]\n",
       "\n",
       "                          Descr                             Value\n",
       " 0  Number of Observations Read                              5960\n",
       " 1  Number of Observations Used                              5960\n",
       " 2  Misclassification Error (%)                      8.2382550336\n",
       "\n",
       "[TunerCasOutputTables]\n",
       "\n",
       " Tuner CAS Output Tables\n",
       " \n",
       "         CAS_Library           Name  Rows  Columns\n",
       " 0  CASUSER(sasdemo)  tree_model_at   135       41\n",
       "\n",
       "[TunerInfo]\n",
       "\n",
       " Tuner Information\n",
       " \n",
       "                            Parameter                               Value\n",
       " 0                         Model Type                       Decision Tree\n",
       " 1           Tuner Objective Function  Misclassification Error Percentage\n",
       " 2                      Search Method                                  GA\n",
       " 3                    Population Size                                  10\n",
       " 4                 Maximum Iterations                                   5\n",
       " 5     Maximum Tuning Time in Seconds                               36000\n",
       " 6                    Validation Type                    Single Partition\n",
       " 7      Validation Partition Fraction                                0.30\n",
       " 8                          Log Level                                   2\n",
       " 9                               Seed                          1876970011\n",
       " 10    Number of Parallel Evaluations                                   4\n",
       " 11  Number of Workers per Subsession                                   0\n",
       "\n",
       "[TunerResults]\n",
       "\n",
       " Tuner Results\n",
       " \n",
       "     Evaluation  MAXLEVEL  NBINS       CRIT  MisclassErr  EvaluationTime\n",
       " 0            0        11     20       GAIN    13.255034        0.325845\n",
       " 1           20        16     69  GAINRATIO    10.570470        0.867248\n",
       " 2           69        18     69  GAINRATIO    10.682327        0.881478\n",
       " 3           44        20     69  GAINRATIO    10.961969        0.903958\n",
       " 4           68        14     69  GAINRATIO    11.017897        0.902059\n",
       " 5           53        15     77  GAINRATIO    11.129754        0.591072\n",
       " 6            7        10    120       GINI    11.241611        0.613608\n",
       " 7           25         8    131       GINI    11.297539        0.315831\n",
       " 8           46        16    159  GAINRATIO    11.297539        0.188161\n",
       " 9           58        16    114  GAINRATIO    11.297539        0.497017\n",
       " 10          64         8    144  CHISQUARE    11.297539        0.508096\n",
       "\n",
       "[TunerSummary]\n",
       "\n",
       " Tuner Summary\n",
       " \n",
       "                                           Parameter      Value\n",
       " 0             Initial Configuration Objective Value  13.255034\n",
       " 1                Best Configuration Objective Value  10.570470\n",
       " 2               Worst Configuration Objective Value  15.492170\n",
       " 3  Initial Configuration Evaluation Time in Seconds   0.325845\n",
       " 4     Best Configuration Evaluation Time in Seconds   0.867237\n",
       " 5                 Number of Improved Configurations   5.000000\n",
       " 6                Number of Evaluated Configurations  71.000000\n",
       " 7                      Total Tuning Time in Seconds  12.299052\n",
       " 8                           Parallel Tuning Speedup   3.366582\n",
       "\n",
       "[TunerTiming]\n",
       "\n",
       " Tuner Task Timing\n",
       " \n",
       "                           Task   Time_sec  Time_percent\n",
       " 0               Model Training  35.370924     85.425110\n",
       " 1                Model Scoring   4.093047      9.885210\n",
       " 2  Total Objective Evaluations  39.967290     96.525895\n",
       " 3                        Tuner   1.438480      3.474105\n",
       " 4               Total CPU Time  41.405770    100.000000\n",
       "\n",
       "+ Elapsed: 12.4s, user: 0.295s, sys: 0.135s, mem: 0.276mb"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.autotune.tuneDecisionTree(\n",
    "  trainOptions=dict(\n",
    "  table=\"Home_Equity_p\",\n",
    "  inputs=all_inputs,\n",
    "  target=\"bad\",\n",
    "  nominals=class_vars,\n",
    "  crit=\"GAIN\",\n",
    "  prune=True,\n",
    "  varImp=True,\n",
    "  missing=\"USEINSEARCH\",\n",
    "\n",
    "  casOut={\"name\":\"tree_model_at\", \"replace\":True}\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: Autotune is started for 'Gradient Boosting Tree' model.\n",
      "NOTE: Autotune option SEARCHMETHOD='GA'.\n",
      "NOTE: Autotune option MAXTIME=36000 (sec.).\n",
      "NOTE: Autotune option SEED=1876966578.\n",
      "NOTE: Autotune objective is 'Misclassification Error Percentage'.\n",
      "NOTE: Early stopping is activated; 'NTREE' will not be tuned.\n",
      "NOTE: Autotune number of parallel evaluations is set to 4, each using 0 worker nodes.\n",
      "NOTE: Automatic early stopping is activated with STAGNATION=4;  set EARLYSTOP=false to deactivate.\n",
      "         Iteration       Evals     Best Objective  Elapsed Time\n",
      "                 0           1             8.1655          0.89\n",
      "                 1          25             7.6063         29.27\n",
      "                 2          46             7.6063         75.19\n",
      "                 3          65             7.6063        117.75\n",
      "                 4          83             7.2148        168.48\n",
      "                 5         102             6.9911        232.00\n",
      "NOTE: Data was partitioned during tuning, to tune based on validation score; the final model is trained and scored on all data.\n",
      "NOTE: The number of trees used in the final model is 150.\n",
      "NOTE: Autotune time is 234.38 seconds.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"cas-results-key\"><b>&#167; BestConfiguration</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><caption>Best Configuration</caption>\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"Parameter\">Parameter</th>\n",
       "      <th title=\"Internal Name\">Name</th>\n",
       "      <th title=\"Value\">Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Evaluation</td>\n",
       "      <td>Evaluation</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Number of Variables to Try</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Learning Rate</td>\n",
       "      <td>LEARNINGRATE</td>\n",
       "      <td>0.57375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Sampling Rate</td>\n",
       "      <td>SUBSAMPLERATE</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>LASSO</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>RIDGE</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Number of Bins</td>\n",
       "      <td>NBINS</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Maximum Tree Levels</td>\n",
       "      <td>MAXLEVEL</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Misclassification Error Percentage</td>\n",
       "      <td>Objective</td>\n",
       "      <td>6.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-results-key\"><hr/><b>&#167; EncodedName</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"BAD\">LEVNAME</th>\n",
       "      <th title=\"LEVINDEX\">LEVINDEX</th>\n",
       "      <th title=\"Name\">VARNAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>P_BAD1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>P_BAD0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-results-key\"><hr/><b>&#167; EncodedTargetName</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"BAD\">LEVNAME</th>\n",
       "      <th title=\"LEVINDEX\">LEVINDEX</th>\n",
       "      <th title=\"Name\">VARNAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>I_BAD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-results-key\"><hr/><b>&#167; ErrorMetricInfo</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"TreeID\">TreeID</th>\n",
       "      <th title=\"Trees\">Trees</th>\n",
       "      <th title=\"NLeaves\">NLeaves</th>\n",
       "      <th title=\"MCR\">MCR</th>\n",
       "      <th title=\"LogLoss\">LogLoss</th>\n",
       "      <th title=\"ASE\">ASE</th>\n",
       "      <th title=\"RASE\">RASE</th>\n",
       "      <th title=\"MAXAE\">MAXAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.199497</td>\n",
       "      <td>0.433672</td>\n",
       "      <td>0.134581</td>\n",
       "      <td>0.366853</td>\n",
       "      <td>0.852176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.139262</td>\n",
       "      <td>0.343284</td>\n",
       "      <td>0.101518</td>\n",
       "      <td>0.318619</td>\n",
       "      <td>0.900487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.122987</td>\n",
       "      <td>0.311157</td>\n",
       "      <td>0.091225</td>\n",
       "      <td>0.302035</td>\n",
       "      <td>0.930311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.117785</td>\n",
       "      <td>0.295864</td>\n",
       "      <td>0.086687</td>\n",
       "      <td>0.294427</td>\n",
       "      <td>0.948163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>0.110067</td>\n",
       "      <td>0.285628</td>\n",
       "      <td>0.083787</td>\n",
       "      <td>0.289460</td>\n",
       "      <td>0.957989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>145.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>5709.0</td>\n",
       "      <td>0.004027</td>\n",
       "      <td>0.037560</td>\n",
       "      <td>0.006254</td>\n",
       "      <td>0.079083</td>\n",
       "      <td>0.862794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146</td>\n",
       "      <td>146.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>5752.0</td>\n",
       "      <td>0.003859</td>\n",
       "      <td>0.037249</td>\n",
       "      <td>0.006092</td>\n",
       "      <td>0.078054</td>\n",
       "      <td>0.856313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147</td>\n",
       "      <td>147.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>5784.0</td>\n",
       "      <td>0.003859</td>\n",
       "      <td>0.036923</td>\n",
       "      <td>0.006041</td>\n",
       "      <td>0.077722</td>\n",
       "      <td>0.850913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148</td>\n",
       "      <td>148.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>5832.0</td>\n",
       "      <td>0.003523</td>\n",
       "      <td>0.036680</td>\n",
       "      <td>0.005970</td>\n",
       "      <td>0.077264</td>\n",
       "      <td>0.867468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>149</td>\n",
       "      <td>149.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>5877.0</td>\n",
       "      <td>0.003020</td>\n",
       "      <td>0.036299</td>\n",
       "      <td>0.005904</td>\n",
       "      <td>0.076840</td>\n",
       "      <td>0.876877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows  8 columns</p>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-results-key\"><hr/><b>&#167; EvalMetricInfo</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"Progress\">Progress</th>\n",
       "      <th title=\"Metric\">Metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.199497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.139262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.122987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.117785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.110067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>146.0</td>\n",
       "      <td>0.004027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146</td>\n",
       "      <td>147.0</td>\n",
       "      <td>0.003859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147</td>\n",
       "      <td>148.0</td>\n",
       "      <td>0.003859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148</td>\n",
       "      <td>149.0</td>\n",
       "      <td>0.003523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>149</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.003020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows  2 columns</p>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-results-key\"><hr/><b>&#167; EvaluationHistory</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><caption>Tuner Evaluation History</caption>\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"Evaluation\">Evaluation</th>\n",
       "      <th title=\"Iteration\">Iteration</th>\n",
       "      <th title=\"M\">M</th>\n",
       "      <th title=\"LEARNINGRATE\">LEARNINGRATE</th>\n",
       "      <th title=\"SUBSAMPLERATE\">SUBSAMPLERATE</th>\n",
       "      <th title=\"LASSO\">LASSO</th>\n",
       "      <th title=\"RIDGE\">RIDGE</th>\n",
       "      <th title=\"NBINS\">NBINS</th>\n",
       "      <th title=\"MAXLEVEL\">MAXLEVEL</th>\n",
       "      <th title=\"Misclassification Error Percentage\">MisclassErr</th>\n",
       "      <th title=\"Evaluation Time in Seconds\">EvaluationTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>8.165548</td>\n",
       "      <td>0.890372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.89000</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>8.888889</td>\n",
       "      <td>47</td>\n",
       "      <td>6</td>\n",
       "      <td>10.458613</td>\n",
       "      <td>0.763631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.12000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>4.444444</td>\n",
       "      <td>7.777778</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>19.966443</td>\n",
       "      <td>1.366838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0.67000</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>8.888889</td>\n",
       "      <td>2.222222</td>\n",
       "      <td>38</td>\n",
       "      <td>4</td>\n",
       "      <td>9.172260</td>\n",
       "      <td>4.550784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0.78000</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>7.777778</td>\n",
       "      <td>1.111111</td>\n",
       "      <td>82</td>\n",
       "      <td>2</td>\n",
       "      <td>9.228188</td>\n",
       "      <td>1.053525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.57375</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>1.111111</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>64</td>\n",
       "      <td>6</td>\n",
       "      <td>8.277405</td>\n",
       "      <td>8.213627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.57375</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>64</td>\n",
       "      <td>7</td>\n",
       "      <td>6.991051</td>\n",
       "      <td>18.154711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.57375</td>\n",
       "      <td>0.3875</td>\n",
       "      <td>1.111111</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>64</td>\n",
       "      <td>7</td>\n",
       "      <td>8.948546</td>\n",
       "      <td>11.803152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.57375</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>2.361111</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>64</td>\n",
       "      <td>7</td>\n",
       "      <td>9.004474</td>\n",
       "      <td>11.711179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.57375</td>\n",
       "      <td>0.6125</td>\n",
       "      <td>1.111111</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>64</td>\n",
       "      <td>7</td>\n",
       "      <td>8.557047</td>\n",
       "      <td>11.382936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103 rows  11 columns</p>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-results-key\"><hr/><b>&#167; FitStat</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><caption>Fit Statistics for _AUTOTUNE_DEFAULT_SCORE_TABLE_</caption>\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"Number of Observations\">NOBS</th>\n",
       "      <th title=\"Average Squared Error\">ASE</th>\n",
       "      <th title=\"Divisor for ASE\">DIV</th>\n",
       "      <th title=\"Root Average Squared Error\">RASE</th>\n",
       "      <th title=\"Misclassification (MCE)\">MCE</th>\n",
       "      <th title=\"Multi-Class Log Loss\">MCLL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5960.0</td>\n",
       "      <td>0.005904</td>\n",
       "      <td>5960.0</td>\n",
       "      <td>0.07684</td>\n",
       "      <td>0.00302</td>\n",
       "      <td>0.036299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-results-key\"><hr/><b>&#167; HyperparameterImportance</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><caption>Hyperparameter Importance</caption>\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"Hyperparameter\">Hyperparameter</th>\n",
       "      <th title=\"Relative Importance\">RelImportance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>LEARNINGRATE</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>SUBSAMPLERATE</td>\n",
       "      <td>0.384487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>LASSO</td>\n",
       "      <td>0.285032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>NBINS</td>\n",
       "      <td>0.258914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>0.181542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>MAXLEVEL</td>\n",
       "      <td>0.118315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>RIDGE</td>\n",
       "      <td>0.092150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-results-key\"><hr/><b>&#167; IterationHistory</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><caption>Tuner Iteration History</caption>\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"Iteration\">Iteration</th>\n",
       "      <th title=\"Evaluations\">Evaluations</th>\n",
       "      <th title=\"Best Objective\">Best_obj</th>\n",
       "      <th title=\"Elapsed Time\">Time_sec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.165548</td>\n",
       "      <td>0.890372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>7.606264</td>\n",
       "      <td>30.159947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>46</td>\n",
       "      <td>7.606264</td>\n",
       "      <td>76.081322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>65</td>\n",
       "      <td>7.606264</td>\n",
       "      <td>118.644823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>83</td>\n",
       "      <td>7.214765</td>\n",
       "      <td>169.373595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>102</td>\n",
       "      <td>6.991051</td>\n",
       "      <td>232.894078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-results-key\"><hr/><b>&#167; ModelInfo</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><caption>Gradient Boosting Tree for HOME_EQUITY_P_AUTOTUNE_DATA_11FA4B25-9848-604F-9F45-7E73830B6354</caption>\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"Descr\">Descr</th>\n",
       "      <th title=\"Value\">Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Number of Trees</td>\n",
       "      <td>1.500000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Distribution</td>\n",
       "      <td>2.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Learning Rate</td>\n",
       "      <td>5.737500e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Subsampling Rate</td>\n",
       "      <td>5.000000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Number of Selected Variables (M)</td>\n",
       "      <td>2.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Number of Bins</td>\n",
       "      <td>6.400000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Number of Variables</td>\n",
       "      <td>1.400000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Max Number of Tree Nodes</td>\n",
       "      <td>1.090000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Min Number of Tree Nodes</td>\n",
       "      <td>1.100000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Max Number of Branches</td>\n",
       "      <td>2.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>Min Number of Branches</td>\n",
       "      <td>2.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>Max Number of Levels</td>\n",
       "      <td>7.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>Min Number of Levels</td>\n",
       "      <td>6.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>Max Number of Leaves</td>\n",
       "      <td>5.500000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>Min Number of Leaves</td>\n",
       "      <td>6.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>Maximum Size of Leaves</td>\n",
       "      <td>2.276000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>Minimum Size of Leaves</td>\n",
       "      <td>5.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>Random Number Seed</td>\n",
       "      <td>1.876967e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>Lasso (L1) penalty</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>Ridge (L2) penalty</td>\n",
       "      <td>1.000000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>Actual Number of Trees</td>\n",
       "      <td>1.500000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>Average number of Leaves</td>\n",
       "      <td>3.918000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>Early stopping stagnation</td>\n",
       "      <td>4.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>Early stopping threshold</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>Early stopping threshold iterations</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>Early stopping tolerance</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-results-key\"><hr/><b>&#167; ROCInfo</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><caption>ROC Information for _AUTOTUNE_DEFAULT_SCORE_TABLE_</caption>\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"Analysis Variable\">Variable</th>\n",
       "      <th title=\"Event\">Event</th>\n",
       "      <th title=\"CutOff\">CutOff</th>\n",
       "      <th title=\"True Positive\">TP</th>\n",
       "      <th title=\"False Positive\">FP</th>\n",
       "      <th title=\"False Negative\">FN</th>\n",
       "      <th title=\"True Negative\">TN</th>\n",
       "      <th title=\"Sensitivity\">Sensitivity</th>\n",
       "      <th title=\"Specificity\">Specificity</th>\n",
       "      <th title=\"KS Cutoff\">KS</th>\n",
       "      <th title=\"False Positive Rate\">FPR</th>\n",
       "      <th title=\"Accuracy\">ACC</th>\n",
       "      <th title=\"False Discovery Rate\">FDR</th>\n",
       "      <th title=\"F1 Score\">F1</th>\n",
       "      <th title=\"Area Under ROC\">C</th>\n",
       "      <th title=\"Gini Coefficient\">Gini</th>\n",
       "      <th title=\"Gamma\">Gamma</th>\n",
       "      <th title=\"Tau\">Tau</th>\n",
       "      <th title=\"Misclassification (Event)\">MISCEVENT</th>\n",
       "      <th title=\"False Negative Rate\">FNR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>P_BAD0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4771.0</td>\n",
       "      <td>1189.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800503</td>\n",
       "      <td>0.199497</td>\n",
       "      <td>0.889200</td>\n",
       "      <td>0.999927</td>\n",
       "      <td>0.999854</td>\n",
       "      <td>0.999865</td>\n",
       "      <td>0.319402</td>\n",
       "      <td>0.199497</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>P_BAD0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4771.0</td>\n",
       "      <td>835.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>354.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.297729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.702271</td>\n",
       "      <td>0.859899</td>\n",
       "      <td>0.148948</td>\n",
       "      <td>0.919534</td>\n",
       "      <td>0.999927</td>\n",
       "      <td>0.999854</td>\n",
       "      <td>0.999865</td>\n",
       "      <td>0.319402</td>\n",
       "      <td>0.140101</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>P_BAD0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>4771.0</td>\n",
       "      <td>740.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>449.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.377628</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.622372</td>\n",
       "      <td>0.875839</td>\n",
       "      <td>0.134277</td>\n",
       "      <td>0.928030</td>\n",
       "      <td>0.999927</td>\n",
       "      <td>0.999854</td>\n",
       "      <td>0.999865</td>\n",
       "      <td>0.319402</td>\n",
       "      <td>0.124161</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>P_BAD0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>4771.0</td>\n",
       "      <td>646.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>543.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.456686</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.543314</td>\n",
       "      <td>0.891611</td>\n",
       "      <td>0.119254</td>\n",
       "      <td>0.936592</td>\n",
       "      <td>0.999927</td>\n",
       "      <td>0.999854</td>\n",
       "      <td>0.999865</td>\n",
       "      <td>0.319402</td>\n",
       "      <td>0.108389</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>P_BAD0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>4771.0</td>\n",
       "      <td>581.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>608.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.511354</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.488646</td>\n",
       "      <td>0.902517</td>\n",
       "      <td>0.108558</td>\n",
       "      <td>0.942606</td>\n",
       "      <td>0.999927</td>\n",
       "      <td>0.999854</td>\n",
       "      <td>0.999865</td>\n",
       "      <td>0.319402</td>\n",
       "      <td>0.097483</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>P_BAD0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>4294.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>477.0</td>\n",
       "      <td>1189.0</td>\n",
       "      <td>0.900021</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.919966</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.947380</td>\n",
       "      <td>0.999927</td>\n",
       "      <td>0.999854</td>\n",
       "      <td>0.999865</td>\n",
       "      <td>0.319402</td>\n",
       "      <td>0.080034</td>\n",
       "      <td>0.099979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>P_BAD0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.96</td>\n",
       "      <td>4183.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>588.0</td>\n",
       "      <td>1189.0</td>\n",
       "      <td>0.876755</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.901342</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.934331</td>\n",
       "      <td>0.999927</td>\n",
       "      <td>0.999854</td>\n",
       "      <td>0.999865</td>\n",
       "      <td>0.319402</td>\n",
       "      <td>0.098658</td>\n",
       "      <td>0.123245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>P_BAD0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.97</td>\n",
       "      <td>4042.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>729.0</td>\n",
       "      <td>1189.0</td>\n",
       "      <td>0.847202</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.877685</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.917281</td>\n",
       "      <td>0.999927</td>\n",
       "      <td>0.999854</td>\n",
       "      <td>0.999865</td>\n",
       "      <td>0.319402</td>\n",
       "      <td>0.122315</td>\n",
       "      <td>0.152798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>P_BAD0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.98</td>\n",
       "      <td>3783.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>988.0</td>\n",
       "      <td>1189.0</td>\n",
       "      <td>0.792916</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.834228</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.884498</td>\n",
       "      <td>0.999927</td>\n",
       "      <td>0.999854</td>\n",
       "      <td>0.999865</td>\n",
       "      <td>0.319402</td>\n",
       "      <td>0.165772</td>\n",
       "      <td>0.207084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>P_BAD0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>3205.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1566.0</td>\n",
       "      <td>1189.0</td>\n",
       "      <td>0.671767</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.737248</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.803661</td>\n",
       "      <td>0.999927</td>\n",
       "      <td>0.999854</td>\n",
       "      <td>0.999865</td>\n",
       "      <td>0.319402</td>\n",
       "      <td>0.262752</td>\n",
       "      <td>0.328233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows  22 columns</p>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-results-key\"><hr/><b>&#167; ScoreInfo</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"Descr\">Descr</th>\n",
       "      <th title=\"Value\">Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Number of Observations Read</td>\n",
       "      <td>5960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Number of Observations Used</td>\n",
       "      <td>5960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Misclassification Error (%)</td>\n",
       "      <td>0.3020134228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-results-key\"><hr/><b>&#167; TunerCasOutputTables</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><caption>Tuner CAS Output Tables</caption>\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"CAS Library\">CAS_Library</th>\n",
       "      <th title=\"Name\">Name</th>\n",
       "      <th title=\"Number of Rows\">Rows</th>\n",
       "      <th title=\"Number of Columns\">Columns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>CASUSER(sasdemo)</td>\n",
       "      <td>gb_model_at</td>\n",
       "      <td>11604</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-results-key\"><hr/><b>&#167; TunerInfo</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><caption>Tuner Information</caption>\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"Parameter\">Parameter</th>\n",
       "      <th title=\"Value\">Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Model Type</td>\n",
       "      <td>Gradient Boosting Tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Tuner Objective Function</td>\n",
       "      <td>Misclassification Error Percentage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Search Method</td>\n",
       "      <td>GA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Population Size</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Maximum Iterations</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Maximum Tuning Time in Seconds</td>\n",
       "      <td>36000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Validation Type</td>\n",
       "      <td>Single Partition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Validation Partition Fraction</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Log Level</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Seed</td>\n",
       "      <td>1876966578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>Number of Parallel Evaluations</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>Number of Workers per Subsession</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-results-key\"><hr/><b>&#167; TunerResults</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><caption>Tuner Results</caption>\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"Evaluation\">Evaluation</th>\n",
       "      <th title=\"M\">M</th>\n",
       "      <th title=\"LEARNINGRATE\">LEARNINGRATE</th>\n",
       "      <th title=\"SUBSAMPLERATE\">SUBSAMPLERATE</th>\n",
       "      <th title=\"LASSO\">LASSO</th>\n",
       "      <th title=\"RIDGE\">RIDGE</th>\n",
       "      <th title=\"NBINS\">NBINS</th>\n",
       "      <th title=\"MAXLEVEL\">MAXLEVEL</th>\n",
       "      <th title=\"Misclassification Error Percentage\">MisclassErr</th>\n",
       "      <th title=\"Evaluation Time in Seconds\">EvaluationTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>8.165548</td>\n",
       "      <td>0.890372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>2</td>\n",
       "      <td>0.573750</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>64</td>\n",
       "      <td>7</td>\n",
       "      <td>6.991051</td>\n",
       "      <td>18.154711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>77</td>\n",
       "      <td>2</td>\n",
       "      <td>0.573750</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.111111</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>64</td>\n",
       "      <td>7</td>\n",
       "      <td>7.214765</td>\n",
       "      <td>24.295455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.111111</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>64</td>\n",
       "      <td>7</td>\n",
       "      <td>7.606264</td>\n",
       "      <td>11.695281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.111111</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>64</td>\n",
       "      <td>7</td>\n",
       "      <td>7.662192</td>\n",
       "      <td>13.883914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>93</td>\n",
       "      <td>2</td>\n",
       "      <td>0.573750</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.111111</td>\n",
       "      <td>8.750000</td>\n",
       "      <td>64</td>\n",
       "      <td>7</td>\n",
       "      <td>7.662192</td>\n",
       "      <td>26.292212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>96</td>\n",
       "      <td>2</td>\n",
       "      <td>0.573750</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.111111</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>54</td>\n",
       "      <td>7</td>\n",
       "      <td>7.662192</td>\n",
       "      <td>20.816867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>84</td>\n",
       "      <td>2</td>\n",
       "      <td>0.432009</td>\n",
       "      <td>0.504985</td>\n",
       "      <td>0.893873</td>\n",
       "      <td>9.927209</td>\n",
       "      <td>63</td>\n",
       "      <td>7</td>\n",
       "      <td>7.829978</td>\n",
       "      <td>11.673819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>0.938050</td>\n",
       "      <td>0.625271</td>\n",
       "      <td>3.754523</td>\n",
       "      <td>7.918174</td>\n",
       "      <td>58</td>\n",
       "      <td>6</td>\n",
       "      <td>7.885906</td>\n",
       "      <td>13.792341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>45</td>\n",
       "      <td>9</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.111111</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>64</td>\n",
       "      <td>7</td>\n",
       "      <td>7.885906</td>\n",
       "      <td>10.651089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>53</td>\n",
       "      <td>6</td>\n",
       "      <td>0.389599</td>\n",
       "      <td>0.694323</td>\n",
       "      <td>3.354649</td>\n",
       "      <td>6.564363</td>\n",
       "      <td>42</td>\n",
       "      <td>6</td>\n",
       "      <td>7.885906</td>\n",
       "      <td>9.106488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-results-key\"><hr/><b>&#167; TunerSummary</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><caption>Tuner Summary</caption>\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"Parameter\">Parameter</th>\n",
       "      <th title=\"Value\">Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Initial Configuration Objective Value</td>\n",
       "      <td>8.165548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Best Configuration Objective Value</td>\n",
       "      <td>6.991051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Worst Configuration Objective Value</td>\n",
       "      <td>19.966443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Initial Configuration Evaluation Time in Seconds</td>\n",
       "      <td>0.890372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Best Configuration Evaluation Time in Seconds</td>\n",
       "      <td>18.154686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Number of Improved Configurations</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Number of Evaluated Configurations</td>\n",
       "      <td>102.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Total Tuning Time in Seconds</td>\n",
       "      <td>234.381348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Parallel Tuning Speedup</td>\n",
       "      <td>3.895622</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-results-key\"><hr/><b>&#167; TunerTiming</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><caption>Tuner Task Timing</caption>\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"Task\">Task</th>\n",
       "      <th title=\"Seconds\">Time_sec</th>\n",
       "      <th title=\"Percent\">Time_percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Model Training</td>\n",
       "      <td>893.361548</td>\n",
       "      <td>97.842465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Model Scoring</td>\n",
       "      <td>18.672055</td>\n",
       "      <td>2.044995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Total Objective Evaluations</td>\n",
       "      <td>912.054606</td>\n",
       "      <td>99.889760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Tuner</td>\n",
       "      <td>1.006561</td>\n",
       "      <td>0.110240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Total CPU Time</td>\n",
       "      <td>913.061167</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-output-area\"></div>\n",
       "<p class=\"cas-results-performance\"><small><span class=\"cas-elapsed\">elapsed 234s</span> &#183; <span class=\"cas-user\">user 0.515s</span> &#183; <span class=\"cas-sys\">sys 0.754s</span> &#183; <span class=\"cas-memory\">mem 0.276MB</span></small></p>"
      ],
      "text/plain": [
       "[BestConfiguration]\n",
       "\n",
       " Best Configuration\n",
       " \n",
       "                             Parameter           Name    Value\n",
       " 0                          Evaluation     Evaluation       99\n",
       " 1          Number of Variables to Try              M        2\n",
       " 2                       Learning Rate   LEARNINGRATE  0.57375\n",
       " 3                       Sampling Rate  SUBSAMPLERATE      0.5\n",
       " 4                               Lasso          LASSO        0\n",
       " 5                               Ridge          RIDGE       10\n",
       " 6                      Number of Bins          NBINS       64\n",
       " 7                 Maximum Tree Levels       MAXLEVEL        7\n",
       " 8  Misclassification Error Percentage      Objective     6.99\n",
       "\n",
       "[EncodedName]\n",
       "\n",
       "         LEVNAME  LEVINDEX VARNAME\n",
       " 0             1         0  P_BAD1\n",
       " 1             0         1  P_BAD0\n",
       "\n",
       "[EncodedTargetName]\n",
       "\n",
       "   LEVNAME  LEVINDEX VARNAME\n",
       " 0                 0   I_BAD\n",
       "\n",
       "[ErrorMetricInfo]\n",
       "\n",
       "      TreeID  Trees  NLeaves       MCR   LogLoss       ASE      RASE     MAXAE\n",
       " 0       0.0    1.0     27.0  0.199497  0.433672  0.134581  0.366853  0.852176\n",
       " 1       1.0    2.0     33.0  0.139262  0.343284  0.101518  0.318619  0.900487\n",
       " 2       2.0    3.0     70.0  0.122987  0.311157  0.091225  0.302035  0.930311\n",
       " 3       3.0    4.0    100.0  0.117785  0.295864  0.086687  0.294427  0.948163\n",
       " 4       4.0    5.0    139.0  0.110067  0.285628  0.083787  0.289460  0.957989\n",
       " 5       5.0    6.0    166.0  0.107550  0.275311  0.080748  0.284161  0.964979\n",
       " 6       6.0    7.0    196.0  0.104530  0.263378  0.077475  0.278343  0.972604\n",
       " 7       7.0    8.0    234.0  0.101342  0.255377  0.075024  0.273905  0.976012\n",
       " 8       8.0    9.0    262.0  0.098658  0.248209  0.072782  0.269782  0.980868\n",
       " 9       9.0   10.0    305.0  0.095470  0.237658  0.069412  0.263462  0.985438\n",
       " 10     10.0   11.0    348.0  0.093456  0.231497  0.067387  0.259590  0.986082\n",
       " 11     11.0   12.0    394.0  0.091443  0.226054  0.066045  0.256993  0.986864\n",
       " 12     12.0   13.0    433.0  0.088255  0.220170  0.064319  0.253612  0.989634\n",
       " 13     13.0   14.0    461.0  0.085570  0.215360  0.062687  0.250373  0.989566\n",
       " 14     14.0   15.0    492.0  0.082047  0.211279  0.061594  0.248182  0.991525\n",
       " 15     15.0   16.0    520.0  0.081040  0.206573  0.060186  0.245327  0.993107\n",
       " 16     16.0   17.0    562.0  0.080201  0.201303  0.058570  0.242013  0.995143\n",
       " 17     17.0   18.0    592.0  0.080537  0.197990  0.057764  0.240341  0.995899\n",
       " 18     18.0   19.0    626.0  0.077349  0.193424  0.056153  0.236966  0.997073\n",
       " 19     19.0   20.0    676.0  0.073993  0.188815  0.054671  0.233819  0.996146\n",
       " 20     20.0   21.0    731.0  0.075671  0.185688  0.053719  0.231773  0.994492\n",
       " 21     21.0   22.0    757.0  0.073154  0.183183  0.052963  0.230136  0.995461\n",
       " 22     22.0   23.0    799.0  0.071141  0.180773  0.051915  0.227849  0.993978\n",
       " 23     23.0   24.0    827.0  0.069128  0.177344  0.050696  0.225159  0.994872\n",
       " 24     24.0   25.0    870.0  0.067114  0.171724  0.048858  0.221038  0.995653\n",
       " 25     25.0   26.0    893.0  0.065604  0.169879  0.048270  0.219705  0.996707\n",
       " 26     26.0   27.0    931.0  0.066779  0.167686  0.047675  0.218347  0.997141\n",
       " 27     27.0   28.0    971.0  0.064597  0.163412  0.046253  0.215065  0.996901\n",
       " 28     28.0   29.0   1011.0  0.059396  0.159554  0.044942  0.211995  0.995941\n",
       " 29     29.0   30.0   1055.0  0.059060  0.157026  0.044016  0.209800  0.996592\n",
       " 30     30.0   31.0   1077.0  0.058557  0.155260  0.043462  0.208476  0.995406\n",
       " 31     31.0   32.0   1123.0  0.058221  0.151787  0.042648  0.206515  0.994682\n",
       " 32     32.0   33.0   1172.0  0.057383  0.149690  0.041844  0.204558  0.995815\n",
       " 33     33.0   34.0   1202.0  0.054698  0.147325  0.041134  0.202814  0.994606\n",
       " 34     34.0   35.0   1248.0  0.054362  0.144902  0.040137  0.200342  0.993483\n",
       " 35     35.0   36.0   1281.0  0.051846  0.142667  0.039439  0.198591  0.993050\n",
       " 36     36.0   37.0   1333.0  0.051342  0.140713  0.038799  0.196974  0.993999\n",
       " 37     37.0   38.0   1382.0  0.048826  0.137861  0.037638  0.194005  0.994597\n",
       " 38     38.0   39.0   1409.0  0.047483  0.135708  0.037035  0.192446  0.992661\n",
       " 39     39.0   40.0   1434.0  0.047315  0.133945  0.036291  0.190502  0.992100\n",
       " 40     40.0   41.0   1461.0  0.046644  0.132663  0.035660  0.188838  0.991947\n",
       " 41     41.0   42.0   1493.0  0.045805  0.130129  0.035117  0.187395  0.991838\n",
       " 42     42.0   43.0   1522.0  0.044463  0.128129  0.034474  0.185671  0.992397\n",
       " 43     43.0   44.0   1566.0  0.045470  0.126428  0.034155  0.184811  0.992175\n",
       " 44     44.0   45.0   1610.0  0.043792  0.124782  0.033745  0.183699  0.993388\n",
       " 45     45.0   46.0   1640.0  0.042785  0.122385  0.032920  0.181439  0.993271\n",
       " 46     46.0   47.0   1691.0  0.040604  0.120033  0.032127  0.179240  0.992604\n",
       " 47     47.0   48.0   1739.0  0.039597  0.118001  0.031524  0.177549  0.990546\n",
       " 48     48.0   49.0   1787.0  0.038255  0.115881  0.030732  0.175305  0.988265\n",
       " 49     49.0   50.0   1826.0  0.038255  0.114026  0.030183  0.173733  0.989691\n",
       " 50     50.0   51.0   1878.0  0.036577  0.112256  0.029317  0.171221  0.987195\n",
       " 51     51.0   52.0   1913.0  0.036577  0.110731  0.028921  0.170061  0.988734\n",
       " 52     52.0   53.0   1957.0  0.036409  0.109075  0.028529  0.168905  0.990014\n",
       " 53     53.0   54.0   1992.0  0.034396  0.107120  0.028022  0.167397  0.987728\n",
       " 54     54.0   55.0   2030.0  0.034228  0.105752  0.027472  0.165748  0.987970\n",
       " 55     55.0   56.0   2068.0  0.034564  0.104633  0.027150  0.164772  0.987127\n",
       " 56     56.0   57.0   2109.0  0.033557  0.103624  0.026850  0.163858  0.985384\n",
       " 57     57.0   58.0   2145.0  0.033054  0.101491  0.026252  0.162025  0.984758\n",
       " 58     58.0   59.0   2182.0  0.032047  0.099696  0.025791  0.160596  0.986313\n",
       " 59     59.0   60.0   2228.0  0.031376  0.098006  0.025118  0.158486  0.985496\n",
       " 60     60.0   61.0   2270.0  0.030537  0.096290  0.024665  0.157050  0.987436\n",
       " 61     61.0   62.0   2314.0  0.030034  0.095238  0.024315  0.155934  0.988469\n",
       " 62     62.0   63.0   2346.0  0.029866  0.093858  0.023757  0.154132  0.988584\n",
       " 63     63.0   64.0   2385.0  0.029195  0.092023  0.023233  0.152423  0.989594\n",
       " 64     64.0   65.0   2432.0  0.028356  0.091322  0.023169  0.152215  0.989575\n",
       " 65     65.0   66.0   2474.0  0.028020  0.090790  0.022802  0.151002  0.990157\n",
       " 66     66.0   67.0   2520.0  0.026678  0.089738  0.022475  0.149917  0.991540\n",
       " 67     67.0   68.0   2559.0  0.026174  0.088414  0.022109  0.148692  0.992433\n",
       " 68     68.0   69.0   2606.0  0.024161  0.087128  0.021638  0.147099  0.991255\n",
       " 69     69.0   70.0   2648.0  0.024497  0.085895  0.021203  0.145611  0.992831\n",
       " 70     70.0   71.0   2685.0  0.024329  0.084616  0.020907  0.144594  0.992813\n",
       " 71     71.0   72.0   2730.0  0.023154  0.083275  0.020411  0.142865  0.990715\n",
       " 72     72.0   73.0   2774.0  0.023322  0.082175  0.020007  0.141447  0.991685\n",
       " 73     73.0   74.0   2811.0  0.021477  0.080773  0.019394  0.139262  0.990030\n",
       " 74     74.0   75.0   2843.0  0.020470  0.080041  0.019192  0.138537  0.988879\n",
       " 75     75.0   76.0   2887.0  0.020134  0.079219  0.018895  0.137459  0.985812\n",
       " 76     76.0   77.0   2929.0  0.020302  0.078310  0.018640  0.136529  0.989148\n",
       " 77     77.0   78.0   2971.0  0.019799  0.077519  0.018403  0.135658  0.987244\n",
       " 78     78.0   79.0   3021.0  0.019128  0.076299  0.017932  0.133910  0.987927\n",
       " 79     79.0   80.0   3059.0  0.019631  0.075945  0.017813  0.133465  0.985730\n",
       " 80     80.0   81.0   3107.0  0.017785  0.075435  0.017550  0.132478  0.986401\n",
       " 81     81.0   82.0   3159.0  0.017114  0.074524  0.017158  0.130990  0.988618\n",
       " 82     82.0   83.0   3194.0  0.016107  0.073655  0.016853  0.129819  0.985970\n",
       " 83     83.0   84.0   3236.0  0.015436  0.072780  0.016727  0.129334  0.984369\n",
       " 84     84.0   85.0   3282.0  0.016275  0.071677  0.016396  0.128049  0.987117\n",
       " 85     85.0   86.0   3325.0  0.016107  0.070615  0.016044  0.126663  0.983446\n",
       " 86     86.0   87.0   3368.0  0.014933  0.069779  0.015729  0.125416  0.979757\n",
       " 87     87.0   88.0   3400.0  0.015604  0.068697  0.015312  0.123743  0.978233\n",
       " 88     88.0   89.0   3437.0  0.014430  0.068048  0.015088  0.122832  0.976158\n",
       " 89     89.0   90.0   3473.0  0.015604  0.067343  0.015038  0.122629  0.979538\n",
       " 90     90.0   91.0   3509.0  0.016107  0.066862  0.015265  0.123552  0.976296\n",
       " 91     91.0   92.0   3545.0  0.014430  0.065799  0.014888  0.122018  0.977045\n",
       " 92     92.0   93.0   3596.0  0.014430  0.064650  0.014526  0.120526  0.971090\n",
       " 93     93.0   94.0   3644.0  0.013591  0.063762  0.014206  0.119190  0.967033\n",
       " 94     94.0   95.0   3687.0  0.013758  0.063060  0.013859  0.117722  0.963816\n",
       " 95     95.0   96.0   3729.0  0.014094  0.062546  0.013736  0.117201  0.961698\n",
       " 96     96.0   97.0   3753.0  0.013087  0.061907  0.013590  0.116576  0.967516\n",
       " 97     97.0   98.0   3795.0  0.013087  0.060929  0.013274  0.115215  0.961841\n",
       " 98     98.0   99.0   3841.0  0.012416  0.060309  0.013125  0.114563  0.959367\n",
       " 99     99.0  100.0   3880.0  0.012081  0.059716  0.013070  0.114323  0.965631\n",
       " 100   100.0  101.0   3927.0  0.011409  0.058892  0.012811  0.113184  0.960229\n",
       " 101   101.0  102.0   3971.0  0.010906  0.057821  0.012393  0.111323  0.964018\n",
       " 102   102.0  103.0   4015.0  0.011074  0.057171  0.012132  0.110144  0.970663\n",
       " 103   103.0  104.0   4067.0  0.009899  0.056349  0.011792  0.108591  0.974263\n",
       " 104   104.0  105.0   4104.0  0.009899  0.055763  0.011581  0.107614  0.970796\n",
       " 105   105.0  106.0   4138.0  0.009899  0.055276  0.011379  0.106674  0.973285\n",
       " 106   106.0  107.0   4189.0  0.010067  0.054780  0.011330  0.106440  0.970751\n",
       " 107   107.0  108.0   4236.0  0.009396  0.054155  0.011140  0.105547  0.970413\n",
       " 108   108.0  109.0   4279.0  0.009060  0.053713  0.011034  0.105042  0.973844\n",
       " 109   109.0  110.0   4317.0  0.008893  0.053126  0.010894  0.104372  0.971758\n",
       " 110   110.0  111.0   4366.0  0.008725  0.052404  0.010518  0.102556  0.968306\n",
       " 111   111.0  112.0   4402.0  0.009396  0.052179  0.010725  0.103562  0.969562\n",
       " 112   112.0  113.0   4436.0  0.008557  0.051770  0.010413  0.102046  0.966629\n",
       " 113   113.0  114.0   4485.0  0.008725  0.050974  0.010190  0.100948  0.972101\n",
       " 114   114.0  115.0   4521.0  0.009060  0.050413  0.010095  0.100474  0.972414\n",
       " 115   115.0  116.0   4557.0  0.008725  0.049954  0.009824  0.099115  0.971850\n",
       " 116   116.0  117.0   4594.0  0.007550  0.049490  0.009613  0.098047  0.976352\n",
       " 117   117.0  118.0   4627.0  0.007718  0.049017  0.009462  0.097271  0.974367\n",
       " 118   118.0  119.0   4668.0  0.007383  0.048415  0.009317  0.096524  0.977430\n",
       " 119   119.0  120.0   4702.0  0.007047  0.047978  0.009102  0.095405  0.972585\n",
       " 120   120.0  121.0   4732.0  0.006879  0.047636  0.008931  0.094502  0.967481\n",
       " 121   121.0  122.0   4755.0  0.007215  0.047366  0.008938  0.094543  0.969879\n",
       " 122   122.0  123.0   4785.0  0.007718  0.047100  0.008951  0.094611  0.974193\n",
       " 123   123.0  124.0   4827.0  0.007215  0.046806  0.008809  0.093858  0.969798\n",
       " 124   124.0  125.0   4870.0  0.006879  0.046245  0.008729  0.093427  0.968788\n",
       " 125   125.0  126.0   4915.0  0.006544  0.045793  0.008540  0.092410  0.964192\n",
       " 126   126.0  127.0   4955.0  0.006544  0.045343  0.008399  0.091644  0.957951\n",
       " 127   127.0  128.0   4993.0  0.006376  0.044895  0.008339  0.091318  0.959072\n",
       " 128   128.0  129.0   5027.0  0.006208  0.044700  0.008222  0.090674  0.957308\n",
       " 129   129.0  130.0   5051.0  0.005369  0.044533  0.008131  0.090172  0.955727\n",
       " 130   130.0  131.0   5085.0  0.004866  0.044160  0.007945  0.089134  0.948644\n",
       " 131   131.0  132.0   5139.0  0.004698  0.043698  0.007871  0.088720  0.943306\n",
       " 132   132.0  133.0   5178.0  0.004866  0.043228  0.007712  0.087817  0.931079\n",
       " 133   133.0  134.0   5219.0  0.004866  0.042726  0.007560  0.086948  0.925800\n",
       " 134   134.0  135.0   5265.0  0.004530  0.042221  0.007411  0.086089  0.912383\n",
       " 135   135.0  136.0   5297.0  0.004195  0.041669  0.007301  0.085445  0.919877\n",
       " 136   136.0  137.0   5339.0  0.003859  0.041330  0.007169  0.084673  0.910560\n",
       " 137   137.0  138.0   5380.0  0.003859  0.040861  0.007019  0.083778  0.922878\n",
       " 138   138.0  139.0   5420.0  0.003859  0.040437  0.006893  0.083024  0.915884\n",
       " 139   139.0  140.0   5459.0  0.004027  0.039943  0.006795  0.082429  0.904589\n",
       " 140   140.0  141.0   5490.0  0.003188  0.039581  0.006658  0.081598  0.893942\n",
       " 141   141.0  142.0   5538.0  0.004027  0.039130  0.006600  0.081239  0.884838\n",
       " 142   142.0  143.0   5575.0  0.003859  0.038889  0.006588  0.081164  0.898975\n",
       " 143   143.0  144.0   5622.0  0.003356  0.038401  0.006437  0.080230  0.886150\n",
       " 144   144.0  145.0   5663.0  0.003691  0.037973  0.006390  0.079940  0.881653\n",
       " 145   145.0  146.0   5709.0  0.004027  0.037560  0.006254  0.079083  0.862794\n",
       " 146   146.0  147.0   5752.0  0.003859  0.037249  0.006092  0.078054  0.856313\n",
       " 147   147.0  148.0   5784.0  0.003859  0.036923  0.006041  0.077722  0.850913\n",
       " 148   148.0  149.0   5832.0  0.003523  0.036680  0.005970  0.077264  0.867468\n",
       " 149   149.0  150.0   5877.0  0.003020  0.036299  0.005904  0.076840  0.876877\n",
       "\n",
       "[EvalMetricInfo]\n",
       "\n",
       "      Progress    Metric\n",
       " 0         1.0  0.199497\n",
       " 1         2.0  0.139262\n",
       " 2         3.0  0.122987\n",
       " 3         4.0  0.117785\n",
       " 4         5.0  0.110067\n",
       " 5         6.0  0.107383\n",
       " 6         7.0  0.104362\n",
       " 7         8.0  0.101174\n",
       " 8         9.0  0.098490\n",
       " 9        10.0  0.095470\n",
       " 10       11.0  0.093456\n",
       " 11       12.0  0.091443\n",
       " 12       13.0  0.088255\n",
       " 13       14.0  0.085570\n",
       " 14       15.0  0.082047\n",
       " 15       16.0  0.081040\n",
       " 16       17.0  0.080201\n",
       " 17       18.0  0.080537\n",
       " 18       19.0  0.077349\n",
       " 19       20.0  0.073993\n",
       " 20       21.0  0.075671\n",
       " 21       22.0  0.073154\n",
       " 22       23.0  0.071141\n",
       " 23       24.0  0.068792\n",
       " 24       25.0  0.066946\n",
       " 25       26.0  0.065436\n",
       " 26       27.0  0.066611\n",
       " 27       28.0  0.064597\n",
       " 28       29.0  0.059396\n",
       " 29       30.0  0.059060\n",
       " 30       31.0  0.058557\n",
       " 31       32.0  0.058054\n",
       " 32       33.0  0.057383\n",
       " 33       34.0  0.054698\n",
       " 34       35.0  0.054362\n",
       " 35       36.0  0.052013\n",
       " 36       37.0  0.051342\n",
       " 37       38.0  0.048826\n",
       " 38       39.0  0.047483\n",
       " 39       40.0  0.047315\n",
       " 40       41.0  0.046644\n",
       " 41       42.0  0.045805\n",
       " 42       43.0  0.044463\n",
       " 43       44.0  0.045470\n",
       " 44       45.0  0.043960\n",
       " 45       46.0  0.042785\n",
       " 46       47.0  0.040604\n",
       " 47       48.0  0.039597\n",
       " 48       49.0  0.038255\n",
       " 49       50.0  0.038423\n",
       " 50       51.0  0.036577\n",
       " 51       52.0  0.036745\n",
       " 52       53.0  0.036577\n",
       " 53       54.0  0.034564\n",
       " 54       55.0  0.034228\n",
       " 55       56.0  0.034732\n",
       " 56       57.0  0.033557\n",
       " 57       58.0  0.033054\n",
       " 58       59.0  0.032047\n",
       " 59       60.0  0.031376\n",
       " 60       61.0  0.030537\n",
       " 61       62.0  0.030034\n",
       " 62       63.0  0.029866\n",
       " 63       64.0  0.029195\n",
       " 64       65.0  0.028356\n",
       " 65       66.0  0.028020\n",
       " 66       67.0  0.026678\n",
       " 67       68.0  0.026174\n",
       " 68       69.0  0.024161\n",
       " 69       70.0  0.024497\n",
       " 70       71.0  0.024329\n",
       " 71       72.0  0.023154\n",
       " 72       73.0  0.023322\n",
       " 73       74.0  0.021477\n",
       " 74       75.0  0.020470\n",
       " 75       76.0  0.020134\n",
       " 76       77.0  0.020302\n",
       " 77       78.0  0.019799\n",
       " 78       79.0  0.019128\n",
       " 79       80.0  0.019631\n",
       " 80       81.0  0.017785\n",
       " 81       82.0  0.017114\n",
       " 82       83.0  0.016107\n",
       " 83       84.0  0.015436\n",
       " 84       85.0  0.016275\n",
       " 85       86.0  0.016107\n",
       " 86       87.0  0.014933\n",
       " 87       88.0  0.015604\n",
       " 88       89.0  0.014430\n",
       " 89       90.0  0.015604\n",
       " 90       91.0  0.016107\n",
       " 91       92.0  0.014430\n",
       " 92       93.0  0.014430\n",
       " 93       94.0  0.013591\n",
       " 94       95.0  0.013758\n",
       " 95       96.0  0.014094\n",
       " 96       97.0  0.013087\n",
       " 97       98.0  0.013087\n",
       " 98       99.0  0.012416\n",
       " 99      100.0  0.012081\n",
       " 100     101.0  0.011409\n",
       " 101     102.0  0.010906\n",
       " 102     103.0  0.011074\n",
       " 103     104.0  0.009899\n",
       " 104     105.0  0.009899\n",
       " 105     106.0  0.009899\n",
       " 106     107.0  0.010067\n",
       " 107     108.0  0.009396\n",
       " 108     109.0  0.009060\n",
       " 109     110.0  0.008893\n",
       " 110     111.0  0.008725\n",
       " 111     112.0  0.009396\n",
       " 112     113.0  0.008557\n",
       " 113     114.0  0.008725\n",
       " 114     115.0  0.009060\n",
       " 115     116.0  0.008725\n",
       " 116     117.0  0.007550\n",
       " 117     118.0  0.007718\n",
       " 118     119.0  0.007383\n",
       " 119     120.0  0.007047\n",
       " 120     121.0  0.006879\n",
       " 121     122.0  0.007215\n",
       " 122     123.0  0.007718\n",
       " 123     124.0  0.007215\n",
       " 124     125.0  0.006879\n",
       " 125     126.0  0.006544\n",
       " 126     127.0  0.006544\n",
       " 127     128.0  0.006376\n",
       " 128     129.0  0.006208\n",
       " 129     130.0  0.005369\n",
       " 130     131.0  0.004866\n",
       " 131     132.0  0.004698\n",
       " 132     133.0  0.004866\n",
       " 133     134.0  0.004866\n",
       " 134     135.0  0.004530\n",
       " 135     136.0  0.004195\n",
       " 136     137.0  0.003859\n",
       " 137     138.0  0.003859\n",
       " 138     139.0  0.003859\n",
       " 139     140.0  0.004027\n",
       " 140     141.0  0.003188\n",
       " 141     142.0  0.004027\n",
       " 142     143.0  0.003859\n",
       " 143     144.0  0.003356\n",
       " 144     145.0  0.003691\n",
       " 145     146.0  0.004027\n",
       " 146     147.0  0.003859\n",
       " 147     148.0  0.003859\n",
       " 148     149.0  0.003523\n",
       " 149     150.0  0.003020\n",
       "\n",
       "[EvaluationHistory]\n",
       "\n",
       " Tuner Evaluation History\n",
       " \n",
       "      Evaluation  Iteration   M  LEARNINGRATE  SUBSAMPLERATE      LASSO      RIDGE  NBINS  MAXLEVEL  MisclassErr  EvaluationTime\n",
       " 0             0          0  14      0.100000       0.500000   0.000000   1.000000     50         5     8.165548        0.890372\n",
       " 1             1          1   1      0.890000       0.800000   6.666667   8.888889     47         6    10.458613        0.763631\n",
       " 2             2          1   5      0.120000       1.000000   4.444444   7.777778     29         2    19.966443        1.366838\n",
       " 3             3          1  13      0.670000       0.200000   8.888889   2.222222     38         4     9.172260        4.550784\n",
       " 4             4          1  14      0.780000       0.600000   7.777778   1.111111     82         2     9.228188        1.053525\n",
       " 5             5          1  10      0.340000       0.900000   5.555556   3.333333     20         5     8.836689        4.394710\n",
       " 6             6          1   8      1.000000       0.400000   0.000000   6.666667     73         5     9.340045       12.704420\n",
       " 7             7          1   2      0.450000       0.500000   1.111111  10.000000     64         7     7.606264       11.695281\n",
       " 8             8          1   7      0.010000       0.700000   3.333333   4.444444    100         7    19.966443        2.599725\n",
       " 9             9          1  11      0.230000       0.300000   2.222222   5.555556     56         4     9.955257        5.104902\n",
       " 10           10          1  14      0.100000       0.500000   0.000000   1.000000     50         5     8.165548        0.000000\n",
       " 11           11          1   8      0.505000       0.550000   5.000000   5.000000     60         5     8.892617        6.022385\n",
       " 12           12          1  14      0.505000       0.550000   5.000000   5.000000     60         5     8.389262        7.584723\n",
       " 13           13          1   1      0.505000       0.550000   5.000000   5.000000     60         5    10.011186        5.504640\n",
       " 14           14          1   8      1.000000       0.550000   5.000000   5.000000     60         5     9.563758        2.593388\n",
       " 15           15          1   8      0.010000       0.550000   5.000000   5.000000     60         5    19.966443        1.701455\n",
       " 16           16          1   8      0.505000       1.000000   5.000000   5.000000     60         5     8.053691        7.104381\n",
       " 17           17          1   8      0.505000       0.100000   5.000000   5.000000     60         5    10.626398        7.194569\n",
       " 18           18          1   8      0.505000       0.550000  10.000000   5.000000     60         5     9.116331        5.315112\n",
       " 19           19          1   8      0.505000       0.550000   0.000000   5.000000     60         5     8.668904        4.592439\n",
       " 20           20          1   8      0.505000       0.550000   5.000000  10.000000     60         5     8.389262        5.226623\n",
       " 21           21          1   8      0.505000       0.550000   5.000000   0.000000     60         5     8.724832        4.600219\n",
       " 22           22          1   8      0.505000       0.550000   5.000000   5.000000    100         5     9.284116        4.498070\n",
       " 23           23          1   8      0.505000       0.550000   5.000000   5.000000     20         5     9.563758        4.493888\n",
       " 24           24          1   8      0.505000       0.550000   5.000000   5.000000     60         7     9.116331        0.816011\n",
       " 25           25          1   8      0.505000       0.550000   5.000000   5.000000     60         2    10.961969        0.411127\n",
       " 26           26          2   7      0.697716       0.450392   8.608932   0.000000    100         4     9.228188        5.279637\n",
       " 27           27          2  11      0.807716       0.650392   7.497820   3.070812     73         3     9.172260        3.873856\n",
       " 28           28          2  10      0.328666       0.838178   5.212099   3.562304     24         5     8.557047       15.272349\n",
       " 29           29          2   1      0.519449       0.247458   0.000000   3.766432     92         6     9.619687        7.085266\n",
       " 30           30          2   5      0.409449       0.647458   2.749536   7.542363     48         6     8.165548        8.608712\n",
       " 31           31          2  11      0.972594       0.225271   6.345077   5.695952     84         5    10.178971        6.504051\n",
       " 32           32          2   4      0.938050       0.625271   3.754523   7.918174     58         6     7.885906       13.792341\n",
       " 33           33          2  12      1.000000       0.873640  10.000000   0.000000    100         3     9.395973        4.791308\n",
       " 34           34          2  14      0.731673       0.573640   7.289625   1.501633     80         2    10.682327        1.687698\n",
       " 35           35          2   2      0.450000       0.500000   6.111111  10.000000     64         7     8.501119        9.214444\n",
       " 36           36          2   2      0.945000       0.500000   1.111111  10.000000     64         7     8.389262       14.115289\n",
       " 37           37          2   2      0.010000       0.500000   1.111111  10.000000     64         7    19.966443        1.713496\n",
       " 38           38          2   2      0.450000       0.950000   1.111111  10.000000     64         7     8.389262       11.194454\n",
       " 39           39          2   2      0.450000       0.100000   1.111111  10.000000     64         7    11.129754        8.501407\n",
       " 40           40          2   2      0.450000       0.500000   1.111111  10.000000     24         7     9.004474        6.300372\n",
       " 41           41          2   2      0.450000       0.500000   0.000000  10.000000     64         7     9.675615        5.890473\n",
       " 42           42          2   2      0.450000       0.500000   1.111111   5.000000     64         7     7.662192       13.883914\n",
       " 43           43          2   2      0.450000       0.500000   1.111111  10.000000    100         7     8.724832        8.606809\n",
       " 44           44          2   2      0.450000       0.500000   1.111111  10.000000     64         5     8.109620       15.689251\n",
       " 45           45          2   9      0.450000       0.500000   1.111111  10.000000     64         7     7.885906       10.651089\n",
       " 46           46          2   1      0.450000       0.500000   1.111111  10.000000     64         7     9.060403        7.519762\n",
       " 47           47          3  11      0.751263       0.795950   7.892510   2.171985     69         2     9.787472        1.867231\n",
       " 48           48          3  11      0.916141       0.370829   6.739767   4.797125     80         4     9.060403        3.856365\n",
       " 49           49          3   6      0.658538       0.441874   3.617698   3.430795     83         5     8.165548       14.250183\n",
       " 50           50          3   2      0.384680       0.483234   0.757322   8.166310     65         6     8.557047        6.651233\n",
       " 51           51          3   4      0.872731       0.608505   3.400734   0.000000     59         6     8.277405        5.803727\n",
       " 52           52          3   1      0.470382       0.503603   0.892086  10.000000     66         7    10.906040        3.610585\n",
       " 53           53          3   6      0.389599       0.694323   3.354649   6.564363     42         6     7.885906        9.106488\n",
       " 54           54          3   1      0.182224       0.100000   0.000000   4.256846     57         3    19.966443        1.000549\n",
       " 55           55          3   4      0.539940       0.537813   2.716909   8.257808     66         6     8.612975        9.288118\n",
       " 56           56          3   2      0.450000       0.500000   1.111111  10.000000     64         6     8.221477        9.992248\n",
       " 57           57          3   2      0.450000       0.500000   1.111111   7.500000     64         7     8.445190       12.303644\n",
       " 58           58          3   2      0.450000       0.275000   1.111111  10.000000     64         7    10.290828        7.689640\n",
       " 59           59          3   2      0.450000       0.500000   3.611111  10.000000     64         7     8.668904       13.609361\n",
       " 60           60          3   2      0.202500       0.500000   1.111111  10.000000     64         7     8.165548       20.612567\n",
       " 61           61          3   2      0.450000       0.725000   1.111111  10.000000     64         7     9.451902        6.705153\n",
       " 62           62          3   2      0.450000       0.500000   1.111111  10.000000     84         7     8.501119       14.602028\n",
       " 63           63          3   2      0.450000       0.500000   1.111111  10.000000     44         7     8.445190        8.609855\n",
       " 64           64          3   5      0.450000       0.500000   1.111111  10.000000     64         7     8.109620       11.989480\n",
       " 65           65          3   2      0.697500       0.500000   1.111111  10.000000     64         7     8.612975        3.799840\n",
       " 66           66          4   7      0.062127       0.752491   3.323413  10.000000     30         6    19.966443        0.400484\n",
       " 67           67          4   5      0.545259       0.666673   3.369497   4.449395     47         6     8.053691        5.997883\n",
       " 68           68          4   3      0.510637       0.483197   1.843304   9.323194     66         7     8.389262       16.701500\n",
       " 69           69          4   7      0.083543       0.748687   3.325456  10.000000     31         6    19.966443        0.610228\n",
       " 70           70          4   5      0.566675       0.662869   3.371540   4.158408     48         6     8.109620        4.900888\n",
       " 71           71          4   8      0.392179       0.805071   4.717339   5.723900     30         6     7.997763       15.284756\n",
       " 72           72          4   4      0.387261       0.593982   2.120012   7.325847     53         6     9.004474        6.395634\n",
       " 73           73          4   6      0.665115       0.440881   3.686397   3.317060     83         5     8.445190        9.597665\n",
       " 74           74          4   2      0.391258       0.482241   0.826021   8.052574     65         6     9.172260        5.104234\n",
       " 75           75          4   2      0.450000       0.500000   1.111111   8.750000     64         7     8.109620       18.093848\n",
       " 76           76          4   2      0.450000       0.500000   1.111111  10.000000     74         7     8.724832        8.198003\n",
       " 77           77          4   2      0.573750       0.500000   1.111111  10.000000     64         7     7.214765       24.295455\n",
       " 78           78          4   4      0.450000       0.500000   1.111111  10.000000     64         7     7.997763       19.494898\n",
       " 79           79          4   2      0.450000       0.387500   1.111111  10.000000     64         7     8.501119       13.902104\n",
       " 80           80          4   2      0.450000       0.500000   2.361111  10.000000     64         7     8.780761       16.299690\n",
       " 81           81          4   2      0.450000       0.612500   1.111111  10.000000     64         7     8.389262       14.300335\n",
       " 82           82          4   2      0.450000       0.500000   1.111111  10.000000     54         7     8.445190       12.730456\n",
       " 83           83          4   2      0.326250       0.500000   1.111111  10.000000     64         7     8.724832        9.730716\n",
       " 84           84          5   2      0.432009       0.504985   0.893873   9.927209     63         7     7.829978       11.673819\n",
       " 85           85          5   3      0.492646       0.488182   1.626066   9.523999     65         7     8.501119       10.555134\n",
       " 86           86          5   6      0.411192       0.704756   3.531525   7.129984     41         2    10.234899        1.468907\n",
       " 87           87          5   1      0.548176       0.433375   0.517875  10.000000     73         6     9.172260        7.568699\n",
       " 88           88          5   6      0.181719       0.682062   2.732219  10.000000     40         6     8.165548       17.221549\n",
       " 89           89          5   1      0.261934       0.551686   0.000000   8.124278     47         5     8.892617       11.503824\n",
       " 90           90          5   3      0.477050       0.492566   1.434939   9.159656     66         7     8.221477       20.302421\n",
       " 91           91          5   7      0.663875       0.808729   5.328565   1.674110     33         6     8.053691        7.794160\n",
       " 92           92          5   4      0.509874       0.624297   2.785089   5.277289     51         6     8.780761        4.982334\n",
       " 93           93          5   2      0.573750       0.500000   1.111111   8.750000     64         7     7.662192       26.292212\n",
       " 94           94          5   4      0.573750       0.500000   1.111111  10.000000     64         7     8.333333       11.689562\n",
       " 95           95          5   2      0.573750       0.500000   1.111111  10.000000     74         7     7.885906       18.297474\n",
       " 96           96          5   2      0.573750       0.500000   1.111111  10.000000     54         7     7.662192       20.816867\n",
       " 97           97          5   1      0.573750       0.500000   1.111111  10.000000     64         7     9.451902       20.000093\n",
       " 98           98          5   2      0.573750       0.500000   1.111111  10.000000     64         6     8.277405        8.213627\n",
       " 99           99          5   2      0.573750       0.500000   0.000000  10.000000     64         7     6.991051       18.154711\n",
       " 100         100          5   2      0.573750       0.387500   1.111111  10.000000     64         7     8.948546       11.803152\n",
       " 101         101          5   2      0.573750       0.500000   2.361111  10.000000     64         7     9.004474       11.711179\n",
       " 102         102          5   2      0.573750       0.612500   1.111111  10.000000     64         7     8.557047       11.382936\n",
       "\n",
       "[FitStat]\n",
       "\n",
       " Fit Statistics for _AUTOTUNE_DEFAULT_SCORE_TABLE_\n",
       " \n",
       "      NOBS       ASE     DIV     RASE      MCE      MCLL\n",
       " 0  5960.0  0.005904  5960.0  0.07684  0.00302  0.036299\n",
       "\n",
       "[HyperparameterImportance]\n",
       "\n",
       " Hyperparameter Importance\n",
       " \n",
       "   Hyperparameter  RelImportance\n",
       " 0   LEARNINGRATE       1.000000\n",
       " 1  SUBSAMPLERATE       0.384487\n",
       " 2          LASSO       0.285032\n",
       " 3          NBINS       0.258914\n",
       " 4              M       0.181542\n",
       " 5       MAXLEVEL       0.118315\n",
       " 6          RIDGE       0.092150\n",
       "\n",
       "[IterationHistory]\n",
       "\n",
       " Tuner Iteration History\n",
       " \n",
       "    Iteration  Evaluations  Best_obj    Time_sec\n",
       " 0          0            1  8.165548    0.890372\n",
       " 1          1           25  7.606264   30.159947\n",
       " 2          2           46  7.606264   76.081322\n",
       " 3          3           65  7.606264  118.644823\n",
       " 4          4           83  7.214765  169.373595\n",
       " 5          5          102  6.991051  232.894078\n",
       "\n",
       "[ModelInfo]\n",
       "\n",
       " Gradient Boosting Tree for HOME_EQUITY_P_AUTOTUNE_DATA_11FA4B25-9848-604F-9F45-7E73830B6354\n",
       " \n",
       "                                   Descr         Value\n",
       " 0                       Number of Trees  1.500000e+02\n",
       " 1                          Distribution  2.000000e+00\n",
       " 2                         Learning Rate  5.737500e-01\n",
       " 3                      Subsampling Rate  5.000000e-01\n",
       " 4      Number of Selected Variables (M)  2.000000e+00\n",
       " 5                        Number of Bins  6.400000e+01\n",
       " 6                   Number of Variables  1.400000e+01\n",
       " 7              Max Number of Tree Nodes  1.090000e+02\n",
       " 8              Min Number of Tree Nodes  1.100000e+01\n",
       " 9                Max Number of Branches  2.000000e+00\n",
       " 10               Min Number of Branches  2.000000e+00\n",
       " 11                 Max Number of Levels  7.000000e+00\n",
       " 12                 Min Number of Levels  6.000000e+00\n",
       " 13                 Max Number of Leaves  5.500000e+01\n",
       " 14                 Min Number of Leaves  6.000000e+00\n",
       " 15               Maximum Size of Leaves  2.276000e+03\n",
       " 16               Minimum Size of Leaves  5.000000e+00\n",
       " 17                   Random Number Seed  1.876967e+09\n",
       " 18                   Lasso (L1) penalty  0.000000e+00\n",
       " 19                   Ridge (L2) penalty  1.000000e+01\n",
       " 20               Actual Number of Trees  1.500000e+02\n",
       " 21             Average number of Leaves  3.918000e+01\n",
       " 22            Early stopping stagnation  4.000000e+00\n",
       " 23             Early stopping threshold  0.000000e+00\n",
       " 24  Early stopping threshold iterations  0.000000e+00\n",
       " 25             Early stopping tolerance  0.000000e+00\n",
       "\n",
       "[ROCInfo]\n",
       "\n",
       " ROC Information for _AUTOTUNE_DEFAULT_SCORE_TABLE_\n",
       " \n",
       "    Variable Event  CutOff      TP      FP      FN      TN  Sensitivity  Specificity   KS       KS2    F_HALF       FPR       ACC       FDR        F1         C      Gini     Gamma       Tau  MISCEVENT       FNR\n",
       " 0    P_BAD0     0    0.00  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.999927  0.999854  0.999865  0.319402   0.199497  0.000000\n",
       " 1    P_BAD0     0    0.01  4771.0   835.0     0.0   354.0     1.000000     0.297729  0.0  0.297729  0.877183  0.702271  0.859899  0.148948  0.919534  0.999927  0.999854  0.999865  0.319402   0.140101  0.000000\n",
       " 2    P_BAD0     0    0.02  4771.0   740.0     0.0   449.0     1.000000     0.377628  0.0  0.377628  0.889614  0.622372  0.875839  0.134277  0.928030  0.999927  0.999854  0.999865  0.319402   0.124161  0.000000\n",
       " 3    P_BAD0     0    0.03  4771.0   646.0     0.0   543.0     1.000000     0.456686  0.0  0.456686  0.902266  0.543314  0.891611  0.119254  0.936592  0.999927  0.999854  0.999865  0.319402   0.108389  0.000000\n",
       " 4    P_BAD0     0    0.04  4771.0   581.0     0.0   608.0     1.000000     0.511354  0.0  0.511354  0.911227  0.488646  0.902517  0.108558  0.942606  0.999927  0.999854  0.999865  0.319402   0.097483  0.000000\n",
       " 5    P_BAD0     0    0.05  4771.0   521.0     0.0   668.0     1.000000     0.561817  0.0  0.561817  0.919658  0.438183  0.912584  0.098450  0.948226  0.999927  0.999854  0.999865  0.319402   0.087416  0.000000\n",
       " 6    P_BAD0     0    0.06  4771.0   483.0     0.0   706.0     1.000000     0.593776  0.0  0.593776  0.925079  0.406224  0.918960  0.091930  0.951820  0.999927  0.999854  0.999865  0.319402   0.081040  0.000000\n",
       " 7    P_BAD0     0    0.07  4771.0   439.0     0.0   750.0     1.000000     0.630782  0.0  0.630782  0.931436  0.369218  0.926342  0.084261  0.956016  0.999927  0.999854  0.999865  0.319402   0.073658  0.000000\n",
       " 8    P_BAD0     0    0.08  4771.0   400.0     0.0   789.0     1.000000     0.663583  0.0  0.663583  0.937144  0.336417  0.932886  0.077354  0.959767  0.999927  0.999854  0.999865  0.319402   0.067114  0.000000\n",
       " 9    P_BAD0     0    0.09  4771.0   357.0     0.0   832.0     1.000000     0.699748  0.0  0.699748  0.943519  0.300252  0.940101  0.069618  0.963936  0.999927  0.999854  0.999865  0.319402   0.059899  0.000000\n",
       " 10   P_BAD0     0    0.10  4771.0   330.0     0.0   859.0     1.000000     0.722456  0.0  0.722456  0.947567  0.277544  0.944631  0.064693  0.966572  0.999927  0.999854  0.999865  0.319402   0.055369  0.000000\n",
       " 11   P_BAD0     0    0.11  4771.0   299.0     0.0   890.0     1.000000     0.748528  0.0  0.748528  0.952257  0.251472  0.949832  0.058974  0.969617  0.999927  0.999854  0.999865  0.319402   0.050168  0.000000\n",
       " 12   P_BAD0     0    0.12  4771.0   269.0     0.0   920.0     1.000000     0.773759  0.0  0.773759  0.956841  0.226241  0.954866  0.053373  0.972582  0.999927  0.999854  0.999865  0.319402   0.045134  0.000000\n",
       " 13   P_BAD0     0    0.13  4771.0   253.0     0.0   936.0     1.000000     0.787216  0.0  0.787216  0.959303  0.212784  0.957550  0.050358  0.974170  0.999927  0.999854  0.999865  0.319402   0.042450  0.000000\n",
       " 14   P_BAD0     0    0.14  4771.0   242.0     0.0   947.0     1.000000     0.796468  0.0  0.796468  0.961004  0.203532  0.959396  0.048274  0.975266  0.999927  0.999854  0.999865  0.319402   0.040604  0.000000\n",
       " 15   P_BAD0     0    0.15  4771.0   224.0     0.0   965.0     1.000000     0.811606  0.0  0.811606  0.963799  0.188394  0.962416  0.044845  0.977063  0.999927  0.999854  0.999865  0.319402   0.037584  0.000000\n",
       " 16   P_BAD0     0    0.16  4771.0   203.0     0.0   986.0     1.000000     0.829268  0.0  0.829268  0.967082  0.170732  0.965940  0.040812  0.979169  0.999927  0.999854  0.999865  0.319402   0.034060  0.000000\n",
       " 17   P_BAD0     0    0.17  4771.0   182.0     0.0  1007.0     1.000000     0.846930  0.0  0.846930  0.970386  0.153070  0.969463  0.036745  0.981283  0.999927  0.999854  0.999865  0.319402   0.030537  0.000000\n",
       " 18   P_BAD0     0    0.18  4771.0   170.0     0.0  1019.0     1.000000     0.857023  0.0  0.857023  0.972284  0.142977  0.971477  0.034406  0.982496  0.999927  0.999854  0.999865  0.319402   0.028523  0.000000\n",
       " 19   P_BAD0     0    0.19  4771.0   163.0     0.0  1026.0     1.000000     0.862910  0.0  0.862910  0.973395  0.137090  0.972651  0.033036  0.983205  0.999927  0.999854  0.999865  0.319402   0.027349  0.000000\n",
       " 20   P_BAD0     0    0.20  4771.0   154.0     0.0  1035.0     1.000000     0.870479  0.0  0.870479  0.974827  0.129521  0.974161  0.031269  0.984117  0.999927  0.999854  0.999865  0.319402   0.025839  0.000000\n",
       " 21   P_BAD0     0    0.21  4771.0   135.0     0.0  1054.0     1.000000     0.886459  0.0  0.886459  0.977864  0.113541  0.977349  0.027517  0.986049  0.999927  0.999854  0.999865  0.319402   0.022651  0.000000\n",
       " 22   P_BAD0     0    0.22  4771.0   120.0     0.0  1069.0     1.000000     0.899075  0.0  0.899075  0.980275  0.100925  0.979866  0.024535  0.987580  0.999927  0.999854  0.999865  0.319402   0.020134  0.000000\n",
       " 23   P_BAD0     0    0.23  4771.0   107.0     0.0  1082.0     1.000000     0.910008  0.0  0.910008  0.982375  0.089992  0.982047  0.021935  0.988911  0.999927  0.999854  0.999865  0.319402   0.017953  0.000000\n",
       " 24   P_BAD0     0    0.24  4771.0    98.0     0.0  1091.0     1.000000     0.917578  0.0  0.917578  0.983833  0.082422  0.983557  0.020127  0.989834  0.999927  0.999854  0.999865  0.319402   0.016443  0.000000\n",
       " 25   P_BAD0     0    0.25  4771.0    91.0     0.0  1098.0     1.000000     0.923465  0.0  0.923465  0.984970  0.076535  0.984732  0.018717  0.990553  0.999927  0.999854  0.999865  0.319402   0.015268  0.000000\n",
       " 26   P_BAD0     0    0.26  4771.0    85.0     0.0  1104.0     1.000000     0.928511  0.0  0.928511  0.985948  0.071489  0.985738  0.017504  0.991171  0.999927  0.999854  0.999865  0.319402   0.014262  0.000000\n",
       " 27   P_BAD0     0    0.27  4771.0    83.0     0.0  1106.0     1.000000     0.930193  0.0  0.930193  0.986274  0.069807  0.986074  0.017099  0.991377  0.999927  0.999854  0.999865  0.319402   0.013926  0.000000\n",
       " 28   P_BAD0     0    0.28  4771.0    78.0     0.0  1111.0     1.000000     0.934399  0.0  0.934399  0.987090  0.065601  0.986913  0.016086  0.991892  0.999927  0.999854  0.999865  0.319402   0.013087  0.000000\n",
       " 29   P_BAD0     0    0.29  4771.0    71.0     0.0  1118.0     1.000000     0.940286  0.0  0.940286  0.988235  0.059714  0.988087  0.014663  0.992614  0.999927  0.999854  0.999865  0.319402   0.011913  0.000000\n",
       " 30   P_BAD0     0    0.30  4771.0    64.0     0.0  1125.0     1.000000     0.946173  0.0  0.946173  0.989382  0.053827  0.989262  0.013237  0.993337  0.999927  0.999854  0.999865  0.319402   0.010738  0.000000\n",
       " 31   P_BAD0     0    0.31  4771.0    62.0     0.0  1127.0     1.000000     0.947855  0.0  0.947855  0.989711  0.052145  0.989597  0.012828  0.993544  0.999927  0.999854  0.999865  0.319402   0.010403  0.000000\n",
       " 32   P_BAD0     0    0.32  4771.0    59.0     0.0  1130.0     1.000000     0.950378  0.0  0.950378  0.990204  0.049622  0.990101  0.012215  0.993855  0.999927  0.999854  0.999865  0.319402   0.009899  0.000000\n",
       " 33   P_BAD0     0    0.33  4771.0    54.0     0.0  1135.0     1.000000     0.954584  0.0  0.954584  0.991027  0.045416  0.990940  0.011192  0.994373  0.999927  0.999854  0.999865  0.319402   0.009060  0.000000\n",
       " 34   P_BAD0     0    0.34  4771.0    50.0     0.0  1139.0     1.000000     0.957948  0.0  0.957948  0.991686  0.042052  0.991611  0.010371  0.994787  0.999927  0.999854  0.999865  0.319402   0.008389  0.000000\n",
       " 35   P_BAD0     0    0.35  4771.0    47.0     0.0  1142.0     1.000000     0.960471  0.0  0.960471  0.992181  0.039529  0.992114  0.009755  0.995099  0.999927  0.999854  0.999865  0.319402   0.007886  0.000000\n",
       " 36   P_BAD0     0    0.36  4771.0    44.0     0.0  1145.0     1.000000     0.962994  0.0  0.962994  0.992676  0.037006  0.992617  0.009138  0.995410  0.999927  0.999854  0.999865  0.319402   0.007383  0.000000\n",
       " 37   P_BAD0     0    0.37  4771.0    42.0     0.0  1147.0     1.000000     0.964676  0.0  0.964676  0.993007  0.035324  0.992953  0.008726  0.995618  0.999927  0.999854  0.999865  0.319402   0.007047  0.000000\n",
       " 38   P_BAD0     0    0.38  4771.0    37.0     0.0  1152.0     1.000000     0.968881  0.0  0.968881  0.993834  0.031119  0.993792  0.007696  0.996137  0.999927  0.999854  0.999865  0.319402   0.006208  0.000000\n",
       " 39   P_BAD0     0    0.39  4771.0    32.0     0.0  1157.0     1.000000     0.973087  0.0  0.973087  0.994663  0.026913  0.994631  0.006663  0.996658  0.999927  0.999854  0.999865  0.319402   0.005369  0.000000\n",
       " 40   P_BAD0     0    0.40  4771.0    31.0     0.0  1158.0     1.000000     0.973928  0.0  0.973928  0.994829  0.026072  0.994799  0.006456  0.996762  0.999927  0.999854  0.999865  0.319402   0.005201  0.000000\n",
       " 41   P_BAD0     0    0.41  4771.0    29.0     0.0  1160.0     1.000000     0.975610  0.0  0.975610  0.995161  0.024390  0.995134  0.006042  0.996970  0.999927  0.999854  0.999865  0.319402   0.004866  0.000000\n",
       " 42   P_BAD0     0    0.42  4771.0    25.0     0.0  1164.0     1.000000     0.978974  0.0  0.978974  0.995826  0.021026  0.995805  0.005213  0.997387  0.999927  0.999854  0.999865  0.319402   0.004195  0.000000\n",
       " 43   P_BAD0     0    0.43  4771.0    23.0     0.0  1166.0     1.000000     0.980656  0.0  0.980656  0.996158  0.019344  0.996141  0.004798  0.997595  0.999927  0.999854  0.999865  0.319402   0.003859  0.000000\n",
       " 44   P_BAD0     0    0.44  4771.0    23.0     0.0  1166.0     1.000000     0.980656  0.0  0.980656  0.996158  0.019344  0.996141  0.004798  0.997595  0.999927  0.999854  0.999865  0.319402   0.003859  0.000000\n",
       " 45   P_BAD0     0    0.45  4770.0    21.0     1.0  1168.0     0.999790     0.982338  0.0  0.982128  0.996449  0.017662  0.996309  0.004383  0.997699  0.999927  0.999854  0.999865  0.319402   0.003691  0.000210\n",
       " 46   P_BAD0     0    0.46  4770.0    20.0     1.0  1169.0     0.999790     0.983179  0.0  0.982970  0.996615  0.016821  0.996477  0.004175  0.997804  0.999927  0.999854  0.999865  0.319402   0.003523  0.000210\n",
       " 47   P_BAD0     0    0.47  4770.0    20.0     1.0  1169.0     0.999790     0.983179  0.0  0.982970  0.996615  0.016821  0.996477  0.004175  0.997804  0.999927  0.999854  0.999865  0.319402   0.003523  0.000210\n",
       " 48   P_BAD0     0    0.48  4769.0    18.0     2.0  1171.0     0.999581     0.984861  0.0  0.984442  0.996906  0.015139  0.996644  0.003760  0.997908  0.999927  0.999854  0.999865  0.319402   0.003356  0.000419\n",
       " 49   P_BAD0     0    0.49  4769.0    16.0     2.0  1173.0     0.999581     0.986543  0.0  0.986124  0.997240  0.013457  0.996980  0.003344  0.998116  0.999927  0.999854  0.999865  0.319402   0.003020  0.000419\n",
       " 50   P_BAD0     0    0.50  4769.0    16.0     2.0  1173.0     0.999581     0.986543  0.0  0.986124  0.997240  0.013457  0.996980  0.003344  0.998116  0.999927  0.999854  0.999865  0.319402   0.003020  0.000419\n",
       " 51   P_BAD0     0    0.51  4768.0    15.0     3.0  1174.0     0.999371     0.987384  0.0  0.986756  0.997364  0.012616  0.996980  0.003136  0.998116  0.999927  0.999854  0.999865  0.319402   0.003020  0.000629\n",
       " 52   P_BAD0     0    0.52  4768.0    15.0     3.0  1174.0     0.999371     0.987384  0.0  0.986756  0.997364  0.012616  0.996980  0.003136  0.998116  0.999927  0.999854  0.999865  0.319402   0.003020  0.000629\n",
       " 53   P_BAD0     0    0.53  4768.0    15.0     3.0  1174.0     0.999371     0.987384  0.0  0.986756  0.997364  0.012616  0.996980  0.003136  0.998116  0.999927  0.999854  0.999865  0.319402   0.003020  0.000629\n",
       " 54   P_BAD0     0    0.54  4767.0    15.0     4.0  1174.0     0.999162     0.987384  0.0  0.986546  0.997322  0.012616  0.996812  0.003137  0.998011  0.999927  0.999854  0.999865  0.319402   0.003188  0.000838\n",
       " 55   P_BAD0     0    0.55  4767.0    12.0     4.0  1177.0     0.999162     0.989907  0.0  0.989069  0.997823  0.010093  0.997315  0.002511  0.998325  0.999927  0.999854  0.999865  0.319402   0.002685  0.000838\n",
       " 56   P_BAD0     0    0.56  4765.0    11.0     6.0  1178.0     0.998742     0.990749  0.0  0.989491  0.997906  0.009251  0.997148  0.002303  0.998219  0.999927  0.999854  0.999865  0.319402   0.002852  0.001258\n",
       " 57   P_BAD0     0    0.57  4765.0    10.0     6.0  1179.0     0.998742     0.991590  0.0  0.990332  0.998073  0.008410  0.997315  0.002094  0.998324  0.999927  0.999854  0.999865  0.319402   0.002685  0.001258\n",
       " 58   P_BAD0     0    0.58  4764.0    10.0     7.0  1179.0     0.998533     0.991590  0.0  0.990122  0.998031  0.008410  0.997148  0.002095  0.998219  0.999927  0.999854  0.999865  0.319402   0.002852  0.001467\n",
       " 59   P_BAD0     0    0.59  4764.0     9.0     7.0  1180.0     0.998533     0.992431  0.0  0.990963  0.998198  0.007569  0.997315  0.001886  0.998324  0.999927  0.999854  0.999865  0.319402   0.002685  0.001467\n",
       " 60   P_BAD0     0    0.60  4763.0     8.0     8.0  1181.0     0.998323     0.993272  0.0  0.991595  0.998323  0.006728  0.997315  0.001677  0.998323  0.999927  0.999854  0.999865  0.319402   0.002685  0.001677\n",
       " 61   P_BAD0     0    0.61  4763.0     7.0     8.0  1182.0     0.998323     0.994113  0.0  0.992436  0.998491  0.005887  0.997483  0.001468  0.998428  0.999927  0.999854  0.999865  0.319402   0.002517  0.001677\n",
       " 62   P_BAD0     0    0.62  4759.0     6.0    12.0  1183.0     0.997485     0.994954  0.0  0.992439  0.998489  0.005046  0.996980  0.001259  0.998112  0.999927  0.999854  0.999865  0.319402   0.003020  0.002515\n",
       " 63   P_BAD0     0    0.63  4759.0     5.0    12.0  1184.0     0.997485     0.995795  0.0  0.993280  0.998657  0.004205  0.997148  0.001050  0.998217  0.999927  0.999854  0.999865  0.319402   0.002852  0.002515\n",
       " 64   P_BAD0     0    0.64  4757.0     4.0    14.0  1185.0     0.997066     0.996636  0.0  0.993701  0.998740  0.003364  0.996980  0.000840  0.998112  0.999927  0.999854  0.999865  0.319402   0.003020  0.002934\n",
       " 65   P_BAD0     0    0.65  4755.0     4.0    16.0  1185.0     0.996646     0.996636  0.0  0.993282  0.998656  0.003364  0.996644  0.000841  0.997901  0.999927  0.999854  0.999865  0.319402   0.003356  0.003354\n",
       " 66   P_BAD0     0    0.66  4755.0     4.0    16.0  1185.0     0.996646     0.996636  0.0  0.993282  0.998656  0.003364  0.996644  0.000841  0.997901  0.999927  0.999854  0.999865  0.319402   0.003356  0.003354\n",
       " 67   P_BAD0     0    0.67  4753.0     4.0    18.0  1185.0     0.996227     0.996636  0.0  0.992863  0.998571  0.003364  0.996309  0.000841  0.997691  0.999927  0.999854  0.999865  0.319402   0.003691  0.003773\n",
       " 68   P_BAD0     0    0.68  4753.0     3.0    18.0  1186.0     0.996227     0.997477  1.0  0.993704  0.998739  0.002523  0.996477  0.000631  0.997796  0.999927  0.999854  0.999865  0.319402   0.003523  0.003773\n",
       " 69   P_BAD0     0    0.69  4753.0     3.0    18.0  1186.0     0.996227     0.997477  0.0  0.993704  0.998739  0.002523  0.996477  0.000631  0.997796  0.999927  0.999854  0.999865  0.319402   0.003523  0.003773\n",
       " 70   P_BAD0     0    0.70  4748.0     2.0    23.0  1187.0     0.995179     0.998318  0.0  0.993497  0.998696  0.001682  0.995805  0.000421  0.997374  0.999927  0.999854  0.999865  0.319402   0.004195  0.004821\n",
       " 71   P_BAD0     0    0.71  4743.0     2.0    28.0  1187.0     0.994131     0.998318  0.0  0.992449  0.998484  0.001682  0.994966  0.000421  0.996847  0.999927  0.999854  0.999865  0.319402   0.005034  0.005869\n",
       " 72   P_BAD0     0    0.72  4741.0     2.0    30.0  1187.0     0.993712     0.998318  0.0  0.992030  0.998400  0.001682  0.994631  0.000422  0.996637  0.999927  0.999854  0.999865  0.319402   0.005369  0.006288\n",
       " 73   P_BAD0     0    0.73  4739.0     2.0    32.0  1187.0     0.993293     0.998318  0.0  0.991611  0.998315  0.001682  0.994295  0.000422  0.996426  0.999927  0.999854  0.999865  0.319402   0.005705  0.006707\n",
       " 74   P_BAD0     0    0.74  4732.0     2.0    39.0  1187.0     0.991826     0.998318  0.0  0.990144  0.998017  0.001682  0.993121  0.000422  0.995686  0.999927  0.999854  0.999865  0.319402   0.006879  0.008174\n",
       " 75   P_BAD0     0    0.75  4727.0     2.0    44.0  1187.0     0.990778     0.998318  0.0  0.989096  0.997805  0.001682  0.992282  0.000423  0.995158  0.999927  0.999854  0.999865  0.319402   0.007718  0.009222\n",
       " 76   P_BAD0     0    0.76  4724.0     2.0    47.0  1187.0     0.990149     0.998318  0.0  0.988467  0.997677  0.001682  0.991779  0.000423  0.994840  0.999927  0.999854  0.999865  0.319402   0.008221  0.009851\n",
       " 77   P_BAD0     0    0.77  4722.0     2.0    49.0  1187.0     0.989730     0.998318  0.0  0.988048  0.997592  0.001682  0.991443  0.000423  0.994629  0.999927  0.999854  0.999865  0.319402   0.008557  0.010270\n",
       " 78   P_BAD0     0    0.78  4718.0     2.0    53.0  1187.0     0.988891     0.998318  0.0  0.987209  0.997421  0.001682  0.990772  0.000424  0.994205  0.999927  0.999854  0.999865  0.319402   0.009228  0.011109\n",
       " 79   P_BAD0     0    0.79  4711.0     2.0    60.0  1187.0     0.987424     0.998318  0.0  0.985742  0.997121  0.001682  0.989597  0.000424  0.993463  0.999927  0.999854  0.999865  0.319402   0.010403  0.012576\n",
       " 80   P_BAD0     0    0.80  4706.0     2.0    65.0  1187.0     0.986376     0.998318  0.0  0.984694  0.996907  0.001682  0.988758  0.000425  0.992932  0.999927  0.999854  0.999865  0.319402   0.011242  0.013624\n",
       " 81   P_BAD0     0    0.81  4694.0     2.0    77.0  1187.0     0.983861     0.998318  0.0  0.982179  0.996391  0.001682  0.986745  0.000426  0.991655  0.999927  0.999854  0.999865  0.319402   0.013255  0.016139\n",
       " 82   P_BAD0     0    0.82  4678.0     2.0    93.0  1187.0     0.980507     0.998318  0.0  0.978825  0.995700  0.001682  0.984060  0.000427  0.989948  0.999927  0.999854  0.999865  0.319402   0.015940  0.019493\n",
       " 83   P_BAD0     0    0.83  4670.0     2.0   101.0  1187.0     0.978830     0.998318  0.0  0.977148  0.995354  0.001682  0.982718  0.000428  0.989092  0.999927  0.999854  0.999865  0.319402   0.017282  0.021170\n",
       " 84   P_BAD0     0    0.84  4651.0     1.0   120.0  1188.0     0.974848     0.999159  0.0  0.974007  0.994696  0.000841  0.979698  0.000215  0.987159  0.999927  0.999854  0.999865  0.319402   0.020302  0.025152\n",
       " 85   P_BAD0     0    0.85  4641.0     1.0   130.0  1188.0     0.972752     0.999159  0.0  0.971911  0.994259  0.000841  0.978020  0.000215  0.986083  0.999927  0.999854  0.999865  0.319402   0.021980  0.027248\n",
       " 86   P_BAD0     0    0.86  4625.0     1.0   146.0  1188.0     0.969398     0.999159  0.0  0.968557  0.993555  0.000841  0.975336  0.000216  0.984357  0.999927  0.999854  0.999865  0.319402   0.024664  0.030602\n",
       " 87   P_BAD0     0    0.87  4609.0     1.0   162.0  1188.0     0.966045     0.999159  0.0  0.965204  0.992848  0.000841  0.972651  0.000217  0.982624  0.999927  0.999854  0.999865  0.319402   0.027349  0.033955\n",
       " 88   P_BAD0     0    0.88  4586.0     0.0   185.0  1189.0     0.961224     1.000000  0.0  0.961224  0.991997  0.000000  0.968960  0.000000  0.980229  0.999927  0.999854  0.999865  0.319402   0.031040  0.038776\n",
       " 89   P_BAD0     0    0.89  4559.0     0.0   212.0  1189.0     0.955565     1.000000  0.0  0.955565  0.990785  0.000000  0.964430  0.000000  0.977278  0.999927  0.999854  0.999865  0.319402   0.035570  0.044435\n",
       " 90   P_BAD0     0    0.90  4536.0     0.0   235.0  1189.0     0.950744     1.000000  0.0  0.950744  0.989745  0.000000  0.960570  0.000000  0.974750  0.999927  0.999854  0.999865  0.319402   0.039430  0.049256\n",
       " 91   P_BAD0     0    0.91  4513.0     0.0   258.0  1189.0     0.945923     1.000000  0.0  0.945923  0.988696  0.000000  0.956711  0.000000  0.972210  0.999927  0.999854  0.999865  0.319402   0.043289  0.054077\n",
       " 92   P_BAD0     0    0.92  4481.0     0.0   290.0  1189.0     0.939216     1.000000  0.0  0.939216  0.987222  0.000000  0.951342  0.000000  0.968655  0.999927  0.999854  0.999865  0.319402   0.048658  0.060784\n",
       " 93   P_BAD0     0    0.93  4436.0     0.0   335.0  1189.0     0.929784     1.000000  0.0  0.929784  0.985121  0.000000  0.943792  0.000000  0.963615  0.999927  0.999854  0.999865  0.319402   0.056208  0.070216\n",
       " 94   P_BAD0     0    0.94  4383.0     0.0   388.0  1189.0     0.918675     1.000000  0.0  0.918675  0.982603  0.000000  0.934899  0.000000  0.957614  0.999927  0.999854  0.999865  0.319402   0.065101  0.081325\n",
       " 95   P_BAD0     0    0.95  4294.0     0.0   477.0  1189.0     0.900021     1.000000  0.0  0.900021  0.978266  0.000000  0.919966  0.000000  0.947380  0.999927  0.999854  0.999865  0.319402   0.080034  0.099979\n",
       " 96   P_BAD0     0    0.96  4183.0     0.0   588.0  1189.0     0.876755     1.000000  0.0  0.876755  0.972655  0.000000  0.901342  0.000000  0.934331  0.999927  0.999854  0.999865  0.319402   0.098658  0.123245\n",
       " 97   P_BAD0     0    0.97  4042.0     0.0   729.0  1189.0     0.847202     1.000000  0.0  0.847202  0.965185  0.000000  0.877685  0.000000  0.917281  0.999927  0.999854  0.999865  0.319402   0.122315  0.152798\n",
       " 98   P_BAD0     0    0.98  3783.0     0.0   988.0  1189.0     0.792916     1.000000  0.0  0.792916  0.950359  0.000000  0.834228  0.000000  0.884498  0.999927  0.999854  0.999865  0.319402   0.165772  0.207084\n",
       " 99   P_BAD0     0    0.99  3205.0     0.0  1566.0  1189.0     0.671767     1.000000  0.0  0.671767  0.910977  0.000000  0.737248  0.000000  0.803661  0.999927  0.999854  0.999865  0.319402   0.262752  0.328233\n",
       "\n",
       "[ScoreInfo]\n",
       "\n",
       "                          Descr                             Value\n",
       " 0  Number of Observations Read                              5960\n",
       " 1  Number of Observations Used                              5960\n",
       " 2  Misclassification Error (%)                      0.3020134228\n",
       "\n",
       "[TunerCasOutputTables]\n",
       "\n",
       " Tuner CAS Output Tables\n",
       " \n",
       "         CAS_Library         Name   Rows  Columns\n",
       " 0  CASUSER(sasdemo)  gb_model_at  11604       33\n",
       "\n",
       "[TunerInfo]\n",
       "\n",
       " Tuner Information\n",
       " \n",
       "                            Parameter                               Value\n",
       " 0                         Model Type              Gradient Boosting Tree\n",
       " 1           Tuner Objective Function  Misclassification Error Percentage\n",
       " 2                      Search Method                                  GA\n",
       " 3                    Population Size                                  10\n",
       " 4                 Maximum Iterations                                   5\n",
       " 5     Maximum Tuning Time in Seconds                               36000\n",
       " 6                    Validation Type                    Single Partition\n",
       " 7      Validation Partition Fraction                                0.30\n",
       " 8                          Log Level                                   2\n",
       " 9                               Seed                          1876966578\n",
       " 10    Number of Parallel Evaluations                                   4\n",
       " 11  Number of Workers per Subsession                                   0\n",
       "\n",
       "[TunerResults]\n",
       "\n",
       " Tuner Results\n",
       " \n",
       "     Evaluation   M  LEARNINGRATE  SUBSAMPLERATE     LASSO      RIDGE  NBINS  MAXLEVEL  MisclassErr  EvaluationTime\n",
       " 0            0  14      0.100000       0.500000  0.000000   1.000000     50         5     8.165548        0.890372\n",
       " 1           99   2      0.573750       0.500000  0.000000  10.000000     64         7     6.991051       18.154711\n",
       " 2           77   2      0.573750       0.500000  1.111111  10.000000     64         7     7.214765       24.295455\n",
       " 3            7   2      0.450000       0.500000  1.111111  10.000000     64         7     7.606264       11.695281\n",
       " 4           42   2      0.450000       0.500000  1.111111   5.000000     64         7     7.662192       13.883914\n",
       " 5           93   2      0.573750       0.500000  1.111111   8.750000     64         7     7.662192       26.292212\n",
       " 6           96   2      0.573750       0.500000  1.111111  10.000000     54         7     7.662192       20.816867\n",
       " 7           84   2      0.432009       0.504985  0.893873   9.927209     63         7     7.829978       11.673819\n",
       " 8           32   4      0.938050       0.625271  3.754523   7.918174     58         6     7.885906       13.792341\n",
       " 9           45   9      0.450000       0.500000  1.111111  10.000000     64         7     7.885906       10.651089\n",
       " 10          53   6      0.389599       0.694323  3.354649   6.564363     42         6     7.885906        9.106488\n",
       "\n",
       "[TunerSummary]\n",
       "\n",
       " Tuner Summary\n",
       " \n",
       "                                           Parameter       Value\n",
       " 0             Initial Configuration Objective Value    8.165548\n",
       " 1                Best Configuration Objective Value    6.991051\n",
       " 2               Worst Configuration Objective Value   19.966443\n",
       " 3  Initial Configuration Evaluation Time in Seconds    0.890372\n",
       " 4     Best Configuration Evaluation Time in Seconds   18.154686\n",
       " 5                 Number of Improved Configurations    3.000000\n",
       " 6                Number of Evaluated Configurations  102.000000\n",
       " 7                      Total Tuning Time in Seconds  234.381348\n",
       " 8                           Parallel Tuning Speedup    3.895622\n",
       "\n",
       "[TunerTiming]\n",
       "\n",
       " Tuner Task Timing\n",
       " \n",
       "                           Task    Time_sec  Time_percent\n",
       " 0               Model Training  893.361548     97.842465\n",
       " 1                Model Scoring   18.672055      2.044995\n",
       " 2  Total Objective Evaluations  912.054606     99.889760\n",
       " 3                        Tuner    1.006561      0.110240\n",
       " 4               Total CPU Time  913.061167    100.000000\n",
       "\n",
       "+ Elapsed: 234s, user: 0.515s, sys: 0.754s, mem: 0.276mb"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.autotune.tuneGradientBoostTree(\n",
    "  trainOptions=dict(\n",
    "  table=\"Home_Equity_p\",\n",
    "  inputs=all_inputs,\n",
    "  target=\"bad\",\n",
    "  nominals=class_vars,\n",
    "\n",
    "  casOut={\"name\":\"gb_model_at\", \"replace\":True}\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](images/MR_07_pipeline_opensource.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use The Data Science Pilot Action Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dsAutoMl action creates a policy-based, scalable, end-to-end automated machine learning pipeline for both regression and classification problems. The only input required from the user is the input data set and the target variable, but optional parameters include the policy parameters for data exploration, variable screening, feature selection, and feature transformation. Overriding the default policy parameters allow a data scientist to configure their pipeline in their data science workflow. In addition, a data scientist may also select additional models to consider. By default, only a decision tree model is included in the pipeline, but neural networks, random forest models, and gradient boosting models are also available.\n",
    "\n",
    "The dsAutoMl action first explores the data and groups the input variables into categories with the same statistical profile, like the exploreData action. Next the dsAutoMl action screens variables to identify noise variables to exclude from further analysis, like the screenVariables action. Then, the dsAutoMl action generates several new features for the input variables, like the featureMachine action. After there are various new cleaned features, the dsAutoMl action will select features based on selected criterion, like the selectFeatures action.\n",
    "\n",
    "From here, various pipelines are created using subsets of the selected features, chosen for each pipeline using a feature-representation algorithm. Then the chosen models are added to each pipeline and the hyperparameters for the selected models are optimized, like the modelComposer action of the Autotune action set. These hyperparameters are optimized for the selected objective parameter when cross-validated. By default, classification problems are optimized to have the smallest Misclassification Error Rate (MCE) and regression problems are optimized to have the smallest Average Square Error (ASR). Data scientists can then select their champion and challenger models from the pipelines.\n",
    "\n",
    "This action returns four CAS tables: the first lists information around the transformation pipelines, the second lists information around the transformed features, the third lists pipeline performance according to the objective parameter and the fourth is an analytical store for scoring any additional input tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Science Pilot Action Set - This section will cover feature selection, feature creation and automated pipeline creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](images/MR_09_DataSciencePilot.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploration Policy \n",
    "expo = {'cardinality': {'lowMediumCutoff':40}}\n",
    "# Screen Policy \n",
    "scpo = {'missingPercentThreshold':35}\n",
    "# Selection Policy \n",
    "sepo = {'criterion': 'SU', 'topk':4}\n",
    "# Transformation Policy \n",
    "trpo = {'entropy': True, 'iqv': True, 'kurtosis': True, 'outlier': True}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The selectFeatures action performs a filter-based selection by the criterion selected in the selectionPolicy (default is the best ten input variables according to the Mutual Information statistic). The criterion available for selection include Chi-Square, Cramers V, F-test, G2, Information Value, Mutual Information, Normalized Mutual Information statistic, Pearson correlation, and the Symmetric Uncertainty statistic. This action returns a CAS table listing the variables, their rank according to the selected criterion, and the value of the selected criterion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"cas-results-key\"><b>&#167; Fetch</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><caption>Selected Rows from Table SCREEN_VARIABLES_OUT_PY</caption>\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"Variable\">Variable</th>\n",
       "      <th title=\"Recommendation\">Recommendation</th>\n",
       "      <th title=\"Reason\">Reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>REASON</td>\n",
       "      <td>keep</td>\n",
       "      <td>passed all screening tests</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>JOB</td>\n",
       "      <td>keep</td>\n",
       "      <td>passed all screening tests</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>CITY</td>\n",
       "      <td>remove</td>\n",
       "      <td>low target mutual information</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>STATE</td>\n",
       "      <td>keep</td>\n",
       "      <td>passed all screening tests</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>DIVISION</td>\n",
       "      <td>keep</td>\n",
       "      <td>passed all screening tests</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>REGION</td>\n",
       "      <td>remove</td>\n",
       "      <td>low target mutual information</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>IMP_CITY</td>\n",
       "      <td>remove</td>\n",
       "      <td>low target mutual information</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>IMP_JOB</td>\n",
       "      <td>keep</td>\n",
       "      <td>passed all screening tests</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>IMP_REASON</td>\n",
       "      <td>keep</td>\n",
       "      <td>passed all screening tests</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>LOAN</td>\n",
       "      <td>keep</td>\n",
       "      <td>passed all screening tests</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>MORTDUE</td>\n",
       "      <td>keep</td>\n",
       "      <td>passed all screening tests</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>VALUE</td>\n",
       "      <td>keep</td>\n",
       "      <td>passed all screening tests</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>YOJ</td>\n",
       "      <td>keep</td>\n",
       "      <td>passed all screening tests</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>DEROG</td>\n",
       "      <td>keep</td>\n",
       "      <td>passed all screening tests</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>DELINQ</td>\n",
       "      <td>keep</td>\n",
       "      <td>passed all screening tests</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>CLAGE</td>\n",
       "      <td>keep</td>\n",
       "      <td>passed all screening tests</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>NINQ</td>\n",
       "      <td>keep</td>\n",
       "      <td>passed all screening tests</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>CLNO</td>\n",
       "      <td>keep</td>\n",
       "      <td>passed all screening tests</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>DEBTINC</td>\n",
       "      <td>keep</td>\n",
       "      <td>passed all screening tests</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>APPDATE</td>\n",
       "      <td>keep</td>\n",
       "      <td>passed all screening tests</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-output-area\"></div>\n",
       "<p class=\"cas-results-performance\"><small><span class=\"cas-elapsed\">elapsed 0.000817s</span> &#183; <span class=\"cas-user\">user 0.000228s</span> &#183; <span class=\"cas-sys\">sys 0.00057s</span> &#183; <span class=\"cas-memory\">mem 0.911MB</span></small></p>"
      ],
      "text/plain": [
       "[Fetch]\n",
       "\n",
       " Selected Rows from Table SCREEN_VARIABLES_OUT_PY\n",
       " \n",
       "       Variable Recommendation                         Reason\n",
       " 0       REASON           keep     passed all screening tests\n",
       " 1          JOB           keep     passed all screening tests\n",
       " 2         CITY         remove  low target mutual information\n",
       " 3        STATE           keep     passed all screening tests\n",
       " 4     DIVISION           keep     passed all screening tests\n",
       " 5       REGION         remove  low target mutual information\n",
       " 6     IMP_CITY         remove  low target mutual information\n",
       " 7      IMP_JOB           keep     passed all screening tests\n",
       " 8   IMP_REASON           keep     passed all screening tests\n",
       " 9         LOAN           keep     passed all screening tests\n",
       " 10     MORTDUE           keep     passed all screening tests\n",
       " 11       VALUE           keep     passed all screening tests\n",
       " 12         YOJ           keep     passed all screening tests\n",
       " 13       DEROG           keep     passed all screening tests\n",
       " 14      DELINQ           keep     passed all screening tests\n",
       " 15       CLAGE           keep     passed all screening tests\n",
       " 16        NINQ           keep     passed all screening tests\n",
       " 17        CLNO           keep     passed all screening tests\n",
       " 18     DEBTINC           keep     passed all screening tests\n",
       " 19     APPDATE           keep     passed all screening tests\n",
       "\n",
       "+ Elapsed: 0.000817s, user: 0.000228s, sys: 0.00057s, mem: 0.911mb"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.dataSciencePilot.screenVariables(\n",
    "    table = Home_Equity, \n",
    "    target = target, \n",
    "    casOut = {'name': 'SCREEN_VARIABLES_OUT_PY', 'replace': True}, \n",
    "    screenPolicy = {}\n",
    ")\n",
    "conn.fetch(table = {'name': 'SCREEN_VARIABLES_OUT_PY'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The featureMachine action creates an automated and parallel generation of features. The featureMachine action first explores the data and groups the input variables into categories with the same statistical profile, like the exploreData action. Next the featureMachine action screens variables to identify noise variables to exclude from further analysis, like the screenVariables action. Finally, the featureMachine action generates new features by using the available structured pipelines:\n",
    "\n",
    "    Missing indicator addition.\n",
    "    Mode imputation and rare value grouping.\n",
    "    Missing level and rare value grouping.\n",
    "    Median imputation.\n",
    "    Mode imputation and label encoding.\n",
    "    Missing level and label encoding.\n",
    "    Yeo-Johnson transformation and median imputation.\n",
    "    Box-Cox transformation.\n",
    "    Quantile binning with missing bins.\n",
    "    Regression tree binning.\n",
    "    Decision tree binning.\n",
    "    MDLP binning.\n",
    "    Target encoding.\n",
    "    Date, time, and datetime transformations.\n",
    "    \n",
    "Depending on the parameters specified in the transformationPolicy, the featureMachine action can generate several features for each input variable. This action returns four CAS tables: the first lists information around the transformation pipelines, the second lists information around the transformed features, the third is the input table scored with the transformed features, and the fourth is an analytical store for scoring any additional input tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"cas-results-key\"><b>&#167; OutputCasTables</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"CAS Library\">casLib</th>\n",
       "      <th title=\"Name\">Name</th>\n",
       "      <th title=\"Number of Rows\">Rows</th>\n",
       "      <th title=\"Number of Columns\">Columns</th>\n",
       "      <th title=\"Table\">casTable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>CASUSER(sasdemo)</td>\n",
       "      <td>TRANSFORMATION_OUT</td>\n",
       "      <td>36</td>\n",
       "      <td>21</td>\n",
       "      <td>CASTable('TRANSFORMATION_OUT', caslib='CASUSER...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>CASUSER(sasdemo)</td>\n",
       "      <td>FEATURE_OUT</td>\n",
       "      <td>129</td>\n",
       "      <td>9</td>\n",
       "      <td>CASTable('FEATURE_OUT', caslib='CASUSER(sasdem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>CASUSER(sasdemo)</td>\n",
       "      <td>CAS_OUT</td>\n",
       "      <td>5960</td>\n",
       "      <td>130</td>\n",
       "      <td>CASTable('CAS_OUT', caslib='CASUSER(sasdemo)')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>CASUSER(sasdemo)</td>\n",
       "      <td>ASTORE_OUT</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>CASTable('ASTORE_OUT', caslib='CASUSER(sasdemo)')</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-output-area\"></div>\n",
       "<p class=\"cas-results-performance\"><small><span class=\"cas-elapsed\">elapsed 0.443s</span> &#183; <span class=\"cas-user\">user 1.06s</span> &#183; <span class=\"cas-sys\">sys 0.213s</span> &#183; <span class=\"cas-memory\">mem 2.72MB</span></small></p>"
      ],
      "text/plain": [
       "[OutputCasTables]\n",
       "\n",
       "              casLib                Name  Rows  Columns                                           casTable\n",
       " 0  CASUSER(sasdemo)  TRANSFORMATION_OUT    36       21  CASTable('TRANSFORMATION_OUT', caslib='CASUSER...\n",
       " 1  CASUSER(sasdemo)         FEATURE_OUT   129        9  CASTable('FEATURE_OUT', caslib='CASUSER(sasdem...\n",
       " 2  CASUSER(sasdemo)             CAS_OUT  5960      130     CASTable('CAS_OUT', caslib='CASUSER(sasdemo)')\n",
       " 3  CASUSER(sasdemo)          ASTORE_OUT     1        2  CASTable('ASTORE_OUT', caslib='CASUSER(sasdemo)')\n",
       "\n",
       "+ Elapsed: 0.443s, user: 1.06s, sys: 0.213s, mem: 2.72mb"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.dataSciencePilot.featureMachine(\n",
    "    table = Home_Equity, \n",
    "    target = target, \n",
    "    copyVars = target, \n",
    "    explorationPolicy = expo, \n",
    "    screenPolicy = scpo, \n",
    "    transformationPolicy = trpo, \n",
    "    transformationOut       = {\"name\" : \"TRANSFORMATION_OUT\", \"replace\" : True},\n",
    "    featureOut              = {\"name\" : \"FEATURE_OUT\", \"replace\" : True},\n",
    "    casOut                  = {\"name\" : \"CAS_OUT\", \"replace\" : True},\n",
    "    saveState               = {\"name\" : \"ASTORE_OUT\", \"replace\" : True}  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"cas-results-key\"><b>&#167; Fetch</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><caption>Selected Rows from Table TRANSFORMATION_OUT</caption>\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"FTGPipelineId\">FTGPipelineId</th>\n",
       "      <th title=\"Name\">Name</th>\n",
       "      <th title=\"NVariables\">NVariables</th>\n",
       "      <th title=\"IsInteraction\">IsInteraction</th>\n",
       "      <th title=\"ImputeMethod\">ImputeMethod</th>\n",
       "      <th title=\"OutlierMethod\">OutlierMethod</th>\n",
       "      <th title=\"OutlierTreat\">OutlierTreat</th>\n",
       "      <th title=\"OutlierArgs\">OutlierArgs</th>\n",
       "      <th title=\"FunctionMethod\">FunctionMethod</th>\n",
       "      <th title=\"FunctionArgs\">FunctionArgs</th>\n",
       "      <th title=\"MapIntervalArgs\">MapIntervalArgs</th>\n",
       "      <th title=\"HashMethod\">HashMethod</th>\n",
       "      <th title=\"HashArgs\">HashArgs</th>\n",
       "      <th title=\"DateTimeMethod\">DateTimeMethod</th>\n",
       "      <th title=\"DiscretizeMethod\">DiscretizeMethod</th>\n",
       "      <th title=\"DiscretizeArgs\">DiscretizeArgs</th>\n",
       "      <th title=\"CatTransMethod\">CatTransMethod</th>\n",
       "      <th title=\"CatTransArgs\">CatTransArgs</th>\n",
       "      <th title=\"InteractionMethod\">InteractionMethod</th>\n",
       "      <th title=\"InteractionSynthesizer\">InteractionSynthesizer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>miss_ind</td>\n",
       "      <td>5.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>MissIndicator</td>\n",
       "      <td>2.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>Label (Sparse One-Hot)</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>grp_rare2</td>\n",
       "      <td>2.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>Group Rare</td>\n",
       "      <td>5.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>hc_tar_frq_rat</td>\n",
       "      <td>4.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>10.0</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>hc_lbl_cnt</td>\n",
       "      <td>4.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>hc_cnt</td>\n",
       "      <td>4.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>hc_cnt_log</td>\n",
       "      <td>4.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>Log</td>\n",
       "      <td>e</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>7.0</td>\n",
       "      <td>lchehi_lab</td>\n",
       "      <td>4.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>Label (Sparse One-Hot)</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>lcnhenhi_grp_rare</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>Group Rare</td>\n",
       "      <td>5.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>9.0</td>\n",
       "      <td>lcnhenhi_dtree5</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>DTree</td>\n",
       "      <td>5.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>10.0</td>\n",
       "      <td>lcnhenhi_dtree10</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>DTree</td>\n",
       "      <td>10.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>11.0</td>\n",
       "      <td>ho_winsor</td>\n",
       "      <td>11.0</td>\n",
       "      <td></td>\n",
       "      <td>Median</td>\n",
       "      <td>Modified IQR</td>\n",
       "      <td>Winsor</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>12.0</td>\n",
       "      <td>ho_quan_disct5</td>\n",
       "      <td>11.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Modified IQR</td>\n",
       "      <td>Trim</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>Equal-Freq (Quantile)</td>\n",
       "      <td>5.0</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>13.0</td>\n",
       "      <td>ho_quan_disct10</td>\n",
       "      <td>11.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Modified IQR</td>\n",
       "      <td>Trim</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>Equal-Freq (Quantile)</td>\n",
       "      <td>10.0</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>14.0</td>\n",
       "      <td>ho_dtree_disct5</td>\n",
       "      <td>11.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>DTree</td>\n",
       "      <td>5.0</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>15.0</td>\n",
       "      <td>ho_dtree_disct10</td>\n",
       "      <td>11.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>DTree</td>\n",
       "      <td>10.0</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>16.0</td>\n",
       "      <td>hk_yj_n2</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td>Median</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yeo-Johnson</td>\n",
       "      <td>-2</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>17.0</td>\n",
       "      <td>hk_yj_n1</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td>Median</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yeo-Johnson</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>18.0</td>\n",
       "      <td>hk_yj_0</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td>Median</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yeo-Johnson</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>19.0</td>\n",
       "      <td>hk_yj_p1</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td>Median</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yeo-Johnson</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>20.0</td>\n",
       "      <td>hk_yj_p2</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td>Median</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yeo-Johnson</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-output-area\"></div>\n",
       "<p class=\"cas-results-performance\"><small><span class=\"cas-elapsed\">elapsed 0.00118s</span> &#183; <span class=\"cas-user\">user 0.000405s</span> &#183; <span class=\"cas-sys\">sys 0.000755s</span> &#183; <span class=\"cas-memory\">mem 0.974MB</span></small></p>"
      ],
      "text/plain": [
       "[Fetch]\n",
       "\n",
       " Selected Rows from Table TRANSFORMATION_OUT\n",
       " \n",
       "     FTGPipelineId               Name  NVariables IsInteraction ImputeMethod OutlierMethod OutlierTreat  OutlierArgs FunctionMethod FunctionArgs MapIntervalMethod  MapIntervalArgs     HashMethod  HashArgs DateTimeMethod       DiscretizeMethod  DiscretizeArgs          CatTransMethod  CatTransArgs InteractionMethod InteractionSynthesizer\n",
       " 0             1.0           miss_ind         5.0                                                                NaN                                                            NaN  MissIndicator       2.0                                                   NaN  Label (Sparse One-Hot)           NaN                                         \n",
       " 1             2.0          grp_rare2         2.0                                                                NaN                                                            NaN                      NaN                                                   NaN              Group Rare           5.0                                         \n",
       " 2             3.0     hc_tar_frq_rat         4.0                                                                NaN                               Frequency Ratio             10.0                      NaN                                                   NaN                                   NaN                                         \n",
       " 3             4.0         hc_lbl_cnt         4.0                                                                NaN                                   Label Count              0.0                      NaN                                                   NaN                                   NaN                                         \n",
       " 4             5.0             hc_cnt         4.0                                                                NaN                                   Count Input              0.0                      NaN                                                   NaN                                   NaN                                         \n",
       " 5             6.0         hc_cnt_log         4.0                                                                NaN            Log            e       Count Input              0.0                      NaN                                                   NaN                                   NaN                                         \n",
       " 6             7.0         lchehi_lab         4.0                                                                NaN                                                            NaN                      NaN                                                   NaN  Label (Sparse One-Hot)           0.0                                         \n",
       " 7             8.0  lcnhenhi_grp_rare         1.0                                                                NaN                                                            NaN                      NaN                                                   NaN              Group Rare           5.0                                         \n",
       " 8             9.0    lcnhenhi_dtree5         1.0                                                                NaN                                                            NaN                      NaN                                                   NaN                   DTree           5.0                                         \n",
       " 9            10.0   lcnhenhi_dtree10         1.0                                                                NaN                                                            NaN                      NaN                                                   NaN                   DTree          10.0                                         \n",
       " 10           11.0          ho_winsor        11.0                     Median  Modified IQR       Winsor          0.0                                                            NaN                      NaN                                                   NaN                                   NaN                                         \n",
       " 11           12.0     ho_quan_disct5        11.0                             Modified IQR         Trim          0.0                                                            NaN                      NaN                 Equal-Freq (Quantile)             5.0                                   NaN                                         \n",
       " 12           13.0    ho_quan_disct10        11.0                             Modified IQR         Trim          0.0                                                            NaN                      NaN                 Equal-Freq (Quantile)            10.0                                   NaN                                         \n",
       " 13           14.0    ho_dtree_disct5        11.0                                                                NaN                                                            NaN                      NaN                                 DTree             5.0                                   NaN                                         \n",
       " 14           15.0   ho_dtree_disct10        11.0                                                                NaN                                                            NaN                      NaN                                 DTree            10.0                                   NaN                                         \n",
       " 15           16.0           hk_yj_n2         1.0                     Median                                     NaN    Yeo-Johnson           -2                                NaN                      NaN                                                   NaN                                   NaN                                         \n",
       " 16           17.0           hk_yj_n1         1.0                     Median                                     NaN    Yeo-Johnson           -1                                NaN                      NaN                                                   NaN                                   NaN                                         \n",
       " 17           18.0            hk_yj_0         1.0                     Median                                     NaN    Yeo-Johnson            0                                NaN                      NaN                                                   NaN                                   NaN                                         \n",
       " 18           19.0           hk_yj_p1         1.0                     Median                                     NaN    Yeo-Johnson            1                                NaN                      NaN                                                   NaN                                   NaN                                         \n",
       " 19           20.0           hk_yj_p2         1.0                     Median                                     NaN    Yeo-Johnson            2                                NaN                      NaN                                                   NaN                                   NaN                                         \n",
       "\n",
       "+ Elapsed: 0.00118s, user: 0.000405s, sys: 0.000755s, mem: 0.974mb"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.fetch(table = {'name': 'TRANSFORMATION_OUT'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"cas-results-key\"><b>&#167; Fetch</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><caption>Selected Rows from Table FEATURE_OUT</caption>\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"FeatureId\">FeatureId</th>\n",
       "      <th title=\"Name\">Name</th>\n",
       "      <th title=\"IsNominal\">IsNominal</th>\n",
       "      <th title=\"FTGPipelineId\">FTGPipelineId</th>\n",
       "      <th title=\"NInputs\">NInputs</th>\n",
       "      <th title=\"InputVar1\">InputVar1</th>\n",
       "      <th title=\"InputVar2\">InputVar2</th>\n",
       "      <th title=\"InputVar3\">InputVar3</th>\n",
       "      <th title=\"Label\">Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>all_l_oks_dtree_10_APPDATE</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>APPDATE</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>APPDATE: Low (outlier, kurtosis, skewness) - t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>all_l_oks_dtree_5_APPDATE</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>APPDATE</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>APPDATE: Low (outlier, kurtosis, skewness) - f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>cpy_int_med_imp_APPDATE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>APPDATE</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>APPDATE: Low missing rate - median imputation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>all_l_oks_dtree_10_var_1_</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>DATE_SINCE_LAST_APP</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>DATE_SINCE_LAST_APP: Low (outlier, kurtosis, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>all_l_oks_dtree_5_var_1_</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>DATE_SINCE_LAST_APP</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>DATE_SINCE_LAST_APP: Low (outlier, kurtosis, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>cpy_int_med_imp_var_1_</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>DATE_SINCE_LAST_APP</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>DATE_SINCE_LAST_APP: Low missing rate - median...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>7.0</td>\n",
       "      <td>cpy_int_med_imp_DEBTINC</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>DEBTINC</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>DEBTINC: Low missing rate - median imputation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>hk_dtree_disct10_DEBTINC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>DEBTINC</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>DEBTINC: High kurtosis - ten bin decision tree...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>9.0</td>\n",
       "      <td>hk_dtree_disct5_DEBTINC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>DEBTINC</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>DEBTINC: High kurtosis - five bin decision tre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>10.0</td>\n",
       "      <td>hk_yj_0_DEBTINC</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>DEBTINC</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>DEBTINC: High kurtosis - Yeo-Johnson(lambda=0)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>11.0</td>\n",
       "      <td>hk_yj_n1_DEBTINC</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>DEBTINC</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>DEBTINC: High kurtosis - Yeo-Johnson(lambda=-1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>12.0</td>\n",
       "      <td>hk_yj_n2_DEBTINC</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>DEBTINC</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>DEBTINC: High kurtosis - Yeo-Johnson(lambda=-2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>13.0</td>\n",
       "      <td>hk_yj_p1_DEBTINC</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>DEBTINC</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>DEBTINC: High kurtosis - Yeo-Johnson(lambda=1)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>14.0</td>\n",
       "      <td>hk_yj_p2_DEBTINC</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>DEBTINC</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>DEBTINC: High kurtosis - Yeo-Johnson(lambda=2)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>15.0</td>\n",
       "      <td>miss_ind_DEBTINC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>DEBTINC</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>DEBTINC: Significant missing - missing indicator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>16.0</td>\n",
       "      <td>cpy_int_med_imp_IMP_CLAGE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>IMP_CLAGE</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>IMP_CLAGE: Low missing rate - median imputation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>17.0</td>\n",
       "      <td>ho_dtree_disct10_IMP_CLAGE</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>IMP_CLAGE</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>IMP_CLAGE: High outlier - ten bin decision tre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>18.0</td>\n",
       "      <td>ho_dtree_disct5_IMP_CLAGE</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>IMP_CLAGE</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>IMP_CLAGE: High outlier - five bin decision tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>19.0</td>\n",
       "      <td>ho_quan_disct10_IMP_CLAGE</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>IMP_CLAGE</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>IMP_CLAGE: High outlier - robust IQR + ten bin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>20.0</td>\n",
       "      <td>ho_quan_disct5_IMP_CLAGE</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>IMP_CLAGE</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>IMP_CLAGE: High outlier - robust IQR + five bi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-output-area\"></div>\n",
       "<p class=\"cas-results-performance\"><small><span class=\"cas-elapsed\">elapsed 0.00093s</span> &#183; <span class=\"cas-user\">user 0.000317s</span> &#183; <span class=\"cas-sys\">sys 0.000593s</span> &#183; <span class=\"cas-memory\">mem 0.974MB</span></small></p>"
      ],
      "text/plain": [
       "[Fetch]\n",
       "\n",
       " Selected Rows from Table FEATURE_OUT\n",
       " \n",
       "     FeatureId                        Name  IsNominal  FTGPipelineId  NInputs            InputVar1 InputVar2 InputVar3                                              Label\n",
       " 0         1.0  all_l_oks_dtree_10_APPDATE        1.0           33.0      1.0              APPDATE                      APPDATE: Low (outlier, kurtosis, skewness) - t...\n",
       " 1         2.0   all_l_oks_dtree_5_APPDATE        1.0           32.0      1.0              APPDATE                      APPDATE: Low (outlier, kurtosis, skewness) - f...\n",
       " 2         3.0     cpy_int_med_imp_APPDATE        0.0           34.0      1.0              APPDATE                          APPDATE: Low missing rate - median imputation\n",
       " 3         4.0   all_l_oks_dtree_10_var_1_        1.0           33.0      1.0  DATE_SINCE_LAST_APP                      DATE_SINCE_LAST_APP: Low (outlier, kurtosis, s...\n",
       " 4         5.0    all_l_oks_dtree_5_var_1_        1.0           32.0      1.0  DATE_SINCE_LAST_APP                      DATE_SINCE_LAST_APP: Low (outlier, kurtosis, s...\n",
       " 5         6.0      cpy_int_med_imp_var_1_        0.0           34.0      1.0  DATE_SINCE_LAST_APP                      DATE_SINCE_LAST_APP: Low missing rate - median...\n",
       " 6         7.0     cpy_int_med_imp_DEBTINC        0.0           34.0      1.0              DEBTINC                          DEBTINC: Low missing rate - median imputation\n",
       " 7         8.0    hk_dtree_disct10_DEBTINC        1.0           22.0      1.0              DEBTINC                      DEBTINC: High kurtosis - ten bin decision tree...\n",
       " 8         9.0     hk_dtree_disct5_DEBTINC        1.0           21.0      1.0              DEBTINC                      DEBTINC: High kurtosis - five bin decision tre...\n",
       " 9        10.0             hk_yj_0_DEBTINC        0.0           18.0      1.0              DEBTINC                      DEBTINC: High kurtosis - Yeo-Johnson(lambda=0)...\n",
       " 10       11.0            hk_yj_n1_DEBTINC        0.0           17.0      1.0              DEBTINC                      DEBTINC: High kurtosis - Yeo-Johnson(lambda=-1...\n",
       " 11       12.0            hk_yj_n2_DEBTINC        0.0           16.0      1.0              DEBTINC                      DEBTINC: High kurtosis - Yeo-Johnson(lambda=-2...\n",
       " 12       13.0            hk_yj_p1_DEBTINC        0.0           19.0      1.0              DEBTINC                      DEBTINC: High kurtosis - Yeo-Johnson(lambda=1)...\n",
       " 13       14.0            hk_yj_p2_DEBTINC        0.0           20.0      1.0              DEBTINC                      DEBTINC: High kurtosis - Yeo-Johnson(lambda=2)...\n",
       " 14       15.0            miss_ind_DEBTINC        1.0            1.0      1.0              DEBTINC                       DEBTINC: Significant missing - missing indicator\n",
       " 15       16.0   cpy_int_med_imp_IMP_CLAGE        0.0           34.0      1.0            IMP_CLAGE                        IMP_CLAGE: Low missing rate - median imputation\n",
       " 16       17.0  ho_dtree_disct10_IMP_CLAGE        1.0           15.0      1.0            IMP_CLAGE                      IMP_CLAGE: High outlier - ten bin decision tre...\n",
       " 17       18.0   ho_dtree_disct5_IMP_CLAGE        1.0           14.0      1.0            IMP_CLAGE                      IMP_CLAGE: High outlier - five bin decision tr...\n",
       " 18       19.0   ho_quan_disct10_IMP_CLAGE        1.0           13.0      1.0            IMP_CLAGE                      IMP_CLAGE: High outlier - robust IQR + ten bin...\n",
       " 19       20.0    ho_quan_disct5_IMP_CLAGE        1.0           12.0      1.0            IMP_CLAGE                      IMP_CLAGE: High outlier - robust IQR + five bi...\n",
       "\n",
       "+ Elapsed: 0.00093s, user: 0.000317s, sys: 0.000593s, mem: 0.974mb"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.fetch(table = {'name': 'FEATURE_OUT'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"cas-results-key\"><b>&#167; Fetch</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><caption>Selected Rows from Table CAS_OUT</caption>\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"BAD\">BAD</th>\n",
       "      <th title=\"APPDATE: Low (outlier, kurtosis, skewness) - ten bin decision tree binning\">all_l_oks_dtree_10_APPDATE</th>\n",
       "      <th title=\"APPDATE: Low (outlier, kurtosis, skewness) - five bin decision tree binning\">all_l_oks_dtree_5_APPDATE</th>\n",
       "      <th title=\"APPDATE: Low missing rate - median imputation\">cpy_int_med_imp_APPDATE</th>\n",
       "      <th title=\"DATE_SINCE_LAST_APP: Low (outlier, kurtosis, skewness) - ten bin decision tree binning\">all_l_oks_dtree_10_var_1_</th>\n",
       "      <th title=\"DATE_SINCE_LAST_APP: Low (outlier, kurtosis, skewness) - five bin decision tree binning\">all_l_oks_dtree_5_var_1_</th>\n",
       "      <th title=\"DATE_SINCE_LAST_APP: Low missing rate - median imputation\">cpy_int_med_imp_var_1_</th>\n",
       "      <th title=\"DEBTINC: Low missing rate - median imputation\">cpy_int_med_imp_DEBTINC</th>\n",
       "      <th title=\"DEBTINC: High kurtosis - ten bin decision tree binning\">hk_dtree_disct10_DEBTINC</th>\n",
       "      <th title=\"DEBTINC: High kurtosis - five bin decision tree binning\">hk_dtree_disct5_DEBTINC</th>\n",
       "      <th title=\"IMP_CITY: High cardinality - log(count) encoding\">hc_cnt_log_IMP_CITY</th>\n",
       "      <th title=\"IMP_CITY: High cardinality - label count encoding\">hc_lbl_cnt_IMP_CITY</th>\n",
       "      <th title=\"IMP_CITY: High cardinality - target frequency ratio encoding\">hc_tar_frq_rat_IMP_CITY</th>\n",
       "      <th title=\"IMP_JOB: Low missing rate - mode imputation + label transformation\">cpy_nom_mode_imp_lab_IMP_JOB</th>\n",
       "      <th title=\"IMP_JOB: Low cardinality, high (entropy, IQV) - label transformation\">lchehi_lab_IMP_JOB</th>\n",
       "      <th title=\"IMP_REASON: Low missing rate - mode imputation + label transformation\">cpy_nom_mode_imp_lab_IMP_REASON</th>\n",
       "      <th title=\"JOB: Low missing rate - missing level\">cpy_nom_miss_lev_lab_JOB</th>\n",
       "      <th title=\"JOB: Low cardinality, high (entropy, IQV) - label transformation\">lchehi_lab_JOB</th>\n",
       "      <th title=\"REASON: Low missing rate - missing level\">cpy_nom_miss_lev_lab_REASON</th>\n",
       "      <th title=\"STATE: Low missing rate - mode imputation + label transformation\">cpy_nom_mode_imp_lab_STATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>22040.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1105.0</td>\n",
       "      <td>34.818262</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>22229.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>916.0</td>\n",
       "      <td>34.818262</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>289.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21396.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1749.0</td>\n",
       "      <td>34.818262</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>282.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>22213.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>34.818262</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.178054</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>22329.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>816.0</td>\n",
       "      <td>34.818262</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.127134</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21534.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1611.0</td>\n",
       "      <td>37.113614</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.367296</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21936.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1209.0</td>\n",
       "      <td>34.818262</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.258097</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21804.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1341.0</td>\n",
       "      <td>36.884894</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.833213</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21724.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1421.0</td>\n",
       "      <td>34.818262</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.484907</td>\n",
       "      <td>136.0</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21713.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1432.0</td>\n",
       "      <td>34.818262</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>184.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>22116.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1029.0</td>\n",
       "      <td>34.818262</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.218876</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20919.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2226.0</td>\n",
       "      <td>34.818262</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>246.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>22438.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>707.0</td>\n",
       "      <td>34.818262</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>541.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>22453.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>34.818262</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>299.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21128.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>34.818262</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.890372</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21580.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1565.0</td>\n",
       "      <td>34.818262</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.496508</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21900.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1245.0</td>\n",
       "      <td>34.818262</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>264.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21657.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1488.0</td>\n",
       "      <td>3.711312</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>377.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21687.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1458.0</td>\n",
       "      <td>34.818262</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>198.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>22593.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>552.0</td>\n",
       "      <td>31.588503</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.135494</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-output-area\"></div>\n",
       "<p class=\"cas-results-performance\"><small><span class=\"cas-elapsed\">elapsed 0.00196s</span> &#183; <span class=\"cas-user\">user 0.000678s</span> &#183; <span class=\"cas-sys\">sys 0.00127s</span> &#183; <span class=\"cas-memory\">mem 1.36MB</span></small></p>"
      ],
      "text/plain": [
       "[Fetch]\n",
       "\n",
       " Selected Rows from Table CAS_OUT\n",
       " \n",
       "     BAD  all_l_oks_dtree_10_APPDATE  all_l_oks_dtree_5_APPDATE  cpy_int_med_imp_APPDATE  all_l_oks_dtree_10_var_1_  all_l_oks_dtree_5_var_1_  cpy_int_med_imp_var_1_  cpy_int_med_imp_DEBTINC  hk_dtree_disct10_DEBTINC  hk_dtree_disct5_DEBTINC  hk_yj_0_DEBTINC  hk_yj_n1_DEBTINC  hk_yj_n2_DEBTINC  hk_yj_p1_DEBTINC  hk_yj_p2_DEBTINC  miss_ind_DEBTINC  cpy_int_med_imp_IMP_CLAGE  ho_dtree_disct10_IMP_CLAGE  ho_dtree_disct5_IMP_CLAGE  ho_quan_disct10_IMP_CLAGE  ho_quan_disct5_IMP_CLAGE  ho_winsor_IMP_CLAGE  cpy_int_med_imp_IMP_CLNO  ho_dtree_disct10_IMP_CLNO  ho_dtree_disct5_IMP_CLNO  ho_quan_disct10_IMP_CLNO  ho_quan_disct5_IMP_CLNO  ho_winsor_IMP_CLNO  cpy_int_med_imp_IMP_DEBTINC  ho_dtree_disct10_IMP_DEBTINC  ho_dtree_disct5_IMP_DEBTINC  ho_quan_disct10_IMP_DEBTINC  ho_quan_disct5_IMP_DEBTINC  ho_winsor_IMP_DEBTINC  cpy_int_med_imp_IMP_DELINQ  ho_dtree_disct10_IMP_DELINQ  ho_dtree_disct5_IMP_DELINQ  ho_quan_disct10_IMP_DELINQ  ho_quan_disct5_IMP_DELINQ  ho_winsor_IMP_DELINQ  cpy_int_med_imp_IMP_DEROG  ho_dtree_disct10_IMP_DEROG  ho_dtree_disct5_IMP_DEROG  ho_quan_disct10_IMP_DEROG  ho_quan_disct5_IMP_DEROG  ho_winsor_IMP_DEROG  cpy_int_med_imp_IMP_MORTDUE  ho_dtree_disct10_IMP_MORTDUE  ho_dtree_disct5_IMP_MORTDUE  ho_quan_disct10_IMP_MORTDUE  ho_quan_disct5_IMP_MORTDUE  ho_winsor_IMP_MORTDUE  cpy_int_med_imp_IMP_NINQ  ho_dtree_disct10_IMP_NINQ  ho_dtree_disct5_IMP_NINQ  ho_quan_disct10_IMP_NINQ  ho_quan_disct5_IMP_NINQ  ho_winsor_IMP_NINQ  cpy_int_med_imp_IMP_VALUE  ho_dtree_disct10_IMP_VALUE  ho_dtree_disct5_IMP_VALUE  ho_quan_disct10_IMP_VALUE  ho_quan_disct5_IMP_VALUE  ho_winsor_IMP_VALUE  cpy_int_med_imp_IMP_YOJ  ho_dtree_disct10_IMP_YOJ  ho_dtree_disct5_IMP_YOJ  ho_quan_disct10_IMP_YOJ  ho_quan_disct5_IMP_YOJ  ho_winsor_IMP_YOJ  cpy_int_med_imp_MORTDUE  ho_dtree_disct10_MORTDUE  ho_dtree_disct5_MORTDUE  ho_quan_disct10_MORTDUE  ho_quan_disct5_MORTDUE  ho_winsor_MORTDUE  miss_ind_MORTDUE  cpy_int_med_imp_VALUE  ho_dtree_disct10_VALUE  ho_dtree_disct5_VALUE  ho_quan_disct10_VALUE  ho_quan_disct5_VALUE  ho_winsor_VALUE  cpy_int_med_imp_YOJ  miss_ind_YOJ  nhoks_nloks_dtree_10_YOJ  nhoks_nloks_dtree_5_YOJ  nhoks_nloks_log_YOJ  nhoks_nloks_pow_n0_5_YOJ  nhoks_nloks_pow_n1_YOJ  nhoks_nloks_pow_n2_YOJ  nhoks_nloks_pow_p0_5_YOJ  nhoks_nloks_pow_p1_YOJ  nhoks_nloks_pow_p2_YOJ  hc_cnt_CLAGE  hc_cnt_log_CLAGE  hc_lbl_cnt_CLAGE  hc_tar_frq_rat_CLAGE  miss_ind_CLAGE  cpy_nom_miss_lev_lab_CLNO  grp_rare2_DELINQ  grp_rare2_DEROG  hc_cnt_LOAN  hc_cnt_log_LOAN  hc_lbl_cnt_LOAN  hc_tar_frq_rat_LOAN  cpy_nom_miss_lev_lab_NINQ  lcnhenhi_dtree10_NINQ  lcnhenhi_dtree5_NINQ  lcnhenhi_grp_rare_NINQ  miss_ind_NINQ  cpy_nom_mode_imp_lab_YEAR  lchehi_lab_YEAR  hc_cnt_CITY  hc_cnt_log_CITY  hc_lbl_cnt_CITY  hc_tar_frq_rat_CITY  cpy_nom_mode_imp_lab_DIVISION  lchehi_lab_DIVISION  hc_cnt_IMP_CITY  hc_cnt_log_IMP_CITY  hc_lbl_cnt_IMP_CITY  hc_tar_frq_rat_IMP_CITY  cpy_nom_mode_imp_lab_IMP_JOB  lchehi_lab_IMP_JOB  cpy_nom_mode_imp_lab_IMP_REASON  cpy_nom_miss_lev_lab_JOB  lchehi_lab_JOB  cpy_nom_miss_lev_lab_REASON  cpy_nom_mode_imp_lab_STATE\n",
       " 0   1.0                         8.0                        3.0                  22040.0                        3.0                       3.0                  1105.0                34.818262                       0.0                      0.0         3.578458          0.972081          0.499610         34.818262        640.973940               0.0                  94.000000                         3.0                        2.0                        2.0                       1.0            94.000000                  9.000000                        2.0                       2.0                       2.0                      1.0            9.000000                    33.779915                           6.0                          3.0                          6.0                         3.0              33.779915                    0.000000                          1.0                         1.0                         8.0                        4.0              0.000000                    0.00000                         1.0                        1.0                       10.0                       5.0                  0.0                   25860.0000                           1.0                          1.0                          1.0                         1.0             25860.0000                  1.000000                        2.0                       2.0                       7.0                      4.0            1.000000               39025.000000                         1.0                        1.0                        1.0                       1.0         39025.000000                10.500000                       8.0                      4.0                      8.0                     4.0          10.500000                  25860.0                       2.0                      1.0                      1.0                     1.0       25860.000000               1.0                39025.0                     1.0                    1.0                    1.0                   1.0     39025.000000                 10.5           1.0                       9.0                      4.0             2.442347                  0.294884                0.086957                0.007561                  3.391165                    11.5                  132.25          16.0          2.772589             158.0              0.875000             1.0                       10.0               1.0              1.0          1.0         0.000000            528.0                  0.5                        2.0                    2.0                   2.0                     2.0            1.0                        4.0              4.0         10.0         2.302585            188.0             0.700000                            1.0                  1.0             10.0             2.302585                187.0                 0.700000                           3.0                 3.0                              2.0                       3.0             3.0                          2.0                        50.0\n",
       " 1   1.0                         9.0                        4.0                  22229.0                        2.0                       2.0                   916.0                34.818262                       0.0                      0.0         3.578458          0.972081          0.499610         34.818262        640.973940               0.0                 122.000000                         5.0                        2.0                        3.0                       2.0           122.000000                 14.000000                        3.0                       2.0                       3.0                      2.0           14.000000                    33.779915                           6.0                          3.0                          6.0                         3.0              33.779915                    2.000000                          4.0                         4.0                        10.0                        5.0              2.000000                    0.00000                         1.0                        1.0                       10.0                       5.0                  0.0                   70053.0000                           6.0                          2.0                          6.0                         3.0             70053.0000                  0.000000                        1.0                       1.0                       5.0                      3.0            0.000000               68400.000000                         4.0                        2.0                        3.0                       2.0         68400.000000                 7.000000                       6.0                      3.0                      6.0                     3.0           7.000000                  70053.0                       5.0                      2.0                      6.0                     3.0       70053.000000               1.0                68400.0                     4.0                    2.0                    3.0                   2.0     68400.000000                  7.0           1.0                       8.0                      4.0             2.079442                  0.353553                0.125000                0.015625                  2.828427                     8.0                   64.00          41.0          3.713572               3.0              0.560976             1.0                       15.0               3.0              1.0          1.0         0.000000            461.0                  0.5                        1.0                    1.0                   1.0                     1.0            1.0                        4.0              4.0          7.0         1.945910            290.0             0.500000                            7.0                  7.0              7.0             1.945910                289.0                 0.500000                           3.0                 3.0                              2.0                       3.0             3.0                          2.0                        21.0\n",
       " 2   1.0                         5.0                        1.0                  21396.0                        6.0                       5.0                  1749.0                34.818262                       0.0                      0.0         3.578458          0.972081          0.499610         34.818262        640.973940               0.0                 149.000000                         5.0                        2.0                        5.0                       3.0           149.000000                 10.000000                        2.0                       2.0                       2.0                      1.0           10.000000                    33.779915                           6.0                          3.0                          6.0                         3.0              33.779915                    0.000000                          1.0                         1.0                         8.0                        4.0              0.000000                    0.00000                         1.0                        1.0                       10.0                       5.0                  0.0                   13500.0000                           1.0                          1.0                          1.0                         1.0             13500.0000                  1.000000                        2.0                       2.0                       7.0                      4.0            1.000000               16700.000000                         1.0                        1.0                        1.0                       1.0         16700.000000                 4.000000                       3.0                      2.0                      4.0                     2.0           4.000000                  13500.0                       1.0                      1.0                      1.0                     1.0       16113.875751               1.0                16700.0                     1.0                    1.0                   11.0                   6.0     20353.802488                  4.0           1.0                       5.0                      2.0             1.609438                  0.447214                0.200000                0.040000                  2.236068                     5.0                   25.00          20.0          2.995732             120.0              0.750000             1.0                       11.0               1.0              1.0          2.0         0.693147            385.0                  0.5                        2.0                    2.0                   2.0                     2.0            1.0                        2.0              2.0          7.0         1.945910            283.0             0.500000                            6.0                  6.0              7.0             1.945910                282.0                 0.500000                           3.0                 3.0                              2.0                       3.0             3.0                          2.0                        48.0\n",
       " 3   1.0                         9.0                        4.0                  22213.0                        2.0                       2.0                   932.0                34.818262                       0.0                      0.0         3.578458          0.972081          0.499610         34.818262        640.973940               0.0                 179.771762                         6.0                        3.0                        6.0                       3.0           179.771762                 21.296096                        6.0                       2.0                       7.0                      4.0           21.296096                    33.779915                           6.0                          3.0                          6.0                         3.0              33.779915                    0.449442                          2.0                         2.0                         8.0                        4.0              0.449442                    0.25457                         2.0                        2.0                       12.0                       7.0                  0.0                   73760.8172                           6.0                          2.0                          7.0                         4.0             73760.8172                  1.186055                        3.0                       2.0                       8.0                      4.0            1.186055              101776.048741                         7.0                        3.0                        7.0                       4.0        101776.048741                 8.922268                       7.0                      3.0                      7.0                     4.0           8.922268                  65019.0                       0.0                      0.0                      0.0                     0.0       65019.000000               0.0                89235.5                     0.0                    0.0                    0.0                   0.0     89235.500000                  7.0           0.0                       0.0                      0.0             2.079442                  0.353553                0.125000                0.015625                  2.828427                     8.0                   64.00         308.0          5.730100               1.0              0.746753             0.0                        0.0               0.0              0.0          2.0         0.693147            385.0                  0.5                        0.0                    0.0                   0.0                     0.0            0.0                        4.0              4.0         24.0         3.178054             41.0             0.708333                            7.0                  7.0             24.0             3.178054                 41.0                 0.708333                           3.0                 3.0                              1.0                       0.0             0.0                          0.0                        10.0\n",
       " 4   0.0                         9.0                        4.0                  22329.0                        2.0                       2.0                   816.0                34.818262                       0.0                      0.0         3.578458          0.972081          0.499610         34.818262        640.973940               0.0                  93.000000                         2.0                        2.0                        2.0                       1.0            93.000000                 14.000000                        3.0                       2.0                       3.0                      2.0           14.000000                    33.779915                           6.0                          3.0                          6.0                         3.0              33.779915                    0.000000                          1.0                         1.0                         8.0                        4.0              0.000000                    0.00000                         1.0                        1.0                       10.0                       5.0                  0.0                   97800.0000                           8.0                          3.0                          9.0                         5.0             97800.0000                  0.000000                        1.0                       1.0                       5.0                      3.0            0.000000              112000.000000                         8.0                        4.0                        8.0                       4.0        112000.000000                 3.000000                       2.0                      2.0                      3.0                     2.0           3.000000                  97800.0                       8.0                      3.0                      9.0                     5.0       97800.000000               1.0               112000.0                     8.0                    3.0                    8.0                   4.0    112000.000000                  3.0           1.0                       4.0                      2.0             1.386294                  0.500000                0.250000                0.062500                  2.000000                     4.0                   16.00          30.0          3.401197              35.0              0.833333             1.0                       15.0               1.0              1.0          2.0         0.693147            359.0                  0.5                        1.0                    1.0                   1.0                     1.0            1.0                        5.0              5.0         62.0         4.127134              2.0             0.838710                            6.0                  6.0             62.0             4.127134                  2.0                 0.838710                           2.0                 2.0                              2.0                       2.0             2.0                          2.0                         5.0\n",
       " 5   1.0                         5.0                        1.0                  21534.0                        6.0                       5.0                  1611.0                37.113614                       8.0                      4.0         3.640572          0.973763          0.499656         37.113614        725.823769               1.0                 101.000000                         3.0                        2.0                        2.0                       1.0           101.000000                  8.000000                        1.0                       1.0                       1.0                      1.0            8.000000                    37.113614                           8.0                          4.0                          7.0                         4.0              37.113614                    0.000000                          1.0                         1.0                         8.0                        4.0              0.000000                    0.00000                         1.0                        1.0                       10.0                       5.0                  0.0                   30548.0000                           1.0                          1.0                          2.0                         1.0             30548.0000                  1.000000                        2.0                       2.0                       7.0                      4.0            1.000000               40320.000000                         1.0                        1.0                        1.0                       1.0         40320.000000                 9.000000                       7.0                      3.0                      8.0                     4.0           9.000000                  30548.0                       2.0                      1.0                      2.0                     1.0       30548.000000               1.0                40320.0                     1.0                    1.0                    1.0                   1.0     40320.000000                  9.0           1.0                       8.0                      4.0             2.302585                  0.316228                0.100000                0.010000                  3.162278                    10.0                  100.00          25.0          3.218876              74.0              0.760000             1.0                        9.0               1.0              1.0          2.0         0.693147            359.0                  0.5                        2.0                    2.0                   2.0                     2.0            1.0                        2.0              2.0         29.0         3.367296             22.0             0.793103                            6.0                  6.0             29.0             3.367296                 22.0                 0.793103                           3.0                 3.0                              2.0                       3.0             3.0                          2.0                        48.0\n",
       " 6   1.0                         7.0                        2.0                  21936.0                        4.0                       4.0                  1209.0                34.818262                       0.0                      0.0         3.578458          0.972081          0.499610         34.818262        640.973940               0.0                  77.000000                         2.0                        2.0                        1.0                       1.0            77.000000                 17.000000                        5.0                       2.0                       4.0                      2.0           17.000000                    33.779915                           6.0                          3.0                          6.0                         3.0              33.779915                    2.000000                          4.0                         4.0                        10.0                        5.0              2.000000                    3.00000                         3.0                        3.0                       12.0                       7.0                  0.0                   48649.0000                           3.0                          2.0                          3.0                         2.0             48649.0000                  1.000000                        2.0                       2.0                       7.0                      4.0            1.000000               57037.000000                         2.0                        2.0                        2.0                       1.0         57037.000000                 5.000000                       4.0                      2.0                      5.0                     3.0           5.000000                  48649.0                       4.0                      2.0                      3.0                     2.0       48649.000000               1.0                57037.0                     2.0                    2.0                    2.0                   1.0     57037.000000                  5.0           1.0                       6.0                      2.0             1.791759                  0.408248                0.166667                0.027778                  2.449490                     6.0                   36.00          17.0          2.833213             150.0              0.705882             1.0                       18.0               3.0              2.0          2.0         0.693147            401.0                  0.5                        2.0                    2.0                   2.0                     2.0            1.0                        4.0              4.0         26.0         3.258097             34.0             0.769231                            7.0                  7.0             26.0             3.258097                 34.0                 0.769231                           3.0                 3.0                              2.0                       3.0             3.0                          2.0                        10.0\n",
       " 7   1.0                         6.0                        1.0                  21804.0                        5.0                       5.0                  1341.0                36.884894                       7.0                      3.0         3.634552          0.973604          0.499652         36.884894        717.132600               1.0                  89.000000                         2.0                        2.0                        2.0                       1.0            89.000000                  8.000000                        1.0                       1.0                       1.0                      1.0            8.000000                    36.884894                           7.0                          4.0                          7.0                         4.0              36.884894                    0.000000                          1.0                         1.0                         8.0                        4.0              0.000000                    0.00000                         1.0                        1.0                       10.0                       5.0                  0.0                   28502.0000                           1.0                          1.0                          2.0                         1.0             28502.0000                  0.000000                        1.0                       1.0                       5.0                      3.0            0.000000               43034.000000                         2.0                        2.0                        1.0                       1.0         43034.000000                11.000000                       8.0                      4.0                      9.0                     5.0          11.000000                  28502.0                       2.0                      1.0                      1.0                     1.0       28502.000000               1.0                43034.0                     2.0                    2.0                    1.0                   1.0     43034.000000                 11.0           1.0                       9.0                      4.0             2.484907                  0.288675                0.083333                0.006944                  3.464102                    12.0                  144.00          34.0          3.526361              15.0              0.705882             1.0                        9.0               1.0              1.0          2.0         0.693147            401.0                  0.5                        1.0                    1.0                   1.0                     1.0            1.0                        3.0              3.0         17.0         2.833213             77.0             0.823529                            6.0                  6.0             17.0             2.833213                 77.0                 0.823529                           3.0                 3.0                              2.0                       3.0             3.0                          2.0                        48.0\n",
       " 8   1.0                         5.0                        1.0                  21724.0                        6.0                       5.0                  1421.0                34.818262                       0.0                      0.0         3.578458          0.972081          0.499610         34.818262        640.973940               0.0                 217.000000                         8.0                        4.0                        8.0                       4.0           217.000000                 12.000000                        2.0                       2.0                       2.0                      1.0           12.000000                    33.779915                           6.0                          3.0                          6.0                         3.0              33.779915                    2.000000                          4.0                         4.0                        10.0                        5.0              2.000000                    0.00000                         1.0                        1.0                       10.0                       5.0                  0.0                   32700.0000                           1.0                          1.0                          2.0                         1.0             32700.0000                  1.000000                        2.0                       2.0                       7.0                      4.0            1.000000               46740.000000                         2.0                        2.0                        1.0                       1.0         46740.000000                 3.000000                       2.0                      2.0                      3.0                     2.0           3.000000                  32700.0                       2.0                      1.0                      2.0                     1.0       32700.000000               1.0                46740.0                     2.0                    2.0                    1.0                   1.0     46740.000000                  3.0           1.0                       4.0                      2.0             1.386294                  0.500000                0.250000                0.062500                  2.000000                     4.0                   16.00          15.0          2.708050             170.0              0.733333             1.0                       13.0               3.0              1.0          6.0         1.791759            259.0                  0.5                        2.0                    2.0                   2.0                     2.0            1.0                        3.0              3.0         12.0         2.484907            136.0             0.583333                            6.0                  6.0             12.0             2.484907                136.0                 0.583333                           3.0                 3.0                              2.0                       3.0             3.0                          2.0                        48.0\n",
       " 9   1.0                         5.0                        1.0                  21713.0                        6.0                       5.0                  1432.0                34.818262                       0.0                      0.0         3.578458          0.972081          0.499610         34.818262        640.973940               0.0                 116.000000                         4.0                        2.0                        3.0                       2.0           116.000000                 13.000000                        3.0                       2.0                       3.0                      2.0           13.000000                    33.779915                           6.0                          3.0                          6.0                         3.0              33.779915                    0.000000                          1.0                         1.0                         8.0                        4.0              0.000000                    0.00000                         1.0                        1.0                       10.0                       5.0                  0.0                   73760.8172                           6.0                          2.0                          7.0                         4.0             73760.8172                  0.000000                        1.0                       1.0                       5.0                      3.0            0.000000               62250.000000                         3.0                        2.0                        3.0                       2.0         62250.000000                16.000000                       9.0                      4.0                     10.0                     5.0          16.000000                  65019.0                       0.0                      0.0                      0.0                     0.0       65019.000000               0.0                62250.0                     3.0                    2.0                    3.0                   2.0     62250.000000                 16.0           1.0                       9.0                      4.0             2.833213                  0.242536                0.058824                0.003460                  4.123106                    17.0                  289.00          31.0          3.433987              32.0              0.709677             1.0                       14.0               1.0              1.0          6.0         1.791759            259.0                  0.5                        1.0                    1.0                   1.0                     1.0            1.0                        3.0              3.0         10.0         2.302585            185.0             0.500000                            3.0                  3.0             10.0             2.302585                184.0                 0.500000                           5.0                 5.0                              2.0                       5.0             5.0                          2.0                        31.0\n",
       " 10  1.0                         8.0                        3.0                  22116.0                        3.0                       3.0                  1029.0                34.818262                       0.0                      0.0         3.578458          0.972081          0.499610         34.818262        640.973940               0.0                 179.771762                         6.0                        3.0                        6.0                       3.0           179.771762                 21.296096                        6.0                       2.0                       7.0                      4.0           21.296096                    33.779915                           6.0                          3.0                          6.0                         3.0              33.779915                    0.449442                          2.0                         2.0                         8.0                        4.0              0.449442                    0.25457                         2.0                        2.0                       12.0                       7.0                  0.0                   22608.0000                           1.0                          1.0                          1.0                         1.0             22608.0000                  1.186055                        3.0                       2.0                       8.0                      4.0            1.186055              101776.048741                         7.0                        3.0                        7.0                       4.0        101776.048741                18.000000                       9.0                      4.0                     10.0                     5.0          18.000000                  22608.0                       2.0                      1.0                      1.0                     1.0       22608.000000               1.0                89235.5                     0.0                    0.0                    0.0                   0.0     89235.500000                 18.0           1.0                       9.0                      4.0             2.944439                  0.229416                0.052632                0.002770                  4.358899                    19.0                  361.00         308.0          5.730100               1.0              0.746753             0.0                        0.0               0.0              0.0          6.0         1.791759            259.0                  0.5                        0.0                    0.0                   0.0                     0.0            0.0                        4.0              4.0         25.0         3.218876             38.0             0.760000                            6.0                  6.0             25.0             3.218876                 38.0                 0.760000                           3.0                 3.0                              1.0                       0.0             0.0                          0.0                         5.0\n",
       " 11  1.0                         2.0                        1.0                  20919.0                        9.0                       5.0                  2226.0                34.818262                       0.0                      0.0         3.578458          0.972081          0.499610         34.818262        640.973940               0.0                 123.000000                         5.0                        2.0                        3.0                       2.0           123.000000                  9.000000                        2.0                       2.0                       2.0                      1.0            9.000000                    33.779915                           6.0                          3.0                          6.0                         3.0              33.779915                    1.000000                          3.0                         3.0                        10.0                        5.0              1.000000                    0.00000                         1.0                        1.0                       10.0                       5.0                  0.0                   20627.0000                           1.0                          1.0                          1.0                         1.0             20627.0000                  1.000000                        2.0                       2.0                       7.0                      4.0            1.000000               29800.000000                         1.0                        1.0                        1.0                       1.0         29800.000000                11.000000                       8.0                      4.0                      9.0                     5.0          11.000000                  20627.0                       1.0                      1.0                      1.0                     1.0       20627.000000               1.0                29800.0                     1.0                    1.0                    1.0                   1.0     29800.000000                 11.0           1.0                       9.0                      4.0             2.484907                  0.288675                0.083333                0.006944                  3.464102                    12.0                  144.00          51.0          3.931826               2.0              0.627451             1.0                       10.0               2.0              1.0          6.0         1.791759            259.0                  0.5                        2.0                    2.0                   2.0                     2.0            1.0                        1.0              1.0          8.0         2.079442            247.0             0.500000                            7.0                  7.0              8.0             2.079442                246.0                 0.500000                           2.0                 2.0                              2.0                       2.0             2.0                          2.0                        10.0\n",
       " 12  1.0                        10.0                        5.0                  22438.0                        1.0                       1.0                   707.0                34.818262                       0.0                      0.0         3.578458          0.972081          0.499610         34.818262        640.973940               0.0                  86.000000                         2.0                        2.0                        2.0                       1.0            86.000000                 25.000000                        7.0                       3.0                       8.0                      4.0           25.000000                    33.779915                           6.0                          3.0                          6.0                         3.0              33.779915                    0.000000                          1.0                         1.0                         8.0                        4.0              0.000000                    0.00000                         1.0                        1.0                       10.0                       5.0                  0.0                   45000.0000                           2.0                          2.0                          3.0                         2.0             45000.0000                  2.000000                        4.0                       3.0                       9.0                      5.0            2.000000               55000.000000                         2.0                        2.0                        2.0                       1.0         55000.000000                 3.000000                       2.0                      2.0                      3.0                     2.0           3.000000                  45000.0                       3.0                      2.0                      3.0                     2.0       45000.000000               1.0                55000.0                     2.0                    2.0                    2.0                   1.0     55000.000000                  3.0           1.0                       4.0                      2.0             1.386294                  0.500000                0.250000                0.062500                  2.000000                     4.0                   16.00          27.0          3.295837              56.0              0.629630             1.0                       26.0               1.0              1.0          6.0         1.791759            259.0                  0.5                        3.0                    3.0                   3.0                     3.0            1.0                        5.0              5.0          3.0         1.098612            542.0             0.500000                            1.0                  1.0              3.0             1.098612                541.0                 0.500000                           3.0                 3.0                              2.0                       3.0             3.0                          2.0                        50.0\n",
       " 13  0.0                        10.0                        5.0                  22453.0                        1.0                       1.0                   692.0                34.818262                       0.0                      0.0         3.578458          0.972081          0.499610         34.818262        640.973940               0.0                 147.000000                         5.0                        2.0                        5.0                       3.0           147.000000                 24.000000                        7.0                       3.0                       8.0                      4.0           24.000000                    33.779915                           6.0                          3.0                          6.0                         3.0              33.779915                    0.000000                          1.0                         1.0                         8.0                        4.0              0.000000                    0.00000                         1.0                        1.0                       10.0                       5.0                  0.0                   64536.0000                           5.0                          2.0                          5.0                         3.0             64536.0000                  0.000000                        1.0                       1.0                       5.0                      3.0            0.000000               87400.000000                         5.0                        2.0                        5.0                       3.0         87400.000000                 2.500000                       2.0                      2.0                      3.0                     2.0           2.500000                  64536.0                       5.0                      2.0                      5.0                     3.0       64536.000000               1.0                87400.0                     5.0                    3.0                    5.0                   3.0     87400.000000                  2.5           1.0                       3.0                      2.0             1.252763                  0.534522                0.285714                0.081633                  1.870829                     3.5                   12.25          23.0          3.135494              94.0              0.782609             1.0                       25.0               1.0              1.0          6.0         1.791759            259.0                  0.5                        1.0                    1.0                   1.0                     1.0            1.0                        5.0              5.0          6.0         1.791759            300.0             0.500000                            3.0                  3.0              6.0             1.791759                299.0                 0.500000                           1.0                 1.0                              1.0                       1.0             1.0                          0.0                        39.0\n",
       " 14  1.0                         3.0                        1.0                  21128.0                        8.0                       5.0                  2017.0                34.818262                       0.0                      0.0         3.578458          0.972081          0.499610         34.818262        640.973940               0.0                 123.000000                         5.0                        2.0                        3.0                       2.0           123.000000                 16.000000                        4.0                       2.0                       4.0                      2.0           16.000000                    33.779915                           6.0                          3.0                          6.0                         3.0              33.779915                    1.000000                          3.0                         3.0                        10.0                        5.0              1.000000                    0.00000                         1.0                        1.0                       10.0                       5.0                  0.0                   71000.0000                           6.0                          2.0                          6.0                         3.0             71000.0000                  0.000000                        1.0                       1.0                       5.0                      3.0            0.000000               83850.000000                         4.0                        2.0                        5.0                       3.0         83850.000000                 8.000000                       6.0                      3.0                      6.0                     3.0           8.000000                  71000.0                       5.0                      2.0                      6.0                     3.0       71000.000000               1.0                83850.0                     4.0                    2.0                    5.0                   3.0     83850.000000                  8.0           1.0                       8.0                      4.0             2.197225                  0.333333                0.111111                0.012346                  3.000000                     9.0                   81.00          51.0          3.931826               2.0              0.627451             1.0                       17.0               2.0              1.0          1.0         0.000000            447.0                  0.5                        1.0                    1.0                   1.0                     1.0            1.0                        1.0              1.0         18.0         2.890372             72.0             0.833333                            1.0                  1.0             18.0             2.890372                 72.0                 0.833333                           3.0                 3.0                              2.0                       3.0             3.0                          2.0                        23.0\n",
       " 15  1.0                         5.0                        1.0                  21580.0                        6.0                       5.0                  1565.0                34.818262                       0.0                      0.0         3.578458          0.972081          0.499610         34.818262        640.973940               0.0                 301.000000                        10.0                        5.0                       10.0                       5.0           301.000000                  8.000000                        1.0                       1.0                       1.0                      1.0            8.000000                    33.779915                           6.0                          3.0                          6.0                         3.0              33.779915                    1.000000                          3.0                         3.0                        10.0                        5.0              1.000000                    0.00000                         1.0                        1.0                       10.0                       5.0                  0.0                   24280.0000                           1.0                          1.0                          1.0                         1.0             24280.0000                  0.000000                        1.0                       1.0                       5.0                      3.0            0.000000               34687.000000                         1.0                        1.0                        1.0                       1.0         34687.000000                 8.922268                       7.0                      3.0                      7.0                     4.0           8.922268                  24280.0                       2.0                      1.0                      1.0                     1.0       24280.000000               1.0                34687.0                     1.0                    1.0                    1.0                   1.0     34687.000000                  7.0           0.0                       0.0                      0.0             2.079442                  0.353553                0.125000                0.015625                  2.828427                     8.0                   64.00          16.0          2.772589             166.0              0.750000             1.0                        9.0               2.0              1.0          3.0         1.098612            339.0                  0.5                        1.0                    1.0                   1.0                     1.0            1.0                        3.0              3.0         33.0         3.496508             14.0             0.757576                            6.0                  6.0             33.0             3.496508                 14.0                 0.757576                           3.0                 3.0                              2.0                       3.0             3.0                          2.0                         5.0\n",
       " 16  1.0                         7.0                        2.0                  21900.0                        4.0                       4.0                  1245.0                34.818262                       0.0                      0.0         3.578458          0.972081          0.499610         34.818262        640.973940               0.0                 123.000000                         5.0                        2.0                        3.0                       2.0           123.000000                 22.000000                        6.0                       2.0                       7.0                      4.0           22.000000                    33.779915                           6.0                          3.0                          6.0                         3.0              33.779915                    6.000000                          4.0                         4.0                        10.0                        5.0              6.000000                    2.00000                         3.0                        3.0                       12.0                       7.0                  0.0                   90957.0000                           8.0                          3.0                          9.0                         5.0             90957.0000                  1.000000                        2.0                       2.0                       7.0                      4.0            1.000000              102600.000000                         7.0                        3.0                        7.0                       4.0        102600.000000                 7.000000                       6.0                      3.0                      6.0                     3.0           7.000000                  90957.0                       8.0                      3.0                      8.0                     4.0       90957.000000               1.0               102600.0                     7.0                    3.0                    7.0                   4.0    102600.000000                  7.0           1.0                       8.0                      4.0             2.079442                  0.353553                0.125000                0.015625                  2.828427                     8.0                   64.00          51.0          3.931826               2.0              0.627451             1.0                       23.0               3.0              2.0          3.0         1.098612            339.0                  0.5                        2.0                    2.0                   2.0                     2.0            1.0                        3.0              3.0          7.0         1.945910            265.0             0.500000                            1.0                  1.0              7.0             1.945910                264.0                 0.500000                           1.0                 1.0                              2.0                       1.0             1.0                          2.0                        14.0\n",
       " 17  1.0                         5.0                        1.0                  21657.0                        6.0                       5.0                  1488.0                 3.711312                       1.0                      1.0         1.549966          0.787745          0.477474          3.711312         10.598232               1.0                 179.771762                         6.0                        3.0                        6.0                       3.0           179.771762                 21.296096                        6.0                       2.0                       7.0                      4.0           21.296096                     3.711312                           1.0                          1.0                         11.0                         6.0              25.060107                    0.449442                          2.0                         2.0                         8.0                        4.0              0.449442                    0.25457                         2.0                        2.0                       12.0                       7.0                  0.0                   23030.0000                           1.0                          1.0                          1.0                         1.0             23030.0000                  1.186055                        3.0                       2.0                       8.0                      4.0            1.186055              101776.048741                         7.0                        3.0                        7.0                       4.0        101776.048741                19.000000                       9.0                      4.0                     10.0                     5.0          19.000000                  23030.0                       2.0                      1.0                      1.0                     1.0       23030.000000               1.0                89235.5                     0.0                    0.0                    0.0                   0.0     89235.500000                 19.0           1.0                       9.0                      4.0             2.995732                  0.223607                0.050000                0.002500                  4.472136                    20.0                  400.00         308.0          5.730100               1.0              0.746753             0.0                        0.0               0.0              0.0          3.0         1.098612            339.0                  0.5                        0.0                    0.0                   0.0                     0.0            0.0                        3.0              3.0          5.0         1.609438            377.0             0.500000                            6.0                  6.0              5.0             1.609438                377.0                 0.500000                           3.0                 3.0                              1.0                       0.0             0.0                          0.0                         5.0\n",
       " 18  1.0                         5.0                        1.0                  21687.0                        6.0                       5.0                  1458.0                34.818262                       0.0                      0.0         3.578458          0.972081          0.499610         34.818262        640.973940               0.0                  55.000000                         1.0                        1.0                        1.0                       1.0            55.000000                 16.000000                        4.0                       2.0                       4.0                      2.0           16.000000                    33.779915                           6.0                          3.0                          6.0                         3.0              33.779915                    0.000000                          1.0                         1.0                         8.0                        4.0              0.000000                    0.00000                         1.0                        1.0                       10.0                       5.0                  0.0                   28192.0000                           1.0                          1.0                          2.0                         1.0             28192.0000                  1.000000                        2.0                       2.0                       7.0                      4.0            1.000000               40150.000000                         1.0                        1.0                        1.0                       1.0         40150.000000                 4.500000                       4.0                      2.0                      4.0                     2.0           4.500000                  28192.0                       2.0                      1.0                      1.0                     1.0       28192.000000               1.0                40150.0                     1.0                    1.0                    1.0                   1.0     40150.000000                  4.5           1.0                       6.0                      2.0             1.704748                  0.426401                0.181818                0.033058                  2.345208                     5.5                   30.25          10.0          2.302585             230.0              0.700000             1.0                       17.0               1.0              1.0          3.0         1.098612            353.0                  0.5                        2.0                    2.0                   2.0                     2.0            1.0                        3.0              3.0          9.0         2.197225            199.0             0.500000                            6.0                  6.0              9.0             2.197225                198.0                 0.500000                           3.0                 3.0                              2.0                       3.0             3.0                          2.0                         2.0\n",
       " 19  0.0                        10.0                        5.0                  22593.0                        1.0                       1.0                   552.0                31.588503                       5.0                      3.0         3.483960          0.969314          0.499529         31.588503        530.505270               1.0                  91.000000                         2.0                        2.0                        2.0                       1.0            91.000000                 13.000000                        3.0                       2.0                       3.0                      2.0           13.000000                    31.588503                           5.0                          2.0                          2.0                         1.0              31.588503                    0.000000                          1.0                         1.0                         8.0                        4.0              0.000000                    0.00000                         1.0                        1.0                       10.0                       5.0                  0.0                  102370.0000                           8.0                          3.0                         10.0                         5.0            102370.0000                  0.000000                        1.0                       1.0                       5.0                      3.0            0.000000              120953.000000                         8.0                        4.0                        8.0                       4.0        120953.000000                 2.000000                       2.0                      2.0                      3.0                     2.0           2.000000                 102370.0                       8.0                      3.0                      9.0                     5.0      102370.000000               1.0               120953.0                     8.0                    3.0                    8.0                   4.0    120953.000000                  2.0           1.0                       3.0                      2.0             1.098612                  0.577350                0.333333                0.111111                  1.732051                     3.0                    9.00          29.0          3.367296              44.0              0.655172             1.0                       14.0               1.0              1.0          3.0         1.098612            353.0                  0.5                        1.0                    1.0                   1.0                     1.0            1.0                        5.0              5.0         23.0         3.135494             43.0             0.826087                            9.0                  9.0             23.0             3.135494                 43.0                 0.826087                           2.0                 2.0                              2.0                       2.0             2.0                          2.0                        44.0\n",
       "\n",
       "+ Elapsed: 0.00196s, user: 0.000678s, sys: 0.00127s, mem: 1.36mb"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.fetch(table = {'name': 'CAS_OUT'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Science Automated Machine Learning Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [dsAutoMl action]creates a policy-based, scalable, end-to-end automated machine learning pipeline for both regression and classification problems. The only input required from the user is the input data set and the target variable, but optional parameters include the policy parameters for data exploration, variable screening, feature selection, and feature transformation.  Overriding the default policy parameters allow a data scientist to configure their pipeline in their data science workflow. In addition, a data scientist may also select additional models to consider. By default, only a decision tree model is included in the pipeline, but neural networks, random forest models, and gradient boosting models are also available. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](images/MR_08_auto_pipeline.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: Added action set 'autotune'.\n",
      "NOTE: Added action set 'decisionTree'.\n",
      "NOTE: Early stopping is activated; 'NTREE' will not be tuned.\n",
      "NOTE: Added action set 'autotune'.\n",
      "NOTE: Added action set 'decisionTree'.\n",
      "NOTE: Early stopping is activated; 'NTREE' will not be tuned.\n",
      "NOTE: Added action set 'autotune'.\n",
      "NOTE: The number of bins will not be tuned since all inputs are nominal.\n",
      "NOTE: Added action set 'decisionTree'.\n",
      "NOTE: The Hyperparameter Importance results table is not created since data is insufficient to calculate importance values.\n",
      "NOTE: Early stopping is activated; 'NTREE' will not be tuned.\n",
      "NOTE: The number of bins will not be tuned since all inputs are nominal.\n",
      "NOTE: Added action set 'autotune'.\n",
      "NOTE: The number of bins will not be tuned since all inputs are nominal.\n",
      "NOTE: Added action set 'decisionTree'.\n",
      "NOTE: The Hyperparameter Importance results table is not created since data is insufficient to calculate importance values.\n",
      "NOTE: Early stopping is activated; 'NTREE' will not be tuned.\n",
      "NOTE: The number of bins will not be tuned since all inputs are nominal.\n",
      "NOTE: Added action set 'autotune'.\n",
      "NOTE: The number of bins will not be tuned since all inputs are nominal.\n",
      "NOTE: Added action set 'decisionTree'.\n",
      "NOTE: Early stopping is activated; 'NTREE' will not be tuned.\n",
      "NOTE: The number of bins will not be tuned since all inputs are nominal.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"cas-results-key\"><b>&#167; list</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>[Decision Tree for __TEMP_FEATURE_MACHINE_CASOUT___AUTOTUNE_DATA_11FA4B25-9848-604F-9F45-7E73830B6354\n",
       "\n",
       "                           Descr        Value\n",
       "0           Number of Tree Nodes   437.000000\n",
       "1         Max Number of Branches     2.000000\n",
       "2               Number of Levels    15.000000\n",
       "3               Number of Leaves   219.000000\n",
       "4                 Number of Bins   100.000000\n",
       "5         Minimum Size of Leaves     5.000000\n",
       "6         Maximum Size of Leaves   612.000000\n",
       "7            Number of Variables     6.000000\n",
       "8   Confidence Level for Pruning     0.250000\n",
       "9    Number of Observations Used  5960.000000\n",
       "10   Misclassification Error (%)    11.895973,                          Descr                             Value\n",
       "0  Number of Observations Read                              5960\n",
       "1  Number of Observations Used                              5960\n",
       "2  Misclassification Error (%)                      11.895973154,         LEVNAME  LEVINDEX VARNAME\n",
       "0             1         0  P_BAD1\n",
       "1             0         1  P_BAD0,   LEVNAME  LEVINDEX VARNAME\n",
       "0                 0   I_BAD, ROC Information for _AUTOTUNE_DEFAULT_SCORE_TABLE_\n",
       "\n",
       "   Variable Event  CutOff      TP      FP      FN      TN  Sensitivity  \\\n",
       "0    P_BAD0     0    0.00  4771.0  1189.0     0.0     0.0     1.000000   \n",
       "1    P_BAD0     0    0.01  4771.0  1019.0     0.0   170.0     1.000000   \n",
       "2    P_BAD0     0    0.02  4771.0  1019.0     0.0   170.0     1.000000   \n",
       "3    P_BAD0     0    0.03  4771.0  1019.0     0.0   170.0     1.000000   \n",
       "4    P_BAD0     0    0.04  4771.0  1019.0     0.0   170.0     1.000000   \n",
       "..      ...   ...     ...     ...     ...     ...     ...          ...   \n",
       "95   P_BAD0     0    0.95  2718.0    45.0  2053.0  1144.0     0.569692   \n",
       "96   P_BAD0     0    0.96  2553.0    37.0  2218.0  1152.0     0.535108   \n",
       "97   P_BAD0     0    0.97  2368.0    30.0  2403.0  1159.0     0.496332   \n",
       "98   P_BAD0     0    0.98  1282.0     2.0  3489.0  1187.0     0.268707   \n",
       "99   P_BAD0     0    0.99  1166.0     0.0  3605.0  1189.0     0.244393   \n",
       "\n",
       "    Specificity   KS       FPR       ACC       FDR        F1         C  \\\n",
       "0      0.000000  0.0  1.000000  0.800503  0.199497  0.889200  0.917425   \n",
       "1      0.142977  0.0  0.857023  0.829027  0.175993  0.903513  0.917425   \n",
       "2      0.142977  0.0  0.857023  0.829027  0.175993  0.903513  0.917425   \n",
       "3      0.142977  0.0  0.857023  0.829027  0.175993  0.903513  0.917425   \n",
       "4      0.142977  0.0  0.857023  0.829027  0.175993  0.903513  0.917425   \n",
       "..          ...  ...       ...       ...       ...       ...       ...   \n",
       "95     0.962153  0.0  0.037847  0.647987  0.016287  0.721529  0.917425   \n",
       "96     0.968881  0.0  0.031119  0.621644  0.014286  0.693656  0.917425   \n",
       "97     0.974769  0.0  0.025231  0.591779  0.012510  0.660622  0.917425   \n",
       "98     0.998318  0.0  0.001682  0.414262  0.001558  0.423452  0.917425   \n",
       "99     1.000000  0.0  0.000000  0.395134  0.000000  0.392791  0.917425   \n",
       "\n",
       "       Gini     Gamma       Tau  MISCEVENT       FNR  \n",
       "0   0.83485  0.859642  0.266692   0.199497  0.000000  \n",
       "1   0.83485  0.859642  0.266692   0.170973  0.000000  \n",
       "2   0.83485  0.859642  0.266692   0.170973  0.000000  \n",
       "3   0.83485  0.859642  0.266692   0.170973  0.000000  \n",
       "4   0.83485  0.859642  0.266692   0.170973  0.000000  \n",
       "..      ...       ...       ...        ...       ...  \n",
       "95  0.83485  0.859642  0.266692   0.352013  0.430308  \n",
       "96  0.83485  0.859642  0.266692   0.378356  0.464892  \n",
       "97  0.83485  0.859642  0.266692   0.408221  0.503668  \n",
       "98  0.83485  0.859642  0.266692   0.585738  0.731293  \n",
       "99  0.83485  0.859642  0.266692   0.604866  0.755607  \n",
       "\n",
       "[100 rows x 22 columns], Fit Statistics for _AUTOTUNE_DEFAULT_SCORE_TABLE_\n",
       "\n",
       "     NOBS       ASE     DIV      RASE      MCE      MCLL\n",
       "0  5960.0  0.083021  5960.0  0.288133  0.11896  0.268032, Tuner Information\n",
       "\n",
       "                           Parameter              Value\n",
       "0                         Model Type      Decision Tree\n",
       "1           Tuner Objective Function  Misclassification\n",
       "2                      Search Method               GRID\n",
       "3              Number of Grid Points                  6\n",
       "4     Maximum Tuning Time in Seconds              36000\n",
       "5                    Validation Type   Cross-Validation\n",
       "6      Num Folds in Cross-Validation                  5\n",
       "7                          Log Level                  0\n",
       "8                               Seed         1876924690\n",
       "9     Number of Parallel Evaluations                  4\n",
       "10  Number of Workers per Subsession                  0, Tuner Results\n",
       "\n",
       "   Evaluation  MAXLEVEL  NBINS       CRIT  MeanConseqError  EvaluationTime\n",
       "0           0        11     20  gainRatio         0.139260        0.380601\n",
       "1           6        15    100       gain         0.116296        1.072245\n",
       "2           2        10    100       gain         0.117282        1.595850\n",
       "3           5        10    100  gainRatio         0.122506        0.941197\n",
       "4           1        15    100  gainRatio         0.124835        0.552839\n",
       "5           3         5    100       gain         0.140584        0.594192\n",
       "6           4         5    100  gainRatio         0.165438        1.099558, Tuner Iteration History\n",
       "\n",
       "   Iteration  Evaluations  Best_obj  Time_sec\n",
       "0          0            1  0.139260  0.380601\n",
       "1          1            7  0.116296  2.046567, Tuner Evaluation History\n",
       "\n",
       "   Evaluation  Iteration  MAXLEVEL  NBINS       CRIT  MeanConseqError  \\\n",
       "0           0          0        11     20  gainRatio         0.139260   \n",
       "1           1          1        15    100  gainRatio         0.124835   \n",
       "2           2          1        10    100       gain         0.117282   \n",
       "3           3          1         5    100       gain         0.140584   \n",
       "4           4          1         5    100  gainRatio         0.165438   \n",
       "5           5          1        10    100  gainRatio         0.122506   \n",
       "6           6          1        15    100       gain         0.116296   \n",
       "\n",
       "   EvaluationTime  \n",
       "0        0.380601  \n",
       "1        0.552839  \n",
       "2        1.595850  \n",
       "3        0.594192  \n",
       "4        1.099558  \n",
       "5        0.941197  \n",
       "6        1.072245  , Best Configuration\n",
       "\n",
       "             Parameter        Name        Value\n",
       "0           Evaluation  Evaluation            6\n",
       "1  Maximum Tree Levels    MAXLEVEL           15\n",
       "2         Maximum Bins       NBINS          100\n",
       "3            Criterion        CRIT         gain\n",
       "4    Misclassification   Objective  0.116295595, Tuner Summary\n",
       "\n",
       "                                          Parameter     Value\n",
       "0             Initial Configuration Objective Value  0.139260\n",
       "1                Best Configuration Objective Value  0.116296\n",
       "2               Worst Configuration Objective Value  0.165438\n",
       "3  Initial Configuration Evaluation Time in Seconds  0.380601\n",
       "4     Best Configuration Evaluation Time in Seconds  1.072237\n",
       "5                 Number of Improved Configurations  4.000000\n",
       "6                Number of Evaluated Configurations  7.000000\n",
       "7                      Total Tuning Time in Seconds  2.143804\n",
       "8                           Parallel Tuning Speedup  2.640009, Tuner Task Timing\n",
       "\n",
       "                          Task  Time_sec  Time_percent\n",
       "0               Model Training  3.969640     70.139171\n",
       "1                Model Scoring  1.109903     19.610758\n",
       "2  Total Objective Evaluations  5.085044     89.847139\n",
       "3                        Tuner  0.574618     10.152861\n",
       "4               Total CPU Time  5.659662    100.000000, Hyperparameter Importance\n",
       "\n",
       "  Hyperparameter  RelImportance\n",
       "0       MAXLEVEL       1.000000\n",
       "1           CRIT       0.244249\n",
       "2          NBINS       0.000000, Gradient Boosting Tree for __TEMP_FEATURE_MACHINE_CASOUT___AUTOTUNE_DATA_11FA4B25-9848-604F-9F45-7E73830B6354\n",
       "\n",
       "                                  Descr         Value\n",
       "0                       Number of Trees  1.500000e+02\n",
       "1                          Distribution  2.000000e+00\n",
       "2                         Learning Rate  1.000000e-01\n",
       "3                      Subsampling Rate  6.000000e-01\n",
       "4      Number of Selected Variables (M)  6.000000e+00\n",
       "5                        Number of Bins  7.700000e+01\n",
       "6                   Number of Variables  6.000000e+00\n",
       "7              Max Number of Tree Nodes  9.700000e+01\n",
       "8              Min Number of Tree Nodes  6.100000e+01\n",
       "9                Max Number of Branches  2.000000e+00\n",
       "10               Min Number of Branches  2.000000e+00\n",
       "11                 Max Number of Levels  7.000000e+00\n",
       "12                 Min Number of Levels  7.000000e+00\n",
       "13                 Max Number of Leaves  4.900000e+01\n",
       "14                 Min Number of Leaves  3.100000e+01\n",
       "15               Maximum Size of Leaves  1.871000e+03\n",
       "16               Minimum Size of Leaves  5.000000e+00\n",
       "17                   Random Number Seed  1.876924e+09\n",
       "18                   Lasso (L1) penalty  0.000000e+00\n",
       "19                   Ridge (L2) penalty  0.000000e+00\n",
       "20               Actual Number of Trees  3.700000e+01\n",
       "21             Average number of Leaves  4.327027e+01\n",
       "22            Early stopping stagnation  4.000000e+00\n",
       "23             Early stopping threshold  0.000000e+00\n",
       "24  Early stopping threshold iterations  0.000000e+00\n",
       "25             Early stopping tolerance  0.000000e+00,     Progress    Metric\n",
       "0        1.0  0.199497\n",
       "1        2.0  0.199497\n",
       "2        3.0  0.199497\n",
       "3        4.0  0.199329\n",
       "4        5.0  0.171477\n",
       "5        6.0  0.150671\n",
       "6        7.0  0.133557\n",
       "7        8.0  0.122819\n",
       "8        9.0  0.122651\n",
       "9       10.0  0.122315\n",
       "10      11.0  0.122148\n",
       "11      12.0  0.121980\n",
       "12      13.0  0.121644\n",
       "13      14.0  0.121477\n",
       "14      15.0  0.120973\n",
       "15      16.0  0.120638\n",
       "16      17.0  0.120805\n",
       "17      18.0  0.120805\n",
       "18      19.0  0.120470\n",
       "19      20.0  0.120470\n",
       "20      21.0  0.120302\n",
       "21      22.0  0.120302\n",
       "22      23.0  0.119966\n",
       "23      24.0  0.119799\n",
       "24      25.0  0.119799\n",
       "25      26.0  0.119631\n",
       "26      27.0  0.119295\n",
       "27      28.0  0.119295\n",
       "28      29.0  0.119128\n",
       "29      30.0  0.118960\n",
       "30      31.0  0.118960\n",
       "31      32.0  0.118960\n",
       "32      33.0  0.118792\n",
       "33      34.0  0.118792\n",
       "34      35.0  0.118624\n",
       "35      36.0  0.118624\n",
       "36      37.0  0.118456,                          Descr                             Value\n",
       "0  Number of Observations Read                              5960\n",
       "1  Number of Observations Used                              5960\n",
       "2  Misclassification Error (%)                      11.845637584,     TreeID  Trees  NLeaves       MCR   LogLoss       ASE      RASE     MAXAE\n",
       "0      0.0    1.0     34.0  0.199497  0.458062  0.145324  0.381213  0.819707\n",
       "1      1.0    2.0     77.0  0.199497  0.428302  0.134097  0.366193  0.837039\n",
       "2      2.0    3.0    117.0  0.199497  0.405943  0.125369  0.354075  0.846872\n",
       "3      3.0    4.0    166.0  0.199329  0.387308  0.118036  0.343564  0.858878\n",
       "4      4.0    5.0    211.0  0.171477  0.372489  0.112284  0.335088  0.872428\n",
       "5      5.0    6.0    260.0  0.150671  0.360248  0.107613  0.328044  0.882384\n",
       "6      6.0    7.0    300.0  0.133557  0.350278  0.103854  0.322264  0.891237\n",
       "7      7.0    8.0    348.0  0.122819  0.341928  0.100908  0.317660  0.899596\n",
       "8      8.0    9.0    396.0  0.122651  0.334594  0.098382  0.313658  0.907467\n",
       "9      9.0   10.0    443.0  0.122315  0.328321  0.096282  0.310294  0.916313\n",
       "10    10.0   11.0    481.0  0.122148  0.323144  0.094602  0.307574  0.921580\n",
       "11    11.0   12.0    530.0  0.121980  0.318625  0.093240  0.305352  0.929089\n",
       "12    12.0   13.0    573.0  0.121644  0.314815  0.092159  0.303577  0.931408\n",
       "13    13.0   14.0    616.0  0.121477  0.311302  0.091184  0.301967  0.937955\n",
       "14    14.0   15.0    659.0  0.120973  0.307892  0.090244  0.300406  0.942256\n",
       "15    15.0   16.0    706.0  0.120638  0.305183  0.089545  0.299241  0.946963\n",
       "16    16.0   17.0    747.0  0.120805  0.302956  0.088980  0.298296  0.952085\n",
       "17    17.0   18.0    794.0  0.120805  0.301044  0.088502  0.297493  0.953885\n",
       "18    18.0   19.0    841.0  0.120470  0.299184  0.088080  0.296783  0.956635\n",
       "19    19.0   20.0    882.0  0.120302  0.297550  0.087684  0.296115  0.958109\n",
       "20    20.0   21.0    925.0  0.120302  0.296313  0.087438  0.295699  0.960262\n",
       "21    21.0   22.0    967.0  0.120302  0.295120  0.087197  0.295292  0.961652\n",
       "22    22.0   23.0   1015.0  0.119966  0.293888  0.086912  0.294808  0.962634\n",
       "23    23.0   24.0   1060.0  0.119799  0.292774  0.086669  0.294395  0.963763\n",
       "24    24.0   25.0   1105.0  0.119799  0.291821  0.086470  0.294058  0.966357\n",
       "25    25.0   26.0   1148.0  0.119631  0.290800  0.086251  0.293686  0.966103\n",
       "26    26.0   27.0   1185.0  0.119295  0.290096  0.086056  0.293353  0.966959\n",
       "27    27.0   28.0   1227.0  0.119295  0.289363  0.085925  0.293130  0.967952\n",
       "28    28.0   29.0   1271.0  0.119128  0.288501  0.085716  0.292773  0.968597\n",
       "29    29.0   30.0   1305.0  0.118960  0.288133  0.085657  0.292673  0.971593\n",
       "30    30.0   31.0   1336.0  0.118960  0.287502  0.085548  0.292486  0.972649\n",
       "31    31.0   32.0   1384.0  0.118960  0.286716  0.085372  0.292184  0.975305\n",
       "32    32.0   33.0   1423.0  0.118792  0.286178  0.085270  0.292011  0.973893\n",
       "33    33.0   34.0   1470.0  0.118792  0.285672  0.085197  0.291886  0.975078\n",
       "34    34.0   35.0   1514.0  0.118624  0.285183  0.085085  0.291693  0.974935\n",
       "35    35.0   36.0   1555.0  0.118624  0.284793  0.085021  0.291583  0.977051\n",
       "36    36.0   37.0   1601.0  0.118456  0.284300  0.084931  0.291429  0.977485,         LEVNAME  LEVINDEX VARNAME\n",
       "0             1         0  P_BAD1\n",
       "1             0         1  P_BAD0,   LEVNAME  LEVINDEX VARNAME\n",
       "0                 0   I_BAD, ROC Information for _AUTOTUNE_DEFAULT_SCORE_TABLE_\n",
       "\n",
       "   Variable Event  CutOff      TP      FP      FN      TN  Sensitivity  \\\n",
       "0    P_BAD0     0    0.00  4771.0  1189.0     0.0     0.0     1.000000   \n",
       "1    P_BAD0     0    0.01  4771.0  1189.0     0.0     0.0     1.000000   \n",
       "2    P_BAD0     0    0.02  4771.0  1188.0     0.0     1.0     1.000000   \n",
       "3    P_BAD0     0    0.03  4771.0  1158.0     0.0    31.0     1.000000   \n",
       "4    P_BAD0     0    0.04  4771.0  1111.0     0.0    78.0     1.000000   \n",
       "..      ...   ...     ...     ...     ...     ...     ...          ...   \n",
       "95   P_BAD0     0    0.95  2029.0    40.0  2742.0  1149.0     0.425278   \n",
       "96   P_BAD0     0    0.96  1664.0    28.0  3107.0  1161.0     0.348774   \n",
       "97   P_BAD0     0    0.97   817.0     8.0  3954.0  1181.0     0.171243   \n",
       "98   P_BAD0     0    0.98   130.0     0.0  4641.0  1189.0     0.027248   \n",
       "99   P_BAD0     0    0.99     5.0     0.0  4766.0  1189.0     0.001048   \n",
       "\n",
       "    Specificity   KS       FPR       ACC       FDR        F1         C  \\\n",
       "0      0.000000  0.0  1.000000  0.800503  0.199497  0.889200  0.904484   \n",
       "1      0.000000  0.0  1.000000  0.800503  0.199497  0.889200  0.904484   \n",
       "2      0.000841  0.0  0.999159  0.800671  0.199362  0.889282  0.904484   \n",
       "3      0.026072  0.0  0.973928  0.805705  0.195311  0.891776  0.904484   \n",
       "4      0.065601  0.0  0.934399  0.813591  0.188881  0.895710  0.904484   \n",
       "..          ...  ...       ...       ...       ...       ...       ...   \n",
       "95     0.966358  0.0  0.033642  0.533221  0.019333  0.593275  0.904484   \n",
       "96     0.976451  0.0  0.023549  0.473993  0.016548  0.514931  0.904484   \n",
       "97     0.993272  0.0  0.006728  0.335235  0.009697  0.291994  0.904484   \n",
       "98     1.000000  0.0  0.000000  0.221309  0.000000  0.053050  0.904484   \n",
       "99     1.000000  0.0  0.000000  0.200336  0.000000  0.002094  0.904484   \n",
       "\n",
       "        Gini     Gamma       Tau  MISCEVENT       FNR  \n",
       "0   0.808969  0.836393  0.258424   0.199497  0.000000  \n",
       "1   0.808969  0.836393  0.258424   0.199497  0.000000  \n",
       "2   0.808969  0.836393  0.258424   0.199329  0.000000  \n",
       "3   0.808969  0.836393  0.258424   0.194295  0.000000  \n",
       "4   0.808969  0.836393  0.258424   0.186409  0.000000  \n",
       "..       ...       ...       ...        ...       ...  \n",
       "95  0.808969  0.836393  0.258424   0.466779  0.574722  \n",
       "96  0.808969  0.836393  0.258424   0.526007  0.651226  \n",
       "97  0.808969  0.836393  0.258424   0.664765  0.828757  \n",
       "98  0.808969  0.836393  0.258424   0.778691  0.972752  \n",
       "99  0.808969  0.836393  0.258424   0.799664  0.998952  \n",
       "\n",
       "[100 rows x 22 columns], Fit Statistics for _AUTOTUNE_DEFAULT_SCORE_TABLE_\n",
       "\n",
       "     NOBS       ASE     DIV      RASE       MCE    MCLL\n",
       "0  5960.0  0.084931  5960.0  0.291429  0.118456  0.2843, Tuner Information\n",
       "\n",
       "                           Parameter                   Value\n",
       "0                         Model Type  Gradient Boosting Tree\n",
       "1           Tuner Objective Function       Misclassification\n",
       "2                      Search Method                    GRID\n",
       "3              Number of Grid Points                      16\n",
       "4     Maximum Tuning Time in Seconds                   36000\n",
       "5                    Validation Type        Cross-Validation\n",
       "6      Num Folds in Cross-Validation                       5\n",
       "7                          Log Level                       0\n",
       "8                               Seed              1876924475\n",
       "9     Number of Parallel Evaluations                       4\n",
       "10  Number of Workers per Subsession                       0, Tuner Results\n",
       "\n",
       "    Evaluation  M  LEARNINGRATE  SUBSAMPLERATE  LASSO  RIDGE  NBINS  MAXLEVEL  \\\n",
       "0            0  6          0.10            0.5    0.0    1.0     50         5   \n",
       "1           15  6          0.10            0.6    0.0    0.0     77         7   \n",
       "2            2  6          0.10            0.8    0.0    0.0     77         7   \n",
       "3            8  6          0.10            0.6    0.0    0.0     77         5   \n",
       "4            3  6          0.10            0.8    0.5    0.0     77         7   \n",
       "5            7  6          0.10            0.8    0.0    0.0     77         5   \n",
       "6            6  6          0.10            0.6    0.5    0.0     77         5   \n",
       "7            1  6          0.10            0.6    0.5    0.0     77         7   \n",
       "8           12  6          0.10            0.8    0.5    0.0     77         5   \n",
       "9            5  6          0.05            0.8    0.0    0.0     77         5   \n",
       "10           9  6          0.05            0.8    0.0    0.0     77         7   \n",
       "\n",
       "    MeanConseqError  EvaluationTime  \n",
       "0          0.199497        0.695014  \n",
       "1          0.118456        4.524489  \n",
       "2          0.123280       10.743994  \n",
       "3          0.123826        8.513625  \n",
       "4          0.123951        8.821270  \n",
       "5          0.124979        8.407472  \n",
       "6          0.125461        9.598000  \n",
       "7          0.126029        7.335360  \n",
       "8          0.127203        6.906760  \n",
       "9          0.199329        4.799554  \n",
       "10         0.199385        4.075705  , Tuner Iteration History\n",
       "\n",
       "   Iteration  Evaluations  Best_obj   Time_sec\n",
       "0          0            1  0.199497   0.695014\n",
       "1          1           17  0.118456  25.460558, Tuner Evaluation History\n",
       "\n",
       "    Evaluation  Iteration  M  LEARNINGRATE  SUBSAMPLERATE  LASSO  RIDGE  \\\n",
       "0            0          0  6          0.10            0.5    0.0    1.0   \n",
       "1            1          1  6          0.10            0.6    0.5    0.0   \n",
       "2            2          1  6          0.10            0.8    0.0    0.0   \n",
       "3            3          1  6          0.10            0.8    0.5    0.0   \n",
       "4            4          1  6          0.05            0.8    0.5    0.0   \n",
       "5            5          1  6          0.05            0.8    0.0    0.0   \n",
       "6            6          1  6          0.10            0.6    0.5    0.0   \n",
       "7            7          1  6          0.10            0.8    0.0    0.0   \n",
       "8            8          1  6          0.10            0.6    0.0    0.0   \n",
       "9            9          1  6          0.05            0.8    0.0    0.0   \n",
       "10          10          1  6          0.05            0.6    0.5    0.0   \n",
       "11          11          1  6          0.05            0.6    0.0    0.0   \n",
       "12          12          1  6          0.10            0.8    0.5    0.0   \n",
       "13          13          1  6          0.05            0.6    0.5    0.0   \n",
       "14          14          1  6          0.05            0.8    0.5    0.0   \n",
       "15          15          1  6          0.10            0.6    0.0    0.0   \n",
       "16          16          1  6          0.05            0.6    0.0    0.0   \n",
       "\n",
       "    NBINS  MAXLEVEL  MeanConseqError  EvaluationTime  \n",
       "0      50         5         0.199497        0.695014  \n",
       "1      77         7         0.126029        7.335360  \n",
       "2      77         7         0.123280       10.743994  \n",
       "3      77         7         0.123951        8.821270  \n",
       "4      77         7         0.199631        5.731433  \n",
       "5      77         5         0.199329        4.799554  \n",
       "6      77         5         0.125461        9.598000  \n",
       "7      77         5         0.124979        8.407472  \n",
       "8      77         5         0.123826        8.513625  \n",
       "9      77         7         0.199385        4.075705  \n",
       "10     77         5         0.199664        2.796085  \n",
       "11     77         7         0.199385        3.307633  \n",
       "12     77         5         0.127203        6.906760  \n",
       "13     77         7         0.199385        3.703292  \n",
       "14     77         5         0.199497        2.782104  \n",
       "15     77         7         0.118456        4.524489  \n",
       "16     77         5         0.199385        2.403660  , Best Configuration\n",
       "\n",
       "                    Parameter           Name         Value\n",
       "0                  Evaluation     Evaluation            15\n",
       "1  Number of Variables to Try              M             6\n",
       "2               Learning Rate   LEARNINGRATE           0.1\n",
       "3               Sampling Rate  SUBSAMPLERATE           0.6\n",
       "4                       Lasso          LASSO             0\n",
       "5                       Ridge          RIDGE             0\n",
       "6              Number of Bins          NBINS            77\n",
       "7         Maximum Tree Levels       MAXLEVEL             7\n",
       "8           Misclassification      Objective  0.1184563758, Tuner Summary\n",
       "\n",
       "                                          Parameter      Value\n",
       "0             Initial Configuration Objective Value   0.199497\n",
       "1                Best Configuration Objective Value   0.118456\n",
       "2               Worst Configuration Objective Value   0.199664\n",
       "3  Initial Configuration Evaluation Time in Seconds   0.695014\n",
       "4     Best Configuration Evaluation Time in Seconds   4.524478\n",
       "5                 Number of Improved Configurations   4.000000\n",
       "6                Number of Evaluated Configurations  17.000000\n",
       "7                      Total Tuning Time in Seconds  26.164469\n",
       "8                           Parallel Tuning Speedup   3.628316, Tuner Task Timing\n",
       "\n",
       "                          Task   Time_sec  Time_percent\n",
       "0               Model Training  88.568628     93.295974\n",
       "1                Model Scoring   5.184516      5.461239\n",
       "2  Total Objective Evaluations  93.765150     98.769860\n",
       "3                        Tuner   1.167808      1.230140\n",
       "4               Total CPU Time  94.932958    100.000000, Hyperparameter Importance\n",
       "\n",
       "  Hyperparameter  RelImportance\n",
       "0   LEARNINGRATE       1.000000\n",
       "1       MAXLEVEL       0.006388\n",
       "2  SUBSAMPLERATE       0.002765\n",
       "3          LASSO       0.001600\n",
       "4              M       0.000000\n",
       "5          RIDGE       0.000000\n",
       "6          NBINS       0.000000, TuneAll Results Summary\n",
       "\n",
       "          ModelID               ModelType  Evaluations  BestObjective  \\\n",
       "0  1_DecisionTree           Decision Tree            6       0.116296   \n",
       "1     2_GradBoost  Gradient Boosting Tree           16       0.118456   \n",
       "\n",
       "   AverageObjective  StdDevObjective  BestObjTime  AverageTime  StdDevTime  \n",
       "0          0.131157         0.018933     1.072245     0.975980    0.383353  \n",
       "1          0.170000         0.053381     4.524489     5.964151    2.731222  , TuneAll Best Models\n",
       "\n",
       "          ModelID  Evaluation  MeanConseqError  EvaluationTime\n",
       "0  1_DecisionTree           6         0.116296        1.072245\n",
       "1  1_DecisionTree           2         0.117282        1.595850\n",
       "2     2_GradBoost          15         0.118456        4.524489\n",
       "3  1_DecisionTree           5         0.122506        0.941197\n",
       "4     2_GradBoost           2         0.123280       10.743994\n",
       "5     2_GradBoost           8         0.123826        8.513625\n",
       "6     2_GradBoost           3         0.123951        8.821270\n",
       "7  1_DecisionTree           1         0.124835        0.552839\n",
       "8     2_GradBoost           7         0.124979        8.407472\n",
       "9     2_GradBoost           6         0.125461        9.598000, TuneAll CAS Output Tables\n",
       "\n",
       "Empty SASDataFrame\n",
       "Columns: [ModelID, CAS_Library, Name, Rows, Columns]\n",
       "Index: [], Decision Tree for __TEMP_FEATURE_MACHINE_CASOUT___AUTOTUNE_DATA_11FA4B25-9848-604F-9F45-7E73830B6354\n",
       "\n",
       "                           Descr        Value\n",
       "0           Number of Tree Nodes   135.000000\n",
       "1         Max Number of Branches     2.000000\n",
       "2               Number of Levels    10.000000\n",
       "3               Number of Leaves    68.000000\n",
       "4                 Number of Bins   100.000000\n",
       "5         Minimum Size of Leaves     5.000000\n",
       "6         Maximum Size of Leaves  1178.000000\n",
       "7            Number of Variables     4.000000\n",
       "8   Confidence Level for Pruning     0.250000\n",
       "9    Number of Observations Used  5960.000000\n",
       "10   Misclassification Error (%)    14.395973,                          Descr                             Value\n",
       "0  Number of Observations Read                              5960\n",
       "1  Number of Observations Used                              5960\n",
       "2  Misclassification Error (%)                      14.395973154,         LEVNAME  LEVINDEX VARNAME\n",
       "0             1         0  P_BAD1\n",
       "1             0         1  P_BAD0,   LEVNAME  LEVINDEX VARNAME\n",
       "0                 0   I_BAD, ROC Information for _AUTOTUNE_DEFAULT_SCORE_TABLE_\n",
       "\n",
       "   Variable Event  CutOff      TP      FP      FN      TN  Sensitivity  \\\n",
       "0    P_BAD0     0    0.00  4771.0  1189.0     0.0     0.0     1.000000   \n",
       "1    P_BAD0     0    0.01  4771.0  1094.0     0.0    95.0     1.000000   \n",
       "2    P_BAD0     0    0.02  4771.0  1094.0     0.0    95.0     1.000000   \n",
       "3    P_BAD0     0    0.03  4771.0  1094.0     0.0    95.0     1.000000   \n",
       "4    P_BAD0     0    0.04  4771.0  1094.0     0.0    95.0     1.000000   \n",
       "..      ...   ...     ...     ...     ...     ...     ...          ...   \n",
       "95   P_BAD0     0    0.95  2946.0   121.0  1825.0  1068.0     0.617481   \n",
       "96   P_BAD0     0    0.96   579.0    12.0  4192.0  1177.0     0.121358   \n",
       "97   P_BAD0     0    0.97   579.0    12.0  4192.0  1177.0     0.121358   \n",
       "98   P_BAD0     0    0.98   269.0     3.0  4502.0  1186.0     0.056382   \n",
       "99   P_BAD0     0    0.99   110.0     0.0  4661.0  1189.0     0.023056   \n",
       "\n",
       "    Specificity   KS       FPR       ACC       FDR        F1         C  \\\n",
       "0      0.000000  0.0  1.000000  0.800503  0.199497  0.889200  0.851587   \n",
       "1      0.079899  0.0  0.920101  0.816443  0.186530  0.897142  0.851587   \n",
       "2      0.079899  0.0  0.920101  0.816443  0.186530  0.897142  0.851587   \n",
       "3      0.079899  0.0  0.920101  0.816443  0.186530  0.897142  0.851587   \n",
       "4      0.079899  0.0  0.920101  0.816443  0.186530  0.897142  0.851587   \n",
       "..          ...  ...       ...       ...       ...       ...       ...   \n",
       "95     0.898234  0.0  0.101766  0.673490  0.039452  0.751722  0.851587   \n",
       "96     0.989907  0.0  0.010093  0.294631  0.020305  0.215964  0.851587   \n",
       "97     0.989907  0.0  0.010093  0.294631  0.020305  0.215964  0.851587   \n",
       "98     0.997477  0.0  0.002523  0.244128  0.011029  0.106683  0.851587   \n",
       "99     1.000000  0.0  0.000000  0.217953  0.000000  0.045073  0.851587   \n",
       "\n",
       "        Gini     Gamma       Tau  MISCEVENT       FNR  \n",
       "0   0.703174  0.769122  0.224628   0.199497  0.000000  \n",
       "1   0.703174  0.769122  0.224628   0.183557  0.000000  \n",
       "2   0.703174  0.769122  0.224628   0.183557  0.000000  \n",
       "3   0.703174  0.769122  0.224628   0.183557  0.000000  \n",
       "4   0.703174  0.769122  0.224628   0.183557  0.000000  \n",
       "..       ...       ...       ...        ...       ...  \n",
       "95  0.703174  0.769122  0.224628   0.326510  0.382519  \n",
       "96  0.703174  0.769122  0.224628   0.705369  0.878642  \n",
       "97  0.703174  0.769122  0.224628   0.705369  0.878642  \n",
       "98  0.703174  0.769122  0.224628   0.755872  0.943618  \n",
       "99  0.703174  0.769122  0.224628   0.782047  0.976944  \n",
       "\n",
       "[100 rows x 22 columns], Fit Statistics for _AUTOTUNE_DEFAULT_SCORE_TABLE_\n",
       "\n",
       "     NOBS       ASE     DIV     RASE      MCE      MCLL\n",
       "0  5960.0  0.106041  5960.0  0.32564  0.14396  0.342706, Tuner Information\n",
       "\n",
       "                           Parameter              Value\n",
       "0                         Model Type      Decision Tree\n",
       "1           Tuner Objective Function  Misclassification\n",
       "2                      Search Method               GRID\n",
       "3              Number of Grid Points                  6\n",
       "4     Maximum Tuning Time in Seconds              36000\n",
       "5                    Validation Type   Cross-Validation\n",
       "6      Num Folds in Cross-Validation                  5\n",
       "7                          Log Level                  0\n",
       "8                               Seed         1876921820\n",
       "9     Number of Parallel Evaluations                  4\n",
       "10  Number of Workers per Subsession                  0, Tuner Results\n",
       "\n",
       "   Evaluation  MAXLEVEL  NBINS       CRIT  MeanConseqError  EvaluationTime\n",
       "0           0        11     20  gainRatio         0.150505        0.396938\n",
       "1           3        15    100       gain         0.144102        1.393360\n",
       "2           2        10    100       gain         0.144297        0.987102\n",
       "3           6        10    100  gainRatio         0.148155        0.845976\n",
       "4           4         5    100       gain         0.151704        0.532106\n",
       "5           1        15    100  gainRatio         0.152519        0.532106\n",
       "6           5         5    100  gainRatio         0.154530        0.757470, Tuner Iteration History\n",
       "\n",
       "   Iteration  Evaluations  Best_obj  Time_sec\n",
       "0          0            1  0.150505  0.396938\n",
       "1          1            7  0.144102  1.789386, Tuner Evaluation History\n",
       "\n",
       "   Evaluation  Iteration  MAXLEVEL  NBINS       CRIT  MeanConseqError  \\\n",
       "0           0          0        11     20  gainRatio         0.150505   \n",
       "1           1          1        15    100  gainRatio         0.152519   \n",
       "2           2          1        10    100       gain         0.144297   \n",
       "3           3          1        15    100       gain         0.144102   \n",
       "4           4          1         5    100       gain         0.151704   \n",
       "5           5          1         5    100  gainRatio         0.154530   \n",
       "6           6          1        10    100  gainRatio         0.148155   \n",
       "\n",
       "   EvaluationTime  \n",
       "0        0.396938  \n",
       "1        0.532106  \n",
       "2        0.987102  \n",
       "3        1.393360  \n",
       "4        0.532106  \n",
       "5        0.757470  \n",
       "6        0.845976  , Best Configuration\n",
       "\n",
       "             Parameter        Name         Value\n",
       "0           Evaluation  Evaluation             3\n",
       "1  Maximum Tree Levels    MAXLEVEL            15\n",
       "2         Maximum Bins       NBINS           100\n",
       "3            Criterion        CRIT          gain\n",
       "4    Misclassification   Objective  0.1441016388, Tuner Summary\n",
       "\n",
       "                                          Parameter     Value\n",
       "0             Initial Configuration Objective Value  0.150505\n",
       "1                Best Configuration Objective Value  0.144102\n",
       "2               Worst Configuration Objective Value  0.154530\n",
       "3  Initial Configuration Evaluation Time in Seconds  0.396938\n",
       "4     Best Configuration Evaluation Time in Seconds  0.861276\n",
       "5                 Number of Improved Configurations  2.000000\n",
       "6                Number of Evaluated Configurations  7.000000\n",
       "7                      Total Tuning Time in Seconds  1.859142\n",
       "8                           Parallel Tuning Speedup  2.459482, Tuner Task Timing\n",
       "\n",
       "                          Task  Time_sec  Time_percent\n",
       "0               Model Training  3.286560     71.876262\n",
       "1                Model Scoring  0.727036     15.900099\n",
       "2  Total Objective Evaluations  4.019285     87.900770\n",
       "3                        Tuner  0.553240     12.099230\n",
       "4               Total CPU Time  4.572525    100.000000, Hyperparameter Importance\n",
       "\n",
       "  Hyperparameter  RelImportance\n",
       "0       MAXLEVEL       1.000000\n",
       "1           CRIT       0.977507\n",
       "2          NBINS       0.000000, Gradient Boosting Tree for __TEMP_FEATURE_MACHINE_CASOUT___AUTOTUNE_DATA_11FA4B25-9848-604F-9F45-7E73830B6354\n",
       "\n",
       "                                  Descr         Value\n",
       "0                       Number of Trees  1.500000e+02\n",
       "1                          Distribution  2.000000e+00\n",
       "2                         Learning Rate  1.000000e-01\n",
       "3                      Subsampling Rate  6.000000e-01\n",
       "4      Number of Selected Variables (M)  4.000000e+00\n",
       "5                        Number of Bins  7.700000e+01\n",
       "6                   Number of Variables  4.000000e+00\n",
       "7              Max Number of Tree Nodes  5.900000e+01\n",
       "8              Min Number of Tree Nodes  3.700000e+01\n",
       "9                Max Number of Branches  2.000000e+00\n",
       "10               Min Number of Branches  2.000000e+00\n",
       "11                 Max Number of Levels  7.000000e+00\n",
       "12                 Min Number of Levels  7.000000e+00\n",
       "13                 Max Number of Leaves  3.000000e+01\n",
       "14                 Min Number of Leaves  1.900000e+01\n",
       "15               Maximum Size of Leaves  1.901000e+03\n",
       "16               Minimum Size of Leaves  5.000000e+00\n",
       "17                   Random Number Seed  1.876922e+09\n",
       "18                   Lasso (L1) penalty  5.000000e-01\n",
       "19                   Ridge (L2) penalty  0.000000e+00\n",
       "20               Actual Number of Trees  2.000000e+01\n",
       "21             Average number of Leaves  2.395000e+01\n",
       "22            Early stopping stagnation  4.000000e+00\n",
       "23             Early stopping threshold  0.000000e+00\n",
       "24  Early stopping threshold iterations  0.000000e+00\n",
       "25             Early stopping tolerance  0.000000e+00,     Progress    Metric\n",
       "0        1.0  0.199497\n",
       "1        2.0  0.199497\n",
       "2        3.0  0.199497\n",
       "3        4.0  0.199497\n",
       "4        5.0  0.185235\n",
       "5        6.0  0.170134\n",
       "6        7.0  0.168624\n",
       "7        8.0  0.162081\n",
       "8        9.0  0.161745\n",
       "9       10.0  0.157886\n",
       "10      11.0  0.150000\n",
       "11      12.0  0.149664\n",
       "12      13.0  0.149329\n",
       "13      14.0  0.143960\n",
       "14      15.0  0.143960\n",
       "15      16.0  0.143960\n",
       "16      17.0  0.143960\n",
       "17      18.0  0.143289\n",
       "18      19.0  0.143121\n",
       "19      20.0  0.142785,                          Descr                             Value\n",
       "0  Number of Observations Read                              5960\n",
       "1  Number of Observations Used                              5960\n",
       "2  Misclassification Error (%)                       14.27852349,     TreeID  Trees  NLeaves       MCR   LogLoss       ASE      RASE     MAXAE\n",
       "0      0.0    1.0     24.0  0.199497  0.468589  0.149078  0.386106  0.815742\n",
       "1      1.0    2.0     44.0  0.199497  0.446474  0.140894  0.375359  0.829874\n",
       "2      2.0    3.0     65.0  0.199497  0.429755  0.134538  0.366794  0.841710\n",
       "3      3.0    4.0     88.0  0.199497  0.415759  0.129184  0.359421  0.853080\n",
       "4      4.0    5.0    108.0  0.185235  0.404737  0.124989  0.353537  0.863127\n",
       "5      5.0    6.0    131.0  0.170134  0.395801  0.121642  0.348772  0.872147\n",
       "6      6.0    7.0    156.0  0.168624  0.388213  0.118908  0.344831  0.881248\n",
       "7      7.0    8.0    183.0  0.162081  0.381663  0.116620  0.341497  0.889103\n",
       "8      8.0    9.0    213.0  0.161745  0.376465  0.114837  0.338876  0.895443\n",
       "9      9.0   10.0    243.0  0.157886  0.371781  0.113278  0.336567  0.901697\n",
       "10    10.0   11.0    271.0  0.150000  0.367904  0.112022  0.334696  0.907537\n",
       "11    11.0   12.0    293.0  0.149664  0.364666  0.110993  0.333156  0.912122\n",
       "12    12.0   13.0    313.0  0.149329  0.361915  0.110179  0.331932  0.916695\n",
       "13    13.0   14.0    336.0  0.143960  0.359329  0.109451  0.330834  0.921120\n",
       "14    14.0   15.0    359.0  0.143960  0.357242  0.108884  0.329975  0.924959\n",
       "15    15.0   16.0    384.0  0.143960  0.355362  0.108385  0.329219  0.928939\n",
       "16    16.0   17.0    403.0  0.143960  0.353784  0.107992  0.328622  0.933832\n",
       "17    17.0   18.0    426.0  0.143289  0.352327  0.107592  0.328013  0.938289\n",
       "18    18.0   19.0    452.0  0.143121  0.351152  0.107287  0.327547  0.940495\n",
       "19    19.0   20.0    479.0  0.142785  0.350075  0.107058  0.327197  0.945084,         LEVNAME  LEVINDEX VARNAME\n",
       "0             1         0  P_BAD1\n",
       "1             0         1  P_BAD0,   LEVNAME  LEVINDEX VARNAME\n",
       "0                 0   I_BAD, ROC Information for _AUTOTUNE_DEFAULT_SCORE_TABLE_\n",
       "\n",
       "   Variable Event  CutOff      TP      FP      FN      TN  Sensitivity  \\\n",
       "0    P_BAD0     0    0.00  4771.0  1189.0     0.0     0.0     1.000000   \n",
       "1    P_BAD0     0    0.01  4771.0  1189.0     0.0     0.0     1.000000   \n",
       "2    P_BAD0     0    0.02  4771.0  1189.0     0.0     0.0     1.000000   \n",
       "3    P_BAD0     0    0.03  4771.0  1189.0     0.0     0.0     1.000000   \n",
       "4    P_BAD0     0    0.04  4771.0  1189.0     0.0     0.0     1.000000   \n",
       "..      ...   ...     ...     ...     ...     ...     ...          ...   \n",
       "95   P_BAD0     0    0.95    16.0     0.0  4755.0  1189.0     0.003354   \n",
       "96   P_BAD0     0    0.96     0.0     0.0  4771.0  1189.0     0.000000   \n",
       "97   P_BAD0     0    0.97     0.0     0.0  4771.0  1189.0     0.000000   \n",
       "98   P_BAD0     0    0.98     0.0     0.0  4771.0  1189.0     0.000000   \n",
       "99   P_BAD0     0    0.99     0.0     0.0  4771.0  1189.0     0.000000   \n",
       "\n",
       "    Specificity   KS  FPR       ACC       FDR        F1         C      Gini  \\\n",
       "0           0.0  0.0  1.0  0.800503  0.199497  0.889200  0.850296  0.700592   \n",
       "1           0.0  0.0  1.0  0.800503  0.199497  0.889200  0.850296  0.700592   \n",
       "2           0.0  0.0  1.0  0.800503  0.199497  0.889200  0.850296  0.700592   \n",
       "3           0.0  0.0  1.0  0.800503  0.199497  0.889200  0.850296  0.700592   \n",
       "4           0.0  0.0  1.0  0.800503  0.199497  0.889200  0.850296  0.700592   \n",
       "..          ...  ...  ...       ...       ...       ...       ...       ...   \n",
       "95          1.0  0.0  0.0  0.202181  0.000000  0.006685  0.850296  0.700592   \n",
       "96          1.0  0.0  0.0  0.199497       NaN  0.000000  0.850296  0.700592   \n",
       "97          1.0  0.0  0.0  0.199497       NaN  0.000000  0.850296  0.700592   \n",
       "98          1.0  0.0  0.0  0.199497       NaN  0.000000  0.850296  0.700592   \n",
       "99          1.0  0.0  0.0  0.199497       NaN  0.000000  0.850296  0.700592   \n",
       "\n",
       "       Gamma       Tau  MISCEVENT       FNR  \n",
       "0   0.771013  0.223804   0.199497  0.000000  \n",
       "1   0.771013  0.223804   0.199497  0.000000  \n",
       "2   0.771013  0.223804   0.199497  0.000000  \n",
       "3   0.771013  0.223804   0.199497  0.000000  \n",
       "4   0.771013  0.223804   0.199497  0.000000  \n",
       "..       ...       ...        ...       ...  \n",
       "95  0.771013  0.223804   0.797819  0.996646  \n",
       "96  0.771013  0.223804   0.800503  1.000000  \n",
       "97  0.771013  0.223804   0.800503  1.000000  \n",
       "98  0.771013  0.223804   0.800503  1.000000  \n",
       "99  0.771013  0.223804   0.800503  1.000000  \n",
       "\n",
       "[100 rows x 22 columns], Fit Statistics for _AUTOTUNE_DEFAULT_SCORE_TABLE_\n",
       "\n",
       "     NOBS       ASE     DIV      RASE       MCE      MCLL\n",
       "0  5960.0  0.107058  5960.0  0.327197  0.142785  0.350075, Tuner Information\n",
       "\n",
       "                           Parameter                   Value\n",
       "0                         Model Type  Gradient Boosting Tree\n",
       "1           Tuner Objective Function       Misclassification\n",
       "2                      Search Method                    GRID\n",
       "3              Number of Grid Points                      16\n",
       "4     Maximum Tuning Time in Seconds                   36000\n",
       "5                    Validation Type        Cross-Validation\n",
       "6      Num Folds in Cross-Validation                       5\n",
       "7                          Log Level                       0\n",
       "8                               Seed              1876921633\n",
       "9     Number of Parallel Evaluations                       4\n",
       "10  Number of Workers per Subsession                       0, Tuner Results\n",
       "\n",
       "    Evaluation  M  LEARNINGRATE  SUBSAMPLERATE  LASSO  RIDGE  NBINS  MAXLEVEL  \\\n",
       "0            0  4          0.10            0.5    0.0    1.0     50         5   \n",
       "1           13  4          0.10            0.6    0.5    0.0     77         7   \n",
       "2           14  4          0.10            0.6    0.0    0.0     77         5   \n",
       "3           10  4          0.10            0.6    0.5    0.0     77         5   \n",
       "4           15  4          0.10            0.8    0.0    0.0     77         5   \n",
       "5            7  4          0.10            0.6    0.0    0.0     77         7   \n",
       "6            2  4          0.10            0.8    0.0    0.0     77         7   \n",
       "7            3  4          0.10            0.8    0.5    0.0     77         5   \n",
       "8            6  4          0.10            0.8    0.5    0.0     77         7   \n",
       "9            8  4          0.05            0.8    0.0    0.0     77         7   \n",
       "10           1  4          0.05            0.6    0.0    0.0     77         5   \n",
       "\n",
       "    MeanConseqError  EvaluationTime  \n",
       "0          0.199497        0.670014  \n",
       "1          0.139405       12.511936  \n",
       "2          0.140579        9.822356  \n",
       "3          0.141972       10.613496  \n",
       "4          0.142307        9.294920  \n",
       "5          0.143817       14.823709  \n",
       "6          0.145134        8.639427  \n",
       "7          0.145353       13.533517  \n",
       "8          0.146116       13.496130  \n",
       "9          0.199362        6.389004  \n",
       "10         0.199463        1.648640  , Tuner Iteration History\n",
       "\n",
       "   Iteration  Evaluations  Best_obj   Time_sec\n",
       "0          0            1  0.199497   0.670014\n",
       "1          1           17  0.139405  35.240054, Tuner Evaluation History\n",
       "\n",
       "    Evaluation  Iteration  M  LEARNINGRATE  SUBSAMPLERATE  LASSO  RIDGE  \\\n",
       "0            0          0  4          0.10            0.5    0.0    1.0   \n",
       "1            1          1  4          0.05            0.6    0.0    0.0   \n",
       "2            2          1  4          0.10            0.8    0.0    0.0   \n",
       "3            3          1  4          0.10            0.8    0.5    0.0   \n",
       "4            4          1  4          0.05            0.6    0.5    0.0   \n",
       "5            5          1  4          0.05            0.6    0.0    0.0   \n",
       "6            6          1  4          0.10            0.8    0.5    0.0   \n",
       "7            7          1  4          0.10            0.6    0.0    0.0   \n",
       "8            8          1  4          0.05            0.8    0.0    0.0   \n",
       "9            9          1  4          0.05            0.8    0.5    0.0   \n",
       "10          10          1  4          0.10            0.6    0.5    0.0   \n",
       "11          11          1  4          0.05            0.6    0.5    0.0   \n",
       "12          12          1  4          0.05            0.8    0.0    0.0   \n",
       "13          13          1  4          0.10            0.6    0.5    0.0   \n",
       "14          14          1  4          0.10            0.6    0.0    0.0   \n",
       "15          15          1  4          0.10            0.8    0.0    0.0   \n",
       "16          16          1  4          0.05            0.8    0.5    0.0   \n",
       "\n",
       "    NBINS  MAXLEVEL  MeanConseqError  EvaluationTime  \n",
       "0      50         5         0.199497        0.670014  \n",
       "1      77         5         0.199463        1.648640  \n",
       "2      77         7         0.145134        8.639427  \n",
       "3      77         5         0.145353       13.533517  \n",
       "4      77         5         0.199530        4.638940  \n",
       "5      77         7         0.199664        5.586327  \n",
       "6      77         7         0.146116       13.496130  \n",
       "7      77         7         0.143817       14.823709  \n",
       "8      77         7         0.199362        6.389004  \n",
       "9      77         7         0.199631        6.217389  \n",
       "10     77         5         0.141972       10.613496  \n",
       "11     77         7         0.199530        6.591687  \n",
       "12     77         5         0.199497        5.000299  \n",
       "13     77         7         0.139405       12.511936  \n",
       "14     77         5         0.140579        9.822356  \n",
       "15     77         5         0.142307        9.294920  \n",
       "16     77         5         0.199497        6.482619  , Best Configuration\n",
       "\n",
       "                    Parameter           Name         Value\n",
       "0                  Evaluation     Evaluation            13\n",
       "1  Number of Variables to Try              M             4\n",
       "2               Learning Rate   LEARNINGRATE           0.1\n",
       "3               Sampling Rate  SUBSAMPLERATE           0.6\n",
       "4                       Lasso          LASSO           0.5\n",
       "5                       Ridge          RIDGE             0\n",
       "6              Number of Bins          NBINS            77\n",
       "7         Maximum Tree Levels       MAXLEVEL             7\n",
       "8           Misclassification      Objective  0.1394047773, Tuner Summary\n",
       "\n",
       "                                          Parameter      Value\n",
       "0             Initial Configuration Objective Value   0.199497\n",
       "1                Best Configuration Objective Value   0.139405\n",
       "2               Worst Configuration Objective Value   0.199664\n",
       "3  Initial Configuration Evaluation Time in Seconds   0.670014\n",
       "4     Best Configuration Evaluation Time in Seconds  12.511924\n",
       "5                 Number of Improved Configurations   6.000000\n",
       "6                Number of Evaluated Configurations  17.000000\n",
       "7                      Total Tuning Time in Seconds  35.556643\n",
       "8                           Parallel Tuning Speedup   3.811450, Tuner Task Timing\n",
       "\n",
       "                          Task    Time_sec  Time_percent\n",
       "0               Model Training  127.032699     93.735588\n",
       "1                Model Scoring    7.598382      5.606736\n",
       "2  Total Objective Evaluations  134.644803     99.352449\n",
       "3                        Tuner    0.877577      0.647551\n",
       "4               Total CPU Time  135.522379    100.000000, Hyperparameter Importance\n",
       "\n",
       "  Hyperparameter  RelImportance\n",
       "0   LEARNINGRATE       1.000000\n",
       "1          LASSO       0.003551\n",
       "2       MAXLEVEL       0.002698\n",
       "3  SUBSAMPLERATE       0.001024\n",
       "4              M       0.000000\n",
       "5          RIDGE       0.000000\n",
       "6          NBINS       0.000000, TuneAll Results Summary\n",
       "\n",
       "          ModelID               ModelType  Evaluations  BestObjective  \\\n",
       "0  1_DecisionTree           Decision Tree            6       0.144102   \n",
       "1     2_GradBoost  Gradient Boosting Tree           16       0.139405   \n",
       "\n",
       "   AverageObjective  StdDevObjective  BestObjTime  AverageTime  StdDevTime  \n",
       "0          0.149218         0.004400     1.393360     0.841353    0.323815  \n",
       "1          0.180630         0.035188    12.511936     8.508234    3.773154  , TuneAll Best Models\n",
       "\n",
       "          ModelID  Evaluation  MeanConseqError  EvaluationTime\n",
       "0     2_GradBoost          13         0.139405       12.511936\n",
       "1     2_GradBoost          14         0.140579        9.822356\n",
       "2     2_GradBoost          10         0.141972       10.613496\n",
       "3     2_GradBoost          15         0.142307        9.294920\n",
       "4     2_GradBoost           7         0.143817       14.823709\n",
       "5  1_DecisionTree           3         0.144102        1.393360\n",
       "6  1_DecisionTree           2         0.144297        0.987102\n",
       "7     2_GradBoost           2         0.145134        8.639427\n",
       "8     2_GradBoost           3         0.145353       13.533517\n",
       "9     2_GradBoost           6         0.146116       13.496130, TuneAll CAS Output Tables\n",
       "\n",
       "Empty SASDataFrame\n",
       "Columns: [ModelID, CAS_Library, Name, Rows, Columns]\n",
       "Index: [], Decision Tree for __TEMP_FEATURE_MACHINE_CASOUT___AUTOTUNE_DATA_11FA4B25-9848-604F-9F45-7E73830B6354\n",
       "\n",
       "                           Descr        Value\n",
       "0           Number of Tree Nodes     7.000000\n",
       "1         Max Number of Branches     2.000000\n",
       "2               Number of Levels     4.000000\n",
       "3               Number of Leaves     4.000000\n",
       "4                 Number of Bins    50.000000\n",
       "5         Minimum Size of Leaves   546.000000\n",
       "6         Maximum Size of Leaves  4179.000000\n",
       "7            Number of Variables     1.000000\n",
       "8   Confidence Level for Pruning     0.250000\n",
       "9    Number of Observations Used  5960.000000\n",
       "10   Misclassification Error (%)    18.674497,                          Descr                             Value\n",
       "0  Number of Observations Read                              5960\n",
       "1  Number of Observations Used                              5960\n",
       "2  Misclassification Error (%)                      18.674496644,         LEVNAME  LEVINDEX VARNAME\n",
       "0             1         0  P_BAD1\n",
       "1             0         1  P_BAD0,   LEVNAME  LEVINDEX VARNAME\n",
       "0                 0   I_BAD, ROC Information for _AUTOTUNE_DEFAULT_SCORE_TABLE_\n",
       "\n",
       "   Variable Event  CutOff      TP      FP      FN      TN  Sensitivity  \\\n",
       "0    P_BAD0     0    0.00  4771.0  1189.0     0.0     0.0          1.0   \n",
       "1    P_BAD0     0    0.01  4771.0  1189.0     0.0     0.0          1.0   \n",
       "2    P_BAD0     0    0.02  4771.0  1189.0     0.0     0.0          1.0   \n",
       "3    P_BAD0     0    0.03  4771.0  1189.0     0.0     0.0          1.0   \n",
       "4    P_BAD0     0    0.04  4771.0  1189.0     0.0     0.0          1.0   \n",
       "..      ...   ...     ...     ...     ...     ...     ...          ...   \n",
       "95   P_BAD0     0    0.95     0.0     0.0  4771.0  1189.0          0.0   \n",
       "96   P_BAD0     0    0.96     0.0     0.0  4771.0  1189.0          0.0   \n",
       "97   P_BAD0     0    0.97     0.0     0.0  4771.0  1189.0          0.0   \n",
       "98   P_BAD0     0    0.98     0.0     0.0  4771.0  1189.0          0.0   \n",
       "99   P_BAD0     0    0.99     0.0     0.0  4771.0  1189.0          0.0   \n",
       "\n",
       "    Specificity   KS  FPR       ACC       FDR      F1         C      Gini  \\\n",
       "0           0.0  0.0  1.0  0.800503  0.199497  0.8892  0.664447  0.328893   \n",
       "1           0.0  0.0  1.0  0.800503  0.199497  0.8892  0.664447  0.328893   \n",
       "2           0.0  0.0  1.0  0.800503  0.199497  0.8892  0.664447  0.328893   \n",
       "3           0.0  0.0  1.0  0.800503  0.199497  0.8892  0.664447  0.328893   \n",
       "4           0.0  0.0  1.0  0.800503  0.199497  0.8892  0.664447  0.328893   \n",
       "..          ...  ...  ...       ...       ...     ...       ...       ...   \n",
       "95          1.0  0.0  0.0  0.199497       NaN  0.0000  0.664447  0.328893   \n",
       "96          1.0  0.0  0.0  0.199497       NaN  0.0000  0.664447  0.328893   \n",
       "97          1.0  0.0  0.0  0.199497       NaN  0.0000  0.664447  0.328893   \n",
       "98          1.0  0.0  0.0  0.199497       NaN  0.0000  0.664447  0.328893   \n",
       "99          1.0  0.0  0.0  0.199497       NaN  0.0000  0.664447  0.328893   \n",
       "\n",
       "       Gamma       Tau  MISCEVENT  FNR  \n",
       "0   0.553596  0.105065   0.199497  0.0  \n",
       "1   0.553596  0.105065   0.199497  0.0  \n",
       "2   0.553596  0.105065   0.199497  0.0  \n",
       "3   0.553596  0.105065   0.199497  0.0  \n",
       "4   0.553596  0.105065   0.199497  0.0  \n",
       "..       ...       ...        ...  ...  \n",
       "95  0.553596  0.105065   0.800503  1.0  \n",
       "96  0.553596  0.105065   0.800503  1.0  \n",
       "97  0.553596  0.105065   0.800503  1.0  \n",
       "98  0.553596  0.105065   0.800503  1.0  \n",
       "99  0.553596  0.105065   0.800503  1.0  \n",
       "\n",
       "[100 rows x 22 columns], Fit Statistics for _AUTOTUNE_DEFAULT_SCORE_TABLE_\n",
       "\n",
       "     NOBS       ASE     DIV      RASE       MCE      MCLL\n",
       "0  5960.0  0.141945  5960.0  0.376756  0.186745  0.453084, Tuner Information\n",
       "\n",
       "                           Parameter              Value\n",
       "0                         Model Type      Decision Tree\n",
       "1           Tuner Objective Function  Misclassification\n",
       "2                      Search Method               GRID\n",
       "3              Number of Grid Points                  6\n",
       "4     Maximum Tuning Time in Seconds              36000\n",
       "5                    Validation Type   Cross-Validation\n",
       "6      Num Folds in Cross-Validation                  5\n",
       "7                          Log Level                  0\n",
       "8                               Seed         1876918040\n",
       "9     Number of Parallel Evaluations                  4\n",
       "10  Number of Workers per Subsession                  0, Tuner Results\n",
       "\n",
       "   Evaluation  MAXLEVEL       CRIT  MeanConseqError  EvaluationTime\n",
       "0           0        11  gainRatio         0.186747        0.307288\n",
       "1           1         5  gainRatio         0.186747        0.312266\n",
       "2           2        10       gain         0.186747        0.466998\n",
       "3           3        10  gainRatio         0.186747        0.467011\n",
       "4           4        15       gain         0.186747        0.706889\n",
       "5           5        15  gainRatio         0.186747        0.454053\n",
       "6           6         5       gain         0.186747        0.299689, Tuner Iteration History\n",
       "\n",
       "   Iteration  Evaluations  Best_obj  Time_sec\n",
       "0          0            1  0.186747  0.307288\n",
       "1          1            7  0.186747  1.073706, Tuner Evaluation History\n",
       "\n",
       "   Evaluation  Iteration  MAXLEVEL       CRIT  MeanConseqError  EvaluationTime\n",
       "0           0          0        11  gainRatio         0.186747        0.307288\n",
       "1           1          1         5  gainRatio         0.186747        0.312266\n",
       "2           2          1        10       gain         0.186747        0.466998\n",
       "3           3          1        10  gainRatio         0.186747        0.467011\n",
       "4           4          1        15       gain         0.186747        0.706889\n",
       "5           5          1        15  gainRatio         0.186747        0.454053\n",
       "6           6          1         5       gain         0.186747        0.299689, Best Configuration\n",
       "\n",
       "             Parameter        Name         Value\n",
       "0           Evaluation  Evaluation             0\n",
       "1  Maximum Tree Levels    MAXLEVEL            11\n",
       "2            Criterion        CRIT     gainRatio\n",
       "3    Misclassification   Objective  0.1867467085, Tuner Summary\n",
       "\n",
       "                                          Parameter     Value\n",
       "0             Initial Configuration Objective Value  0.186747\n",
       "1                Best Configuration Objective Value  0.186747\n",
       "2               Worst Configuration Objective Value  0.186747\n",
       "3  Initial Configuration Evaluation Time in Seconds  0.307288\n",
       "4     Best Configuration Evaluation Time in Seconds  0.307288\n",
       "5                 Number of Improved Configurations  0.000000\n",
       "6                Number of Evaluated Configurations  7.000000\n",
       "7                      Total Tuning Time in Seconds  1.115528\n",
       "8                           Parallel Tuning Speedup  1.927359, Tuner Task Timing\n",
       "\n",
       "                          Task  Time_sec  Time_percent\n",
       "0               Model Training  0.690982     32.138362\n",
       "1                Model Scoring  0.658662     30.635122\n",
       "2  Total Objective Evaluations  1.508758     70.174051\n",
       "3                        Tuner  0.641265     29.825949\n",
       "4               Total CPU Time  2.150023    100.000000, Gradient Boosting Tree for __TEMP_FEATURE_MACHINE_CASOUT___AUTOTUNE_DATA_11FA4B25-9848-604F-9F45-7E73830B6354\n",
       "\n",
       "                                  Descr         Value\n",
       "0                       Number of Trees  1.500000e+02\n",
       "1                          Distribution  2.000000e+00\n",
       "2                         Learning Rate  5.000000e-02\n",
       "3                      Subsampling Rate  6.000000e-01\n",
       "4      Number of Selected Variables (M)  1.000000e+00\n",
       "5                        Number of Bins  5.000000e+01\n",
       "6                   Number of Variables  1.000000e+00\n",
       "7              Max Number of Tree Nodes  5.000000e+00\n",
       "8              Min Number of Tree Nodes  5.000000e+00\n",
       "9                Max Number of Branches  2.000000e+00\n",
       "10               Min Number of Branches  2.000000e+00\n",
       "11                 Max Number of Levels  3.000000e+00\n",
       "12                 Min Number of Levels  3.000000e+00\n",
       "13                 Max Number of Leaves  3.000000e+00\n",
       "14                 Min Number of Leaves  3.000000e+00\n",
       "15               Maximum Size of Leaves  2.829000e+03\n",
       "16               Minimum Size of Leaves  3.380000e+02\n",
       "17                   Random Number Seed  1.876918e+09\n",
       "18                   Lasso (L1) penalty  5.000000e-01\n",
       "19                   Ridge (L2) penalty  0.000000e+00\n",
       "20               Actual Number of Trees  1.000000e+00\n",
       "21             Average number of Leaves  3.000000e+00\n",
       "22            Early stopping stagnation  4.000000e+00\n",
       "23             Early stopping threshold  0.000000e+00\n",
       "24  Early stopping threshold iterations  0.000000e+00\n",
       "25             Early stopping tolerance  0.000000e+00,    Progress    Metric\n",
       "0       1.0  0.199497,                          Descr                             Value\n",
       "0  Number of Observations Read                              5960\n",
       "1  Number of Observations Used                              5960\n",
       "2  Misclassification Error (%)                       19.94966443,    TreeID  Trees  NLeaves       MCR  LogLoss       ASE      RASE     MAXAE\n",
       "0     0.0    1.0      3.0  0.199497  0.49413  0.157872  0.397331  0.803768,         LEVNAME  LEVINDEX VARNAME\n",
       "0             1         0  P_BAD1\n",
       "1             0         1  P_BAD0,   LEVNAME  LEVINDEX VARNAME\n",
       "0                 0   I_BAD, ROC Information for _AUTOTUNE_DEFAULT_SCORE_TABLE_\n",
       "\n",
       "   Variable Event  CutOff      TP      FP      FN      TN  Sensitivity  \\\n",
       "0    P_BAD0     0    0.00  4771.0  1189.0     0.0     0.0          1.0   \n",
       "1    P_BAD0     0    0.01  4771.0  1189.0     0.0     0.0          1.0   \n",
       "2    P_BAD0     0    0.02  4771.0  1189.0     0.0     0.0          1.0   \n",
       "3    P_BAD0     0    0.03  4771.0  1189.0     0.0     0.0          1.0   \n",
       "4    P_BAD0     0    0.04  4771.0  1189.0     0.0     0.0          1.0   \n",
       "..      ...   ...     ...     ...     ...     ...     ...          ...   \n",
       "95   P_BAD0     0    0.95     0.0     0.0  4771.0  1189.0          0.0   \n",
       "96   P_BAD0     0    0.96     0.0     0.0  4771.0  1189.0          0.0   \n",
       "97   P_BAD0     0    0.97     0.0     0.0  4771.0  1189.0          0.0   \n",
       "98   P_BAD0     0    0.98     0.0     0.0  4771.0  1189.0          0.0   \n",
       "99   P_BAD0     0    0.99     0.0     0.0  4771.0  1189.0          0.0   \n",
       "\n",
       "    Specificity   KS  FPR       ACC       FDR      F1        C     Gini  \\\n",
       "0           0.0  0.0  1.0  0.800503  0.199497  0.8892  0.66148  0.32296   \n",
       "1           0.0  0.0  1.0  0.800503  0.199497  0.8892  0.66148  0.32296   \n",
       "2           0.0  0.0  1.0  0.800503  0.199497  0.8892  0.66148  0.32296   \n",
       "3           0.0  0.0  1.0  0.800503  0.199497  0.8892  0.66148  0.32296   \n",
       "4           0.0  0.0  1.0  0.800503  0.199497  0.8892  0.66148  0.32296   \n",
       "..          ...  ...  ...       ...       ...     ...      ...      ...   \n",
       "95          1.0  0.0  0.0  0.199497       NaN  0.0000  0.66148  0.32296   \n",
       "96          1.0  0.0  0.0  0.199497       NaN  0.0000  0.66148  0.32296   \n",
       "97          1.0  0.0  0.0  0.199497       NaN  0.0000  0.66148  0.32296   \n",
       "98          1.0  0.0  0.0  0.199497       NaN  0.0000  0.66148  0.32296   \n",
       "99          1.0  0.0  0.0  0.199497       NaN  0.0000  0.66148  0.32296   \n",
       "\n",
       "      Gamma       Tau  MISCEVENT  FNR  \n",
       "0   0.65163  0.103169   0.199497  0.0  \n",
       "1   0.65163  0.103169   0.199497  0.0  \n",
       "2   0.65163  0.103169   0.199497  0.0  \n",
       "3   0.65163  0.103169   0.199497  0.0  \n",
       "4   0.65163  0.103169   0.199497  0.0  \n",
       "..      ...       ...        ...  ...  \n",
       "95  0.65163  0.103169   0.800503  1.0  \n",
       "96  0.65163  0.103169   0.800503  1.0  \n",
       "97  0.65163  0.103169   0.800503  1.0  \n",
       "98  0.65163  0.103169   0.800503  1.0  \n",
       "99  0.65163  0.103169   0.800503  1.0  \n",
       "\n",
       "[100 rows x 22 columns], Fit Statistics for _AUTOTUNE_DEFAULT_SCORE_TABLE_\n",
       "\n",
       "     NOBS       ASE     DIV      RASE       MCE     MCLL\n",
       "0  5960.0  0.157872  5960.0  0.397331  0.199497  0.49413, Tuner Information\n",
       "\n",
       "                           Parameter                   Value\n",
       "0                         Model Type  Gradient Boosting Tree\n",
       "1           Tuner Objective Function       Misclassification\n",
       "2                      Search Method                    GRID\n",
       "3              Number of Grid Points                      16\n",
       "4     Maximum Tuning Time in Seconds                   36000\n",
       "5                    Validation Type        Cross-Validation\n",
       "6      Num Folds in Cross-Validation                       5\n",
       "7                          Log Level                       0\n",
       "8                               Seed              1876917928\n",
       "9     Number of Parallel Evaluations                       4\n",
       "10  Number of Workers per Subsession                       0, Tuner Results\n",
       "\n",
       "    Evaluation  M  LEARNINGRATE  SUBSAMPLERATE  LASSO  RIDGE  MAXLEVEL  \\\n",
       "0            0  1          0.10            0.5    0.0    1.0         5   \n",
       "1            7  1          0.05            0.6    0.5    0.0         7   \n",
       "2           11  1          0.10            0.6    0.5    0.0         5   \n",
       "3           12  1          0.10            0.8    0.0    0.0         7   \n",
       "4            1  1          0.10            0.8    0.5    0.0         5   \n",
       "5            2  1          0.10            0.6    0.0    0.0         7   \n",
       "6           10  1          0.05            0.6    0.5    0.0         5   \n",
       "7            9  1          0.05            0.8    0.5    0.0         5   \n",
       "8            3  1          0.05            0.8    0.5    0.0         7   \n",
       "9           15  1          0.05            0.6    0.0    0.0         5   \n",
       "10          13  1          0.05            0.6    0.0    0.0         7   \n",
       "\n",
       "    MeanConseqError  EvaluationTime  \n",
       "0          0.199497        0.585741  \n",
       "1          0.199329        1.402759  \n",
       "2          0.199362        1.312134  \n",
       "3          0.199362        1.302134  \n",
       "4          0.199463        2.065594  \n",
       "5          0.199463        0.711724  \n",
       "6          0.199463        1.398297  \n",
       "7          0.199497        1.875132  \n",
       "8          0.199497        1.575085  \n",
       "9          0.199497        0.797184  \n",
       "10         0.199530        1.007869  , Tuner Iteration History\n",
       "\n",
       "   Iteration  Evaluations  Best_obj  Time_sec\n",
       "0          0            1  0.199497  0.585741\n",
       "1          1           17  0.199329  6.279187, Tuner Evaluation History\n",
       "\n",
       "    Evaluation  Iteration  M  LEARNINGRATE  SUBSAMPLERATE  LASSO  RIDGE  \\\n",
       "0            0          0  1          0.10            0.5    0.0    1.0   \n",
       "1            1          1  1          0.10            0.8    0.5    0.0   \n",
       "2            2          1  1          0.10            0.6    0.0    0.0   \n",
       "3            3          1  1          0.05            0.8    0.5    0.0   \n",
       "4            4          1  1          0.10            0.8    0.0    0.0   \n",
       "5            5          1  1          0.05            0.8    0.0    0.0   \n",
       "6            6          1  1          0.10            0.8    0.5    0.0   \n",
       "7            7          1  1          0.05            0.6    0.5    0.0   \n",
       "8            8          1  1          0.05            0.8    0.0    0.0   \n",
       "9            9          1  1          0.05            0.8    0.5    0.0   \n",
       "10          10          1  1          0.05            0.6    0.5    0.0   \n",
       "11          11          1  1          0.10            0.6    0.5    0.0   \n",
       "12          12          1  1          0.10            0.8    0.0    0.0   \n",
       "13          13          1  1          0.05            0.6    0.0    0.0   \n",
       "14          14          1  1          0.10            0.6    0.0    0.0   \n",
       "15          15          1  1          0.05            0.6    0.0    0.0   \n",
       "16          16          1  1          0.10            0.6    0.5    0.0   \n",
       "\n",
       "    MAXLEVEL  MeanConseqError  EvaluationTime  \n",
       "0          5         0.199497        0.585741  \n",
       "1          5         0.199463        2.065594  \n",
       "2          7         0.199463        0.711724  \n",
       "3          7         0.199497        1.575085  \n",
       "4          5         0.199564        2.081283  \n",
       "5          7         0.199597        1.484827  \n",
       "6          7         0.199597        1.509942  \n",
       "7          7         0.199329        1.402759  \n",
       "8          5         0.199597        1.690688  \n",
       "9          5         0.199497        1.875132  \n",
       "10         5         0.199463        1.398297  \n",
       "11         5         0.199362        1.312134  \n",
       "12         7         0.199362        1.302134  \n",
       "13         7         0.199530        1.007869  \n",
       "14         5         0.199530        1.003341  \n",
       "15         5         0.199497        0.797184  \n",
       "16         7         0.199664        0.619296  , Best Configuration\n",
       "\n",
       "                    Parameter           Name         Value\n",
       "0                  Evaluation     Evaluation             7\n",
       "1  Number of Variables to Try              M             1\n",
       "2               Learning Rate   LEARNINGRATE          0.05\n",
       "3               Sampling Rate  SUBSAMPLERATE           0.6\n",
       "4                       Lasso          LASSO           0.5\n",
       "5                       Ridge          RIDGE             0\n",
       "6         Maximum Tree Levels       MAXLEVEL             7\n",
       "7           Misclassification      Objective  0.1993286897, Tuner Summary\n",
       "\n",
       "                                          Parameter      Value\n",
       "0             Initial Configuration Objective Value   0.199497\n",
       "1                Best Configuration Objective Value   0.199329\n",
       "2               Worst Configuration Objective Value   0.199664\n",
       "3  Initial Configuration Evaluation Time in Seconds   0.585741\n",
       "4     Best Configuration Evaluation Time in Seconds   1.402750\n",
       "5                 Number of Improved Configurations   2.000000\n",
       "6                Number of Evaluated Configurations  17.000000\n",
       "7                      Total Tuning Time in Seconds   6.379699\n",
       "8                           Parallel Tuning Speedup   3.515300, Tuner Task Timing\n",
       "\n",
       "                          Task   Time_sec  Time_percent\n",
       "0               Model Training  18.614787     83.003326\n",
       "1                Model Scoring   2.298753     10.250140\n",
       "2  Total Objective Evaluations  21.436752     95.586467\n",
       "3                        Tuner   0.989803      4.413533\n",
       "4               Total CPU Time  22.426555    100.000000, Hyperparameter Importance\n",
       "\n",
       "  Hyperparameter  RelImportance\n",
       "0  SUBSAMPLERATE       1.000000\n",
       "1          LASSO       0.603883\n",
       "2       MAXLEVEL       0.043346\n",
       "3              M       0.000000\n",
       "4   LEARNINGRATE       0.000000\n",
       "5          RIDGE       0.000000, TuneAll Results Summary\n",
       "\n",
       "          ModelID               ModelType  Evaluations  BestObjective  \\\n",
       "0  1_DecisionTree           Decision Tree            6       0.186747   \n",
       "1     2_GradBoost  Gradient Boosting Tree           16       0.199329   \n",
       "\n",
       "   AverageObjective  StdDevObjective  BestObjTime  AverageTime  StdDevTime  \n",
       "0          0.186747         0.000000     0.307288     0.451151    0.147067  \n",
       "1          0.211172         0.012055     1.402759     1.393028    0.460606  , TuneAll Best Models\n",
       "\n",
       "          ModelID  Evaluation  MeanConseqError  EvaluationTime\n",
       "0  1_DecisionTree           6         0.186747        0.299689\n",
       "1  1_DecisionTree           0         0.186747        0.307288\n",
       "2  1_DecisionTree           1         0.186747        0.312266\n",
       "3  1_DecisionTree           5         0.186747        0.454053\n",
       "4  1_DecisionTree           2         0.186747        0.466998\n",
       "5  1_DecisionTree           3         0.186747        0.467011\n",
       "6  1_DecisionTree           4         0.186747        0.706889\n",
       "7     2_GradBoost           7         0.199329        1.402759\n",
       "8     2_GradBoost          12         0.199362        1.302134\n",
       "9     2_GradBoost          11         0.199362        1.312134, TuneAll CAS Output Tables\n",
       "\n",
       "Empty SASDataFrame\n",
       "Columns: [ModelID, CAS_Library, Name, Rows, Columns]\n",
       "Index: [], Decision Tree for __TEMP_FEATURE_MACHINE_CASOUT___AUTOTUNE_DATA_11FA4B25-9848-604F-9F45-7E73830B6354\n",
       "\n",
       "                           Descr        Value\n",
       "0           Number of Tree Nodes     7.000000\n",
       "1         Max Number of Branches     2.000000\n",
       "2               Number of Levels     4.000000\n",
       "3               Number of Leaves     4.000000\n",
       "4                 Number of Bins    50.000000\n",
       "5         Minimum Size of Leaves   546.000000\n",
       "6         Maximum Size of Leaves  4179.000000\n",
       "7            Number of Variables     1.000000\n",
       "8   Confidence Level for Pruning     0.250000\n",
       "9    Number of Observations Used  5960.000000\n",
       "10   Misclassification Error (%)    18.674497,                          Descr                             Value\n",
       "0  Number of Observations Read                              5960\n",
       "1  Number of Observations Used                              5960\n",
       "2  Misclassification Error (%)                      18.674496644,         LEVNAME  LEVINDEX VARNAME\n",
       "0             1         0  P_BAD1\n",
       "1             0         1  P_BAD0,   LEVNAME  LEVINDEX VARNAME\n",
       "0                 0   I_BAD, ROC Information for _AUTOTUNE_DEFAULT_SCORE_TABLE_\n",
       "\n",
       "   Variable Event  CutOff      TP      FP      FN      TN  Sensitivity  \\\n",
       "0    P_BAD0     0    0.00  4771.0  1189.0     0.0     0.0          1.0   \n",
       "1    P_BAD0     0    0.01  4771.0  1189.0     0.0     0.0          1.0   \n",
       "2    P_BAD0     0    0.02  4771.0  1189.0     0.0     0.0          1.0   \n",
       "3    P_BAD0     0    0.03  4771.0  1189.0     0.0     0.0          1.0   \n",
       "4    P_BAD0     0    0.04  4771.0  1189.0     0.0     0.0          1.0   \n",
       "..      ...   ...     ...     ...     ...     ...     ...          ...   \n",
       "95   P_BAD0     0    0.95     0.0     0.0  4771.0  1189.0          0.0   \n",
       "96   P_BAD0     0    0.96     0.0     0.0  4771.0  1189.0          0.0   \n",
       "97   P_BAD0     0    0.97     0.0     0.0  4771.0  1189.0          0.0   \n",
       "98   P_BAD0     0    0.98     0.0     0.0  4771.0  1189.0          0.0   \n",
       "99   P_BAD0     0    0.99     0.0     0.0  4771.0  1189.0          0.0   \n",
       "\n",
       "    Specificity   KS  FPR       ACC       FDR      F1         C      Gini  \\\n",
       "0           0.0  0.0  1.0  0.800503  0.199497  0.8892  0.664447  0.328893   \n",
       "1           0.0  0.0  1.0  0.800503  0.199497  0.8892  0.664447  0.328893   \n",
       "2           0.0  0.0  1.0  0.800503  0.199497  0.8892  0.664447  0.328893   \n",
       "3           0.0  0.0  1.0  0.800503  0.199497  0.8892  0.664447  0.328893   \n",
       "4           0.0  0.0  1.0  0.800503  0.199497  0.8892  0.664447  0.328893   \n",
       "..          ...  ...  ...       ...       ...     ...       ...       ...   \n",
       "95          1.0  0.0  0.0  0.199497       NaN  0.0000  0.664447  0.328893   \n",
       "96          1.0  0.0  0.0  0.199497       NaN  0.0000  0.664447  0.328893   \n",
       "97          1.0  0.0  0.0  0.199497       NaN  0.0000  0.664447  0.328893   \n",
       "98          1.0  0.0  0.0  0.199497       NaN  0.0000  0.664447  0.328893   \n",
       "99          1.0  0.0  0.0  0.199497       NaN  0.0000  0.664447  0.328893   \n",
       "\n",
       "       Gamma       Tau  MISCEVENT  FNR  \n",
       "0   0.553596  0.105065   0.199497  0.0  \n",
       "1   0.553596  0.105065   0.199497  0.0  \n",
       "2   0.553596  0.105065   0.199497  0.0  \n",
       "3   0.553596  0.105065   0.199497  0.0  \n",
       "4   0.553596  0.105065   0.199497  0.0  \n",
       "..       ...       ...        ...  ...  \n",
       "95  0.553596  0.105065   0.800503  1.0  \n",
       "96  0.553596  0.105065   0.800503  1.0  \n",
       "97  0.553596  0.105065   0.800503  1.0  \n",
       "98  0.553596  0.105065   0.800503  1.0  \n",
       "99  0.553596  0.105065   0.800503  1.0  \n",
       "\n",
       "[100 rows x 22 columns], Fit Statistics for _AUTOTUNE_DEFAULT_SCORE_TABLE_\n",
       "\n",
       "     NOBS       ASE     DIV      RASE       MCE      MCLL\n",
       "0  5960.0  0.141945  5960.0  0.376756  0.186745  0.453084, Tuner Information\n",
       "\n",
       "                           Parameter              Value\n",
       "0                         Model Type      Decision Tree\n",
       "1           Tuner Objective Function  Misclassification\n",
       "2                      Search Method               GRID\n",
       "3              Number of Grid Points                  6\n",
       "4     Maximum Tuning Time in Seconds              36000\n",
       "5                    Validation Type   Cross-Validation\n",
       "6      Num Folds in Cross-Validation                  5\n",
       "7                          Log Level                  0\n",
       "8                               Seed         1876917257\n",
       "9     Number of Parallel Evaluations                  4\n",
       "10  Number of Workers per Subsession                  0, Tuner Results\n",
       "\n",
       "   Evaluation  MAXLEVEL       CRIT  MeanConseqError  EvaluationTime\n",
       "0           0        11  gainRatio         0.186743        0.267086\n",
       "1           1        10  gainRatio         0.186743        0.328704\n",
       "2           2        15  gainRatio         0.186743        0.496010\n",
       "3           3         5       gain         0.186743        0.495985\n",
       "4           4        10       gain         0.186743        0.686710\n",
       "5           5        15       gain         0.186743        0.345324\n",
       "6           6         5  gainRatio         0.186743        0.188794, Tuner Iteration History\n",
       "\n",
       "   Iteration  Evaluations  Best_obj  Time_sec\n",
       "0          0            1  0.186743  0.267086\n",
       "1          1            7  0.186743  0.952953, Tuner Evaluation History\n",
       "\n",
       "   Evaluation  Iteration  MAXLEVEL       CRIT  MeanConseqError  EvaluationTime\n",
       "0           0          0        11  gainRatio         0.186743        0.267086\n",
       "1           1          1        10  gainRatio         0.186743        0.328704\n",
       "2           2          1        15  gainRatio         0.186743        0.496010\n",
       "3           3          1         5       gain         0.186743        0.495985\n",
       "4           4          1        10       gain         0.186743        0.686710\n",
       "5           5          1        15       gain         0.186743        0.345324\n",
       "6           6          1         5  gainRatio         0.186743        0.188794, Best Configuration\n",
       "\n",
       "             Parameter        Name         Value\n",
       "0           Evaluation  Evaluation             0\n",
       "1  Maximum Tree Levels    MAXLEVEL            11\n",
       "2            Criterion        CRIT     gainRatio\n",
       "3    Misclassification   Objective  0.1867431912, Tuner Summary\n",
       "\n",
       "                                          Parameter     Value\n",
       "0             Initial Configuration Objective Value  0.186743\n",
       "1                Best Configuration Objective Value  0.186743\n",
       "2               Worst Configuration Objective Value  0.186743\n",
       "3  Initial Configuration Evaluation Time in Seconds  0.267086\n",
       "4     Best Configuration Evaluation Time in Seconds  0.267086\n",
       "5                 Number of Improved Configurations  0.000000\n",
       "6                Number of Evaluated Configurations  7.000000\n",
       "7                      Total Tuning Time in Seconds  0.994613\n",
       "8                           Parallel Tuning Speedup  1.967282, Tuner Task Timing\n",
       "\n",
       "                          Task  Time_sec  Time_percent\n",
       "0               Model Training  0.475226     24.287303\n",
       "1                Model Scoring  0.626626     32.024914\n",
       "2  Total Objective Evaluations  1.273642     65.091863\n",
       "3                        Tuner  0.683042     34.908137\n",
       "4               Total CPU Time  1.956684    100.000000, Gradient Boosting Tree for __TEMP_FEATURE_MACHINE_CASOUT___AUTOTUNE_DATA_11FA4B25-9848-604F-9F45-7E73830B6354\n",
       "\n",
       "                                  Descr         Value\n",
       "0                       Number of Trees  1.500000e+02\n",
       "1                          Distribution  2.000000e+00\n",
       "2                         Learning Rate  1.000000e-01\n",
       "3                      Subsampling Rate  6.000000e-01\n",
       "4      Number of Selected Variables (M)  1.000000e+00\n",
       "5                        Number of Bins  5.000000e+01\n",
       "6                   Number of Variables  1.000000e+00\n",
       "7              Max Number of Tree Nodes  7.000000e+00\n",
       "8              Min Number of Tree Nodes  7.000000e+00\n",
       "9                Max Number of Branches  2.000000e+00\n",
       "10               Min Number of Branches  2.000000e+00\n",
       "11                 Max Number of Levels  3.000000e+00\n",
       "12                 Min Number of Levels  3.000000e+00\n",
       "13                 Max Number of Leaves  4.000000e+00\n",
       "14                 Min Number of Leaves  4.000000e+00\n",
       "15               Maximum Size of Leaves  2.469000e+03\n",
       "16               Minimum Size of Leaves  3.360000e+02\n",
       "17                   Random Number Seed  1.876917e+09\n",
       "18                   Lasso (L1) penalty  5.000000e-01\n",
       "19                   Ridge (L2) penalty  0.000000e+00\n",
       "20               Actual Number of Trees  1.000000e+00\n",
       "21             Average number of Leaves  4.000000e+00\n",
       "22            Early stopping stagnation  4.000000e+00\n",
       "23             Early stopping threshold  0.000000e+00\n",
       "24  Early stopping threshold iterations  0.000000e+00\n",
       "25             Early stopping tolerance  0.000000e+00,    Progress    Metric\n",
       "0       1.0  0.199497,                          Descr                             Value\n",
       "0  Number of Observations Read                              5960\n",
       "1  Number of Observations Used                              5960\n",
       "2  Misclassification Error (%)                       19.94966443,    TreeID  Trees  NLeaves       MCR   LogLoss       ASE      RASE     MAXAE\n",
       "0     0.0    1.0      4.0  0.199497  0.488979  0.156099  0.395093  0.809417,         LEVNAME  LEVINDEX VARNAME\n",
       "0             1         0  P_BAD1\n",
       "1             0         1  P_BAD0,   LEVNAME  LEVINDEX VARNAME\n",
       "0                 0   I_BAD, ROC Information for _AUTOTUNE_DEFAULT_SCORE_TABLE_\n",
       "\n",
       "   Variable Event  CutOff      TP      FP      FN      TN  Sensitivity  \\\n",
       "0    P_BAD0     0    0.00  4771.0  1189.0     0.0     0.0          1.0   \n",
       "1    P_BAD0     0    0.01  4771.0  1189.0     0.0     0.0          1.0   \n",
       "2    P_BAD0     0    0.02  4771.0  1189.0     0.0     0.0          1.0   \n",
       "3    P_BAD0     0    0.03  4771.0  1189.0     0.0     0.0          1.0   \n",
       "4    P_BAD0     0    0.04  4771.0  1189.0     0.0     0.0          1.0   \n",
       "..      ...   ...     ...     ...     ...     ...     ...          ...   \n",
       "95   P_BAD0     0    0.95     0.0     0.0  4771.0  1189.0          0.0   \n",
       "96   P_BAD0     0    0.96     0.0     0.0  4771.0  1189.0          0.0   \n",
       "97   P_BAD0     0    0.97     0.0     0.0  4771.0  1189.0          0.0   \n",
       "98   P_BAD0     0    0.98     0.0     0.0  4771.0  1189.0          0.0   \n",
       "99   P_BAD0     0    0.99     0.0     0.0  4771.0  1189.0          0.0   \n",
       "\n",
       "    Specificity   KS  FPR       ACC       FDR      F1        C     Gini  \\\n",
       "0           0.0  0.0  1.0  0.800503  0.199497  0.8892  0.66148  0.32296   \n",
       "1           0.0  0.0  1.0  0.800503  0.199497  0.8892  0.66148  0.32296   \n",
       "2           0.0  0.0  1.0  0.800503  0.199497  0.8892  0.66148  0.32296   \n",
       "3           0.0  0.0  1.0  0.800503  0.199497  0.8892  0.66148  0.32296   \n",
       "4           0.0  0.0  1.0  0.800503  0.199497  0.8892  0.66148  0.32296   \n",
       "..          ...  ...  ...       ...       ...     ...      ...      ...   \n",
       "95          1.0  0.0  0.0  0.199497       NaN  0.0000  0.66148  0.32296   \n",
       "96          1.0  0.0  0.0  0.199497       NaN  0.0000  0.66148  0.32296   \n",
       "97          1.0  0.0  0.0  0.199497       NaN  0.0000  0.66148  0.32296   \n",
       "98          1.0  0.0  0.0  0.199497       NaN  0.0000  0.66148  0.32296   \n",
       "99          1.0  0.0  0.0  0.199497       NaN  0.0000  0.66148  0.32296   \n",
       "\n",
       "      Gamma       Tau  MISCEVENT  FNR  \n",
       "0   0.65163  0.103169   0.199497  0.0  \n",
       "1   0.65163  0.103169   0.199497  0.0  \n",
       "2   0.65163  0.103169   0.199497  0.0  \n",
       "3   0.65163  0.103169   0.199497  0.0  \n",
       "4   0.65163  0.103169   0.199497  0.0  \n",
       "..      ...       ...        ...  ...  \n",
       "95  0.65163  0.103169   0.800503  1.0  \n",
       "96  0.65163  0.103169   0.800503  1.0  \n",
       "97  0.65163  0.103169   0.800503  1.0  \n",
       "98  0.65163  0.103169   0.800503  1.0  \n",
       "99  0.65163  0.103169   0.800503  1.0  \n",
       "\n",
       "[100 rows x 22 columns], Fit Statistics for _AUTOTUNE_DEFAULT_SCORE_TABLE_\n",
       "\n",
       "     NOBS       ASE     DIV      RASE       MCE      MCLL\n",
       "0  5960.0  0.156099  5960.0  0.395093  0.199497  0.488979, Tuner Information\n",
       "\n",
       "                           Parameter                   Value\n",
       "0                         Model Type  Gradient Boosting Tree\n",
       "1           Tuner Objective Function       Misclassification\n",
       "2                      Search Method                    GRID\n",
       "3              Number of Grid Points                      16\n",
       "4     Maximum Tuning Time in Seconds                   36000\n",
       "5                    Validation Type        Cross-Validation\n",
       "6      Num Folds in Cross-Validation                       5\n",
       "7                          Log Level                       0\n",
       "8                               Seed              1876917156\n",
       "9     Number of Parallel Evaluations                       4\n",
       "10  Number of Workers per Subsession                       0, Tuner Results\n",
       "\n",
       "    Evaluation  M  LEARNINGRATE  SUBSAMPLERATE  LASSO  RIDGE  MAXLEVEL  \\\n",
       "0            0  1          0.10            0.5    0.0    1.0         5   \n",
       "1            9  1          0.10            0.6    0.5    0.0         5   \n",
       "2           14  1          0.05            0.8    0.0    0.0         7   \n",
       "3            1  1          0.10            0.8    0.5    0.0         7   \n",
       "4            8  1          0.10            0.8    0.5    0.0         5   \n",
       "5            6  1          0.05            0.6    0.0    0.0         7   \n",
       "6            7  1          0.10            0.6    0.0    0.0         5   \n",
       "7           10  1          0.10            0.8    0.0    0.0         7   \n",
       "8           12  1          0.10            0.6    0.0    0.0         7   \n",
       "9           13  1          0.05            0.6    0.0    0.0         5   \n",
       "10           3  1          0.05            0.8    0.5    0.0         5   \n",
       "\n",
       "    MeanConseqError  EvaluationTime  \n",
       "0          0.199497        0.582387  \n",
       "1          0.199261        2.387442  \n",
       "2          0.199295        1.889176  \n",
       "3          0.199329        0.513950  \n",
       "4          0.199329        2.715832  \n",
       "5          0.199362        3.104644  \n",
       "6          0.199362        2.890419  \n",
       "7          0.199396        1.612668  \n",
       "8          0.199463        1.876585  \n",
       "9          0.199463        1.723545  \n",
       "10         0.199497        2.959303  , Tuner Iteration History\n",
       "\n",
       "   Iteration  Evaluations  Best_obj  Time_sec\n",
       "0          0            1  0.199497  0.582387\n",
       "1          1           17  0.199261  8.218669, Tuner Evaluation History\n",
       "\n",
       "    Evaluation  Iteration  M  LEARNINGRATE  SUBSAMPLERATE  LASSO  RIDGE  \\\n",
       "0            0          0  1          0.10            0.5    0.0    1.0   \n",
       "1            1          1  1          0.10            0.8    0.5    0.0   \n",
       "2            2          1  1          0.05            0.6    0.5    0.0   \n",
       "3            3          1  1          0.05            0.8    0.5    0.0   \n",
       "4            4          1  1          0.05            0.8    0.5    0.0   \n",
       "5            5          1  1          0.10            0.8    0.0    0.0   \n",
       "6            6          1  1          0.05            0.6    0.0    0.0   \n",
       "7            7          1  1          0.10            0.6    0.0    0.0   \n",
       "8            8          1  1          0.10            0.8    0.5    0.0   \n",
       "9            9          1  1          0.10            0.6    0.5    0.0   \n",
       "10          10          1  1          0.10            0.8    0.0    0.0   \n",
       "11          11          1  1          0.10            0.6    0.5    0.0   \n",
       "12          12          1  1          0.10            0.6    0.0    0.0   \n",
       "13          13          1  1          0.05            0.6    0.0    0.0   \n",
       "14          14          1  1          0.05            0.8    0.0    0.0   \n",
       "15          15          1  1          0.05            0.6    0.5    0.0   \n",
       "16          16          1  1          0.05            0.8    0.0    0.0   \n",
       "\n",
       "    MAXLEVEL  MeanConseqError  EvaluationTime  \n",
       "0          5         0.199497        0.582387  \n",
       "1          7         0.199329        0.513950  \n",
       "2          7         0.199631        2.073624  \n",
       "3          5         0.199497        2.959303  \n",
       "4          7         0.199497        0.755577  \n",
       "5          5         0.199631        1.837338  \n",
       "6          7         0.199362        3.104644  \n",
       "7          5         0.199362        2.890419  \n",
       "8          5         0.199329        2.715832  \n",
       "9          5         0.199261        2.387442  \n",
       "10         7         0.199396        1.612668  \n",
       "11         7         0.199597        1.594160  \n",
       "12         7         0.199463        1.876585  \n",
       "13         5         0.199463        1.723545  \n",
       "14         7         0.199295        1.889176  \n",
       "15         5         0.199497        1.003774  \n",
       "16         5         0.199530        0.693229  , Best Configuration\n",
       "\n",
       "                    Parameter           Name         Value\n",
       "0                  Evaluation     Evaluation             9\n",
       "1  Number of Variables to Try              M             1\n",
       "2               Learning Rate   LEARNINGRATE           0.1\n",
       "3               Sampling Rate  SUBSAMPLERATE           0.6\n",
       "4                       Lasso          LASSO           0.5\n",
       "5                       Ridge          RIDGE             0\n",
       "6         Maximum Tree Levels       MAXLEVEL             5\n",
       "7           Misclassification      Objective  0.1992612378, Tuner Summary\n",
       "\n",
       "                                          Parameter      Value\n",
       "0             Initial Configuration Objective Value   0.199497\n",
       "1                Best Configuration Objective Value   0.199261\n",
       "2               Worst Configuration Objective Value   0.199631\n",
       "3  Initial Configuration Evaluation Time in Seconds   0.582387\n",
       "4     Best Configuration Evaluation Time in Seconds   2.387434\n",
       "5                 Number of Improved Configurations   2.000000\n",
       "6                Number of Evaluated Configurations  17.000000\n",
       "7                      Total Tuning Time in Seconds   8.323090\n",
       "8                           Parallel Tuning Speedup   3.558607, Tuner Task Timing\n",
       "\n",
       "                          Task   Time_sec  Time_percent\n",
       "0               Model Training  26.135432     88.239914\n",
       "1                Model Scoring   2.934760      9.908503\n",
       "2  Total Objective Evaluations  29.081164     98.185457\n",
       "3                        Tuner   0.537442      1.814543\n",
       "4               Total CPU Time  29.618606    100.000000, Hyperparameter Importance\n",
       "\n",
       "  Hyperparameter  RelImportance\n",
       "0   LEARNINGRATE       1.000000\n",
       "1  SUBSAMPLERATE       0.261105\n",
       "2          LASSO       0.059784\n",
       "3       MAXLEVEL       0.017375\n",
       "4              M       0.000000\n",
       "5          RIDGE       0.000000, TuneAll Results Summary\n",
       "\n",
       "          ModelID               ModelType  Evaluations  BestObjective  \\\n",
       "0  1_DecisionTree           Decision Tree            6       0.186743   \n",
       "1     2_GradBoost  Gradient Boosting Tree           16       0.199261   \n",
       "\n",
       "   AverageObjective  StdDevObjective  BestObjTime  AverageTime  StdDevTime  \n",
       "0          0.186743     3.040471e-17     0.267086     0.423588    0.173191  \n",
       "1          0.211118     1.205480e-02     2.387442     1.878428    0.830149  , TuneAll Best Models\n",
       "\n",
       "          ModelID  Evaluation  MeanConseqError  EvaluationTime\n",
       "0  1_DecisionTree           6         0.186743        0.188794\n",
       "1  1_DecisionTree           0         0.186743        0.267086\n",
       "2  1_DecisionTree           1         0.186743        0.328704\n",
       "3  1_DecisionTree           5         0.186743        0.345324\n",
       "4  1_DecisionTree           3         0.186743        0.495985\n",
       "5  1_DecisionTree           2         0.186743        0.496010\n",
       "6  1_DecisionTree           4         0.186743        0.686710\n",
       "7     2_GradBoost           9         0.199261        2.387442\n",
       "8     2_GradBoost          14         0.199295        1.889176\n",
       "9     2_GradBoost           1         0.199329        0.513950, TuneAll CAS Output Tables\n",
       "\n",
       "Empty SASDataFrame\n",
       "Columns: [ModelID, CAS_Library, Name, Rows, Columns]\n",
       "Index: [], Decision Tree for __TEMP_FEATURE_MACHINE_CASOUT___AUTOTUNE_DATA_11FA4B25-9848-604F-9F45-7E73830B6354\n",
       "\n",
       "                           Descr        Value\n",
       "0           Number of Tree Nodes    39.000000\n",
       "1         Max Number of Branches     2.000000\n",
       "2               Number of Levels     7.000000\n",
       "3               Number of Leaves    20.000000\n",
       "4                 Number of Bins    50.000000\n",
       "5         Minimum Size of Leaves    22.000000\n",
       "6         Maximum Size of Leaves  1300.000000\n",
       "7            Number of Variables     3.000000\n",
       "8   Confidence Level for Pruning     0.250000\n",
       "9    Number of Observations Used  5960.000000\n",
       "10   Misclassification Error (%)    15.587248,                          Descr                             Value\n",
       "0  Number of Observations Read                              5960\n",
       "1  Number of Observations Used                              5960\n",
       "2  Misclassification Error (%)                      15.587248322,         LEVNAME  LEVINDEX VARNAME\n",
       "0             1         0  P_BAD1\n",
       "1             0         1  P_BAD0,   LEVNAME  LEVINDEX VARNAME\n",
       "0                 0   I_BAD, ROC Information for _AUTOTUNE_DEFAULT_SCORE_TABLE_\n",
       "\n",
       "   Variable Event  CutOff      TP      FP      FN      TN  Sensitivity  \\\n",
       "0    P_BAD0     0    0.00  4771.0  1189.0     0.0     0.0     1.000000   \n",
       "1    P_BAD0     0    0.01  4771.0  1189.0     0.0     0.0     1.000000   \n",
       "2    P_BAD0     0    0.02  4771.0  1189.0     0.0     0.0     1.000000   \n",
       "3    P_BAD0     0    0.03  4771.0  1189.0     0.0     0.0     1.000000   \n",
       "4    P_BAD0     0    0.04  4771.0  1189.0     0.0     0.0     1.000000   \n",
       "..      ...   ...     ...     ...     ...     ...     ...          ...   \n",
       "95   P_BAD0     0    0.95  1524.0    61.0  3247.0  1128.0     0.319430   \n",
       "96   P_BAD0     0    0.96   474.0    13.0  4297.0  1176.0     0.099350   \n",
       "97   P_BAD0     0    0.97   192.0     3.0  4579.0  1186.0     0.040243   \n",
       "98   P_BAD0     0    0.98   192.0     3.0  4579.0  1186.0     0.040243   \n",
       "99   P_BAD0     0    0.99     0.0     0.0  4771.0  1189.0     0.000000   \n",
       "\n",
       "    Specificity   KS       FPR       ACC       FDR        F1         C  \\\n",
       "0      0.000000  0.0  1.000000  0.800503  0.199497  0.889200  0.830114   \n",
       "1      0.000000  0.0  1.000000  0.800503  0.199497  0.889200  0.830114   \n",
       "2      0.000000  0.0  1.000000  0.800503  0.199497  0.889200  0.830114   \n",
       "3      0.000000  0.0  1.000000  0.800503  0.199497  0.889200  0.830114   \n",
       "4      0.000000  0.0  1.000000  0.800503  0.199497  0.889200  0.830114   \n",
       "..          ...  ...       ...       ...       ...       ...       ...   \n",
       "95     0.948696  0.0  0.051304  0.444966  0.038486  0.479547  0.830114   \n",
       "96     0.989066  0.0  0.010934  0.276846  0.026694  0.180297  0.830114   \n",
       "97     0.997477  0.0  0.002523  0.231208  0.015385  0.077326  0.830114   \n",
       "98     0.997477  0.0  0.002523  0.231208  0.015385  0.077326  0.830114   \n",
       "99     1.000000  0.0  0.000000  0.199497       NaN  0.000000  0.830114   \n",
       "\n",
       "        Gini     Gamma       Tau  MISCEVENT       FNR  \n",
       "0   0.660229  0.728748  0.210909   0.199497  0.000000  \n",
       "1   0.660229  0.728748  0.210909   0.199497  0.000000  \n",
       "2   0.660229  0.728748  0.210909   0.199497  0.000000  \n",
       "3   0.660229  0.728748  0.210909   0.199497  0.000000  \n",
       "4   0.660229  0.728748  0.210909   0.199497  0.000000  \n",
       "..       ...       ...       ...        ...       ...  \n",
       "95  0.660229  0.728748  0.210909   0.555034  0.680570  \n",
       "96  0.660229  0.728748  0.210909   0.723154  0.900650  \n",
       "97  0.660229  0.728748  0.210909   0.768792  0.959757  \n",
       "98  0.660229  0.728748  0.210909   0.768792  0.959757  \n",
       "99  0.660229  0.728748  0.210909   0.800503  1.000000  \n",
       "\n",
       "[100 rows x 22 columns], Fit Statistics for _AUTOTUNE_DEFAULT_SCORE_TABLE_\n",
       "\n",
       "     NOBS       ASE     DIV      RASE       MCE      MCLL\n",
       "0  5960.0  0.114286  5960.0  0.338062  0.155872  0.366889, Tuner Information\n",
       "\n",
       "                           Parameter              Value\n",
       "0                         Model Type      Decision Tree\n",
       "1           Tuner Objective Function  Misclassification\n",
       "2                      Search Method               GRID\n",
       "3              Number of Grid Points                  6\n",
       "4     Maximum Tuning Time in Seconds              36000\n",
       "5                    Validation Type   Cross-Validation\n",
       "6      Num Folds in Cross-Validation                  5\n",
       "7                          Log Level                  0\n",
       "8                               Seed         1876916290\n",
       "9     Number of Parallel Evaluations                  4\n",
       "10  Number of Workers per Subsession                  0, Tuner Results\n",
       "\n",
       "   Evaluation  MAXLEVEL       CRIT  MeanConseqError  EvaluationTime\n",
       "0           0        11  gainRatio         0.156877        0.341418\n",
       "1           6        15       gain         0.154696        0.470920\n",
       "2           1         5       gain         0.156877        0.311942\n",
       "3           3         5  gainRatio         0.156877        0.472439\n",
       "4           4        10  gainRatio         0.156877        0.927789\n",
       "5           5        15  gainRatio         0.157213        0.634979\n",
       "6           2        10       gain         0.157689        0.472432, Tuner Iteration History\n",
       "\n",
       "   Iteration  Evaluations  Best_obj  Time_sec\n",
       "0          0            1  0.156877  0.341418\n",
       "1          1            7  0.154696  1.288053, Tuner Evaluation History\n",
       "\n",
       "   Evaluation  Iteration  MAXLEVEL       CRIT  MeanConseqError  EvaluationTime\n",
       "0           0          0        11  gainRatio         0.156877        0.341418\n",
       "1           1          1         5       gain         0.156877        0.311942\n",
       "2           2          1        10       gain         0.157689        0.472432\n",
       "3           3          1         5  gainRatio         0.156877        0.472439\n",
       "4           4          1        10  gainRatio         0.156877        0.927789\n",
       "5           5          1        15  gainRatio         0.157213        0.634979\n",
       "6           6          1        15       gain         0.154696        0.470920, Best Configuration\n",
       "\n",
       "             Parameter        Name         Value\n",
       "0           Evaluation  Evaluation             6\n",
       "1  Maximum Tree Levels    MAXLEVEL            15\n",
       "2            Criterion        CRIT          gain\n",
       "3    Misclassification   Objective  0.1546962005, Tuner Summary\n",
       "\n",
       "                                          Parameter     Value\n",
       "0             Initial Configuration Objective Value  0.156877\n",
       "1                Best Configuration Objective Value  0.154696\n",
       "2               Worst Configuration Objective Value  0.157689\n",
       "3  Initial Configuration Evaluation Time in Seconds  0.341418\n",
       "4     Best Configuration Evaluation Time in Seconds  0.470913\n",
       "5                 Number of Improved Configurations  1.000000\n",
       "6                Number of Evaluated Configurations  7.000000\n",
       "7                      Total Tuning Time in Seconds  1.334475\n",
       "8                           Parallel Tuning Speedup  2.160148, Tuner Task Timing\n",
       "\n",
       "                          Task  Time_sec  Time_percent\n",
       "0               Model Training  1.218875     42.282950\n",
       "1                Model Scoring  0.844904     29.309853\n",
       "2  Total Objective Evaluations  2.228993     77.324077\n",
       "3                        Tuner  0.653671     22.675923\n",
       "4               Total CPU Time  2.882663    100.000000, Hyperparameter Importance\n",
       "\n",
       "  Hyperparameter  RelImportance\n",
       "0       MAXLEVEL       1.000000\n",
       "1           CRIT       0.282713, Gradient Boosting Tree for __TEMP_FEATURE_MACHINE_CASOUT___AUTOTUNE_DATA_11FA4B25-9848-604F-9F45-7E73830B6354\n",
       "\n",
       "                                  Descr         Value\n",
       "0                       Number of Trees  1.500000e+02\n",
       "1                          Distribution  2.000000e+00\n",
       "2                         Learning Rate  1.000000e-01\n",
       "3                      Subsampling Rate  6.000000e-01\n",
       "4      Number of Selected Variables (M)  3.000000e+00\n",
       "5                        Number of Bins  5.000000e+01\n",
       "6                   Number of Variables  3.000000e+00\n",
       "7              Max Number of Tree Nodes  1.900000e+01\n",
       "8              Min Number of Tree Nodes  1.900000e+01\n",
       "9                Max Number of Branches  2.000000e+00\n",
       "10               Min Number of Branches  2.000000e+00\n",
       "11                 Max Number of Levels  5.000000e+00\n",
       "12                 Min Number of Levels  5.000000e+00\n",
       "13                 Max Number of Leaves  1.000000e+01\n",
       "14                 Min Number of Leaves  1.000000e+01\n",
       "15               Maximum Size of Leaves  1.844000e+03\n",
       "16               Minimum Size of Leaves  2.400000e+01\n",
       "17                   Random Number Seed  1.876916e+09\n",
       "18                   Lasso (L1) penalty  5.000000e-01\n",
       "19                   Ridge (L2) penalty  0.000000e+00\n",
       "20               Actual Number of Trees  1.000000e+00\n",
       "21             Average number of Leaves  1.000000e+01\n",
       "22            Early stopping stagnation  4.000000e+00\n",
       "23             Early stopping threshold  0.000000e+00\n",
       "24  Early stopping threshold iterations  0.000000e+00\n",
       "25             Early stopping tolerance  0.000000e+00,    Progress    Metric\n",
       "0       1.0  0.199497,                          Descr                             Value\n",
       "0  Number of Observations Read                              5960\n",
       "1  Number of Observations Used                              5960\n",
       "2  Misclassification Error (%)                       19.94966443,    TreeID  Trees  NLeaves       MCR   LogLoss       ASE     RASE     MAXAE\n",
       "0     0.0    1.0     10.0  0.199497  0.473837  0.150956  0.38853  0.814711,         LEVNAME  LEVINDEX VARNAME\n",
       "0             1         0  P_BAD1\n",
       "1             0         1  P_BAD0,   LEVNAME  LEVINDEX VARNAME\n",
       "0                 0   I_BAD, ROC Information for _AUTOTUNE_DEFAULT_SCORE_TABLE_\n",
       "\n",
       "   Variable Event  CutOff      TP      FP      FN      TN  Sensitivity  \\\n",
       "0    P_BAD0     0    0.00  4771.0  1189.0     0.0     0.0          1.0   \n",
       "1    P_BAD0     0    0.01  4771.0  1189.0     0.0     0.0          1.0   \n",
       "2    P_BAD0     0    0.02  4771.0  1189.0     0.0     0.0          1.0   \n",
       "3    P_BAD0     0    0.03  4771.0  1189.0     0.0     0.0          1.0   \n",
       "4    P_BAD0     0    0.04  4771.0  1189.0     0.0     0.0          1.0   \n",
       "..      ...   ...     ...     ...     ...     ...     ...          ...   \n",
       "95   P_BAD0     0    0.95     0.0     0.0  4771.0  1189.0          0.0   \n",
       "96   P_BAD0     0    0.96     0.0     0.0  4771.0  1189.0          0.0   \n",
       "97   P_BAD0     0    0.97     0.0     0.0  4771.0  1189.0          0.0   \n",
       "98   P_BAD0     0    0.98     0.0     0.0  4771.0  1189.0          0.0   \n",
       "99   P_BAD0     0    0.99     0.0     0.0  4771.0  1189.0          0.0   \n",
       "\n",
       "    Specificity   KS  FPR       ACC       FDR      F1         C      Gini  \\\n",
       "0           0.0  0.0  1.0  0.800503  0.199497  0.8892  0.819014  0.638027   \n",
       "1           0.0  0.0  1.0  0.800503  0.199497  0.8892  0.819014  0.638027   \n",
       "2           0.0  0.0  1.0  0.800503  0.199497  0.8892  0.819014  0.638027   \n",
       "3           0.0  0.0  1.0  0.800503  0.199497  0.8892  0.819014  0.638027   \n",
       "4           0.0  0.0  1.0  0.800503  0.199497  0.8892  0.819014  0.638027   \n",
       "..          ...  ...  ...       ...       ...     ...       ...       ...   \n",
       "95          1.0  0.0  0.0  0.199497       NaN  0.0000  0.819014  0.638027   \n",
       "96          1.0  0.0  0.0  0.199497       NaN  0.0000  0.819014  0.638027   \n",
       "97          1.0  0.0  0.0  0.199497       NaN  0.0000  0.819014  0.638027   \n",
       "98          1.0  0.0  0.0  0.199497       NaN  0.0000  0.819014  0.638027   \n",
       "99          1.0  0.0  0.0  0.199497       NaN  0.0000  0.819014  0.638027   \n",
       "\n",
       "       Gamma       Tau  MISCEVENT  FNR  \n",
       "0   0.777591  0.203817   0.199497  0.0  \n",
       "1   0.777591  0.203817   0.199497  0.0  \n",
       "2   0.777591  0.203817   0.199497  0.0  \n",
       "3   0.777591  0.203817   0.199497  0.0  \n",
       "4   0.777591  0.203817   0.199497  0.0  \n",
       "..       ...       ...        ...  ...  \n",
       "95  0.777591  0.203817   0.800503  1.0  \n",
       "96  0.777591  0.203817   0.800503  1.0  \n",
       "97  0.777591  0.203817   0.800503  1.0  \n",
       "98  0.777591  0.203817   0.800503  1.0  \n",
       "99  0.777591  0.203817   0.800503  1.0  \n",
       "\n",
       "[100 rows x 22 columns], Fit Statistics for _AUTOTUNE_DEFAULT_SCORE_TABLE_\n",
       "\n",
       "     NOBS       ASE     DIV     RASE       MCE      MCLL\n",
       "0  5960.0  0.150956  5960.0  0.38853  0.199497  0.473837, Tuner Information\n",
       "\n",
       "                           Parameter                   Value\n",
       "0                         Model Type  Gradient Boosting Tree\n",
       "1           Tuner Objective Function       Misclassification\n",
       "2                      Search Method                    GRID\n",
       "3              Number of Grid Points                      16\n",
       "4     Maximum Tuning Time in Seconds                   36000\n",
       "5                    Validation Type        Cross-Validation\n",
       "6      Num Folds in Cross-Validation                       5\n",
       "7                          Log Level                       0\n",
       "8                               Seed              1876916155\n",
       "9     Number of Parallel Evaluations                       4\n",
       "10  Number of Workers per Subsession                       0, Tuner Results\n",
       "\n",
       "    Evaluation  M  LEARNINGRATE  SUBSAMPLERATE  LASSO  RIDGE  MAXLEVEL  \\\n",
       "0            0  3          0.10            0.5    0.0    1.0         5   \n",
       "1            3  3          0.10            0.6    0.5    0.0         5   \n",
       "2           15  3          0.05            0.6    0.0    0.0         7   \n",
       "3            9  3          0.10            0.8    0.0    0.0         5   \n",
       "4            2  3          0.05            0.8    0.0    0.0         7   \n",
       "5            4  3          0.10            0.8    0.5    0.0         7   \n",
       "6           11  3          0.05            0.6    0.0    0.0         5   \n",
       "7           13  3          0.05            0.6    0.5    0.0         7   \n",
       "8           14  3          0.05            0.8    0.5    0.0         5   \n",
       "9           10  3          0.10            0.6    0.0    0.0         5   \n",
       "10           8  3          0.05            0.8    0.5    0.0         7   \n",
       "\n",
       "    MeanConseqError  EvaluationTime  \n",
       "0          0.199497        0.632475  \n",
       "1          0.199295        1.205958  \n",
       "2          0.199396        2.912694  \n",
       "3          0.199463        3.570540  \n",
       "4          0.199497        2.310202  \n",
       "5          0.199497        3.389764  \n",
       "6          0.199497        3.021106  \n",
       "7          0.199497        4.320703  \n",
       "8          0.199497        3.079410  \n",
       "9          0.199530        3.303823  \n",
       "10         0.199597        3.797840  , Tuner Iteration History\n",
       "\n",
       "   Iteration  Evaluations  Best_obj   Time_sec\n",
       "0          0            1  0.199497   0.632475\n",
       "1          1           17  0.199295  13.840101, Tuner Evaluation History\n",
       "\n",
       "    Evaluation  Iteration  M  LEARNINGRATE  SUBSAMPLERATE  LASSO  RIDGE  \\\n",
       "0            0          0  3          0.10            0.5    0.0    1.0   \n",
       "1            1          1  3          0.05            0.8    0.0    0.0   \n",
       "2            2          1  3          0.05            0.8    0.0    0.0   \n",
       "3            3          1  3          0.10            0.6    0.5    0.0   \n",
       "4            4          1  3          0.10            0.8    0.5    0.0   \n",
       "5            5          1  3          0.05            0.6    0.5    0.0   \n",
       "6            6          1  3          0.10            0.6    0.0    0.0   \n",
       "7            7          1  3          0.10            0.6    0.5    0.0   \n",
       "8            8          1  3          0.05            0.8    0.5    0.0   \n",
       "9            9          1  3          0.10            0.8    0.0    0.0   \n",
       "10          10          1  3          0.10            0.6    0.0    0.0   \n",
       "11          11          1  3          0.05            0.6    0.0    0.0   \n",
       "12          12          1  3          0.10            0.8    0.5    0.0   \n",
       "13          13          1  3          0.05            0.6    0.5    0.0   \n",
       "14          14          1  3          0.05            0.8    0.5    0.0   \n",
       "15          15          1  3          0.05            0.6    0.0    0.0   \n",
       "16          16          1  3          0.10            0.8    0.0    0.0   \n",
       "\n",
       "    MAXLEVEL  MeanConseqError  EvaluationTime  \n",
       "0          5         0.199497        0.632475  \n",
       "1          5         0.199664        3.318110  \n",
       "2          7         0.199497        2.310202  \n",
       "3          5         0.199295        1.205958  \n",
       "4          7         0.199497        3.389764  \n",
       "5          5         0.199631        2.916148  \n",
       "6          7         0.199631        4.396203  \n",
       "7          7         0.199631        4.185158  \n",
       "8          7         0.199597        3.797840  \n",
       "9          5         0.199463        3.570540  \n",
       "10         5         0.199530        3.303823  \n",
       "11         5         0.199497        3.021106  \n",
       "12         5         0.199631        2.794894  \n",
       "13         7         0.199497        4.320703  \n",
       "14         5         0.199497        3.079410  \n",
       "15         7         0.199396        2.912694  \n",
       "16         7         0.199664        2.909528  , Best Configuration\n",
       "\n",
       "                    Parameter           Name         Value\n",
       "0                  Evaluation     Evaluation             3\n",
       "1  Number of Variables to Try              M             3\n",
       "2               Learning Rate   LEARNINGRATE           0.1\n",
       "3               Sampling Rate  SUBSAMPLERATE           0.6\n",
       "4                       Lasso          LASSO           0.5\n",
       "5                       Ridge          RIDGE             0\n",
       "6         Maximum Tree Levels       MAXLEVEL             5\n",
       "7           Misclassification      Objective  0.1992952171, Tuner Summary\n",
       "\n",
       "                                          Parameter      Value\n",
       "0             Initial Configuration Objective Value   0.199497\n",
       "1                Best Configuration Objective Value   0.199295\n",
       "2               Worst Configuration Objective Value   0.199664\n",
       "3  Initial Configuration Evaluation Time in Seconds   0.632475\n",
       "4     Best Configuration Evaluation Time in Seconds   1.060541\n",
       "5                 Number of Improved Configurations   1.000000\n",
       "6                Number of Evaluated Configurations  17.000000\n",
       "7                      Total Tuning Time in Seconds  13.954578\n",
       "8                           Parallel Tuning Speedup   3.732452, Tuner Task Timing\n",
       "\n",
       "                          Task   Time_sec  Time_percent\n",
       "0               Model Training  46.442489     89.167079\n",
       "1                Model Scoring   4.103261      7.878041\n",
       "2  Total Objective Evaluations  51.058608     98.029780\n",
       "3                        Tuner   1.026185      1.970220\n",
       "4               Total CPU Time  52.084793    100.000000, Hyperparameter Importance\n",
       "\n",
       "  Hyperparameter  RelImportance\n",
       "0  SUBSAMPLERATE       1.000000\n",
       "1       MAXLEVEL       0.296013\n",
       "2   LEARNINGRATE       0.003978\n",
       "3          LASSO       0.003695\n",
       "4              M       0.000000\n",
       "5          RIDGE       0.000000, TuneAll Results Summary\n",
       "\n",
       "          ModelID               ModelType  Evaluations  BestObjective  \\\n",
       "0  1_DecisionTree           Decision Tree            6       0.154696   \n",
       "1     2_GradBoost  Gradient Boosting Tree           16       0.199295   \n",
       "\n",
       "   AverageObjective  StdDevObjective  BestObjTime  AverageTime  StdDevTime  \n",
       "0          0.156705         0.001035     0.470920     0.548417    0.212080  \n",
       "1          0.209333         0.013088     1.205958     3.248781    0.802765  , TuneAll Best Models\n",
       "\n",
       "          ModelID  Evaluation  MeanConseqError  EvaluationTime\n",
       "0  1_DecisionTree           6         0.154696        0.470920\n",
       "1  1_DecisionTree           1         0.156877        0.311942\n",
       "2  1_DecisionTree           0         0.156877        0.341418\n",
       "3  1_DecisionTree           3         0.156877        0.472439\n",
       "4  1_DecisionTree           4         0.156877        0.927789\n",
       "5  1_DecisionTree           5         0.157213        0.634979\n",
       "6  1_DecisionTree           2         0.157689        0.472432\n",
       "7     2_GradBoost           3         0.199295        1.205958\n",
       "8     2_GradBoost          15         0.199396        2.912694\n",
       "9     2_GradBoost           9         0.199463        3.570540, TuneAll CAS Output Tables\n",
       "\n",
       "Empty SASDataFrame\n",
       "Columns: [ModelID, CAS_Library, Name, Rows, Columns]\n",
       "Index: [],              casLib                   Name  Rows  Columns  \\\n",
       "0  CASUSER(sasdemo)        PIPELINE_OUT_PY    10       19   \n",
       "1  CASUSER(sasdemo)  TRANSFORMATION_OUT_PY     7       21   \n",
       "2  CASUSER(sasdemo)         FEATURE_OUT_PY    14       15   \n",
       "3  CASUSER(sasdemo)          ASTORE_OUT_PY     1        2   \n",
       "\n",
       "                                            casTable  \n",
       "0  CASTable('PIPELINE_OUT_PY', caslib='CASUSER(sa...  \n",
       "1  CASTable('TRANSFORMATION_OUT_PY', caslib='CASU...  \n",
       "2  CASTable('FEATURE_OUT_PY', caslib='CASUSER(sas...  \n",
       "3  CASTable('ASTORE_OUT_PY', caslib='CASUSER(sasd...  ]</div>\n",
       "</div>\n",
       "<div class=\"cas-results-key\"><hr/><b>&#167; keyedList</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>{'BestConfiguration_1_DecisionTree': Best Configuration\n",
       "\n",
       "             Parameter        Name         Value\n",
       "0           Evaluation  Evaluation             6\n",
       "1  Maximum Tree Levels    MAXLEVEL            15\n",
       "2            Criterion        CRIT          gain\n",
       "3    Misclassification   Objective  0.1546962005, 'BestConfiguration_2_GradBoost': Best Configuration\n",
       "\n",
       "                    Parameter           Name         Value\n",
       "0                  Evaluation     Evaluation             3\n",
       "1  Number of Variables to Try              M             3\n",
       "2               Learning Rate   LEARNINGRATE           0.1\n",
       "3               Sampling Rate  SUBSAMPLERATE           0.6\n",
       "4                       Lasso          LASSO           0.5\n",
       "5                       Ridge          RIDGE             0\n",
       "6         Maximum Tree Levels       MAXLEVEL             5\n",
       "7           Misclassification      Objective  0.1992952171, 'EncodedName_1_DecisionTree':         LEVNAME  LEVINDEX VARNAME\n",
       "0             1         0  P_BAD1\n",
       "1             0         1  P_BAD0, 'EncodedName_2_GradBoost':         LEVNAME  LEVINDEX VARNAME\n",
       "0             1         0  P_BAD1\n",
       "1             0         1  P_BAD0, 'EncodedTargetName_1_DecisionTree':   LEVNAME  LEVINDEX VARNAME\n",
       "0                 0   I_BAD, 'EncodedTargetName_2_GradBoost':   LEVNAME  LEVINDEX VARNAME\n",
       "0                 0   I_BAD, 'ErrorMetricInfo_2_GradBoost':    TreeID  Trees  NLeaves       MCR   LogLoss       ASE     RASE     MAXAE\n",
       "0     0.0    1.0     10.0  0.199497  0.473837  0.150956  0.38853  0.814711, 'EvalMetricInfo_2_GradBoost':    Progress    Metric\n",
       "0       1.0  0.199497, 'EvaluationHistory_1_DecisionTree': Tuner Evaluation History\n",
       "\n",
       "   Evaluation  Iteration  MAXLEVEL       CRIT  MeanConseqError  EvaluationTime\n",
       "0           0          0        11  gainRatio         0.156877        0.341418\n",
       "1           1          1         5       gain         0.156877        0.311942\n",
       "2           2          1        10       gain         0.157689        0.472432\n",
       "3           3          1         5  gainRatio         0.156877        0.472439\n",
       "4           4          1        10  gainRatio         0.156877        0.927789\n",
       "5           5          1        15  gainRatio         0.157213        0.634979\n",
       "6           6          1        15       gain         0.154696        0.470920, 'EvaluationHistory_2_GradBoost': Tuner Evaluation History\n",
       "\n",
       "    Evaluation  Iteration  M  LEARNINGRATE  SUBSAMPLERATE  LASSO  RIDGE  \\\n",
       "0            0          0  3          0.10            0.5    0.0    1.0   \n",
       "1            1          1  3          0.05            0.8    0.0    0.0   \n",
       "2            2          1  3          0.05            0.8    0.0    0.0   \n",
       "3            3          1  3          0.10            0.6    0.5    0.0   \n",
       "4            4          1  3          0.10            0.8    0.5    0.0   \n",
       "5            5          1  3          0.05            0.6    0.5    0.0   \n",
       "6            6          1  3          0.10            0.6    0.0    0.0   \n",
       "7            7          1  3          0.10            0.6    0.5    0.0   \n",
       "8            8          1  3          0.05            0.8    0.5    0.0   \n",
       "9            9          1  3          0.10            0.8    0.0    0.0   \n",
       "10          10          1  3          0.10            0.6    0.0    0.0   \n",
       "11          11          1  3          0.05            0.6    0.0    0.0   \n",
       "12          12          1  3          0.10            0.8    0.5    0.0   \n",
       "13          13          1  3          0.05            0.6    0.5    0.0   \n",
       "14          14          1  3          0.05            0.8    0.5    0.0   \n",
       "15          15          1  3          0.05            0.6    0.0    0.0   \n",
       "16          16          1  3          0.10            0.8    0.0    0.0   \n",
       "\n",
       "    MAXLEVEL  MeanConseqError  EvaluationTime  \n",
       "0          5         0.199497        0.632475  \n",
       "1          5         0.199664        3.318110  \n",
       "2          7         0.199497        2.310202  \n",
       "3          5         0.199295        1.205958  \n",
       "4          7         0.199497        3.389764  \n",
       "5          5         0.199631        2.916148  \n",
       "6          7         0.199631        4.396203  \n",
       "7          7         0.199631        4.185158  \n",
       "8          7         0.199597        3.797840  \n",
       "9          5         0.199463        3.570540  \n",
       "10         5         0.199530        3.303823  \n",
       "11         5         0.199497        3.021106  \n",
       "12         5         0.199631        2.794894  \n",
       "13         7         0.199497        4.320703  \n",
       "14         5         0.199497        3.079410  \n",
       "15         7         0.199396        2.912694  \n",
       "16         7         0.199664        2.909528  , 'FitStat_1_DecisionTree': Fit Statistics for _AUTOTUNE_DEFAULT_SCORE_TABLE_\n",
       "\n",
       "     NOBS       ASE     DIV      RASE       MCE      MCLL\n",
       "0  5960.0  0.114286  5960.0  0.338062  0.155872  0.366889, 'FitStat_2_GradBoost': Fit Statistics for _AUTOTUNE_DEFAULT_SCORE_TABLE_\n",
       "\n",
       "     NOBS       ASE     DIV     RASE       MCE      MCLL\n",
       "0  5960.0  0.150956  5960.0  0.38853  0.199497  0.473837, 'HyperparameterImportance_1_DecisionTree': Hyperparameter Importance\n",
       "\n",
       "  Hyperparameter  RelImportance\n",
       "0       MAXLEVEL       1.000000\n",
       "1           CRIT       0.282713, 'HyperparameterImportance_2_GradBoost': Hyperparameter Importance\n",
       "\n",
       "  Hyperparameter  RelImportance\n",
       "0  SUBSAMPLERATE       1.000000\n",
       "1       MAXLEVEL       0.296013\n",
       "2   LEARNINGRATE       0.003978\n",
       "3          LASSO       0.003695\n",
       "4              M       0.000000\n",
       "5          RIDGE       0.000000, 'IterationHistory_1_DecisionTree': Tuner Iteration History\n",
       "\n",
       "   Iteration  Evaluations  Best_obj  Time_sec\n",
       "0          0            1  0.156877  0.341418\n",
       "1          1            7  0.154696  1.288053, 'IterationHistory_2_GradBoost': Tuner Iteration History\n",
       "\n",
       "   Iteration  Evaluations  Best_obj   Time_sec\n",
       "0          0            1  0.199497   0.632475\n",
       "1          1           17  0.199295  13.840101, 'ModelInfo_1_DecisionTree': Decision Tree for __TEMP_FEATURE_MACHINE_CASOUT___AUTOTUNE_DATA_11FA4B25-9848-604F-9F45-7E73830B6354\n",
       "\n",
       "                           Descr        Value\n",
       "0           Number of Tree Nodes    39.000000\n",
       "1         Max Number of Branches     2.000000\n",
       "2               Number of Levels     7.000000\n",
       "3               Number of Leaves    20.000000\n",
       "4                 Number of Bins    50.000000\n",
       "5         Minimum Size of Leaves    22.000000\n",
       "6         Maximum Size of Leaves  1300.000000\n",
       "7            Number of Variables     3.000000\n",
       "8   Confidence Level for Pruning     0.250000\n",
       "9    Number of Observations Used  5960.000000\n",
       "10   Misclassification Error (%)    15.587248, 'ModelInfo_2_GradBoost': Gradient Boosting Tree for __TEMP_FEATURE_MACHINE_CASOUT___AUTOTUNE_DATA_11FA4B25-9848-604F-9F45-7E73830B6354\n",
       "\n",
       "                                  Descr         Value\n",
       "0                       Number of Trees  1.500000e+02\n",
       "1                          Distribution  2.000000e+00\n",
       "2                         Learning Rate  1.000000e-01\n",
       "3                      Subsampling Rate  6.000000e-01\n",
       "4      Number of Selected Variables (M)  3.000000e+00\n",
       "5                        Number of Bins  5.000000e+01\n",
       "6                   Number of Variables  3.000000e+00\n",
       "7              Max Number of Tree Nodes  1.900000e+01\n",
       "8              Min Number of Tree Nodes  1.900000e+01\n",
       "9                Max Number of Branches  2.000000e+00\n",
       "10               Min Number of Branches  2.000000e+00\n",
       "11                 Max Number of Levels  5.000000e+00\n",
       "12                 Min Number of Levels  5.000000e+00\n",
       "13                 Max Number of Leaves  1.000000e+01\n",
       "14                 Min Number of Leaves  1.000000e+01\n",
       "15               Maximum Size of Leaves  1.844000e+03\n",
       "16               Minimum Size of Leaves  2.400000e+01\n",
       "17                   Random Number Seed  1.876916e+09\n",
       "18                   Lasso (L1) penalty  5.000000e-01\n",
       "19                   Ridge (L2) penalty  0.000000e+00\n",
       "20               Actual Number of Trees  1.000000e+00\n",
       "21             Average number of Leaves  1.000000e+01\n",
       "22            Early stopping stagnation  4.000000e+00\n",
       "23             Early stopping threshold  0.000000e+00\n",
       "24  Early stopping threshold iterations  0.000000e+00\n",
       "25             Early stopping tolerance  0.000000e+00, 'OutputCasTables':              casLib                   Name  Rows  Columns  \\\n",
       "0  CASUSER(sasdemo)        PIPELINE_OUT_PY    10       19   \n",
       "1  CASUSER(sasdemo)  TRANSFORMATION_OUT_PY     7       21   \n",
       "2  CASUSER(sasdemo)         FEATURE_OUT_PY    14       15   \n",
       "3  CASUSER(sasdemo)          ASTORE_OUT_PY     1        2   \n",
       "\n",
       "                                            casTable  \n",
       "0  CASTable('PIPELINE_OUT_PY', caslib='CASUSER(sa...  \n",
       "1  CASTable('TRANSFORMATION_OUT_PY', caslib='CASU...  \n",
       "2  CASTable('FEATURE_OUT_PY', caslib='CASUSER(sas...  \n",
       "3  CASTable('ASTORE_OUT_PY', caslib='CASUSER(sasd...  , 'ROCInfo_1_DecisionTree': ROC Information for _AUTOTUNE_DEFAULT_SCORE_TABLE_\n",
       "\n",
       "   Variable Event  CutOff      TP      FP      FN      TN  Sensitivity  \\\n",
       "0    P_BAD0     0    0.00  4771.0  1189.0     0.0     0.0     1.000000   \n",
       "1    P_BAD0     0    0.01  4771.0  1189.0     0.0     0.0     1.000000   \n",
       "2    P_BAD0     0    0.02  4771.0  1189.0     0.0     0.0     1.000000   \n",
       "3    P_BAD0     0    0.03  4771.0  1189.0     0.0     0.0     1.000000   \n",
       "4    P_BAD0     0    0.04  4771.0  1189.0     0.0     0.0     1.000000   \n",
       "..      ...   ...     ...     ...     ...     ...     ...          ...   \n",
       "95   P_BAD0     0    0.95  1524.0    61.0  3247.0  1128.0     0.319430   \n",
       "96   P_BAD0     0    0.96   474.0    13.0  4297.0  1176.0     0.099350   \n",
       "97   P_BAD0     0    0.97   192.0     3.0  4579.0  1186.0     0.040243   \n",
       "98   P_BAD0     0    0.98   192.0     3.0  4579.0  1186.0     0.040243   \n",
       "99   P_BAD0     0    0.99     0.0     0.0  4771.0  1189.0     0.000000   \n",
       "\n",
       "    Specificity   KS       FPR       ACC       FDR        F1         C  \\\n",
       "0      0.000000  0.0  1.000000  0.800503  0.199497  0.889200  0.830114   \n",
       "1      0.000000  0.0  1.000000  0.800503  0.199497  0.889200  0.830114   \n",
       "2      0.000000  0.0  1.000000  0.800503  0.199497  0.889200  0.830114   \n",
       "3      0.000000  0.0  1.000000  0.800503  0.199497  0.889200  0.830114   \n",
       "4      0.000000  0.0  1.000000  0.800503  0.199497  0.889200  0.830114   \n",
       "..          ...  ...       ...       ...       ...       ...       ...   \n",
       "95     0.948696  0.0  0.051304  0.444966  0.038486  0.479547  0.830114   \n",
       "96     0.989066  0.0  0.010934  0.276846  0.026694  0.180297  0.830114   \n",
       "97     0.997477  0.0  0.002523  0.231208  0.015385  0.077326  0.830114   \n",
       "98     0.997477  0.0  0.002523  0.231208  0.015385  0.077326  0.830114   \n",
       "99     1.000000  0.0  0.000000  0.199497       NaN  0.000000  0.830114   \n",
       "\n",
       "        Gini     Gamma       Tau  MISCEVENT       FNR  \n",
       "0   0.660229  0.728748  0.210909   0.199497  0.000000  \n",
       "1   0.660229  0.728748  0.210909   0.199497  0.000000  \n",
       "2   0.660229  0.728748  0.210909   0.199497  0.000000  \n",
       "3   0.660229  0.728748  0.210909   0.199497  0.000000  \n",
       "4   0.660229  0.728748  0.210909   0.199497  0.000000  \n",
       "..       ...       ...       ...        ...       ...  \n",
       "95  0.660229  0.728748  0.210909   0.555034  0.680570  \n",
       "96  0.660229  0.728748  0.210909   0.723154  0.900650  \n",
       "97  0.660229  0.728748  0.210909   0.768792  0.959757  \n",
       "98  0.660229  0.728748  0.210909   0.768792  0.959757  \n",
       "99  0.660229  0.728748  0.210909   0.800503  1.000000  \n",
       "\n",
       "[100 rows x 22 columns], 'ROCInfo_2_GradBoost': ROC Information for _AUTOTUNE_DEFAULT_SCORE_TABLE_\n",
       "\n",
       "   Variable Event  CutOff      TP      FP      FN      TN  Sensitivity  \\\n",
       "0    P_BAD0     0    0.00  4771.0  1189.0     0.0     0.0          1.0   \n",
       "1    P_BAD0     0    0.01  4771.0  1189.0     0.0     0.0          1.0   \n",
       "2    P_BAD0     0    0.02  4771.0  1189.0     0.0     0.0          1.0   \n",
       "3    P_BAD0     0    0.03  4771.0  1189.0     0.0     0.0          1.0   \n",
       "4    P_BAD0     0    0.04  4771.0  1189.0     0.0     0.0          1.0   \n",
       "..      ...   ...     ...     ...     ...     ...     ...          ...   \n",
       "95   P_BAD0     0    0.95     0.0     0.0  4771.0  1189.0          0.0   \n",
       "96   P_BAD0     0    0.96     0.0     0.0  4771.0  1189.0          0.0   \n",
       "97   P_BAD0     0    0.97     0.0     0.0  4771.0  1189.0          0.0   \n",
       "98   P_BAD0     0    0.98     0.0     0.0  4771.0  1189.0          0.0   \n",
       "99   P_BAD0     0    0.99     0.0     0.0  4771.0  1189.0          0.0   \n",
       "\n",
       "    Specificity   KS  FPR       ACC       FDR      F1         C      Gini  \\\n",
       "0           0.0  0.0  1.0  0.800503  0.199497  0.8892  0.819014  0.638027   \n",
       "1           0.0  0.0  1.0  0.800503  0.199497  0.8892  0.819014  0.638027   \n",
       "2           0.0  0.0  1.0  0.800503  0.199497  0.8892  0.819014  0.638027   \n",
       "3           0.0  0.0  1.0  0.800503  0.199497  0.8892  0.819014  0.638027   \n",
       "4           0.0  0.0  1.0  0.800503  0.199497  0.8892  0.819014  0.638027   \n",
       "..          ...  ...  ...       ...       ...     ...       ...       ...   \n",
       "95          1.0  0.0  0.0  0.199497       NaN  0.0000  0.819014  0.638027   \n",
       "96          1.0  0.0  0.0  0.199497       NaN  0.0000  0.819014  0.638027   \n",
       "97          1.0  0.0  0.0  0.199497       NaN  0.0000  0.819014  0.638027   \n",
       "98          1.0  0.0  0.0  0.199497       NaN  0.0000  0.819014  0.638027   \n",
       "99          1.0  0.0  0.0  0.199497       NaN  0.0000  0.819014  0.638027   \n",
       "\n",
       "       Gamma       Tau  MISCEVENT  FNR  \n",
       "0   0.777591  0.203817   0.199497  0.0  \n",
       "1   0.777591  0.203817   0.199497  0.0  \n",
       "2   0.777591  0.203817   0.199497  0.0  \n",
       "3   0.777591  0.203817   0.199497  0.0  \n",
       "4   0.777591  0.203817   0.199497  0.0  \n",
       "..       ...       ...        ...  ...  \n",
       "95  0.777591  0.203817   0.800503  1.0  \n",
       "96  0.777591  0.203817   0.800503  1.0  \n",
       "97  0.777591  0.203817   0.800503  1.0  \n",
       "98  0.777591  0.203817   0.800503  1.0  \n",
       "99  0.777591  0.203817   0.800503  1.0  \n",
       "\n",
       "[100 rows x 22 columns], 'ScoreInfo_1_DecisionTree':                          Descr                             Value\n",
       "0  Number of Observations Read                              5960\n",
       "1  Number of Observations Used                              5960\n",
       "2  Misclassification Error (%)                      15.587248322, 'ScoreInfo_2_GradBoost':                          Descr                             Value\n",
       "0  Number of Observations Read                              5960\n",
       "1  Number of Observations Used                              5960\n",
       "2  Misclassification Error (%)                       19.94966443, 'TuneAllBestModels': TuneAll Best Models\n",
       "\n",
       "          ModelID  Evaluation  MeanConseqError  EvaluationTime\n",
       "0  1_DecisionTree           6         0.154696        0.470920\n",
       "1  1_DecisionTree           1         0.156877        0.311942\n",
       "2  1_DecisionTree           0         0.156877        0.341418\n",
       "3  1_DecisionTree           3         0.156877        0.472439\n",
       "4  1_DecisionTree           4         0.156877        0.927789\n",
       "5  1_DecisionTree           5         0.157213        0.634979\n",
       "6  1_DecisionTree           2         0.157689        0.472432\n",
       "7     2_GradBoost           3         0.199295        1.205958\n",
       "8     2_GradBoost          15         0.199396        2.912694\n",
       "9     2_GradBoost           9         0.199463        3.570540, 'TuneAllCasOutputTables': TuneAll CAS Output Tables\n",
       "\n",
       "Empty SASDataFrame\n",
       "Columns: [ModelID, CAS_Library, Name, Rows, Columns]\n",
       "Index: [], 'TuneAllResultsSummary': TuneAll Results Summary\n",
       "\n",
       "          ModelID               ModelType  Evaluations  BestObjective  \\\n",
       "0  1_DecisionTree           Decision Tree            6       0.154696   \n",
       "1     2_GradBoost  Gradient Boosting Tree           16       0.199295   \n",
       "\n",
       "   AverageObjective  StdDevObjective  BestObjTime  AverageTime  StdDevTime  \n",
       "0          0.156705         0.001035     0.470920     0.548417    0.212080  \n",
       "1          0.209333         0.013088     1.205958     3.248781    0.802765  , 'TunerInfo_1_DecisionTree': Tuner Information\n",
       "\n",
       "                           Parameter              Value\n",
       "0                         Model Type      Decision Tree\n",
       "1           Tuner Objective Function  Misclassification\n",
       "2                      Search Method               GRID\n",
       "3              Number of Grid Points                  6\n",
       "4     Maximum Tuning Time in Seconds              36000\n",
       "5                    Validation Type   Cross-Validation\n",
       "6      Num Folds in Cross-Validation                  5\n",
       "7                          Log Level                  0\n",
       "8                               Seed         1876916290\n",
       "9     Number of Parallel Evaluations                  4\n",
       "10  Number of Workers per Subsession                  0, 'TunerInfo_2_GradBoost': Tuner Information\n",
       "\n",
       "                           Parameter                   Value\n",
       "0                         Model Type  Gradient Boosting Tree\n",
       "1           Tuner Objective Function       Misclassification\n",
       "2                      Search Method                    GRID\n",
       "3              Number of Grid Points                      16\n",
       "4     Maximum Tuning Time in Seconds                   36000\n",
       "5                    Validation Type        Cross-Validation\n",
       "6      Num Folds in Cross-Validation                       5\n",
       "7                          Log Level                       0\n",
       "8                               Seed              1876916155\n",
       "9     Number of Parallel Evaluations                       4\n",
       "10  Number of Workers per Subsession                       0, 'TunerResults_1_DecisionTree': Tuner Results\n",
       "\n",
       "   Evaluation  MAXLEVEL       CRIT  MeanConseqError  EvaluationTime\n",
       "0           0        11  gainRatio         0.156877        0.341418\n",
       "1           6        15       gain         0.154696        0.470920\n",
       "2           1         5       gain         0.156877        0.311942\n",
       "3           3         5  gainRatio         0.156877        0.472439\n",
       "4           4        10  gainRatio         0.156877        0.927789\n",
       "5           5        15  gainRatio         0.157213        0.634979\n",
       "6           2        10       gain         0.157689        0.472432, 'TunerResults_2_GradBoost': Tuner Results\n",
       "\n",
       "    Evaluation  M  LEARNINGRATE  SUBSAMPLERATE  LASSO  RIDGE  MAXLEVEL  \\\n",
       "0            0  3          0.10            0.5    0.0    1.0         5   \n",
       "1            3  3          0.10            0.6    0.5    0.0         5   \n",
       "2           15  3          0.05            0.6    0.0    0.0         7   \n",
       "3            9  3          0.10            0.8    0.0    0.0         5   \n",
       "4            2  3          0.05            0.8    0.0    0.0         7   \n",
       "5            4  3          0.10            0.8    0.5    0.0         7   \n",
       "6           11  3          0.05            0.6    0.0    0.0         5   \n",
       "7           13  3          0.05            0.6    0.5    0.0         7   \n",
       "8           14  3          0.05            0.8    0.5    0.0         5   \n",
       "9           10  3          0.10            0.6    0.0    0.0         5   \n",
       "10           8  3          0.05            0.8    0.5    0.0         7   \n",
       "\n",
       "    MeanConseqError  EvaluationTime  \n",
       "0          0.199497        0.632475  \n",
       "1          0.199295        1.205958  \n",
       "2          0.199396        2.912694  \n",
       "3          0.199463        3.570540  \n",
       "4          0.199497        2.310202  \n",
       "5          0.199497        3.389764  \n",
       "6          0.199497        3.021106  \n",
       "7          0.199497        4.320703  \n",
       "8          0.199497        3.079410  \n",
       "9          0.199530        3.303823  \n",
       "10         0.199597        3.797840  , 'TunerSummary_1_DecisionTree': Tuner Summary\n",
       "\n",
       "                                          Parameter     Value\n",
       "0             Initial Configuration Objective Value  0.156877\n",
       "1                Best Configuration Objective Value  0.154696\n",
       "2               Worst Configuration Objective Value  0.157689\n",
       "3  Initial Configuration Evaluation Time in Seconds  0.341418\n",
       "4     Best Configuration Evaluation Time in Seconds  0.470913\n",
       "5                 Number of Improved Configurations  1.000000\n",
       "6                Number of Evaluated Configurations  7.000000\n",
       "7                      Total Tuning Time in Seconds  1.334475\n",
       "8                           Parallel Tuning Speedup  2.160148, 'TunerSummary_2_GradBoost': Tuner Summary\n",
       "\n",
       "                                          Parameter      Value\n",
       "0             Initial Configuration Objective Value   0.199497\n",
       "1                Best Configuration Objective Value   0.199295\n",
       "2               Worst Configuration Objective Value   0.199664\n",
       "3  Initial Configuration Evaluation Time in Seconds   0.632475\n",
       "4     Best Configuration Evaluation Time in Seconds   1.060541\n",
       "5                 Number of Improved Configurations   1.000000\n",
       "6                Number of Evaluated Configurations  17.000000\n",
       "7                      Total Tuning Time in Seconds  13.954578\n",
       "8                           Parallel Tuning Speedup   3.732452, 'TunerTiming_1_DecisionTree': Tuner Task Timing\n",
       "\n",
       "                          Task  Time_sec  Time_percent\n",
       "0               Model Training  1.218875     42.282950\n",
       "1                Model Scoring  0.844904     29.309853\n",
       "2  Total Objective Evaluations  2.228993     77.324077\n",
       "3                        Tuner  0.653671     22.675923\n",
       "4               Total CPU Time  2.882663    100.000000, 'TunerTiming_2_GradBoost': Tuner Task Timing\n",
       "\n",
       "                          Task   Time_sec  Time_percent\n",
       "0               Model Training  46.442489     89.167079\n",
       "1                Model Scoring   4.103261      7.878041\n",
       "2  Total Objective Evaluations  51.058608     98.029780\n",
       "3                        Tuner   1.026185      1.970220\n",
       "4               Total CPU Time  52.084793    100.000000}</div>\n",
       "</div>\n",
       "<div class=\"cas-output-area\"></div>\n",
       "<p class=\"cas-results-performance\"><small><span class=\"cas-elapsed\">elapsed 100s</span> &#183; <span class=\"cas-user\">user 1.56s</span> &#183; <span class=\"cas-sys\">sys 0.369s</span> &#183; <span class=\"cas-memory\">mem 0.813MB</span></small></p>"
      ],
      "text/plain": [
       "[list]\n",
       "\n",
       " [Decision Tree for __TEMP_FEATURE_MACHINE_CASOUT___AUTOTUNE_DATA_11FA4B25-9848-604F-9F45-7E73830B6354\n",
       " \n",
       "                            Descr        Value\n",
       " 0           Number of Tree Nodes   437.000000\n",
       " 1         Max Number of Branches     2.000000\n",
       " 2               Number of Levels    15.000000\n",
       " 3               Number of Leaves   219.000000\n",
       " 4                 Number of Bins   100.000000\n",
       " 5         Minimum Size of Leaves     5.000000\n",
       " 6         Maximum Size of Leaves   612.000000\n",
       " 7            Number of Variables     6.000000\n",
       " 8   Confidence Level for Pruning     0.250000\n",
       " 9    Number of Observations Used  5960.000000\n",
       " 10   Misclassification Error (%)    11.895973,\n",
       "                           Descr                             Value\n",
       " 0  Number of Observations Read                              5960\n",
       " 1  Number of Observations Used                              5960\n",
       " 2  Misclassification Error (%)                      11.895973154,\n",
       "          LEVNAME  LEVINDEX VARNAME\n",
       " 0             1         0  P_BAD1\n",
       " 1             0         1  P_BAD0,\n",
       "    LEVNAME  LEVINDEX VARNAME\n",
       " 0                 0   I_BAD,\n",
       "  ROC Information for _AUTOTUNE_DEFAULT_SCORE_TABLE_\n",
       " \n",
       "    Variable Event  CutOff      TP      FP      FN      TN  Sensitivity  Specificity   KS       KS2    F_HALF       FPR       ACC       FDR        F1         C     Gini     Gamma       Tau  MISCEVENT       FNR\n",
       " 0    P_BAD0     0    0.00  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.917425  0.83485  0.859642  0.266692   0.199497  0.000000\n",
       " 1    P_BAD0     0    0.01  4771.0  1019.0     0.0   170.0     1.000000     0.142977  0.0  0.142977  0.854069  0.857023  0.829027  0.175993  0.903513  0.917425  0.83485  0.859642  0.266692   0.170973  0.000000\n",
       " 2    P_BAD0     0    0.02  4771.0  1019.0     0.0   170.0     1.000000     0.142977  0.0  0.142977  0.854069  0.857023  0.829027  0.175993  0.903513  0.917425  0.83485  0.859642  0.266692   0.170973  0.000000\n",
       " 3    P_BAD0     0    0.03  4771.0  1019.0     0.0   170.0     1.000000     0.142977  0.0  0.142977  0.854069  0.857023  0.829027  0.175993  0.903513  0.917425  0.83485  0.859642  0.266692   0.170973  0.000000\n",
       " 4    P_BAD0     0    0.04  4771.0  1019.0     0.0   170.0     1.000000     0.142977  0.0  0.142977  0.854069  0.857023  0.829027  0.175993  0.903513  0.917425  0.83485  0.859642  0.266692   0.170973  0.000000\n",
       " 5    P_BAD0     0    0.05  4771.0  1019.0     0.0   170.0     1.000000     0.142977  0.0  0.142977  0.854069  0.857023  0.829027  0.175993  0.903513  0.917425  0.83485  0.859642  0.266692   0.170973  0.000000\n",
       " 6    P_BAD0     0    0.06  4771.0  1019.0     0.0   170.0     1.000000     0.142977  0.0  0.142977  0.854069  0.857023  0.829027  0.175993  0.903513  0.917425  0.83485  0.859642  0.266692   0.170973  0.000000\n",
       " 7    P_BAD0     0    0.07  4771.0  1019.0     0.0   170.0     1.000000     0.142977  0.0  0.142977  0.854069  0.857023  0.829027  0.175993  0.903513  0.917425  0.83485  0.859642  0.266692   0.170973  0.000000\n",
       " 8    P_BAD0     0    0.08  4771.0  1019.0     0.0   170.0     1.000000     0.142977  0.0  0.142977  0.854069  0.857023  0.829027  0.175993  0.903513  0.917425  0.83485  0.859642  0.266692   0.170973  0.000000\n",
       " 9    P_BAD0     0    0.09  4766.0   967.0     5.0   222.0     0.998952     0.186712  0.0  0.185664  0.860196  0.813288  0.836913  0.168673  0.907464  0.917425  0.83485  0.859642  0.266692   0.163087  0.001048\n",
       " 10   P_BAD0     0    0.10  4760.0   912.0    11.0   277.0     0.997694     0.232969  0.0  0.230663  0.866747  0.767031  0.845134  0.160790  0.911615  0.917425  0.83485  0.859642  0.266692   0.154866  0.002306\n",
       " 11   P_BAD0     0    0.11  4760.0   912.0    11.0   277.0     0.997694     0.232969  0.0  0.230663  0.866747  0.767031  0.845134  0.160790  0.911615  0.917425  0.83485  0.859642  0.266692   0.154866  0.002306\n",
       " 12   P_BAD0     0    0.12  4760.0   912.0    11.0   277.0     0.997694     0.232969  0.0  0.230663  0.866747  0.767031  0.845134  0.160790  0.911615  0.917425  0.83485  0.859642  0.266692   0.154866  0.002306\n",
       " 13   P_BAD0     0    0.13  4760.0   912.0    11.0   277.0     0.997694     0.232969  0.0  0.230663  0.866747  0.767031  0.845134  0.160790  0.911615  0.917425  0.83485  0.859642  0.266692   0.154866  0.002306\n",
       " 14   P_BAD0     0    0.14  4755.0   879.0    16.0   310.0     0.996646     0.260723  0.0  0.257370  0.870656  0.739277  0.849832  0.156017  0.913984  0.917425  0.83485  0.859642  0.266692   0.150168  0.003354\n",
       " 15   P_BAD0     0    0.15  4754.0   873.0    17.0   316.0     0.996437     0.265770  0.0  0.262206  0.871366  0.734230  0.850671  0.155145  0.914407  0.917425  0.83485  0.859642  0.266692   0.149329  0.003563\n",
       " 16   P_BAD0     0    0.16  4751.0   856.0    20.0   333.0     0.995808     0.280067  0.0  0.275875  0.873378  0.719933  0.853020  0.152666  0.915591  0.917425  0.83485  0.859642  0.266692   0.146980  0.004192\n",
       " 17   P_BAD0     0    0.17  4750.0   851.0    21.0   338.0     0.995598     0.284272  0.0  0.279871  0.873965  0.715728  0.853691  0.151937  0.915927  0.917425  0.83485  0.859642  0.266692   0.146309  0.004402\n",
       " 18   P_BAD0     0    0.18  4750.0   851.0    21.0   338.0     0.995598     0.284272  0.0  0.279871  0.873965  0.715728  0.853691  0.151937  0.915927  0.917425  0.83485  0.859642  0.266692   0.146309  0.004402\n",
       " 19   P_BAD0     0    0.19  4750.0   851.0    21.0   338.0     0.995598     0.284272  0.0  0.279871  0.873965  0.715728  0.853691  0.151937  0.915927  0.917425  0.83485  0.859642  0.266692   0.146309  0.004402\n",
       " 20   P_BAD0     0    0.20  4750.0   851.0    21.0   338.0     0.995598     0.284272  0.0  0.279871  0.873965  0.715728  0.853691  0.151937  0.915927  0.917425  0.83485  0.859642  0.266692   0.146309  0.004402\n",
       " 21   P_BAD0     0    0.21  4750.0   851.0    21.0   338.0     0.995598     0.284272  0.0  0.279871  0.873965  0.715728  0.853691  0.151937  0.915927  0.917425  0.83485  0.859642  0.266692   0.146309  0.004402\n",
       " 22   P_BAD0     0    0.22  4750.0   851.0    21.0   338.0     0.995598     0.284272  0.0  0.279871  0.873965  0.715728  0.853691  0.151937  0.915927  0.917425  0.83485  0.859642  0.266692   0.146309  0.004402\n",
       " 23   P_BAD0     0    0.23  4750.0   851.0    21.0   338.0     0.995598     0.284272  0.0  0.279871  0.873965  0.715728  0.853691  0.151937  0.915927  0.917425  0.83485  0.859642  0.266692   0.146309  0.004402\n",
       " 24   P_BAD0     0    0.24  4750.0   851.0    21.0   338.0     0.995598     0.284272  0.0  0.279871  0.873965  0.715728  0.853691  0.151937  0.915927  0.917425  0.83485  0.859642  0.266692   0.146309  0.004402\n",
       " 25   P_BAD0     0    0.25  4750.0   851.0    21.0   338.0     0.995598     0.284272  0.0  0.279871  0.873965  0.715728  0.853691  0.151937  0.915927  0.917425  0.83485  0.859642  0.266692   0.146309  0.004402\n",
       " 26   P_BAD0     0    0.26  4702.0   709.0    69.0   480.0     0.985538     0.403701  0.0  0.389238  0.890025  0.596299  0.869463  0.131029  0.923591  0.917425  0.83485  0.859642  0.266692   0.130537  0.014462\n",
       " 27   P_BAD0     0    0.27  4664.0   606.0   107.0   583.0     0.977573     0.490328  0.0  0.467901  0.902093  0.509672  0.880369  0.114991  0.928991  0.917425  0.83485  0.859642  0.266692   0.119631  0.022427\n",
       " 28   P_BAD0     0    0.28  4664.0   606.0   107.0   583.0     0.977573     0.490328  0.0  0.467901  0.902093  0.509672  0.880369  0.114991  0.928991  0.917425  0.83485  0.859642  0.266692   0.119631  0.022427\n",
       " 29   P_BAD0     0    0.29  4664.0   606.0   107.0   583.0     0.977573     0.490328  0.0  0.467901  0.902093  0.509672  0.880369  0.114991  0.928991  0.917425  0.83485  0.859642  0.266692   0.119631  0.022427\n",
       " 30   P_BAD0     0    0.30  4664.0   606.0   107.0   583.0     0.977573     0.490328  0.0  0.467901  0.902093  0.509672  0.880369  0.114991  0.928991  0.917425  0.83485  0.859642  0.266692   0.119631  0.022427\n",
       " 31   P_BAD0     0    0.31  4664.0   606.0   107.0   583.0     0.977573     0.490328  0.0  0.467901  0.902093  0.509672  0.880369  0.114991  0.928991  0.917425  0.83485  0.859642  0.266692   0.119631  0.022427\n",
       " 32   P_BAD0     0    0.32  4664.0   606.0   107.0   583.0     0.977573     0.490328  0.0  0.467901  0.902093  0.509672  0.880369  0.114991  0.928991  0.917425  0.83485  0.859642  0.266692   0.119631  0.022427\n",
       " 33   P_BAD0     0    0.33  4664.0   606.0   107.0   583.0     0.977573     0.490328  0.0  0.467901  0.902093  0.509672  0.880369  0.114991  0.928991  0.917425  0.83485  0.859642  0.266692   0.119631  0.022427\n",
       " 34   P_BAD0     0    0.34  4664.0   606.0   107.0   583.0     0.977573     0.490328  0.0  0.467901  0.902093  0.509672  0.880369  0.114991  0.928991  0.917425  0.83485  0.859642  0.266692   0.119631  0.022427\n",
       " 35   P_BAD0     0    0.35  4664.0   606.0   107.0   583.0     0.977573     0.490328  0.0  0.467901  0.902093  0.509672  0.880369  0.114991  0.928991  0.917425  0.83485  0.859642  0.266692   0.119631  0.022427\n",
       " 36   P_BAD0     0    0.36  4664.0   606.0   107.0   583.0     0.977573     0.490328  0.0  0.467901  0.902093  0.509672  0.880369  0.114991  0.928991  0.917425  0.83485  0.859642  0.266692   0.119631  0.022427\n",
       " 37   P_BAD0     0    0.37  4664.0   606.0   107.0   583.0     0.977573     0.490328  0.0  0.467901  0.902093  0.509672  0.880369  0.114991  0.928991  0.917425  0.83485  0.859642  0.266692   0.119631  0.022427\n",
       " 38   P_BAD0     0    0.38  4664.0   606.0   107.0   583.0     0.977573     0.490328  0.0  0.467901  0.902093  0.509672  0.880369  0.114991  0.928991  0.917425  0.83485  0.859642  0.266692   0.119631  0.022427\n",
       " 39   P_BAD0     0    0.39  4664.0   606.0   107.0   583.0     0.977573     0.490328  0.0  0.467901  0.902093  0.509672  0.880369  0.114991  0.928991  0.917425  0.83485  0.859642  0.266692   0.119631  0.022427\n",
       " 40   P_BAD0     0    0.40  4664.0   606.0   107.0   583.0     0.977573     0.490328  0.0  0.467901  0.902093  0.509672  0.880369  0.114991  0.928991  0.917425  0.83485  0.859642  0.266692   0.119631  0.022427\n",
       " 41   P_BAD0     0    0.41  4660.0   600.0   111.0   589.0     0.976734     0.495374  0.0  0.472109  0.902716  0.504626  0.880705  0.114068  0.929120  0.917425  0.83485  0.859642  0.266692   0.119295  0.023266\n",
       " 42   P_BAD0     0    0.42  4660.0   600.0   111.0   589.0     0.976734     0.495374  0.0  0.472109  0.902716  0.504626  0.880705  0.114068  0.929120  0.917425  0.83485  0.859642  0.266692   0.119295  0.023266\n",
       " 43   P_BAD0     0    0.43  4657.0   596.0   114.0   593.0     0.976106     0.498738  0.0  0.474844  0.903114  0.501262  0.880872  0.113459  0.929170  0.917425  0.83485  0.859642  0.266692   0.119128  0.023894\n",
       " 44   P_BAD0     0    0.44  4657.0   596.0   114.0   593.0     0.976106     0.498738  0.0  0.474844  0.903114  0.501262  0.880872  0.113459  0.929170  0.917425  0.83485  0.859642  0.266692   0.119128  0.023894\n",
       " 45   P_BAD0     0    0.45  4653.0   591.0   118.0   598.0     0.975267     0.502944  0.0  0.478211  0.903600  0.497056  0.881040  0.112700  0.929206  0.917425  0.83485  0.859642  0.266692   0.118960  0.024733\n",
       " 46   P_BAD0     0    0.46  4653.0   591.0   118.0   598.0     0.975267     0.502944  0.0  0.478211  0.903600  0.497056  0.881040  0.112700  0.929206  0.917425  0.83485  0.859642  0.266692   0.118960  0.024733\n",
       " 47   P_BAD0     0    0.47  4653.0   591.0   118.0   598.0     0.975267     0.502944  0.0  0.478211  0.903600  0.497056  0.881040  0.112700  0.929206  0.917425  0.83485  0.859642  0.266692   0.118960  0.024733\n",
       " 48   P_BAD0     0    0.48  4653.0   591.0   118.0   598.0     0.975267     0.502944  0.0  0.478211  0.903600  0.497056  0.881040  0.112700  0.929206  0.917425  0.83485  0.859642  0.266692   0.118960  0.024733\n",
       " 49   P_BAD0     0    0.49  4653.0   591.0   118.0   598.0     0.975267     0.502944  0.0  0.478211  0.903600  0.497056  0.881040  0.112700  0.929206  0.917425  0.83485  0.859642  0.266692   0.118960  0.024733\n",
       " 50   P_BAD0     0    0.50  4653.0   591.0   118.0   598.0     0.975267     0.502944  0.0  0.478211  0.903600  0.497056  0.881040  0.112700  0.929206  0.917425  0.83485  0.859642  0.266692   0.118960  0.024733\n",
       " 51   P_BAD0     0    0.51  4640.0   578.0   131.0   611.0     0.972542     0.513877  0.0  0.486420  0.904730  0.486123  0.881040  0.110770  0.929022  0.917425  0.83485  0.859642  0.266692   0.118960  0.027458\n",
       " 52   P_BAD0     0    0.52  4590.0   531.0   181.0   658.0     0.962062     0.553406  0.0  0.515469  0.908731  0.446594  0.880537  0.103691  0.928023  0.917425  0.83485  0.859642  0.266692   0.119463  0.037938\n",
       " 53   P_BAD0     0    0.53  4590.0   531.0   181.0   658.0     0.962062     0.553406  0.0  0.515469  0.908731  0.446594  0.880537  0.103691  0.928023  0.917425  0.83485  0.859642  0.266692   0.119463  0.037938\n",
       " 54   P_BAD0     0    0.54  4590.0   531.0   181.0   658.0     0.962062     0.553406  0.0  0.515469  0.908731  0.446594  0.880537  0.103691  0.928023  0.917425  0.83485  0.859642  0.266692   0.119463  0.037938\n",
       " 55   P_BAD0     0    0.55  4584.0   526.0   187.0   663.0     0.960805     0.557611  0.0  0.518416  0.909127  0.442389  0.880369  0.102935  0.927841  0.917425  0.83485  0.859642  0.266692   0.119631  0.039195\n",
       " 56   P_BAD0     0    0.56  4579.0   522.0   192.0   667.0     0.959757     0.560976  0.0  0.520732  0.909434  0.439024  0.880201  0.102333  0.927674  0.917425  0.83485  0.859642  0.266692   0.119799  0.040243\n",
       " 57   P_BAD0     0    0.57  4579.0   522.0   192.0   667.0     0.959757     0.560976  0.0  0.520732  0.909434  0.439024  0.880201  0.102333  0.927674  0.917425  0.83485  0.859642  0.266692   0.119799  0.040243\n",
       " 58   P_BAD0     0    0.58  4218.0   257.0   553.0   932.0     0.884091     0.783852  0.0  0.667943  0.930263  0.216148  0.864094  0.057430  0.912395  0.917425  0.83485  0.859642  0.266692   0.135906  0.115909\n",
       " 59   P_BAD0     0    0.59  4218.0   257.0   553.0   932.0     0.884091     0.783852  0.0  0.667943  0.930263  0.216148  0.864094  0.057430  0.912395  0.917425  0.83485  0.859642  0.266692   0.135906  0.115909\n",
       " 60   P_BAD0     0    0.60  4218.0   257.0   553.0   932.0     0.884091     0.783852  0.0  0.667943  0.930263  0.216148  0.864094  0.057430  0.912395  0.917425  0.83485  0.859642  0.266692   0.135906  0.115909\n",
       " 61   P_BAD0     0    0.61  4197.0   243.0   574.0   946.0     0.879690     0.795627  0.0  0.675316  0.931383  0.204373  0.862919  0.054730  0.911302  0.917425  0.83485  0.859642  0.266692   0.137081  0.120310\n",
       " 62   P_BAD0     0    0.62  4197.0   243.0   574.0   946.0     0.879690     0.795627  0.0  0.675316  0.931383  0.204373  0.862919  0.054730  0.911302  0.917425  0.83485  0.859642  0.266692   0.137081  0.120310\n",
       " 63   P_BAD0     0    0.63  4192.0   240.0   579.0   949.0     0.878642     0.798150  0.0  0.676791  0.931597  0.201850  0.862584  0.054152  0.911007  0.917425  0.83485  0.859642  0.266692   0.137416  0.121358\n",
       " 64   P_BAD0     0    0.64  4192.0   240.0   579.0   949.0     0.878642     0.798150  0.0  0.676791  0.931597  0.201850  0.862584  0.054152  0.911007  0.917425  0.83485  0.859642  0.266692   0.137416  0.121358\n",
       " 65   P_BAD0     0    0.65  4170.0   228.0   601.0   961.0     0.874031     0.808242  0.0  0.682273  0.932344  0.191758  0.860906  0.051842  0.909587  0.917425  0.83485  0.859642  0.266692   0.139094  0.125969\n",
       " 66   P_BAD0     0    0.66  4170.0   228.0   601.0   961.0     0.874031     0.808242  0.0  0.682273  0.932344  0.191758  0.860906  0.051842  0.909587  0.917425  0.83485  0.859642  0.266692   0.139094  0.125969\n",
       " 67   P_BAD0     0    0.67  4146.0   216.0   625.0   973.0     0.869000     0.818335  0.0  0.687335  0.932985  0.181665  0.858893  0.049519  0.907916  0.917425  0.83485  0.859642  0.266692   0.141107  0.131000\n",
       " 68   P_BAD0     0    0.68  4146.0   216.0   625.0   973.0     0.869000     0.818335  0.0  0.687335  0.932985  0.181665  0.858893  0.049519  0.907916  0.917425  0.83485  0.859642  0.266692   0.141107  0.131000\n",
       " 69   P_BAD0     0    0.69  4146.0   216.0   625.0   973.0     0.869000     0.818335  0.0  0.687335  0.932985  0.181665  0.858893  0.049519  0.907916  0.917425  0.83485  0.859642  0.266692   0.141107  0.131000\n",
       " 70   P_BAD0     0    0.70  4146.0   216.0   625.0   973.0     0.869000     0.818335  0.0  0.687335  0.932985  0.181665  0.858893  0.049519  0.907916  0.917425  0.83485  0.859642  0.266692   0.141107  0.131000\n",
       " 71   P_BAD0     0    0.71  4146.0   216.0   625.0   973.0     0.869000     0.818335  0.0  0.687335  0.932985  0.181665  0.858893  0.049519  0.907916  0.917425  0.83485  0.859642  0.266692   0.141107  0.131000\n",
       " 72   P_BAD0     0    0.72  4131.0   210.0   640.0   979.0     0.865856     0.823381  0.0  0.689237  0.933138  0.176619  0.857383  0.048376  0.906716  0.917425  0.83485  0.859642  0.266692   0.142617  0.134144\n",
       " 73   P_BAD0     0    0.73  4123.0   207.0   648.0   982.0     0.864179     0.825904  0.0  0.690084  0.933185  0.174096  0.856544  0.047806  0.906054  0.917425  0.83485  0.859642  0.266692   0.143456  0.135821\n",
       " 74   P_BAD0     0    0.74  4123.0   207.0   648.0   982.0     0.864179     0.825904  0.0  0.690084  0.933185  0.174096  0.856544  0.047806  0.906054  0.917425  0.83485  0.859642  0.266692   0.143456  0.135821\n",
       " 75   P_BAD0     0    0.75  4123.0   207.0   648.0   982.0     0.864179     0.825904  0.0  0.690084  0.933185  0.174096  0.856544  0.047806  0.906054  0.917425  0.83485  0.859642  0.266692   0.143456  0.135821\n",
       " 76   P_BAD0     0    0.76  4087.0   195.0   684.0   994.0     0.856634     0.835997  0.0  0.692630  0.933148  0.164003  0.852517  0.045539  0.902905  0.917425  0.83485  0.859642  0.266692   0.147483  0.143366\n",
       " 77   P_BAD0     0    0.77  4087.0   195.0   684.0   994.0     0.856634     0.835997  0.0  0.692630  0.933148  0.164003  0.852517  0.045539  0.902905  0.917425  0.83485  0.859642  0.266692   0.147483  0.143366\n",
       " 78   P_BAD0     0    0.78  4073.0   191.0   698.0   998.0     0.853699     0.839361  0.0  0.693060  0.933019  0.160639  0.850839  0.044794  0.901605  0.917425  0.83485  0.859642  0.266692   0.149161  0.146301\n",
       " 79   P_BAD0     0    0.79  4073.0   191.0   698.0   998.0     0.853699     0.839361  0.0  0.693060  0.933019  0.160639  0.850839  0.044794  0.901605  0.917425  0.83485  0.859642  0.266692   0.149161  0.146301\n",
       " 80   P_BAD0     0    0.80  4073.0   191.0   698.0   998.0     0.853699     0.839361  0.0  0.693060  0.933019  0.160639  0.850839  0.044794  0.901605  0.917425  0.83485  0.859642  0.266692   0.149161  0.146301\n",
       " 81   P_BAD0     0    0.81  4025.0   179.0   746.0  1010.0     0.843639     0.849453  1.0  0.693092  0.932274  0.150547  0.844799  0.042578  0.896936  0.917425  0.83485  0.859642  0.266692   0.155201  0.156361\n",
       " 82   P_BAD0     0    0.82  4025.0   179.0   746.0  1010.0     0.843639     0.849453  0.0  0.693092  0.932274  0.150547  0.844799  0.042578  0.896936  0.917425  0.83485  0.859642  0.266692   0.155201  0.156361\n",
       " 83   P_BAD0     0    0.83  4025.0   179.0   746.0  1010.0     0.843639     0.849453  0.0  0.693092  0.932274  0.150547  0.844799  0.042578  0.896936  0.917425  0.83485  0.859642  0.266692   0.155201  0.156361\n",
       " 84   P_BAD0     0    0.84  3970.0   168.0   801.0  1021.0     0.832111     0.858705  0.0  0.690815  0.930920  0.141295  0.837416  0.040599  0.891234  0.917425  0.83485  0.859642  0.266692   0.162584  0.167889\n",
       " 85   P_BAD0     0    0.85  3938.0   162.0   833.0  1027.0     0.825403     0.863751  0.0  0.689155  0.930046  0.136249  0.833054  0.039512  0.887837  0.917425  0.83485  0.859642  0.266692   0.166946  0.174597\n",
       " 86   P_BAD0     0    0.86  3866.0   150.0   905.0  1039.0     0.810312     0.873844  0.0  0.684156  0.927766  0.126156  0.822987  0.037351  0.879936  0.917425  0.83485  0.859642  0.266692   0.177013  0.189688\n",
       " 87   P_BAD0     0    0.87  3829.0   144.0   942.0  1045.0     0.802557     0.878890  0.0  0.681447  0.926535  0.121110  0.817785  0.036245  0.875801  0.917425  0.83485  0.859642  0.266692   0.182215  0.197443\n",
       " 88   P_BAD0     0    0.88  3767.0   135.0  1004.0  1054.0     0.789562     0.886459  0.0  0.676021  0.924236  0.113541  0.808893  0.034598  0.868673  0.917425  0.83485  0.859642  0.266692   0.191107  0.210438\n",
       " 89   P_BAD0     0    0.89  3605.0   114.0  1166.0  1075.0     0.755607     0.904121  0.0  0.659728  0.917443  0.095879  0.785235  0.030653  0.849234  0.917425  0.83485  0.859642  0.266692   0.214765  0.244393\n",
       " 90   P_BAD0     0    0.90  3605.0   114.0  1166.0  1075.0     0.755607     0.904121  0.0  0.659728  0.917443  0.095879  0.785235  0.030653  0.849234  0.917425  0.83485  0.859642  0.266692   0.214765  0.244393\n",
       " 91   P_BAD0     0    0.91  3474.0   100.0  1297.0  1089.0     0.728149     0.915896  0.0  0.644045  0.910998  0.084104  0.765604  0.027980  0.832594  0.917425  0.83485  0.859642  0.266692   0.234396  0.271851\n",
       " 92   P_BAD0     0    0.92  3367.0    90.0  1404.0  1099.0     0.705722     0.924306  0.0  0.630028  0.905156  0.075694  0.749329  0.026034  0.818425  0.917425  0.83485  0.859642  0.266692   0.250671  0.294278\n",
       " 93   P_BAD0     0    0.93  3156.0    73.0  1615.0  1116.0     0.661497     0.938604  0.0  0.600100  0.892181  0.061396  0.716779  0.022608  0.789000  0.917425  0.83485  0.859642  0.266692   0.283221  0.338503\n",
       " 94   P_BAD0     0    0.94  2959.0    59.0  1812.0  1130.0     0.620205     0.950378  0.0  0.570584  0.878406  0.049622  0.686074  0.019549  0.759789  0.917425  0.83485  0.859642  0.266692   0.313926  0.379795\n",
       " 95   P_BAD0     0    0.95  2718.0    45.0  2053.0  1144.0     0.569692     0.962153  0.0  0.531845  0.858876  0.037847  0.647987  0.016287  0.721529  0.917425  0.83485  0.859642  0.266692   0.352013  0.430308\n",
       " 96   P_BAD0     0    0.96  2553.0    37.0  2218.0  1152.0     0.535108     0.968881  0.0  0.503989  0.843632  0.031119  0.621644  0.014286  0.693656  0.917425  0.83485  0.859642  0.266692   0.378356  0.464892\n",
       " 97   P_BAD0     0    0.97  2368.0    30.0  2403.0  1159.0     0.496332     0.974769  0.0  0.471101  0.824340  0.025231  0.591779  0.012510  0.660622  0.917425  0.83485  0.859642  0.266692   0.408221  0.503668\n",
       " 98   P_BAD0     0    0.98  1282.0     2.0  3489.0  1187.0     0.268707     0.998318  0.0  0.267025  0.647017  0.001682  0.414262  0.001558  0.423452  0.917425  0.83485  0.859642  0.266692   0.585738  0.731293\n",
       " 99   P_BAD0     0    0.99  1166.0     0.0  3605.0  1189.0     0.244393     1.000000  0.0  0.244393  0.617912  0.000000  0.395134  0.000000  0.392791  0.917425  0.83485  0.859642  0.266692   0.604866  0.755607,\n",
       "  Fit Statistics for _AUTOTUNE_DEFAULT_SCORE_TABLE_\n",
       " \n",
       "      NOBS       ASE     DIV      RASE      MCE      MCLL\n",
       " 0  5960.0  0.083021  5960.0  0.288133  0.11896  0.268032,\n",
       "  Tuner Information\n",
       " \n",
       "                            Parameter              Value\n",
       " 0                         Model Type      Decision Tree\n",
       " 1           Tuner Objective Function  Misclassification\n",
       " 2                      Search Method               GRID\n",
       " 3              Number of Grid Points                  6\n",
       " 4     Maximum Tuning Time in Seconds              36000\n",
       " 5                    Validation Type   Cross-Validation\n",
       " 6      Num Folds in Cross-Validation                  5\n",
       " 7                          Log Level                  0\n",
       " 8                               Seed         1876924690\n",
       " 9     Number of Parallel Evaluations                  4\n",
       " 10  Number of Workers per Subsession                  0,\n",
       "  Tuner Results\n",
       " \n",
       "    Evaluation  MAXLEVEL  NBINS       CRIT  MeanConseqError  EvaluationTime\n",
       " 0           0        11     20  gainRatio         0.139260        0.380601\n",
       " 1           6        15    100       gain         0.116296        1.072245\n",
       " 2           2        10    100       gain         0.117282        1.595850\n",
       " 3           5        10    100  gainRatio         0.122506        0.941197\n",
       " 4           1        15    100  gainRatio         0.124835        0.552839\n",
       " 5           3         5    100       gain         0.140584        0.594192\n",
       " 6           4         5    100  gainRatio         0.165438        1.099558,\n",
       "  Tuner Iteration History\n",
       " \n",
       "    Iteration  Evaluations  Best_obj  Time_sec\n",
       " 0          0            1  0.139260  0.380601\n",
       " 1          1            7  0.116296  2.046567,\n",
       "  Tuner Evaluation History\n",
       " \n",
       "    Evaluation  Iteration  MAXLEVEL  NBINS       CRIT  MeanConseqError  EvaluationTime\n",
       " 0           0          0        11     20  gainRatio         0.139260        0.380601\n",
       " 1           1          1        15    100  gainRatio         0.124835        0.552839\n",
       " 2           2          1        10    100       gain         0.117282        1.595850\n",
       " 3           3          1         5    100       gain         0.140584        0.594192\n",
       " 4           4          1         5    100  gainRatio         0.165438        1.099558\n",
       " 5           5          1        10    100  gainRatio         0.122506        0.941197\n",
       " 6           6          1        15    100       gain         0.116296        1.072245,\n",
       "  Best Configuration\n",
       " \n",
       "              Parameter        Name        Value\n",
       " 0           Evaluation  Evaluation            6\n",
       " 1  Maximum Tree Levels    MAXLEVEL           15\n",
       " 2         Maximum Bins       NBINS          100\n",
       " 3            Criterion        CRIT         gain\n",
       " 4    Misclassification   Objective  0.116295595,\n",
       "  Tuner Summary\n",
       " \n",
       "                                           Parameter     Value\n",
       " 0             Initial Configuration Objective Value  0.139260\n",
       " 1                Best Configuration Objective Value  0.116296\n",
       " 2               Worst Configuration Objective Value  0.165438\n",
       " 3  Initial Configuration Evaluation Time in Seconds  0.380601\n",
       " 4     Best Configuration Evaluation Time in Seconds  1.072237\n",
       " 5                 Number of Improved Configurations  4.000000\n",
       " 6                Number of Evaluated Configurations  7.000000\n",
       " 7                      Total Tuning Time in Seconds  2.143804\n",
       " 8                           Parallel Tuning Speedup  2.640009,\n",
       "  Tuner Task Timing\n",
       " \n",
       "                           Task  Time_sec  Time_percent\n",
       " 0               Model Training  3.969640     70.139171\n",
       " 1                Model Scoring  1.109903     19.610758\n",
       " 2  Total Objective Evaluations  5.085044     89.847139\n",
       " 3                        Tuner  0.574618     10.152861\n",
       " 4               Total CPU Time  5.659662    100.000000,\n",
       "  Hyperparameter Importance\n",
       " \n",
       "   Hyperparameter  RelImportance\n",
       " 0       MAXLEVEL       1.000000\n",
       " 1           CRIT       0.244249\n",
       " 2          NBINS       0.000000,\n",
       "  Gradient Boosting Tree for __TEMP_FEATURE_MACHINE_CASOUT___AUTOTUNE_DATA_11FA4B25-9848-604F-9F45-7E73830B6354\n",
       " \n",
       "                                   Descr         Value\n",
       " 0                       Number of Trees  1.500000e+02\n",
       " 1                          Distribution  2.000000e+00\n",
       " 2                         Learning Rate  1.000000e-01\n",
       " 3                      Subsampling Rate  6.000000e-01\n",
       " 4      Number of Selected Variables (M)  6.000000e+00\n",
       " 5                        Number of Bins  7.700000e+01\n",
       " 6                   Number of Variables  6.000000e+00\n",
       " 7              Max Number of Tree Nodes  9.700000e+01\n",
       " 8              Min Number of Tree Nodes  6.100000e+01\n",
       " 9                Max Number of Branches  2.000000e+00\n",
       " 10               Min Number of Branches  2.000000e+00\n",
       " 11                 Max Number of Levels  7.000000e+00\n",
       " 12                 Min Number of Levels  7.000000e+00\n",
       " 13                 Max Number of Leaves  4.900000e+01\n",
       " 14                 Min Number of Leaves  3.100000e+01\n",
       " 15               Maximum Size of Leaves  1.871000e+03\n",
       " 16               Minimum Size of Leaves  5.000000e+00\n",
       " 17                   Random Number Seed  1.876924e+09\n",
       " 18                   Lasso (L1) penalty  0.000000e+00\n",
       " 19                   Ridge (L2) penalty  0.000000e+00\n",
       " 20               Actual Number of Trees  3.700000e+01\n",
       " 21             Average number of Leaves  4.327027e+01\n",
       " 22            Early stopping stagnation  4.000000e+00\n",
       " 23             Early stopping threshold  0.000000e+00\n",
       " 24  Early stopping threshold iterations  0.000000e+00\n",
       " 25             Early stopping tolerance  0.000000e+00,\n",
       "      Progress    Metric\n",
       " 0        1.0  0.199497\n",
       " 1        2.0  0.199497\n",
       " 2        3.0  0.199497\n",
       " 3        4.0  0.199329\n",
       " 4        5.0  0.171477\n",
       " 5        6.0  0.150671\n",
       " 6        7.0  0.133557\n",
       " 7        8.0  0.122819\n",
       " 8        9.0  0.122651\n",
       " 9       10.0  0.122315\n",
       " 10      11.0  0.122148\n",
       " 11      12.0  0.121980\n",
       " 12      13.0  0.121644\n",
       " 13      14.0  0.121477\n",
       " 14      15.0  0.120973\n",
       " 15      16.0  0.120638\n",
       " 16      17.0  0.120805\n",
       " 17      18.0  0.120805\n",
       " 18      19.0  0.120470\n",
       " 19      20.0  0.120470\n",
       " 20      21.0  0.120302\n",
       " 21      22.0  0.120302\n",
       " 22      23.0  0.119966\n",
       " 23      24.0  0.119799\n",
       " 24      25.0  0.119799\n",
       " 25      26.0  0.119631\n",
       " 26      27.0  0.119295\n",
       " 27      28.0  0.119295\n",
       " 28      29.0  0.119128\n",
       " 29      30.0  0.118960\n",
       " 30      31.0  0.118960\n",
       " 31      32.0  0.118960\n",
       " 32      33.0  0.118792\n",
       " 33      34.0  0.118792\n",
       " 34      35.0  0.118624\n",
       " 35      36.0  0.118624\n",
       " 36      37.0  0.118456,\n",
       "                           Descr                             Value\n",
       " 0  Number of Observations Read                              5960\n",
       " 1  Number of Observations Used                              5960\n",
       " 2  Misclassification Error (%)                      11.845637584,\n",
       "      TreeID  Trees  NLeaves       MCR   LogLoss       ASE      RASE     MAXAE\n",
       " 0      0.0    1.0     34.0  0.199497  0.458062  0.145324  0.381213  0.819707\n",
       " 1      1.0    2.0     77.0  0.199497  0.428302  0.134097  0.366193  0.837039\n",
       " 2      2.0    3.0    117.0  0.199497  0.405943  0.125369  0.354075  0.846872\n",
       " 3      3.0    4.0    166.0  0.199329  0.387308  0.118036  0.343564  0.858878\n",
       " 4      4.0    5.0    211.0  0.171477  0.372489  0.112284  0.335088  0.872428\n",
       " 5      5.0    6.0    260.0  0.150671  0.360248  0.107613  0.328044  0.882384\n",
       " 6      6.0    7.0    300.0  0.133557  0.350278  0.103854  0.322264  0.891237\n",
       " 7      7.0    8.0    348.0  0.122819  0.341928  0.100908  0.317660  0.899596\n",
       " 8      8.0    9.0    396.0  0.122651  0.334594  0.098382  0.313658  0.907467\n",
       " 9      9.0   10.0    443.0  0.122315  0.328321  0.096282  0.310294  0.916313\n",
       " 10    10.0   11.0    481.0  0.122148  0.323144  0.094602  0.307574  0.921580\n",
       " 11    11.0   12.0    530.0  0.121980  0.318625  0.093240  0.305352  0.929089\n",
       " 12    12.0   13.0    573.0  0.121644  0.314815  0.092159  0.303577  0.931408\n",
       " 13    13.0   14.0    616.0  0.121477  0.311302  0.091184  0.301967  0.937955\n",
       " 14    14.0   15.0    659.0  0.120973  0.307892  0.090244  0.300406  0.942256\n",
       " 15    15.0   16.0    706.0  0.120638  0.305183  0.089545  0.299241  0.946963\n",
       " 16    16.0   17.0    747.0  0.120805  0.302956  0.088980  0.298296  0.952085\n",
       " 17    17.0   18.0    794.0  0.120805  0.301044  0.088502  0.297493  0.953885\n",
       " 18    18.0   19.0    841.0  0.120470  0.299184  0.088080  0.296783  0.956635\n",
       " 19    19.0   20.0    882.0  0.120302  0.297550  0.087684  0.296115  0.958109\n",
       " 20    20.0   21.0    925.0  0.120302  0.296313  0.087438  0.295699  0.960262\n",
       " 21    21.0   22.0    967.0  0.120302  0.295120  0.087197  0.295292  0.961652\n",
       " 22    22.0   23.0   1015.0  0.119966  0.293888  0.086912  0.294808  0.962634\n",
       " 23    23.0   24.0   1060.0  0.119799  0.292774  0.086669  0.294395  0.963763\n",
       " 24    24.0   25.0   1105.0  0.119799  0.291821  0.086470  0.294058  0.966357\n",
       " 25    25.0   26.0   1148.0  0.119631  0.290800  0.086251  0.293686  0.966103\n",
       " 26    26.0   27.0   1185.0  0.119295  0.290096  0.086056  0.293353  0.966959\n",
       " 27    27.0   28.0   1227.0  0.119295  0.289363  0.085925  0.293130  0.967952\n",
       " 28    28.0   29.0   1271.0  0.119128  0.288501  0.085716  0.292773  0.968597\n",
       " 29    29.0   30.0   1305.0  0.118960  0.288133  0.085657  0.292673  0.971593\n",
       " 30    30.0   31.0   1336.0  0.118960  0.287502  0.085548  0.292486  0.972649\n",
       " 31    31.0   32.0   1384.0  0.118960  0.286716  0.085372  0.292184  0.975305\n",
       " 32    32.0   33.0   1423.0  0.118792  0.286178  0.085270  0.292011  0.973893\n",
       " 33    33.0   34.0   1470.0  0.118792  0.285672  0.085197  0.291886  0.975078\n",
       " 34    34.0   35.0   1514.0  0.118624  0.285183  0.085085  0.291693  0.974935\n",
       " 35    35.0   36.0   1555.0  0.118624  0.284793  0.085021  0.291583  0.977051\n",
       " 36    36.0   37.0   1601.0  0.118456  0.284300  0.084931  0.291429  0.977485,\n",
       "          LEVNAME  LEVINDEX VARNAME\n",
       " 0             1         0  P_BAD1\n",
       " 1             0         1  P_BAD0,\n",
       "    LEVNAME  LEVINDEX VARNAME\n",
       " 0                 0   I_BAD,\n",
       "  ROC Information for _AUTOTUNE_DEFAULT_SCORE_TABLE_\n",
       " \n",
       "    Variable Event  CutOff      TP      FP      FN      TN  Sensitivity  Specificity   KS       KS2    F_HALF       FPR       ACC       FDR        F1         C      Gini     Gamma       Tau  MISCEVENT       FNR\n",
       " 0    P_BAD0     0    0.00  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.904484  0.808969  0.836393  0.258424   0.199497  0.000000\n",
       " 1    P_BAD0     0    0.01  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.904484  0.808969  0.836393  0.258424   0.199497  0.000000\n",
       " 2    P_BAD0     0    0.02  4771.0  1188.0     0.0     1.0     1.000000     0.000841  0.0  0.000841  0.833887  0.999159  0.800671  0.199362  0.889282  0.904484  0.808969  0.836393  0.258424   0.199329  0.000000\n",
       " 3    P_BAD0     0    0.03  4771.0  1158.0     0.0    31.0     1.000000     0.026072  0.0  0.026072  0.837400  0.973928  0.805705  0.195311  0.891776  0.904484  0.808969  0.836393  0.258424   0.194295  0.000000\n",
       " 4    P_BAD0     0    0.04  4771.0  1111.0     0.0    78.0     1.000000     0.065601  0.0  0.065601  0.842963  0.934399  0.813591  0.188881  0.895710  0.904484  0.808969  0.836393  0.258424   0.186409  0.000000\n",
       " 5    P_BAD0     0    0.05  4771.0  1086.0     0.0   103.0     1.000000     0.086627  0.0  0.086627  0.845952  0.913373  0.817785  0.185419  0.897817  0.904484  0.808969  0.836393  0.258424   0.182215  0.000000\n",
       " 6    P_BAD0     0    0.06  4771.0  1083.0     0.0   106.0     1.000000     0.089151  0.0  0.089151  0.846312  0.910849  0.818289  0.185002  0.898071  0.904484  0.808969  0.836393  0.258424   0.181711  0.000000\n",
       " 7    P_BAD0     0    0.07  4771.0  1074.0     0.0   115.0     1.000000     0.096720  0.0  0.096720  0.847394  0.903280  0.819799  0.183747  0.898832  0.904484  0.808969  0.836393  0.258424   0.180201  0.000000\n",
       " 8    P_BAD0     0    0.08  4771.0  1068.0     0.0   121.0     1.000000     0.101766  0.0  0.101766  0.848117  0.898234  0.820805  0.182908  0.899340  0.904484  0.808969  0.836393  0.258424   0.179195  0.000000\n",
       " 9    P_BAD0     0    0.09  4771.0  1062.0     0.0   127.0     1.000000     0.106812  0.0  0.106812  0.848842  0.893188  0.821812  0.182068  0.899849  0.904484  0.808969  0.836393  0.258424   0.178188  0.000000\n",
       " 10   P_BAD0     0    0.10  4768.0  1026.0     3.0   163.0     0.999371     0.137090  0.0  0.136461  0.853043  0.862910  0.827349  0.177080  0.902603  0.904484  0.808969  0.836393  0.258424   0.172651  0.000629\n",
       " 11   P_BAD0     0    0.11  4766.0  1004.0     5.0   185.0     0.998952     0.155593  0.0  0.154545  0.855625  0.844407  0.830705  0.174003  0.904279  0.904484  0.808969  0.836393  0.258424   0.169295  0.001048\n",
       " 12   P_BAD0     0    0.12  4766.0  1002.0     5.0   187.0     0.998952     0.157275  0.0  0.156227  0.855870  0.842725  0.831040  0.173717  0.904450  0.904484  0.808969  0.836393  0.258424   0.168960  0.001048\n",
       " 13   P_BAD0     0    0.13  4766.0  1002.0     5.0   187.0     0.998952     0.157275  0.0  0.156227  0.855870  0.842725  0.831040  0.173717  0.904450  0.904484  0.808969  0.836393  0.258424   0.168960  0.001048\n",
       " 14   P_BAD0     0    0.14  4756.0   916.0    15.0   273.0     0.996856     0.229605  0.0  0.226461  0.866018  0.770395  0.843792  0.161495  0.910849  0.904484  0.808969  0.836393  0.258424   0.156208  0.003144\n",
       " 15   P_BAD0     0    0.15  4751.0   882.0    20.0   307.0     0.995808     0.258200  0.0  0.254008  0.870051  0.741800  0.848658  0.156577  0.913303  0.904484  0.808969  0.836393  0.258424   0.151342  0.004192\n",
       " 16   P_BAD0     0    0.16  4748.0   865.0    23.0   324.0     0.995179     0.272498  0.0  0.267677  0.872057  0.727502  0.851007  0.154107  0.914484  0.904484  0.808969  0.836393  0.258424   0.148993  0.004821\n",
       " 17   P_BAD0     0    0.17  4748.0   864.0    23.0   325.0     0.995179     0.273339  0.0  0.268518  0.872185  0.726661  0.851174  0.153956  0.914572  0.904484  0.808969  0.836393  0.258424   0.148826  0.004821\n",
       " 18   P_BAD0     0    0.18  4748.0   864.0    23.0   325.0     0.995179     0.273339  0.0  0.268518  0.872185  0.726661  0.851174  0.153956  0.914572  0.904484  0.808969  0.836393  0.258424   0.148826  0.004821\n",
       " 19   P_BAD0     0    0.19  4748.0   863.0    23.0   326.0     0.995179     0.274180  0.0  0.269359  0.872313  0.725820  0.851342  0.153805  0.914660  0.904484  0.808969  0.836393  0.258424   0.148658  0.004821\n",
       " 20   P_BAD0     0    0.20  4748.0   860.0    23.0   329.0     0.995179     0.276703  0.0  0.271882  0.872698  0.723297  0.851846  0.153352  0.914924  0.904484  0.808969  0.836393  0.258424   0.148154  0.004821\n",
       " 21   P_BAD0     0    0.21  4748.0   858.0    23.0   331.0     0.995179     0.278385  0.0  0.273564  0.872955  0.721615  0.852181  0.153050  0.915101  0.904484  0.808969  0.836393  0.258424   0.147819  0.004821\n",
       " 22   P_BAD0     0    0.22  4747.0   857.0    24.0   332.0     0.994970     0.279226  0.0  0.274196  0.873028  0.720774  0.852181  0.152926  0.915084  0.904484  0.808969  0.836393  0.258424   0.147819  0.005030\n",
       " 23   P_BAD0     0    0.23  4747.0   857.0    24.0   332.0     0.994970     0.279226  0.0  0.274196  0.873028  0.720774  0.852181  0.152926  0.915084  0.904484  0.808969  0.836393  0.258424   0.147819  0.005030\n",
       " 24   P_BAD0     0    0.24  4747.0   855.0    24.0   334.0     0.994970     0.280908  0.0  0.275878  0.873285  0.719092  0.852517  0.152624  0.915261  0.904484  0.808969  0.836393  0.258424   0.147483  0.005030\n",
       " 25   P_BAD0     0    0.25  4745.0   849.0    26.0   340.0     0.994550     0.285955  0.0  0.280505  0.873946  0.714045  0.853188  0.151770  0.915581  0.904484  0.808969  0.836393  0.258424   0.146812  0.005450\n",
       " 26   P_BAD0     0    0.26  4732.0   813.0    39.0   376.0     0.991826     0.316232  0.0  0.308058  0.877890  0.683768  0.857047  0.146619  0.917410  0.904484  0.808969  0.836393  0.258424   0.142953  0.008174\n",
       " 27   P_BAD0     0    0.27  4694.0   709.0    77.0   480.0     0.983861     0.403701  0.0  0.387561  0.889588  0.596299  0.868121  0.131223  0.922744  0.904484  0.808969  0.836393  0.258424   0.131879  0.016139\n",
       " 28   P_BAD0     0    0.28  4694.0   709.0    77.0   480.0     0.983861     0.403701  0.0  0.387561  0.889588  0.596299  0.868121  0.131223  0.922744  0.904484  0.808969  0.836393  0.258424   0.131879  0.016139\n",
       " 29   P_BAD0     0    0.29  4661.0   613.0   110.0   576.0     0.976944     0.484441  0.0  0.461385  0.900955  0.515559  0.878691  0.116231  0.928024  0.904484  0.808969  0.836393  0.258424   0.121309  0.023056\n",
       " 30   P_BAD0     0    0.30  4661.0   610.0   110.0   579.0     0.976944     0.486964  0.0  0.463908  0.901373  0.513036  0.879195  0.115728  0.928301  0.904484  0.808969  0.836393  0.258424   0.120805  0.023056\n",
       " 31   P_BAD0     0    0.31  4660.0   610.0   111.0   579.0     0.976734     0.486964  0.0  0.463698  0.901319  0.513036  0.879027  0.115750  0.928194  0.904484  0.808969  0.836393  0.258424   0.120973  0.023266\n",
       " 32   P_BAD0     0    0.32  4660.0   609.0   111.0   580.0     0.976734     0.487805  0.0  0.464539  0.901459  0.512195  0.879195  0.115582  0.928287  0.904484  0.808969  0.836393  0.258424   0.120805  0.023266\n",
       " 33   P_BAD0     0    0.33  4660.0   609.0   111.0   580.0     0.976734     0.487805  0.0  0.464539  0.901459  0.512195  0.879195  0.115582  0.928287  0.904484  0.808969  0.836393  0.258424   0.120805  0.023266\n",
       " 34   P_BAD0     0    0.34  4660.0   609.0   111.0   580.0     0.976734     0.487805  0.0  0.464539  0.901459  0.512195  0.879195  0.115582  0.928287  0.904484  0.808969  0.836393  0.258424   0.120805  0.023266\n",
       " 35   P_BAD0     0    0.35  4660.0   609.0   111.0   580.0     0.976734     0.487805  0.0  0.464539  0.901459  0.512195  0.879195  0.115582  0.928287  0.904484  0.808969  0.836393  0.258424   0.120805  0.023266\n",
       " 36   P_BAD0     0    0.36  4660.0   608.0   111.0   581.0     0.976734     0.488646  0.0  0.465380  0.901598  0.511354  0.879362  0.115414  0.928379  0.904484  0.808969  0.836393  0.258424   0.120638  0.023266\n",
       " 37   P_BAD0     0    0.37  4660.0   607.0   111.0   582.0     0.976734     0.489487  0.0  0.466221  0.901738  0.510513  0.879530  0.115246  0.928472  0.904484  0.808969  0.836393  0.258424   0.120470  0.023266\n",
       " 38   P_BAD0     0    0.38  4660.0   607.0   111.0   582.0     0.976734     0.489487  0.0  0.466221  0.901738  0.510513  0.879530  0.115246  0.928472  0.904484  0.808969  0.836393  0.258424   0.120470  0.023266\n",
       " 39   P_BAD0     0    0.39  4660.0   605.0   111.0   584.0     0.976734     0.491169  0.0  0.467903  0.902017  0.508831  0.879866  0.114910  0.928657  0.904484  0.808969  0.836393  0.258424   0.120134  0.023266\n",
       " 40   P_BAD0     0    0.40  4654.0   599.0   117.0   590.0     0.975477     0.496215  0.0  0.471692  0.902533  0.503785  0.879866  0.114030  0.928571  0.904484  0.808969  0.836393  0.258424   0.120134  0.024523\n",
       " 41   P_BAD0     0    0.41  4652.0   596.0   119.0   593.0     0.975058     0.498738  0.0  0.473796  0.902845  0.501262  0.880034  0.113567  0.928636  0.904484  0.808969  0.836393  0.258424   0.119966  0.024942\n",
       " 42   P_BAD0     0    0.42  4651.0   593.0   120.0   596.0     0.974848     0.501262  0.0  0.476110  0.903212  0.498738  0.880369  0.113082  0.928807  0.904484  0.808969  0.836393  0.258424   0.119631  0.025152\n",
       " 43   P_BAD0     0    0.43  4650.0   591.0   121.0   598.0     0.974638     0.502944  0.0  0.477582  0.903439  0.497056  0.880537  0.112765  0.928885  0.904484  0.808969  0.836393  0.258424   0.119463  0.025362\n",
       " 44   P_BAD0     0    0.44  4648.0   588.0   123.0   601.0     0.974219     0.505467  0.0  0.479686  0.903753  0.494533  0.880705  0.112299  0.928950  0.904484  0.808969  0.836393  0.258424   0.119295  0.025781\n",
       " 45   P_BAD0     0    0.45  4648.0   587.0   123.0   602.0     0.974219     0.506308  0.0  0.480527  0.903893  0.493692  0.880872  0.112130  0.929043  0.904484  0.808969  0.836393  0.258424   0.119128  0.025781\n",
       " 46   P_BAD0     0    0.46  4648.0   586.0   123.0   603.0     0.974219     0.507149  0.0  0.481368  0.904034  0.492851  0.881040  0.111960  0.929135  0.904484  0.808969  0.836393  0.258424   0.118960  0.025781\n",
       " 47   P_BAD0     0    0.47  4648.0   586.0   123.0   603.0     0.974219     0.507149  0.0  0.481368  0.904034  0.492851  0.881040  0.111960  0.929135  0.904484  0.808969  0.836393  0.258424   0.118960  0.025781\n",
       " 48   P_BAD0     0    0.48  4645.0   582.0   126.0   607.0     0.973590     0.510513  0.0  0.484103  0.904436  0.489487  0.881208  0.111345  0.929186  0.904484  0.808969  0.836393  0.258424   0.118792  0.026410\n",
       " 49   P_BAD0     0    0.49  4645.0   581.0   126.0   608.0     0.973590     0.511354  0.0  0.484945  0.904576  0.488646  0.881376  0.111175  0.929279  0.904484  0.808969  0.836393  0.258424   0.118624  0.026410\n",
       " 50   P_BAD0     0    0.50  4645.0   580.0   126.0   609.0     0.973590     0.512195  0.0  0.485786  0.904717  0.487805  0.881544  0.111005  0.929372  0.904484  0.808969  0.836393  0.258424   0.118456  0.026410\n",
       " 51   P_BAD0     0    0.51  4645.0   580.0   126.0   609.0     0.973590     0.512195  0.0  0.485786  0.904717  0.487805  0.881544  0.111005  0.929372  0.904484  0.808969  0.836393  0.258424   0.118456  0.026410\n",
       " 52   P_BAD0     0    0.52  4645.0   579.0   126.0   610.0     0.973590     0.513036  0.0  0.486627  0.904858  0.486964  0.881711  0.110835  0.929465  0.904484  0.808969  0.836393  0.258424   0.118289  0.026410\n",
       " 53   P_BAD0     0    0.53  4645.0   579.0   126.0   610.0     0.973590     0.513036  0.0  0.486627  0.904858  0.486964  0.881711  0.110835  0.929465  0.904484  0.808969  0.836393  0.258424   0.118289  0.026410\n",
       " 54   P_BAD0     0    0.54  4645.0   578.0   126.0   611.0     0.973590     0.513877  0.0  0.487468  0.904999  0.486123  0.881879  0.110664  0.929558  0.904484  0.808969  0.836393  0.258424   0.118121  0.026410\n",
       " 55   P_BAD0     0    0.55  4594.0   532.0   177.0   657.0     0.962901     0.552565  0.0  0.515466  0.908803  0.447435  0.881040  0.103785  0.928362  0.904484  0.808969  0.836393  0.258424   0.118960  0.037099\n",
       " 56   P_BAD0     0    0.56  4593.0   532.0   178.0   657.0     0.962691     0.552565  0.0  0.515256  0.908749  0.447435  0.880872  0.103805  0.928254  0.904484  0.808969  0.836393  0.258424   0.119128  0.037309\n",
       " 57   P_BAD0     0    0.57  4593.0   532.0   178.0   657.0     0.962691     0.552565  0.0  0.515256  0.908749  0.447435  0.880872  0.103805  0.928254  0.904484  0.808969  0.836393  0.258424   0.119128  0.037309\n",
       " 58   P_BAD0     0    0.58  4233.0   269.0   538.0   920.0     0.887235     0.773759  0.0  0.660995  0.929145  0.226241  0.864597  0.059751  0.912973  0.904484  0.808969  0.836393  0.258424   0.135403  0.112765\n",
       " 59   P_BAD0     0    0.59  4233.0   268.0   538.0   921.0     0.887235     0.774601  0.0  0.661836  0.929308  0.225399  0.864765  0.059542  0.913072  0.904484  0.808969  0.836393  0.258424   0.135235  0.112765\n",
       " 60   P_BAD0     0    0.60  4232.0   266.0   539.0   923.0     0.887026     0.776283  0.0  0.663308  0.929579  0.223717  0.864933  0.059137  0.913151  0.904484  0.808969  0.836393  0.258424   0.135067  0.112974\n",
       " 61   P_BAD0     0    0.61  4229.0   262.0   542.0   927.0     0.886397     0.779647  0.0  0.666044  0.930064  0.220353  0.865101  0.058339  0.913194  0.904484  0.808969  0.836393  0.258424   0.134899  0.113603\n",
       " 62   P_BAD0     0    0.62  4226.0   261.0   545.0   928.0     0.885768     0.780488  0.0  0.666256  0.930059  0.219512  0.864765  0.058168  0.912940  0.904484  0.808969  0.836393  0.258424   0.135235  0.114232\n",
       " 63   P_BAD0     0    0.63  4226.0   260.0   545.0   929.0     0.885768     0.781329  0.0  0.667097  0.930222  0.218671  0.864933  0.057958  0.913039  0.904484  0.808969  0.836393  0.258424   0.135067  0.114232\n",
       " 64   P_BAD0     0    0.64  4226.0   260.0   545.0   929.0     0.885768     0.781329  0.0  0.667097  0.930222  0.218671  0.864933  0.057958  0.913039  0.904484  0.808969  0.836393  0.258424   0.135067  0.114232\n",
       " 65   P_BAD0     0    0.65  4223.0   257.0   548.0   932.0     0.885139     0.783852  0.0  0.668991  0.930545  0.216148  0.864933  0.057366  0.912982  0.904484  0.808969  0.836393  0.258424   0.135067  0.114861\n",
       " 66   P_BAD0     0    0.66  4218.0   253.0   553.0   936.0     0.884091     0.787216  0.0  0.671308  0.930920  0.212784  0.864765  0.056587  0.912789  0.904484  0.808969  0.836393  0.258424   0.135235  0.115909\n",
       " 67   P_BAD0     0    0.67  4211.0   248.0   560.0   941.0     0.882624     0.791421  0.0  0.674046  0.931349  0.208579  0.864430  0.055618  0.912459  0.904484  0.808969  0.836393  0.258424   0.135570  0.117376\n",
       " 68   P_BAD0     0    0.68  4208.0   246.0   563.0   943.0     0.881995     0.793103  0.0  0.675099  0.931509  0.206897  0.864262  0.055231  0.912304  0.904484  0.808969  0.836393  0.258424   0.135738  0.118005\n",
       " 69   P_BAD0     0    0.69  4200.0   246.0   571.0   943.0     0.880319     0.793103  0.0  0.673422  0.931057  0.206897  0.862919  0.055331  0.911359  0.904484  0.808969  0.836393  0.258424   0.137081  0.119681\n",
       " 70   P_BAD0     0    0.70  4185.0   239.0   586.0   950.0     0.877175     0.798991  0.0  0.676165  0.931366  0.201009  0.861577  0.054024  0.910277  0.904484  0.808969  0.836393  0.258424   0.138423  0.122825\n",
       " 71   P_BAD0     0    0.71  4181.0   238.0   590.0   951.0     0.876336     0.799832  0.0  0.676168  0.931305  0.200168  0.861074  0.053858  0.909902  0.904484  0.808969  0.836393  0.258424   0.138926  0.123664\n",
       " 72   P_BAD0     0    0.72  4171.0   234.0   600.0   955.0     0.874240     0.803196  0.0  0.677436  0.931401  0.196804  0.860067  0.053121  0.909111  0.904484  0.808969  0.836393  0.258424   0.139933  0.125760\n",
       " 73   P_BAD0     0    0.73  4169.0   233.0   602.0   956.0     0.873821     0.804037  0.0  0.677858  0.931454  0.195963  0.859899  0.052930  0.908972  0.904484  0.808969  0.836393  0.258424   0.140101  0.126179\n",
       " 74   P_BAD0     0    0.74  4168.0   231.0   603.0   958.0     0.873611     0.805719  0.0  0.679330  0.931730  0.194281  0.860067  0.052512  0.909051  0.904484  0.808969  0.836393  0.258424   0.139933  0.126389\n",
       " 75   P_BAD0     0    0.75  4165.0   229.0   606.0   960.0     0.872983     0.807401  0.0  0.680384  0.931892  0.192599  0.859899  0.052117  0.908893  0.904484  0.808969  0.836393  0.258424   0.140101  0.127017\n",
       " 76   P_BAD0     0    0.76  4118.0   214.0   653.0   975.0     0.863131     0.820017  0.0  0.683148  0.931716  0.179983  0.854530  0.049400  0.904757  0.904484  0.808969  0.836393  0.258424   0.145470  0.136869\n",
       " 77   P_BAD0     0    0.77  4111.0   212.0   660.0   977.0     0.861664     0.821699  0.0  0.683363  0.931650  0.178301  0.853691  0.049040  0.904113  0.904484  0.808969  0.836393  0.258424   0.146309  0.138336\n",
       " 78   P_BAD0     0    0.78  4106.0   210.0   665.0   979.0     0.860616     0.823381  0.0  0.683997  0.931700  0.176619  0.853188  0.048656  0.903709  0.904484  0.808969  0.836393  0.258424   0.146812  0.139384\n",
       " 79   P_BAD0     0    0.79  4098.0   207.0   673.0   982.0     0.858939     0.825904  0.0  0.684844  0.931745  0.174096  0.852349  0.048084  0.903041  0.904484  0.808969  0.836393  0.258424   0.147651  0.141061\n",
       " 80   P_BAD0     0    0.80  4090.0   204.0   681.0   985.0     0.857263     0.828427  0.0  0.685690  0.931790  0.171573  0.851510  0.047508  0.902372  0.904484  0.808969  0.836393  0.258424   0.148490  0.142737\n",
       " 81   P_BAD0     0    0.81  4077.0   200.0   694.0   989.0     0.854538     0.831791  1.0  0.686329  0.931715  0.168209  0.850000  0.046762  0.901194  0.904484  0.808969  0.836393  0.258424   0.150000  0.145462\n",
       " 82   P_BAD0     0    0.82  4064.0   198.0   707.0   991.0     0.851813     0.833474  0.0  0.685287  0.931298  0.166526  0.848154  0.046457  0.899812  0.904484  0.808969  0.836393  0.258424   0.151846  0.148187\n",
       " 83   P_BAD0     0    0.83  4057.0   197.0   714.0   992.0     0.850346     0.834315  0.0  0.684660  0.931060  0.165685  0.847148  0.046309  0.899058  0.904484  0.808969  0.836393  0.258424   0.152852  0.149654\n",
       " 84   P_BAD0     0    0.84  4031.0   191.0   740.0   998.0     0.844896     0.839361  0.0  0.684257  0.930560  0.160639  0.843792  0.045239  0.896475  0.904484  0.808969  0.836393  0.258424   0.156208  0.155104\n",
       " 85   P_BAD0     0    0.85  3999.0   185.0   772.0  1004.0     0.838189     0.844407  0.0  0.682596  0.929697  0.155593  0.839430  0.044216  0.893132  0.904484  0.808969  0.836393  0.258424   0.160570  0.161811\n",
       " 86   P_BAD0     0    0.86  3925.0   175.0   846.0  1014.0     0.822679     0.852817  0.0  0.675496  0.926976  0.147183  0.828691  0.042683  0.884906  0.904484  0.808969  0.836393  0.258424   0.171309  0.177321\n",
       " 87   P_BAD0     0    0.87  3899.0   172.0   872.0  1017.0     0.817229     0.855341  0.0  0.672570  0.925908  0.144659  0.824832  0.042250  0.881927  0.904484  0.808969  0.836393  0.258424   0.175168  0.182771\n",
       " 88   P_BAD0     0    0.88  3873.0   168.0   898.0  1021.0     0.811780     0.858705  0.0  0.670484  0.925006  0.141295  0.821141  0.041574  0.879029  0.904484  0.808969  0.836393  0.258424   0.178859  0.188220\n",
       " 89   P_BAD0     0    0.89  3835.0   165.0   936.0  1024.0     0.803815     0.861228  0.0  0.665043  0.923162  0.138772  0.815268  0.041250  0.874473  0.904484  0.808969  0.836393  0.258424   0.184732  0.196185\n",
       " 90   P_BAD0     0    0.90  3746.0   151.0  1025.0  1038.0     0.785160     0.873003  0.0  0.658163  0.919986  0.126997  0.802685  0.038748  0.864329  0.904484  0.808969  0.836393  0.258424   0.197315  0.214840\n",
       " 91   P_BAD0     0    0.91  3588.0   130.0  1183.0  1059.0     0.752044     0.890664  0.0  0.642708  0.913302  0.109336  0.779698  0.034965  0.845329  0.904484  0.808969  0.836393  0.258424   0.220302  0.247956\n",
       " 92   P_BAD0     0    0.92  3511.0   123.0  1260.0  1066.0     0.735904     0.896552  0.0  0.632456  0.909256  0.103448  0.767953  0.033847  0.835455  0.904484  0.808969  0.836393  0.258424   0.232047  0.264096\n",
       " 93   P_BAD0     0    0.93  3261.0   108.0  1510.0  1081.0     0.683505     0.909167  0.0  0.592672  0.893572  0.090833  0.728523  0.032057  0.801229  0.904484  0.808969  0.836393  0.258424   0.271477  0.316495\n",
       " 94   P_BAD0     0    0.94  2641.0    70.0  2130.0  1119.0     0.553553     0.941127  0.0  0.494680  0.845661  0.058873  0.630872  0.025821  0.705961  0.904484  0.808969  0.836393  0.258424   0.369128  0.446447\n",
       " 95   P_BAD0     0    0.95  2029.0    40.0  2742.0  1149.0     0.425278     0.966358  0.0  0.391636  0.777573  0.033642  0.533221  0.019333  0.593275  0.904484  0.808969  0.836393  0.258424   0.466779  0.574722\n",
       " 96   P_BAD0     0    0.96  1664.0    28.0  3107.0  1161.0     0.348774     0.976451  0.0  0.325225  0.721033  0.023549  0.473993  0.016548  0.514931  0.904484  0.808969  0.836393  0.258424   0.526007  0.651226\n",
       " 97   P_BAD0     0    0.97   817.0     8.0  3954.0  1181.0     0.171243     0.993272  0.0  0.164515  0.506133  0.006728  0.335235  0.009697  0.291994  0.904484  0.808969  0.836393  0.258424   0.664765  0.828757\n",
       " 98   P_BAD0     0    0.98   130.0     0.0  4641.0  1189.0     0.027248     1.000000  0.0  0.027248  0.122850  0.000000  0.221309  0.000000  0.053050  0.904484  0.808969  0.836393  0.258424   0.778691  0.972752\n",
       " 99   P_BAD0     0    0.99     5.0     0.0  4766.0  1189.0     0.001048     1.000000  0.0  0.001048  0.005218  0.000000  0.200336  0.000000  0.002094  0.904484  0.808969  0.836393  0.258424   0.799664  0.998952,\n",
       "  Fit Statistics for _AUTOTUNE_DEFAULT_SCORE_TABLE_\n",
       " \n",
       "      NOBS       ASE     DIV      RASE       MCE    MCLL\n",
       " 0  5960.0  0.084931  5960.0  0.291429  0.118456  0.2843,\n",
       "  Tuner Information\n",
       " \n",
       "                            Parameter                   Value\n",
       " 0                         Model Type  Gradient Boosting Tree\n",
       " 1           Tuner Objective Function       Misclassification\n",
       " 2                      Search Method                    GRID\n",
       " 3              Number of Grid Points                      16\n",
       " 4     Maximum Tuning Time in Seconds                   36000\n",
       " 5                    Validation Type        Cross-Validation\n",
       " 6      Num Folds in Cross-Validation                       5\n",
       " 7                          Log Level                       0\n",
       " 8                               Seed              1876924475\n",
       " 9     Number of Parallel Evaluations                       4\n",
       " 10  Number of Workers per Subsession                       0,\n",
       "  Tuner Results\n",
       " \n",
       "     Evaluation  M  LEARNINGRATE  SUBSAMPLERATE  LASSO  RIDGE  NBINS  MAXLEVEL  MeanConseqError  EvaluationTime\n",
       " 0            0  6          0.10            0.5    0.0    1.0     50         5         0.199497        0.695014\n",
       " 1           15  6          0.10            0.6    0.0    0.0     77         7         0.118456        4.524489\n",
       " 2            2  6          0.10            0.8    0.0    0.0     77         7         0.123280       10.743994\n",
       " 3            8  6          0.10            0.6    0.0    0.0     77         5         0.123826        8.513625\n",
       " 4            3  6          0.10            0.8    0.5    0.0     77         7         0.123951        8.821270\n",
       " 5            7  6          0.10            0.8    0.0    0.0     77         5         0.124979        8.407472\n",
       " 6            6  6          0.10            0.6    0.5    0.0     77         5         0.125461        9.598000\n",
       " 7            1  6          0.10            0.6    0.5    0.0     77         7         0.126029        7.335360\n",
       " 8           12  6          0.10            0.8    0.5    0.0     77         5         0.127203        6.906760\n",
       " 9            5  6          0.05            0.8    0.0    0.0     77         5         0.199329        4.799554\n",
       " 10           9  6          0.05            0.8    0.0    0.0     77         7         0.199385        4.075705,\n",
       "  Tuner Iteration History\n",
       " \n",
       "    Iteration  Evaluations  Best_obj   Time_sec\n",
       " 0          0            1  0.199497   0.695014\n",
       " 1          1           17  0.118456  25.460558,\n",
       "  Tuner Evaluation History\n",
       " \n",
       "     Evaluation  Iteration  M  LEARNINGRATE  SUBSAMPLERATE  LASSO  RIDGE  NBINS  MAXLEVEL  MeanConseqError  EvaluationTime\n",
       " 0            0          0  6          0.10            0.5    0.0    1.0     50         5         0.199497        0.695014\n",
       " 1            1          1  6          0.10            0.6    0.5    0.0     77         7         0.126029        7.335360\n",
       " 2            2          1  6          0.10            0.8    0.0    0.0     77         7         0.123280       10.743994\n",
       " 3            3          1  6          0.10            0.8    0.5    0.0     77         7         0.123951        8.821270\n",
       " 4            4          1  6          0.05            0.8    0.5    0.0     77         7         0.199631        5.731433\n",
       " 5            5          1  6          0.05            0.8    0.0    0.0     77         5         0.199329        4.799554\n",
       " 6            6          1  6          0.10            0.6    0.5    0.0     77         5         0.125461        9.598000\n",
       " 7            7          1  6          0.10            0.8    0.0    0.0     77         5         0.124979        8.407472\n",
       " 8            8          1  6          0.10            0.6    0.0    0.0     77         5         0.123826        8.513625\n",
       " 9            9          1  6          0.05            0.8    0.0    0.0     77         7         0.199385        4.075705\n",
       " 10          10          1  6          0.05            0.6    0.5    0.0     77         5         0.199664        2.796085\n",
       " 11          11          1  6          0.05            0.6    0.0    0.0     77         7         0.199385        3.307633\n",
       " 12          12          1  6          0.10            0.8    0.5    0.0     77         5         0.127203        6.906760\n",
       " 13          13          1  6          0.05            0.6    0.5    0.0     77         7         0.199385        3.703292\n",
       " 14          14          1  6          0.05            0.8    0.5    0.0     77         5         0.199497        2.782104\n",
       " 15          15          1  6          0.10            0.6    0.0    0.0     77         7         0.118456        4.524489\n",
       " 16          16          1  6          0.05            0.6    0.0    0.0     77         5         0.199385        2.403660,\n",
       "  Best Configuration\n",
       " \n",
       "                     Parameter           Name         Value\n",
       " 0                  Evaluation     Evaluation            15\n",
       " 1  Number of Variables to Try              M             6\n",
       " 2               Learning Rate   LEARNINGRATE           0.1\n",
       " 3               Sampling Rate  SUBSAMPLERATE           0.6\n",
       " 4                       Lasso          LASSO             0\n",
       " 5                       Ridge          RIDGE             0\n",
       " 6              Number of Bins          NBINS            77\n",
       " 7         Maximum Tree Levels       MAXLEVEL             7\n",
       " 8           Misclassification      Objective  0.1184563758,\n",
       "  Tuner Summary\n",
       " \n",
       "                                           Parameter      Value\n",
       " 0             Initial Configuration Objective Value   0.199497\n",
       " 1                Best Configuration Objective Value   0.118456\n",
       " 2               Worst Configuration Objective Value   0.199664\n",
       " 3  Initial Configuration Evaluation Time in Seconds   0.695014\n",
       " 4     Best Configuration Evaluation Time in Seconds   4.524478\n",
       " 5                 Number of Improved Configurations   4.000000\n",
       " 6                Number of Evaluated Configurations  17.000000\n",
       " 7                      Total Tuning Time in Seconds  26.164469\n",
       " 8                           Parallel Tuning Speedup   3.628316,\n",
       "  Tuner Task Timing\n",
       " \n",
       "                           Task   Time_sec  Time_percent\n",
       " 0               Model Training  88.568628     93.295974\n",
       " 1                Model Scoring   5.184516      5.461239\n",
       " 2  Total Objective Evaluations  93.765150     98.769860\n",
       " 3                        Tuner   1.167808      1.230140\n",
       " 4               Total CPU Time  94.932958    100.000000,\n",
       "  Hyperparameter Importance\n",
       " \n",
       "   Hyperparameter  RelImportance\n",
       " 0   LEARNINGRATE       1.000000\n",
       " 1       MAXLEVEL       0.006388\n",
       " 2  SUBSAMPLERATE       0.002765\n",
       " 3          LASSO       0.001600\n",
       " 4              M       0.000000\n",
       " 5          RIDGE       0.000000\n",
       " 6          NBINS       0.000000,\n",
       "  TuneAll Results Summary\n",
       " \n",
       "           ModelID               ModelType  Evaluations  BestObjective  AverageObjective  StdDevObjective  BestObjTime  AverageTime  StdDevTime\n",
       " 0  1_DecisionTree           Decision Tree            6       0.116296          0.131157         0.018933     1.072245     0.975980    0.383353\n",
       " 1     2_GradBoost  Gradient Boosting Tree           16       0.118456          0.170000         0.053381     4.524489     5.964151    2.731222,\n",
       "  TuneAll Best Models\n",
       " \n",
       "           ModelID  Evaluation  MeanConseqError  EvaluationTime\n",
       " 0  1_DecisionTree           6         0.116296        1.072245\n",
       " 1  1_DecisionTree           2         0.117282        1.595850\n",
       " 2     2_GradBoost          15         0.118456        4.524489\n",
       " 3  1_DecisionTree           5         0.122506        0.941197\n",
       " 4     2_GradBoost           2         0.123280       10.743994\n",
       " 5     2_GradBoost           8         0.123826        8.513625\n",
       " 6     2_GradBoost           3         0.123951        8.821270\n",
       " 7  1_DecisionTree           1         0.124835        0.552839\n",
       " 8     2_GradBoost           7         0.124979        8.407472\n",
       " 9     2_GradBoost           6         0.125461        9.598000,\n",
       "  TuneAll CAS Output Tables\n",
       " \n",
       " Empty SASDataFrame\n",
       " Columns: [ModelID, CAS_Library, Name, Rows, Columns]\n",
       " Index: [],\n",
       "  Decision Tree for __TEMP_FEATURE_MACHINE_CASOUT___AUTOTUNE_DATA_11FA4B25-9848-604F-9F45-7E73830B6354\n",
       " \n",
       "                            Descr        Value\n",
       " 0           Number of Tree Nodes   135.000000\n",
       " 1         Max Number of Branches     2.000000\n",
       " 2               Number of Levels    10.000000\n",
       " 3               Number of Leaves    68.000000\n",
       " 4                 Number of Bins   100.000000\n",
       " 5         Minimum Size of Leaves     5.000000\n",
       " 6         Maximum Size of Leaves  1178.000000\n",
       " 7            Number of Variables     4.000000\n",
       " 8   Confidence Level for Pruning     0.250000\n",
       " 9    Number of Observations Used  5960.000000\n",
       " 10   Misclassification Error (%)    14.395973,\n",
       "                           Descr                             Value\n",
       " 0  Number of Observations Read                              5960\n",
       " 1  Number of Observations Used                              5960\n",
       " 2  Misclassification Error (%)                      14.395973154,\n",
       "          LEVNAME  LEVINDEX VARNAME\n",
       " 0             1         0  P_BAD1\n",
       " 1             0         1  P_BAD0,\n",
       "    LEVNAME  LEVINDEX VARNAME\n",
       " 0                 0   I_BAD,\n",
       "  ROC Information for _AUTOTUNE_DEFAULT_SCORE_TABLE_\n",
       " \n",
       "    Variable Event  CutOff      TP      FP      FN      TN  Sensitivity  Specificity   KS       KS2    F_HALF       FPR       ACC       FDR        F1         C      Gini     Gamma       Tau  MISCEVENT       FNR\n",
       " 0    P_BAD0     0    0.00  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.851587  0.703174  0.769122  0.224628   0.199497  0.000000\n",
       " 1    P_BAD0     0    0.01  4771.0  1094.0     0.0    95.0     1.000000     0.079899  0.0  0.079899  0.844993  0.920101  0.816443  0.186530  0.897142  0.851587  0.703174  0.769122  0.224628   0.183557  0.000000\n",
       " 2    P_BAD0     0    0.02  4771.0  1094.0     0.0    95.0     1.000000     0.079899  0.0  0.079899  0.844993  0.920101  0.816443  0.186530  0.897142  0.851587  0.703174  0.769122  0.224628   0.183557  0.000000\n",
       " 3    P_BAD0     0    0.03  4771.0  1094.0     0.0    95.0     1.000000     0.079899  0.0  0.079899  0.844993  0.920101  0.816443  0.186530  0.897142  0.851587  0.703174  0.769122  0.224628   0.183557  0.000000\n",
       " 4    P_BAD0     0    0.04  4771.0  1094.0     0.0    95.0     1.000000     0.079899  0.0  0.079899  0.844993  0.920101  0.816443  0.186530  0.897142  0.851587  0.703174  0.769122  0.224628   0.183557  0.000000\n",
       " 5    P_BAD0     0    0.05  4771.0  1094.0     0.0    95.0     1.000000     0.079899  0.0  0.079899  0.844993  0.920101  0.816443  0.186530  0.897142  0.851587  0.703174  0.769122  0.224628   0.183557  0.000000\n",
       " 6    P_BAD0     0    0.06  4771.0  1094.0     0.0    95.0     1.000000     0.079899  0.0  0.079899  0.844993  0.920101  0.816443  0.186530  0.897142  0.851587  0.703174  0.769122  0.224628   0.183557  0.000000\n",
       " 7    P_BAD0     0    0.07  4771.0  1094.0     0.0    95.0     1.000000     0.079899  0.0  0.079899  0.844993  0.920101  0.816443  0.186530  0.897142  0.851587  0.703174  0.769122  0.224628   0.183557  0.000000\n",
       " 8    P_BAD0     0    0.08  4771.0  1094.0     0.0    95.0     1.000000     0.079899  0.0  0.079899  0.844993  0.920101  0.816443  0.186530  0.897142  0.851587  0.703174  0.769122  0.224628   0.183557  0.000000\n",
       " 9    P_BAD0     0    0.09  4771.0  1094.0     0.0    95.0     1.000000     0.079899  0.0  0.079899  0.844993  0.920101  0.816443  0.186530  0.897142  0.851587  0.703174  0.769122  0.224628   0.183557  0.000000\n",
       " 10   P_BAD0     0    0.10  4771.0  1094.0     0.0    95.0     1.000000     0.079899  0.0  0.079899  0.844993  0.920101  0.816443  0.186530  0.897142  0.851587  0.703174  0.769122  0.224628   0.183557  0.000000\n",
       " 11   P_BAD0     0    0.11  4771.0  1094.0     0.0    95.0     1.000000     0.079899  0.0  0.079899  0.844993  0.920101  0.816443  0.186530  0.897142  0.851587  0.703174  0.769122  0.224628   0.183557  0.000000\n",
       " 12   P_BAD0     0    0.12  4764.0  1040.0     7.0   149.0     0.998533     0.125315  0.0  0.123848  0.851109  0.874685  0.824329  0.179187  0.900993  0.851587  0.703174  0.769122  0.224628   0.175671  0.001467\n",
       " 13   P_BAD0     0    0.13  4764.0  1040.0     7.0   149.0     0.998533     0.125315  0.0  0.123848  0.851109  0.874685  0.824329  0.179187  0.900993  0.851587  0.703174  0.769122  0.224628   0.175671  0.001467\n",
       " 14   P_BAD0     0    0.14  4764.0  1040.0     7.0   149.0     0.998533     0.125315  0.0  0.123848  0.851109  0.874685  0.824329  0.179187  0.900993  0.851587  0.703174  0.769122  0.224628   0.175671  0.001467\n",
       " 15   P_BAD0     0    0.15  4764.0  1040.0     7.0   149.0     0.998533     0.125315  0.0  0.123848  0.851109  0.874685  0.824329  0.179187  0.900993  0.851587  0.703174  0.769122  0.224628   0.175671  0.001467\n",
       " 16   P_BAD0     0    0.16  4761.0  1023.0    10.0   166.0     0.997904     0.139613  0.0  0.137517  0.853012  0.860387  0.826678  0.176867  0.902132  0.851587  0.703174  0.769122  0.224628   0.173322  0.002096\n",
       " 17   P_BAD0     0    0.17  4760.0  1018.0    11.0   171.0     0.997694     0.143818  0.0  0.141513  0.853567  0.856182  0.827349  0.176186  0.902455  0.851587  0.703174  0.769122  0.224628   0.172651  0.002306\n",
       " 18   P_BAD0     0    0.18  4760.0  1018.0    11.0   171.0     0.997694     0.143818  0.0  0.141513  0.853567  0.856182  0.827349  0.176186  0.902455  0.851587  0.703174  0.769122  0.224628   0.172651  0.002306\n",
       " 19   P_BAD0     0    0.19  4760.0  1018.0    11.0   171.0     0.997694     0.143818  0.0  0.141513  0.853567  0.856182  0.827349  0.176186  0.902455  0.851587  0.703174  0.769122  0.224628   0.172651  0.002306\n",
       " 20   P_BAD0     0    0.20  4760.0  1018.0    11.0   171.0     0.997694     0.143818  0.0  0.141513  0.853567  0.856182  0.827349  0.176186  0.902455  0.851587  0.703174  0.769122  0.224628   0.172651  0.002306\n",
       " 21   P_BAD0     0    0.21  4750.0   980.0    21.0   209.0     0.995598     0.175778  0.0  0.171376  0.857679  0.824222  0.832047  0.171030  0.904676  0.851587  0.703174  0.769122  0.224628   0.167953  0.004402\n",
       " 22   P_BAD0     0    0.22  4750.0   980.0    21.0   209.0     0.995598     0.175778  0.0  0.171376  0.857679  0.824222  0.832047  0.171030  0.904676  0.851587  0.703174  0.769122  0.224628   0.167953  0.004402\n",
       " 23   P_BAD0     0    0.23  4750.0   980.0    21.0   209.0     0.995598     0.175778  0.0  0.171376  0.857679  0.824222  0.832047  0.171030  0.904676  0.851587  0.703174  0.769122  0.224628   0.167953  0.004402\n",
       " 24   P_BAD0     0    0.24  4750.0   980.0    21.0   209.0     0.995598     0.175778  0.0  0.171376  0.857679  0.824222  0.832047  0.171030  0.904676  0.851587  0.703174  0.769122  0.224628   0.167953  0.004402\n",
       " 25   P_BAD0     0    0.25  4750.0   980.0    21.0   209.0     0.995598     0.175778  0.0  0.171376  0.857679  0.824222  0.832047  0.171030  0.904676  0.851587  0.703174  0.769122  0.224628   0.167953  0.004402\n",
       " 26   P_BAD0     0    0.26  4731.0   923.0    40.0   266.0     0.991616     0.223717  0.0  0.215333  0.863731  0.776283  0.838423  0.163247  0.907626  0.851587  0.703174  0.769122  0.224628   0.161577  0.008384\n",
       " 27   P_BAD0     0    0.27  4731.0   923.0    40.0   266.0     0.991616     0.223717  0.0  0.215333  0.863731  0.776283  0.838423  0.163247  0.907626  0.851587  0.703174  0.769122  0.224628   0.161577  0.008384\n",
       " 28   P_BAD0     0    0.28  4731.0   923.0    40.0   266.0     0.991616     0.223717  0.0  0.215333  0.863731  0.776283  0.838423  0.163247  0.907626  0.851587  0.703174  0.769122  0.224628   0.161577  0.008384\n",
       " 29   P_BAD0     0    0.29  4731.0   923.0    40.0   266.0     0.991616     0.223717  0.0  0.215333  0.863731  0.776283  0.838423  0.163247  0.907626  0.851587  0.703174  0.769122  0.224628   0.161577  0.008384\n",
       " 30   P_BAD0     0    0.30  4731.0   923.0    40.0   266.0     0.991616     0.223717  0.0  0.215333  0.863731  0.776283  0.838423  0.163247  0.907626  0.851587  0.703174  0.769122  0.224628   0.161577  0.008384\n",
       " 31   P_BAD0     0    0.31  4714.0   885.0    57.0   304.0     0.988053     0.255677  0.0  0.243730  0.867597  0.744323  0.841946  0.158064  0.909161  0.851587  0.703174  0.769122  0.224628   0.158054  0.011947\n",
       " 32   P_BAD0     0    0.32  4714.0   885.0    57.0   304.0     0.988053     0.255677  0.0  0.243730  0.867597  0.744323  0.841946  0.158064  0.909161  0.851587  0.703174  0.769122  0.224628   0.158054  0.011947\n",
       " 33   P_BAD0     0    0.33  4714.0   885.0    57.0   304.0     0.988053     0.255677  0.0  0.243730  0.867597  0.744323  0.841946  0.158064  0.909161  0.851587  0.703174  0.769122  0.224628   0.158054  0.011947\n",
       " 34   P_BAD0     0    0.34  4714.0   885.0    57.0   304.0     0.988053     0.255677  0.0  0.243730  0.867597  0.744323  0.841946  0.158064  0.909161  0.851587  0.703174  0.769122  0.224628   0.158054  0.011947\n",
       " 35   P_BAD0     0    0.35  4714.0   885.0    57.0   304.0     0.988053     0.255677  0.0  0.243730  0.867597  0.744323  0.841946  0.158064  0.909161  0.851587  0.703174  0.769122  0.224628   0.158054  0.011947\n",
       " 36   P_BAD0     0    0.36  4654.0   778.0   117.0   411.0     0.975477     0.345669  0.0  0.321145  0.878146  0.654331  0.849832  0.143225  0.912281  0.851587  0.703174  0.769122  0.224628   0.150168  0.024523\n",
       " 37   P_BAD0     0    0.37  4654.0   778.0   117.0   411.0     0.975477     0.345669  0.0  0.321145  0.878146  0.654331  0.849832  0.143225  0.912281  0.851587  0.703174  0.769122  0.224628   0.150168  0.024523\n",
       " 38   P_BAD0     0    0.38  4654.0   778.0   117.0   411.0     0.975477     0.345669  0.0  0.321145  0.878146  0.654331  0.849832  0.143225  0.912281  0.851587  0.703174  0.769122  0.224628   0.150168  0.024523\n",
       " 39   P_BAD0     0    0.39  4654.0   778.0   117.0   411.0     0.975477     0.345669  0.0  0.321145  0.878146  0.654331  0.849832  0.143225  0.912281  0.851587  0.703174  0.769122  0.224628   0.150168  0.024523\n",
       " 40   P_BAD0     0    0.40  4592.0   684.0   179.0   505.0     0.962482     0.424727  0.0  0.387208  0.887343  0.575273  0.855201  0.129644  0.914104  0.851587  0.703174  0.769122  0.224628   0.144799  0.037518\n",
       " 41   P_BAD0     0    0.41  4588.0   678.0   183.0   511.0     0.961643     0.429773  0.0  0.391416  0.887943  0.570227  0.855537  0.128750  0.914217  0.851587  0.703174  0.769122  0.224628   0.144463  0.038357\n",
       " 42   P_BAD0     0    0.42  4583.0   671.0   188.0   518.0     0.960595     0.435660  0.0  0.396255  0.888626  0.564340  0.855872  0.127712  0.914314  0.851587  0.703174  0.769122  0.224628   0.144128  0.039405\n",
       " 43   P_BAD0     0    0.43  4580.0   667.0   191.0   522.0     0.959966     0.439024  0.0  0.398991  0.889010  0.560976  0.856040  0.127120  0.914354  0.851587  0.703174  0.769122  0.224628   0.143960  0.040034\n",
       " 44   P_BAD0     0    0.44  4580.0   667.0   191.0   522.0     0.959966     0.439024  0.0  0.398991  0.889010  0.560976  0.856040  0.127120  0.914354  0.851587  0.703174  0.769122  0.224628   0.143960  0.040034\n",
       " 45   P_BAD0     0    0.45  4580.0   667.0   191.0   522.0     0.959966     0.439024  0.0  0.398991  0.889010  0.560976  0.856040  0.127120  0.914354  0.851587  0.703174  0.769122  0.224628   0.143960  0.040034\n",
       " 46   P_BAD0     0    0.46  4580.0   667.0   191.0   522.0     0.959966     0.439024  0.0  0.398991  0.889010  0.560976  0.856040  0.127120  0.914354  0.851587  0.703174  0.769122  0.224628   0.143960  0.040034\n",
       " 47   P_BAD0     0    0.47  4580.0   667.0   191.0   522.0     0.959966     0.439024  0.0  0.398991  0.889010  0.560976  0.856040  0.127120  0.914354  0.851587  0.703174  0.769122  0.224628   0.143960  0.040034\n",
       " 48   P_BAD0     0    0.48  4580.0   667.0   191.0   522.0     0.959966     0.439024  0.0  0.398991  0.889010  0.560976  0.856040  0.127120  0.914354  0.851587  0.703174  0.769122  0.224628   0.143960  0.040034\n",
       " 49   P_BAD0     0    0.49  4580.0   667.0   191.0   522.0     0.959966     0.439024  0.0  0.398991  0.889010  0.560976  0.856040  0.127120  0.914354  0.851587  0.703174  0.769122  0.224628   0.143960  0.040034\n",
       " 50   P_BAD0     0    0.50  4580.0   667.0   191.0   522.0     0.959966     0.439024  0.0  0.398991  0.889010  0.560976  0.856040  0.127120  0.914354  0.851587  0.703174  0.769122  0.224628   0.143960  0.040034\n",
       " 51   P_BAD0     0    0.51  4564.0   651.0   207.0   538.0     0.956613     0.452481  0.0  0.409094  0.890328  0.547519  0.856040  0.124832  0.914080  0.851587  0.703174  0.769122  0.224628   0.143960  0.043387\n",
       " 52   P_BAD0     0    0.52  4544.0   632.0   227.0   557.0     0.952421     0.468461  0.0  0.420882  0.891855  0.531539  0.855872  0.122102  0.913642  0.851587  0.703174  0.769122  0.224628   0.144128  0.047579\n",
       " 53   P_BAD0     0    0.53  4544.0   632.0   227.0   557.0     0.952421     0.468461  0.0  0.420882  0.891855  0.531539  0.855872  0.122102  0.913642  0.851587  0.703174  0.769122  0.224628   0.144128  0.047579\n",
       " 54   P_BAD0     0    0.54  4536.0   625.0   235.0   564.0     0.950744     0.474348  0.0  0.425092  0.892386  0.525652  0.855705  0.121101  0.913411  0.851587  0.703174  0.769122  0.224628   0.144295  0.049256\n",
       " 55   P_BAD0     0    0.55  4536.0   625.0   235.0   564.0     0.950744     0.474348  0.0  0.425092  0.892386  0.525652  0.855705  0.121101  0.913411  0.851587  0.703174  0.769122  0.224628   0.144295  0.049256\n",
       " 56   P_BAD0     0    0.56  4531.0   621.0   240.0   568.0     0.949696     0.477712  0.0  0.427408  0.892667  0.522288  0.855537  0.120536  0.913232  0.851587  0.703174  0.769122  0.224628   0.144463  0.050304\n",
       " 57   P_BAD0     0    0.57  4531.0   621.0   240.0   568.0     0.949696     0.477712  0.0  0.427408  0.892667  0.522288  0.855537  0.120536  0.913232  0.851587  0.703174  0.769122  0.224628   0.144463  0.050304\n",
       " 58   P_BAD0     0    0.58  4531.0   621.0   240.0   568.0     0.949696     0.477712  0.0  0.427408  0.892667  0.522288  0.855537  0.120536  0.913232  0.851587  0.703174  0.769122  0.224628   0.144463  0.050304\n",
       " 59   P_BAD0     0    0.59  4531.0   621.0   240.0   568.0     0.949696     0.477712  0.0  0.427408  0.892667  0.522288  0.855537  0.120536  0.913232  0.851587  0.703174  0.769122  0.224628   0.144463  0.050304\n",
       " 60   P_BAD0     0    0.60  4531.0   621.0   240.0   568.0     0.949696     0.477712  0.0  0.427408  0.892667  0.522288  0.855537  0.120536  0.913232  0.851587  0.703174  0.769122  0.224628   0.144463  0.050304\n",
       " 61   P_BAD0     0    0.61  4528.0   619.0   243.0   570.0     0.949067     0.479394  0.0  0.428462  0.892780  0.520606  0.855369  0.120264  0.913087  0.851587  0.703174  0.769122  0.224628   0.144631  0.050933\n",
       " 62   P_BAD0     0    0.62  4528.0   619.0   243.0   570.0     0.949067     0.479394  0.0  0.428462  0.892780  0.520606  0.855369  0.120264  0.913087  0.851587  0.703174  0.769122  0.224628   0.144631  0.050933\n",
       " 63   P_BAD0     0    0.63  4528.0   619.0   243.0   570.0     0.949067     0.479394  0.0  0.428462  0.892780  0.520606  0.855369  0.120264  0.913087  0.851587  0.703174  0.769122  0.224628   0.144631  0.050933\n",
       " 64   P_BAD0     0    0.64  4521.0   615.0   250.0   574.0     0.947600     0.482759  0.0  0.430359  0.892949  0.517241  0.854866  0.119743  0.912688  0.851587  0.703174  0.769122  0.224628   0.145134  0.052400\n",
       " 65   P_BAD0     0    0.65  4435.0   568.0   336.0   621.0     0.929575     0.522288  0.0  0.451862  0.894767  0.477712  0.848322  0.113532  0.907510  0.851587  0.703174  0.769122  0.224628   0.151678  0.070425\n",
       " 66   P_BAD0     0    0.66  4435.0   568.0   336.0   621.0     0.929575     0.522288  0.0  0.451862  0.894767  0.477712  0.848322  0.113532  0.907510  0.851587  0.703174  0.769122  0.224628   0.151678  0.070425\n",
       " 67   P_BAD0     0    0.67  4431.0   566.0   340.0   623.0     0.928736     0.523970  0.0  0.452706  0.894826  0.476030  0.847987  0.113268  0.907248  0.851587  0.703174  0.769122  0.224628   0.152013  0.071264\n",
       " 68   P_BAD0     0    0.68  4408.0   555.0   363.0   634.0     0.923915     0.533221  0.0  0.457137  0.895098  0.466779  0.845973  0.111828  0.905691  0.851587  0.703174  0.769122  0.224628   0.154027  0.076085\n",
       " 69   P_BAD0     0    0.69  4382.0   543.0   389.0   646.0     0.918466     0.543314  0.0  0.461779  0.895346  0.456686  0.843624  0.110254  0.903878  0.851587  0.703174  0.769122  0.224628   0.156376  0.081534\n",
       " 70   P_BAD0     0    0.70  4382.0   543.0   389.0   646.0     0.918466     0.543314  0.0  0.461779  0.895346  0.456686  0.843624  0.110254  0.903878  0.851587  0.703174  0.769122  0.224628   0.156376  0.081534\n",
       " 71   P_BAD0     0    0.71  3734.0   271.0  1037.0   918.0     0.782645     0.772077  0.0  0.554723  0.897985  0.227923  0.780537  0.067665  0.850957  0.851587  0.703174  0.769122  0.224628   0.219463  0.217355\n",
       " 72   P_BAD0     0    0.72  3734.0   271.0  1037.0   918.0     0.782645     0.772077  0.0  0.554723  0.897985  0.227923  0.780537  0.067665  0.850957  0.851587  0.703174  0.769122  0.224628   0.219463  0.217355\n",
       " 73   P_BAD0     0    0.73  3726.0   268.0  1045.0   921.0     0.780968     0.774601  0.0  0.555569  0.897961  0.225399  0.779698  0.067101  0.850200  0.851587  0.703174  0.769122  0.224628   0.220302  0.219032\n",
       " 74   P_BAD0     0    0.74  3726.0   268.0  1045.0   921.0     0.780968     0.774601  0.0  0.555569  0.897961  0.225399  0.779698  0.067101  0.850200  0.851587  0.703174  0.769122  0.224628   0.220302  0.219032\n",
       " 75   P_BAD0     0    0.75  3726.0   268.0  1045.0   921.0     0.780968     0.774601  0.0  0.555569  0.897961  0.225399  0.779698  0.067101  0.850200  0.851587  0.703174  0.769122  0.224628   0.220302  0.219032\n",
       " 76   P_BAD0     0    0.76  3711.0   263.0  1060.0   926.0     0.777824     0.778806  0.0  0.556630  0.897808  0.221194  0.778020  0.066180  0.848714  0.851587  0.703174  0.769122  0.224628   0.221980  0.222176\n",
       " 77   P_BAD0     0    0.77  3698.0   259.0  1073.0   930.0     0.775100     0.782170  0.0  0.557269  0.897616  0.217830  0.776510  0.065454  0.847388  0.851587  0.703174  0.769122  0.224628   0.223490  0.224900\n",
       " 78   P_BAD0     0    0.78  3691.0   257.0  1080.0   932.0     0.773632     0.783852  0.0  0.557484  0.897486  0.216148  0.775671  0.065096  0.846657  0.851587  0.703174  0.769122  0.224628   0.224329  0.226368\n",
       " 79   P_BAD0     0    0.79  3676.0   253.0  1095.0   936.0     0.770488     0.787216  1.0  0.557705  0.897154  0.212784  0.773826  0.064393  0.845057  0.851587  0.703174  0.769122  0.224628   0.226174  0.229512\n",
       " 80   P_BAD0     0    0.80  3676.0   253.0  1095.0   936.0     0.770488     0.787216  0.0  0.557705  0.897154  0.212784  0.773826  0.064393  0.845057  0.851587  0.703174  0.769122  0.224628   0.226174  0.229512\n",
       " 81   P_BAD0     0    0.81  3364.0   176.0  1407.0  1013.0     0.705093     0.851976  0.0  0.557070  0.888490  0.148024  0.734396  0.049718  0.809530  0.851587  0.703174  0.769122  0.224628   0.265604  0.294907\n",
       " 82   P_BAD0     0    0.82  3364.0   176.0  1407.0  1013.0     0.705093     0.851976  0.0  0.557070  0.888490  0.148024  0.734396  0.049718  0.809530  0.851587  0.703174  0.769122  0.224628   0.265604  0.294907\n",
       " 83   P_BAD0     0    0.83  3336.0   170.0  1435.0  1019.0     0.699224     0.857023  0.0  0.556247  0.887470  0.142977  0.730705  0.048488  0.806089  0.851587  0.703174  0.769122  0.224628   0.269295  0.300776\n",
       " 84   P_BAD0     0    0.84  3246.0   152.0  1525.0  1037.0     0.680361     0.872161  0.0  0.552522  0.883843  0.127839  0.718624  0.044732  0.794712  0.851587  0.703174  0.769122  0.224628   0.281376  0.319639\n",
       " 85   P_BAD0     0    0.85  3246.0   152.0  1525.0  1037.0     0.680361     0.872161  0.0  0.552522  0.883843  0.127839  0.718624  0.044732  0.794712  0.851587  0.703174  0.769122  0.224628   0.281376  0.319639\n",
       " 86   P_BAD0     0    0.86  3240.0   151.0  1531.0  1038.0     0.679103     0.873003  0.0  0.552105  0.883556  0.126997  0.717785  0.044530  0.793923  0.851587  0.703174  0.769122  0.224628   0.282215  0.320897\n",
       " 87   P_BAD0     0    0.87  3240.0   151.0  1531.0  1038.0     0.679103     0.873003  0.0  0.552105  0.883556  0.126997  0.717785  0.044530  0.793923  0.851587  0.703174  0.769122  0.224628   0.282215  0.320897\n",
       " 88   P_BAD0     0    0.88  3240.0   151.0  1531.0  1038.0     0.679103     0.873003  0.0  0.552105  0.883556  0.126997  0.717785  0.044530  0.793923  0.851587  0.703174  0.769122  0.224628   0.282215  0.320897\n",
       " 89   P_BAD0     0    0.89  3194.0   145.0  1577.0  1044.0     0.669461     0.878049  0.0  0.547510  0.881006  0.121951  0.711074  0.043426  0.787670  0.851587  0.703174  0.769122  0.224628   0.288926  0.330539\n",
       " 90   P_BAD0     0    0.90  3088.0   133.0  1683.0  1056.0     0.647244     0.888141  0.0  0.535385  0.874540  0.111859  0.695302  0.041292  0.772773  0.851587  0.703174  0.769122  0.224628   0.304698  0.352756\n",
       " 91   P_BAD0     0    0.91  3070.0   131.0  1701.0  1058.0     0.643471     0.889823  0.0  0.533294  0.873400  0.110177  0.692617  0.040925  0.770196  0.851587  0.703174  0.769122  0.224628   0.307383  0.356529\n",
       " 92   P_BAD0     0    0.92  3059.0   130.0  1712.0  1059.0     0.641165     0.890664  0.0  0.531830  0.872654  0.109336  0.690940  0.040765  0.768593  0.851587  0.703174  0.769122  0.224628   0.309060  0.358835\n",
       " 93   P_BAD0     0    0.93  2946.0   121.0  1825.0  1068.0     0.617481     0.898234  0.0  0.515714  0.864487  0.101766  0.673490  0.039452  0.751722  0.851587  0.703174  0.769122  0.224628   0.326510  0.382519\n",
       " 94   P_BAD0     0    0.94  2946.0   121.0  1825.0  1068.0     0.617481     0.898234  0.0  0.515714  0.864487  0.101766  0.673490  0.039452  0.751722  0.851587  0.703174  0.769122  0.224628   0.326510  0.382519\n",
       " 95   P_BAD0     0    0.95  2946.0   121.0  1825.0  1068.0     0.617481     0.898234  0.0  0.515714  0.864487  0.101766  0.673490  0.039452  0.751722  0.851587  0.703174  0.769122  0.224628   0.326510  0.382519\n",
       " 96   P_BAD0     0    0.96   579.0    12.0  4192.0  1177.0     0.121358     0.989907  0.0  0.111266  0.405746  0.010093  0.294631  0.020305  0.215964  0.851587  0.703174  0.769122  0.224628   0.705369  0.878642\n",
       " 97   P_BAD0     0    0.97   579.0    12.0  4192.0  1177.0     0.121358     0.989907  0.0  0.111266  0.405746  0.010093  0.294631  0.020305  0.215964  0.851587  0.703174  0.769122  0.224628   0.705369  0.878642\n",
       " 98   P_BAD0     0    0.98   269.0     3.0  4502.0  1186.0     0.056382     0.997477  0.0  0.053859  0.229561  0.002523  0.244128  0.011029  0.106683  0.851587  0.703174  0.769122  0.224628   0.755872  0.943618\n",
       " 99   P_BAD0     0    0.99   110.0     0.0  4661.0  1189.0     0.023056     1.000000  0.0  0.023056  0.105546  0.000000  0.217953  0.000000  0.045073  0.851587  0.703174  0.769122  0.224628   0.782047  0.976944,\n",
       "  Fit Statistics for _AUTOTUNE_DEFAULT_SCORE_TABLE_\n",
       " \n",
       "      NOBS       ASE     DIV     RASE      MCE      MCLL\n",
       " 0  5960.0  0.106041  5960.0  0.32564  0.14396  0.342706,\n",
       "  Tuner Information\n",
       " \n",
       "                            Parameter              Value\n",
       " 0                         Model Type      Decision Tree\n",
       " 1           Tuner Objective Function  Misclassification\n",
       " 2                      Search Method               GRID\n",
       " 3              Number of Grid Points                  6\n",
       " 4     Maximum Tuning Time in Seconds              36000\n",
       " 5                    Validation Type   Cross-Validation\n",
       " 6      Num Folds in Cross-Validation                  5\n",
       " 7                          Log Level                  0\n",
       " 8                               Seed         1876921820\n",
       " 9     Number of Parallel Evaluations                  4\n",
       " 10  Number of Workers per Subsession                  0,\n",
       "  Tuner Results\n",
       " \n",
       "    Evaluation  MAXLEVEL  NBINS       CRIT  MeanConseqError  EvaluationTime\n",
       " 0           0        11     20  gainRatio         0.150505        0.396938\n",
       " 1           3        15    100       gain         0.144102        1.393360\n",
       " 2           2        10    100       gain         0.144297        0.987102\n",
       " 3           6        10    100  gainRatio         0.148155        0.845976\n",
       " 4           4         5    100       gain         0.151704        0.532106\n",
       " 5           1        15    100  gainRatio         0.152519        0.532106\n",
       " 6           5         5    100  gainRatio         0.154530        0.757470,\n",
       "  Tuner Iteration History\n",
       " \n",
       "    Iteration  Evaluations  Best_obj  Time_sec\n",
       " 0          0            1  0.150505  0.396938\n",
       " 1          1            7  0.144102  1.789386,\n",
       "  Tuner Evaluation History\n",
       " \n",
       "    Evaluation  Iteration  MAXLEVEL  NBINS       CRIT  MeanConseqError  EvaluationTime\n",
       " 0           0          0        11     20  gainRatio         0.150505        0.396938\n",
       " 1           1          1        15    100  gainRatio         0.152519        0.532106\n",
       " 2           2          1        10    100       gain         0.144297        0.987102\n",
       " 3           3          1        15    100       gain         0.144102        1.393360\n",
       " 4           4          1         5    100       gain         0.151704        0.532106\n",
       " 5           5          1         5    100  gainRatio         0.154530        0.757470\n",
       " 6           6          1        10    100  gainRatio         0.148155        0.845976,\n",
       "  Best Configuration\n",
       " \n",
       "              Parameter        Name         Value\n",
       " 0           Evaluation  Evaluation             3\n",
       " 1  Maximum Tree Levels    MAXLEVEL            15\n",
       " 2         Maximum Bins       NBINS           100\n",
       " 3            Criterion        CRIT          gain\n",
       " 4    Misclassification   Objective  0.1441016388,\n",
       "  Tuner Summary\n",
       " \n",
       "                                           Parameter     Value\n",
       " 0             Initial Configuration Objective Value  0.150505\n",
       " 1                Best Configuration Objective Value  0.144102\n",
       " 2               Worst Configuration Objective Value  0.154530\n",
       " 3  Initial Configuration Evaluation Time in Seconds  0.396938\n",
       " 4     Best Configuration Evaluation Time in Seconds  0.861276\n",
       " 5                 Number of Improved Configurations  2.000000\n",
       " 6                Number of Evaluated Configurations  7.000000\n",
       " 7                      Total Tuning Time in Seconds  1.859142\n",
       " 8                           Parallel Tuning Speedup  2.459482,\n",
       "  Tuner Task Timing\n",
       " \n",
       "                           Task  Time_sec  Time_percent\n",
       " 0               Model Training  3.286560     71.876262\n",
       " 1                Model Scoring  0.727036     15.900099\n",
       " 2  Total Objective Evaluations  4.019285     87.900770\n",
       " 3                        Tuner  0.553240     12.099230\n",
       " 4               Total CPU Time  4.572525    100.000000,\n",
       "  Hyperparameter Importance\n",
       " \n",
       "   Hyperparameter  RelImportance\n",
       " 0       MAXLEVEL       1.000000\n",
       " 1           CRIT       0.977507\n",
       " 2          NBINS       0.000000,\n",
       "  Gradient Boosting Tree for __TEMP_FEATURE_MACHINE_CASOUT___AUTOTUNE_DATA_11FA4B25-9848-604F-9F45-7E73830B6354\n",
       " \n",
       "                                   Descr         Value\n",
       " 0                       Number of Trees  1.500000e+02\n",
       " 1                          Distribution  2.000000e+00\n",
       " 2                         Learning Rate  1.000000e-01\n",
       " 3                      Subsampling Rate  6.000000e-01\n",
       " 4      Number of Selected Variables (M)  4.000000e+00\n",
       " 5                        Number of Bins  7.700000e+01\n",
       " 6                   Number of Variables  4.000000e+00\n",
       " 7              Max Number of Tree Nodes  5.900000e+01\n",
       " 8              Min Number of Tree Nodes  3.700000e+01\n",
       " 9                Max Number of Branches  2.000000e+00\n",
       " 10               Min Number of Branches  2.000000e+00\n",
       " 11                 Max Number of Levels  7.000000e+00\n",
       " 12                 Min Number of Levels  7.000000e+00\n",
       " 13                 Max Number of Leaves  3.000000e+01\n",
       " 14                 Min Number of Leaves  1.900000e+01\n",
       " 15               Maximum Size of Leaves  1.901000e+03\n",
       " 16               Minimum Size of Leaves  5.000000e+00\n",
       " 17                   Random Number Seed  1.876922e+09\n",
       " 18                   Lasso (L1) penalty  5.000000e-01\n",
       " 19                   Ridge (L2) penalty  0.000000e+00\n",
       " 20               Actual Number of Trees  2.000000e+01\n",
       " 21             Average number of Leaves  2.395000e+01\n",
       " 22            Early stopping stagnation  4.000000e+00\n",
       " 23             Early stopping threshold  0.000000e+00\n",
       " 24  Early stopping threshold iterations  0.000000e+00\n",
       " 25             Early stopping tolerance  0.000000e+00,\n",
       "      Progress    Metric\n",
       " 0        1.0  0.199497\n",
       " 1        2.0  0.199497\n",
       " 2        3.0  0.199497\n",
       " 3        4.0  0.199497\n",
       " 4        5.0  0.185235\n",
       " 5        6.0  0.170134\n",
       " 6        7.0  0.168624\n",
       " 7        8.0  0.162081\n",
       " 8        9.0  0.161745\n",
       " 9       10.0  0.157886\n",
       " 10      11.0  0.150000\n",
       " 11      12.0  0.149664\n",
       " 12      13.0  0.149329\n",
       " 13      14.0  0.143960\n",
       " 14      15.0  0.143960\n",
       " 15      16.0  0.143960\n",
       " 16      17.0  0.143960\n",
       " 17      18.0  0.143289\n",
       " 18      19.0  0.143121\n",
       " 19      20.0  0.142785,\n",
       "                           Descr                             Value\n",
       " 0  Number of Observations Read                              5960\n",
       " 1  Number of Observations Used                              5960\n",
       " 2  Misclassification Error (%)                       14.27852349,\n",
       "      TreeID  Trees  NLeaves       MCR   LogLoss       ASE      RASE     MAXAE\n",
       " 0      0.0    1.0     24.0  0.199497  0.468589  0.149078  0.386106  0.815742\n",
       " 1      1.0    2.0     44.0  0.199497  0.446474  0.140894  0.375359  0.829874\n",
       " 2      2.0    3.0     65.0  0.199497  0.429755  0.134538  0.366794  0.841710\n",
       " 3      3.0    4.0     88.0  0.199497  0.415759  0.129184  0.359421  0.853080\n",
       " 4      4.0    5.0    108.0  0.185235  0.404737  0.124989  0.353537  0.863127\n",
       " 5      5.0    6.0    131.0  0.170134  0.395801  0.121642  0.348772  0.872147\n",
       " 6      6.0    7.0    156.0  0.168624  0.388213  0.118908  0.344831  0.881248\n",
       " 7      7.0    8.0    183.0  0.162081  0.381663  0.116620  0.341497  0.889103\n",
       " 8      8.0    9.0    213.0  0.161745  0.376465  0.114837  0.338876  0.895443\n",
       " 9      9.0   10.0    243.0  0.157886  0.371781  0.113278  0.336567  0.901697\n",
       " 10    10.0   11.0    271.0  0.150000  0.367904  0.112022  0.334696  0.907537\n",
       " 11    11.0   12.0    293.0  0.149664  0.364666  0.110993  0.333156  0.912122\n",
       " 12    12.0   13.0    313.0  0.149329  0.361915  0.110179  0.331932  0.916695\n",
       " 13    13.0   14.0    336.0  0.143960  0.359329  0.109451  0.330834  0.921120\n",
       " 14    14.0   15.0    359.0  0.143960  0.357242  0.108884  0.329975  0.924959\n",
       " 15    15.0   16.0    384.0  0.143960  0.355362  0.108385  0.329219  0.928939\n",
       " 16    16.0   17.0    403.0  0.143960  0.353784  0.107992  0.328622  0.933832\n",
       " 17    17.0   18.0    426.0  0.143289  0.352327  0.107592  0.328013  0.938289\n",
       " 18    18.0   19.0    452.0  0.143121  0.351152  0.107287  0.327547  0.940495\n",
       " 19    19.0   20.0    479.0  0.142785  0.350075  0.107058  0.327197  0.945084,\n",
       "          LEVNAME  LEVINDEX VARNAME\n",
       " 0             1         0  P_BAD1\n",
       " 1             0         1  P_BAD0,\n",
       "    LEVNAME  LEVINDEX VARNAME\n",
       " 0                 0   I_BAD,\n",
       "  ROC Information for _AUTOTUNE_DEFAULT_SCORE_TABLE_\n",
       " \n",
       "    Variable Event  CutOff      TP      FP      FN      TN  Sensitivity  Specificity   KS       KS2    F_HALF       FPR       ACC       FDR        F1         C      Gini     Gamma       Tau  MISCEVENT       FNR\n",
       " 0    P_BAD0     0    0.00  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.850296  0.700592  0.771013  0.223804   0.199497  0.000000\n",
       " 1    P_BAD0     0    0.01  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.850296  0.700592  0.771013  0.223804   0.199497  0.000000\n",
       " 2    P_BAD0     0    0.02  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.850296  0.700592  0.771013  0.223804   0.199497  0.000000\n",
       " 3    P_BAD0     0    0.03  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.850296  0.700592  0.771013  0.223804   0.199497  0.000000\n",
       " 4    P_BAD0     0    0.04  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.850296  0.700592  0.771013  0.223804   0.199497  0.000000\n",
       " 5    P_BAD0     0    0.05  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.850296  0.700592  0.771013  0.223804   0.199497  0.000000\n",
       " 6    P_BAD0     0    0.06  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.850296  0.700592  0.771013  0.223804   0.199497  0.000000\n",
       " 7    P_BAD0     0    0.07  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.850296  0.700592  0.771013  0.223804   0.199497  0.000000\n",
       " 8    P_BAD0     0    0.08  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.850296  0.700592  0.771013  0.223804   0.199497  0.000000\n",
       " 9    P_BAD0     0    0.09  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.850296  0.700592  0.771013  0.223804   0.199497  0.000000\n",
       " 10   P_BAD0     0    0.10  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.850296  0.700592  0.771013  0.223804   0.199497  0.000000\n",
       " 11   P_BAD0     0    0.11  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.850296  0.700592  0.771013  0.223804   0.199497  0.000000\n",
       " 12   P_BAD0     0    0.12  4771.0  1186.0     0.0     3.0     1.000000     0.002523  0.0  0.002523  0.834120  0.997477  0.801007  0.199094  0.889448  0.850296  0.700592  0.771013  0.223804   0.198993  0.000000\n",
       " 13   P_BAD0     0    0.13  4771.0  1133.0     0.0    56.0     1.000000     0.047098  0.0  0.047098  0.840349  0.952902  0.809899  0.191904  0.893864  0.850296  0.700592  0.771013  0.223804   0.190101  0.000000\n",
       " 14   P_BAD0     0    0.14  4771.0  1133.0     0.0    56.0     1.000000     0.047098  0.0  0.047098  0.840349  0.952902  0.809899  0.191904  0.893864  0.850296  0.700592  0.771013  0.223804   0.190101  0.000000\n",
       " 15   P_BAD0     0    0.15  4771.0  1128.0     0.0    61.0     1.000000     0.051304  0.0  0.051304  0.840942  0.948696  0.810738  0.191219  0.894283  0.850296  0.700592  0.771013  0.223804   0.189262  0.000000\n",
       " 16   P_BAD0     0    0.16  4771.0  1126.0     0.0    63.0     1.000000     0.052986  0.0  0.052986  0.841179  0.947014  0.811074  0.190945  0.894451  0.850296  0.700592  0.771013  0.223804   0.188926  0.000000\n",
       " 17   P_BAD0     0    0.17  4771.0  1109.0     0.0    80.0     1.000000     0.067283  0.0  0.067283  0.843201  0.932717  0.813926  0.188605  0.895878  0.850296  0.700592  0.771013  0.223804   0.186074  0.000000\n",
       " 18   P_BAD0     0    0.18  4771.0  1101.0     0.0    88.0     1.000000     0.074012  0.0  0.074012  0.844156  0.925988  0.815268  0.187500  0.896552  0.850296  0.700592  0.771013  0.223804   0.184732  0.000000\n",
       " 19   P_BAD0     0    0.19  4768.0  1084.0     3.0   105.0     0.999371     0.088310  0.0  0.087681  0.846020  0.911690  0.817617  0.185236  0.897675  0.850296  0.700592  0.771013  0.223804   0.182383  0.000629\n",
       " 20   P_BAD0     0    0.20  4768.0  1078.0     3.0   111.0     0.999371     0.093356  0.0  0.092727  0.846741  0.906644  0.818624  0.184400  0.898182  0.850296  0.700592  0.771013  0.223804   0.181376  0.000629\n",
       " 21   P_BAD0     0    0.21  4768.0  1078.0     3.0   111.0     0.999371     0.093356  0.0  0.092727  0.846741  0.906644  0.818624  0.184400  0.898182  0.850296  0.700592  0.771013  0.223804   0.181376  0.000629\n",
       " 22   P_BAD0     0    0.22  4765.0  1057.0     6.0   132.0     0.998742     0.111018  0.0  0.109760  0.849104  0.888982  0.821644  0.181553  0.899651  0.850296  0.700592  0.771013  0.223804   0.178356  0.001258\n",
       " 23   P_BAD0     0    0.23  4761.0  1026.0    10.0   163.0     0.997904     0.137090  0.0  0.134994  0.852645  0.862910  0.826174  0.177294  0.901875  0.850296  0.700592  0.771013  0.223804   0.173826  0.002096\n",
       " 24   P_BAD0     0    0.24  4761.0  1026.0    10.0   163.0     0.997904     0.137090  0.0  0.134994  0.852645  0.862910  0.826174  0.177294  0.901875  0.850296  0.700592  0.771013  0.223804   0.173826  0.002096\n",
       " 25   P_BAD0     0    0.25  4761.0  1025.0    10.0   164.0     0.997904     0.137931  0.0  0.135835  0.852767  0.862069  0.826342  0.177152  0.901961  0.850296  0.700592  0.771013  0.223804   0.173658  0.002096\n",
       " 26   P_BAD0     0    0.26  4761.0  1019.0    10.0   170.0     0.997904     0.142977  0.0  0.140881  0.853501  0.857023  0.827349  0.176298  0.902474  0.850296  0.700592  0.771013  0.223804   0.172651  0.002096\n",
       " 27   P_BAD0     0    0.27  4761.0  1019.0    10.0   170.0     0.997904     0.142977  0.0  0.140881  0.853501  0.857023  0.827349  0.176298  0.902474  0.850296  0.700592  0.771013  0.223804   0.172651  0.002096\n",
       " 28   P_BAD0     0    0.28  4761.0  1019.0    10.0   170.0     0.997904     0.142977  0.0  0.140881  0.853501  0.857023  0.827349  0.176298  0.902474  0.850296  0.700592  0.771013  0.223804   0.172651  0.002096\n",
       " 29   P_BAD0     0    0.29  4761.0  1019.0    10.0   170.0     0.997904     0.142977  0.0  0.140881  0.853501  0.857023  0.827349  0.176298  0.902474  0.850296  0.700592  0.771013  0.223804   0.172651  0.002096\n",
       " 30   P_BAD0     0    0.30  4752.0   985.0    19.0   204.0     0.996018     0.171573  0.0  0.167590  0.857174  0.828427  0.831544  0.171693  0.904454  0.850296  0.700592  0.771013  0.223804   0.168456  0.003982\n",
       " 31   P_BAD0     0    0.31  4752.0   985.0    19.0   204.0     0.996018     0.171573  0.0  0.167590  0.857174  0.828427  0.831544  0.171693  0.904454  0.850296  0.700592  0.771013  0.223804   0.168456  0.003982\n",
       " 32   P_BAD0     0    0.32  4752.0   985.0    19.0   204.0     0.996018     0.171573  0.0  0.167590  0.857174  0.828427  0.831544  0.171693  0.904454  0.850296  0.700592  0.771013  0.223804   0.168456  0.003982\n",
       " 33   P_BAD0     0    0.33  4733.0   926.0    38.0   263.0     0.992035     0.221194  0.0  0.213229  0.863466  0.778806  0.838255  0.163633  0.907574  0.850296  0.700592  0.771013  0.223804   0.161745  0.007965\n",
       " 34   P_BAD0     0    0.34  4733.0   926.0    38.0   263.0     0.992035     0.221194  0.0  0.213229  0.863466  0.778806  0.838255  0.163633  0.907574  0.850296  0.700592  0.771013  0.223804   0.161745  0.007965\n",
       " 35   P_BAD0     0    0.35  4733.0   924.0    38.0   265.0     0.992035     0.222876  0.0  0.214912  0.863718  0.777124  0.838591  0.163337  0.907748  0.850296  0.700592  0.771013  0.223804   0.161409  0.007965\n",
       " 36   P_BAD0     0    0.36  4733.0   924.0    38.0   265.0     0.992035     0.222876  0.0  0.214912  0.863718  0.777124  0.838591  0.163337  0.907748  0.850296  0.700592  0.771013  0.223804   0.161409  0.007965\n",
       " 37   P_BAD0     0    0.37  4733.0   924.0    38.0   265.0     0.992035     0.222876  0.0  0.214912  0.863718  0.777124  0.838591  0.163337  0.907748  0.850296  0.700592  0.771013  0.223804   0.161409  0.007965\n",
       " 38   P_BAD0     0    0.38  4712.0   880.0    59.0   309.0     0.987634     0.259882  0.0  0.247516  0.868123  0.740118  0.842450  0.157368  0.909389  0.850296  0.700592  0.771013  0.223804   0.157550  0.012366\n",
       " 39   P_BAD0     0    0.39  4712.0   880.0    59.0   309.0     0.987634     0.259882  0.0  0.247516  0.868123  0.740118  0.842450  0.157368  0.909389  0.850296  0.700592  0.771013  0.223804   0.157550  0.012366\n",
       " 40   P_BAD0     0    0.40  4651.0   770.0   120.0   419.0     0.974848     0.352397  0.0  0.327245  0.879040  0.647603  0.850671  0.142040  0.912677  0.850296  0.700592  0.771013  0.223804   0.149329  0.025152\n",
       " 41   P_BAD0     0    0.41  4651.0   770.0   120.0   419.0     0.974848     0.352397  0.0  0.327245  0.879040  0.647603  0.850671  0.142040  0.912677  0.850296  0.700592  0.771013  0.223804   0.149329  0.025152\n",
       " 42   P_BAD0     0    0.42  4651.0   770.0   120.0   419.0     0.974848     0.352397  0.0  0.327245  0.879040  0.647603  0.850671  0.142040  0.912677  0.850296  0.700592  0.771013  0.223804   0.149329  0.025152\n",
       " 43   P_BAD0     0    0.43  4651.0   770.0   120.0   419.0     0.974848     0.352397  0.0  0.327245  0.879040  0.647603  0.850671  0.142040  0.912677  0.850296  0.700592  0.771013  0.223804   0.149329  0.025152\n",
       " 44   P_BAD0     0    0.44  4589.0   676.0   182.0   513.0     0.961853     0.431455  0.0  0.393308  0.888274  0.568545  0.856040  0.128395  0.914508  0.850296  0.700592  0.771013  0.223804   0.143960  0.038147\n",
       " 45   P_BAD0     0    0.45  4589.0   676.0   182.0   513.0     0.961853     0.431455  0.0  0.393308  0.888274  0.568545  0.856040  0.128395  0.914508  0.850296  0.700592  0.771013  0.223804   0.143960  0.038147\n",
       " 46   P_BAD0     0    0.46  4586.0   673.0   185.0   516.0     0.961224     0.433978  0.0  0.395202  0.888519  0.566022  0.856040  0.127971  0.914457  0.850296  0.700592  0.771013  0.223804   0.143960  0.038776\n",
       " 47   P_BAD0     0    0.47  4586.0   673.0   185.0   516.0     0.961224     0.433978  0.0  0.395202  0.888519  0.566022  0.856040  0.127971  0.914457  0.850296  0.700592  0.771013  0.223804   0.143960  0.038776\n",
       " 48   P_BAD0     0    0.48  4586.0   673.0   185.0   516.0     0.961224     0.433978  0.0  0.395202  0.888519  0.566022  0.856040  0.127971  0.914457  0.850296  0.700592  0.771013  0.223804   0.143960  0.038776\n",
       " 49   P_BAD0     0    0.49  4578.0   658.0   193.0   531.0     0.959547     0.446594  0.0  0.406141  0.890142  0.553406  0.857215  0.125668  0.914960  0.850296  0.700592  0.771013  0.223804   0.142785  0.040453\n",
       " 50   P_BAD0     0    0.50  4578.0   658.0   193.0   531.0     0.959547     0.446594  0.0  0.406141  0.890142  0.553406  0.857215  0.125668  0.914960  0.850296  0.700592  0.771013  0.223804   0.142785  0.040453\n",
       " 51   P_BAD0     0    0.51  4578.0   658.0   193.0   531.0     0.959547     0.446594  0.0  0.406141  0.890142  0.553406  0.857215  0.125668  0.914960  0.850296  0.700592  0.771013  0.223804   0.142785  0.040453\n",
       " 52   P_BAD0     0    0.52  4578.0   658.0   193.0   531.0     0.959547     0.446594  0.0  0.406141  0.890142  0.553406  0.857215  0.125668  0.914960  0.850296  0.700592  0.771013  0.223804   0.142785  0.040453\n",
       " 53   P_BAD0     0    0.53  4573.0   654.0   198.0   535.0     0.958499     0.449958  0.0  0.408457  0.890416  0.550042  0.857047  0.125120  0.914783  0.850296  0.700592  0.771013  0.223804   0.142953  0.041501\n",
       " 54   P_BAD0     0    0.54  4572.0   653.0   199.0   536.0     0.958290     0.450799  0.0  0.409089  0.890499  0.549201  0.857047  0.124976  0.914766  0.850296  0.700592  0.771013  0.223804   0.142953  0.041710\n",
       " 55   P_BAD0     0    0.55  4552.0   634.0   219.0   555.0     0.954098     0.466779  0.0  0.420876  0.892024  0.533221  0.856879  0.122252  0.914332  0.850296  0.700592  0.771013  0.223804   0.143121  0.045902\n",
       " 56   P_BAD0     0    0.56  4552.0   634.0   219.0   555.0     0.954098     0.466779  0.0  0.420876  0.892024  0.533221  0.856879  0.122252  0.914332  0.850296  0.700592  0.771013  0.223804   0.143121  0.045902\n",
       " 57   P_BAD0     0    0.57  4546.0   628.0   225.0   561.0     0.952840     0.471825  0.0  0.424665  0.892528  0.528175  0.856879  0.121376  0.914228  0.850296  0.700592  0.771013  0.223804   0.143121  0.047160\n",
       " 58   P_BAD0     0    0.58  4546.0   628.0   225.0   561.0     0.952840     0.471825  0.0  0.424665  0.892528  0.528175  0.856879  0.121376  0.914228  0.850296  0.700592  0.771013  0.223804   0.143121  0.047160\n",
       " 59   P_BAD0     0    0.59  4546.0   628.0   225.0   561.0     0.952840     0.471825  0.0  0.424665  0.892528  0.528175  0.856879  0.121376  0.914228  0.850296  0.700592  0.771013  0.223804   0.143121  0.047160\n",
       " 60   P_BAD0     0    0.60  4546.0   628.0   225.0   561.0     0.952840     0.471825  0.0  0.424665  0.892528  0.528175  0.856879  0.121376  0.914228  0.850296  0.700592  0.771013  0.223804   0.143121  0.047160\n",
       " 61   P_BAD0     0    0.61  4546.0   628.0   225.0   561.0     0.952840     0.471825  0.0  0.424665  0.892528  0.528175  0.856879  0.121376  0.914228  0.850296  0.700592  0.771013  0.223804   0.143121  0.047160\n",
       " 62   P_BAD0     0    0.62  4542.0   624.0   229.0   565.0     0.952002     0.475189  0.0  0.427191  0.892864  0.524811  0.856879  0.120790  0.914159  0.850296  0.700592  0.771013  0.223804   0.143121  0.047998\n",
       " 63   P_BAD0     0    0.63  4542.0   624.0   229.0   565.0     0.952002     0.475189  0.0  0.427191  0.892864  0.524811  0.856879  0.120790  0.914159  0.850296  0.700592  0.771013  0.223804   0.143121  0.047998\n",
       " 64   P_BAD0     0    0.64  4534.0   617.0   237.0   572.0     0.950325     0.481077  0.0  0.431401  0.893399  0.518923  0.856711  0.119783  0.913929  0.850296  0.700592  0.771013  0.223804   0.143289  0.049675\n",
       " 65   P_BAD0     0    0.65  4531.0   616.0   240.0   573.0     0.949696     0.481918  0.0  0.431614  0.893371  0.518082  0.856376  0.119681  0.913692  0.850296  0.700592  0.771013  0.223804   0.143624  0.050304\n",
       " 66   P_BAD0     0    0.66  4531.0   616.0   240.0   573.0     0.949696     0.481918  0.0  0.431614  0.893371  0.518082  0.856376  0.119681  0.913692  0.850296  0.700592  0.771013  0.223804   0.143624  0.050304\n",
       " 67   P_BAD0     0    0.67  4527.0   614.0   244.0   575.0     0.948858     0.483600  0.0  0.432457  0.893428  0.516400  0.856040  0.119432  0.913438  0.850296  0.700592  0.771013  0.223804   0.143960  0.051142\n",
       " 68   P_BAD0     0    0.68  4432.0   564.0   339.0   625.0     0.928946     0.525652  0.0  0.454598  0.895173  0.474348  0.848490  0.112890  0.907546  0.850296  0.700592  0.771013  0.223804   0.151510  0.071054\n",
       " 69   P_BAD0     0    0.69  4429.0   564.0   342.0   625.0     0.928317     0.525652  0.0  0.453969  0.895001  0.474348  0.847987  0.112958  0.907210  0.850296  0.700592  0.771013  0.223804   0.152013  0.071683\n",
       " 70   P_BAD0     0    0.70  4429.0   564.0   342.0   625.0     0.928317     0.525652  0.0  0.453969  0.895001  0.474348  0.847987  0.112958  0.907210  0.850296  0.700592  0.771013  0.223804   0.152013  0.071683\n",
       " 71   P_BAD0     0    0.71  4403.0   552.0   368.0   637.0     0.922867     0.535744  0.0  0.458612  0.895246  0.464256  0.845638  0.111403  0.905408  0.850296  0.700592  0.771013  0.223804   0.154362  0.077133\n",
       " 72   P_BAD0     0    0.72  3741.0   276.0  1030.0   913.0     0.784112     0.767872  0.0  0.551985  0.897596  0.232128  0.780872  0.068708  0.851388  0.850296  0.700592  0.771013  0.223804   0.219128  0.215888\n",
       " 73   P_BAD0     0    0.73  3740.0   275.0  1031.0   914.0     0.783903     0.768713  0.0  0.552616  0.897701  0.231287  0.780872  0.068493  0.851354  0.850296  0.700592  0.771013  0.223804   0.219128  0.216097\n",
       " 74   P_BAD0     0    0.74  3733.0   273.0  1038.0   916.0     0.782436     0.770395  0.0  0.552831  0.897572  0.229605  0.780034  0.068148  0.850632  0.850296  0.700592  0.771013  0.223804   0.219966  0.217564\n",
       " 75   P_BAD0     0    0.75  3733.0   273.0  1038.0   916.0     0.782436     0.770395  0.0  0.552831  0.897572  0.229605  0.780034  0.068148  0.850632  0.850296  0.700592  0.771013  0.223804   0.219966  0.217564\n",
       " 76   P_BAD0     0    0.76  3728.0   272.0  1043.0   917.0     0.781388     0.771236  0.0  0.552624  0.897405  0.228764  0.779362  0.068000  0.850074  0.850296  0.700592  0.771013  0.223804   0.220638  0.218612\n",
       " 77   P_BAD0     0    0.77  3728.0   272.0  1043.0   917.0     0.781388     0.771236  0.0  0.552624  0.897405  0.228764  0.779362  0.068000  0.850074  0.850296  0.700592  0.771013  0.223804   0.220638  0.218612\n",
       " 78   P_BAD0     0    0.78  3728.0   272.0  1043.0   917.0     0.781388     0.771236  0.0  0.552624  0.897405  0.228764  0.779362  0.068000  0.850074  0.850296  0.700592  0.771013  0.223804   0.220638  0.218612\n",
       " 79   P_BAD0     0    0.79  3645.0   246.0  1126.0   943.0     0.763991     0.793103  1.0  0.557094  0.896238  0.206897  0.769799  0.063223  0.841607  0.850296  0.700592  0.771013  0.223804   0.230201  0.236009\n",
       " 80   P_BAD0     0    0.80  3642.0   246.0  1129.0   943.0     0.763362     0.793103  0.0  0.556465  0.896029  0.206897  0.769295  0.063272  0.841206  0.850296  0.700592  0.771013  0.223804   0.230705  0.236638\n",
       " 81   P_BAD0     0    0.81  3350.0   176.0  1421.0  1013.0     0.702159     0.851976  0.0  0.554135  0.887417  0.148024  0.732047  0.049915  0.807521  0.850296  0.700592  0.771013  0.223804   0.267953  0.297841\n",
       " 82   P_BAD0     0    0.82  3322.0   170.0  1449.0  1019.0     0.696290     0.857023  0.0  0.553313  0.886387  0.142977  0.728356  0.048683  0.804066  0.850296  0.700592  0.771013  0.223804   0.271644  0.303710\n",
       " 83   P_BAD0     0    0.83  3247.0   155.0  1524.0  1034.0     0.680570     0.869638  0.0  0.550208  0.883345  0.130362  0.718289  0.045561  0.794567  0.850296  0.700592  0.771013  0.223804   0.281711  0.319430\n",
       " 84   P_BAD0     0    0.84  3236.0   154.0  1535.0  1035.0     0.678265     0.870479  0.0  0.548744  0.882658  0.129521  0.716611  0.045428  0.793040  0.850296  0.700592  0.771013  0.223804   0.283389  0.321735\n",
       " 85   P_BAD0     0    0.85  3222.0   152.0  1549.0  1037.0     0.675330     0.872161  0.0  0.547492  0.881918  0.127839  0.714597  0.045050  0.791160  0.850296  0.700592  0.771013  0.223804   0.285403  0.324670\n",
       " 86   P_BAD0     0    0.86  3212.0   150.0  1559.0  1039.0     0.673234     0.873844  0.0  0.547078  0.881497  0.126156  0.713255  0.044616  0.789868  0.850296  0.700592  0.771013  0.223804   0.286745  0.326766\n",
       " 87   P_BAD0     0    0.87  3182.0   144.0  1589.0  1045.0     0.666946     0.878890  0.0  0.545836  0.880221  0.121110  0.709228  0.043295  0.785970  0.850296  0.700592  0.771013  0.223804   0.290772  0.333054\n",
       " 88   P_BAD0     0    0.88  3177.0   143.0  1594.0  1046.0     0.665898     0.879731  0.0  0.545629  0.880007  0.120269  0.708557  0.043072  0.785317  0.850296  0.700592  0.771013  0.223804   0.291443  0.334102\n",
       " 89   P_BAD0     0    0.89  3071.0   131.0  1700.0  1058.0     0.643681     0.889823  0.0  0.533504  0.873485  0.110177  0.692785  0.040912  0.770350  0.850296  0.700592  0.771013  0.223804   0.307215  0.356319\n",
       " 90   P_BAD0     0    0.90  3032.0   128.0  1739.0  1061.0     0.635506     0.892347  0.0  0.527853  0.870714  0.107653  0.686745  0.040506  0.764595  0.850296  0.700592  0.771013  0.223804   0.313255  0.364494\n",
       " 91   P_BAD0     0    0.91  2958.0   122.0  1813.0  1067.0     0.619996     0.897393  0.0  0.517389  0.865368  0.102607  0.675336  0.039610  0.753535  0.850296  0.700592  0.771013  0.223804   0.324664  0.380004\n",
       " 92   P_BAD0     0    0.92  2958.0   122.0  1813.0  1067.0     0.619996     0.897393  0.0  0.517389  0.865368  0.102607  0.675336  0.039610  0.753535  0.850296  0.700592  0.771013  0.223804   0.324664  0.380004\n",
       " 93   P_BAD0     0    0.93  2845.0   116.0  1926.0  1073.0     0.596311     0.902439  0.0  0.498750  0.856154  0.097561  0.657383  0.039176  0.735903  0.850296  0.700592  0.771013  0.223804   0.342617  0.403689\n",
       " 94   P_BAD0     0    0.94   284.0     4.0  4487.0  1185.0     0.059526     0.996636  0.0  0.056162  0.239743  0.003364  0.246477  0.013889  0.112275  0.850296  0.700592  0.771013  0.223804   0.753523  0.940474\n",
       " 95   P_BAD0     0    0.95    16.0     0.0  4755.0  1189.0     0.003354     1.000000  0.0  0.003354  0.016546  0.000000  0.202181  0.000000  0.006685  0.850296  0.700592  0.771013  0.223804   0.797819  0.996646\n",
       " 96   P_BAD0     0    0.96     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.850296  0.700592  0.771013  0.223804   0.800503  1.000000\n",
       " 97   P_BAD0     0    0.97     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.850296  0.700592  0.771013  0.223804   0.800503  1.000000\n",
       " 98   P_BAD0     0    0.98     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.850296  0.700592  0.771013  0.223804   0.800503  1.000000\n",
       " 99   P_BAD0     0    0.99     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.850296  0.700592  0.771013  0.223804   0.800503  1.000000,\n",
       "  Fit Statistics for _AUTOTUNE_DEFAULT_SCORE_TABLE_\n",
       " \n",
       "      NOBS       ASE     DIV      RASE       MCE      MCLL\n",
       " 0  5960.0  0.107058  5960.0  0.327197  0.142785  0.350075,\n",
       "  Tuner Information\n",
       " \n",
       "                            Parameter                   Value\n",
       " 0                         Model Type  Gradient Boosting Tree\n",
       " 1           Tuner Objective Function       Misclassification\n",
       " 2                      Search Method                    GRID\n",
       " 3              Number of Grid Points                      16\n",
       " 4     Maximum Tuning Time in Seconds                   36000\n",
       " 5                    Validation Type        Cross-Validation\n",
       " 6      Num Folds in Cross-Validation                       5\n",
       " 7                          Log Level                       0\n",
       " 8                               Seed              1876921633\n",
       " 9     Number of Parallel Evaluations                       4\n",
       " 10  Number of Workers per Subsession                       0,\n",
       "  Tuner Results\n",
       " \n",
       "     Evaluation  M  LEARNINGRATE  SUBSAMPLERATE  LASSO  RIDGE  NBINS  MAXLEVEL  MeanConseqError  EvaluationTime\n",
       " 0            0  4          0.10            0.5    0.0    1.0     50         5         0.199497        0.670014\n",
       " 1           13  4          0.10            0.6    0.5    0.0     77         7         0.139405       12.511936\n",
       " 2           14  4          0.10            0.6    0.0    0.0     77         5         0.140579        9.822356\n",
       " 3           10  4          0.10            0.6    0.5    0.0     77         5         0.141972       10.613496\n",
       " 4           15  4          0.10            0.8    0.0    0.0     77         5         0.142307        9.294920\n",
       " 5            7  4          0.10            0.6    0.0    0.0     77         7         0.143817       14.823709\n",
       " 6            2  4          0.10            0.8    0.0    0.0     77         7         0.145134        8.639427\n",
       " 7            3  4          0.10            0.8    0.5    0.0     77         5         0.145353       13.533517\n",
       " 8            6  4          0.10            0.8    0.5    0.0     77         7         0.146116       13.496130\n",
       " 9            8  4          0.05            0.8    0.0    0.0     77         7         0.199362        6.389004\n",
       " 10           1  4          0.05            0.6    0.0    0.0     77         5         0.199463        1.648640,\n",
       "  Tuner Iteration History\n",
       " \n",
       "    Iteration  Evaluations  Best_obj   Time_sec\n",
       " 0          0            1  0.199497   0.670014\n",
       " 1          1           17  0.139405  35.240054,\n",
       "  Tuner Evaluation History\n",
       " \n",
       "     Evaluation  Iteration  M  LEARNINGRATE  SUBSAMPLERATE  LASSO  RIDGE  NBINS  MAXLEVEL  MeanConseqError  EvaluationTime\n",
       " 0            0          0  4          0.10            0.5    0.0    1.0     50         5         0.199497        0.670014\n",
       " 1            1          1  4          0.05            0.6    0.0    0.0     77         5         0.199463        1.648640\n",
       " 2            2          1  4          0.10            0.8    0.0    0.0     77         7         0.145134        8.639427\n",
       " 3            3          1  4          0.10            0.8    0.5    0.0     77         5         0.145353       13.533517\n",
       " 4            4          1  4          0.05            0.6    0.5    0.0     77         5         0.199530        4.638940\n",
       " 5            5          1  4          0.05            0.6    0.0    0.0     77         7         0.199664        5.586327\n",
       " 6            6          1  4          0.10            0.8    0.5    0.0     77         7         0.146116       13.496130\n",
       " 7            7          1  4          0.10            0.6    0.0    0.0     77         7         0.143817       14.823709\n",
       " 8            8          1  4          0.05            0.8    0.0    0.0     77         7         0.199362        6.389004\n",
       " 9            9          1  4          0.05            0.8    0.5    0.0     77         7         0.199631        6.217389\n",
       " 10          10          1  4          0.10            0.6    0.5    0.0     77         5         0.141972       10.613496\n",
       " 11          11          1  4          0.05            0.6    0.5    0.0     77         7         0.199530        6.591687\n",
       " 12          12          1  4          0.05            0.8    0.0    0.0     77         5         0.199497        5.000299\n",
       " 13          13          1  4          0.10            0.6    0.5    0.0     77         7         0.139405       12.511936\n",
       " 14          14          1  4          0.10            0.6    0.0    0.0     77         5         0.140579        9.822356\n",
       " 15          15          1  4          0.10            0.8    0.0    0.0     77         5         0.142307        9.294920\n",
       " 16          16          1  4          0.05            0.8    0.5    0.0     77         5         0.199497        6.482619,\n",
       "  Best Configuration\n",
       " \n",
       "                     Parameter           Name         Value\n",
       " 0                  Evaluation     Evaluation            13\n",
       " 1  Number of Variables to Try              M             4\n",
       " 2               Learning Rate   LEARNINGRATE           0.1\n",
       " 3               Sampling Rate  SUBSAMPLERATE           0.6\n",
       " 4                       Lasso          LASSO           0.5\n",
       " 5                       Ridge          RIDGE             0\n",
       " 6              Number of Bins          NBINS            77\n",
       " 7         Maximum Tree Levels       MAXLEVEL             7\n",
       " 8           Misclassification      Objective  0.1394047773,\n",
       "  Tuner Summary\n",
       " \n",
       "                                           Parameter      Value\n",
       " 0             Initial Configuration Objective Value   0.199497\n",
       " 1                Best Configuration Objective Value   0.139405\n",
       " 2               Worst Configuration Objective Value   0.199664\n",
       " 3  Initial Configuration Evaluation Time in Seconds   0.670014\n",
       " 4     Best Configuration Evaluation Time in Seconds  12.511924\n",
       " 5                 Number of Improved Configurations   6.000000\n",
       " 6                Number of Evaluated Configurations  17.000000\n",
       " 7                      Total Tuning Time in Seconds  35.556643\n",
       " 8                           Parallel Tuning Speedup   3.811450,\n",
       "  Tuner Task Timing\n",
       " \n",
       "                           Task    Time_sec  Time_percent\n",
       " 0               Model Training  127.032699     93.735588\n",
       " 1                Model Scoring    7.598382      5.606736\n",
       " 2  Total Objective Evaluations  134.644803     99.352449\n",
       " 3                        Tuner    0.877577      0.647551\n",
       " 4               Total CPU Time  135.522379    100.000000,\n",
       "  Hyperparameter Importance\n",
       " \n",
       "   Hyperparameter  RelImportance\n",
       " 0   LEARNINGRATE       1.000000\n",
       " 1          LASSO       0.003551\n",
       " 2       MAXLEVEL       0.002698\n",
       " 3  SUBSAMPLERATE       0.001024\n",
       " 4              M       0.000000\n",
       " 5          RIDGE       0.000000\n",
       " 6          NBINS       0.000000,\n",
       "  TuneAll Results Summary\n",
       " \n",
       "           ModelID               ModelType  Evaluations  BestObjective  AverageObjective  StdDevObjective  BestObjTime  AverageTime  StdDevTime\n",
       " 0  1_DecisionTree           Decision Tree            6       0.144102          0.149218         0.004400     1.393360     0.841353    0.323815\n",
       " 1     2_GradBoost  Gradient Boosting Tree           16       0.139405          0.180630         0.035188    12.511936     8.508234    3.773154,\n",
       "  TuneAll Best Models\n",
       " \n",
       "           ModelID  Evaluation  MeanConseqError  EvaluationTime\n",
       " 0     2_GradBoost          13         0.139405       12.511936\n",
       " 1     2_GradBoost          14         0.140579        9.822356\n",
       " 2     2_GradBoost          10         0.141972       10.613496\n",
       " 3     2_GradBoost          15         0.142307        9.294920\n",
       " 4     2_GradBoost           7         0.143817       14.823709\n",
       " 5  1_DecisionTree           3         0.144102        1.393360\n",
       " 6  1_DecisionTree           2         0.144297        0.987102\n",
       " 7     2_GradBoost           2         0.145134        8.639427\n",
       " 8     2_GradBoost           3         0.145353       13.533517\n",
       " 9     2_GradBoost           6         0.146116       13.496130,\n",
       "  TuneAll CAS Output Tables\n",
       " \n",
       " Empty SASDataFrame\n",
       " Columns: [ModelID, CAS_Library, Name, Rows, Columns]\n",
       " Index: [],\n",
       "  Decision Tree for __TEMP_FEATURE_MACHINE_CASOUT___AUTOTUNE_DATA_11FA4B25-9848-604F-9F45-7E73830B6354\n",
       " \n",
       "                            Descr        Value\n",
       " 0           Number of Tree Nodes     7.000000\n",
       " 1         Max Number of Branches     2.000000\n",
       " 2               Number of Levels     4.000000\n",
       " 3               Number of Leaves     4.000000\n",
       " 4                 Number of Bins    50.000000\n",
       " 5         Minimum Size of Leaves   546.000000\n",
       " 6         Maximum Size of Leaves  4179.000000\n",
       " 7            Number of Variables     1.000000\n",
       " 8   Confidence Level for Pruning     0.250000\n",
       " 9    Number of Observations Used  5960.000000\n",
       " 10   Misclassification Error (%)    18.674497,\n",
       "                           Descr                             Value\n",
       " 0  Number of Observations Read                              5960\n",
       " 1  Number of Observations Used                              5960\n",
       " 2  Misclassification Error (%)                      18.674496644,\n",
       "          LEVNAME  LEVINDEX VARNAME\n",
       " 0             1         0  P_BAD1\n",
       " 1             0         1  P_BAD0,\n",
       "    LEVNAME  LEVINDEX VARNAME\n",
       " 0                 0   I_BAD,\n",
       "  ROC Information for _AUTOTUNE_DEFAULT_SCORE_TABLE_\n",
       " \n",
       "    Variable Event  CutOff      TP      FP      FN      TN  Sensitivity  Specificity   KS       KS2    F_HALF       FPR       ACC       FDR        F1         C      Gini     Gamma       Tau  MISCEVENT       FNR\n",
       " 0    P_BAD0     0    0.00  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 1    P_BAD0     0    0.01  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 2    P_BAD0     0    0.02  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 3    P_BAD0     0    0.03  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 4    P_BAD0     0    0.04  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 5    P_BAD0     0    0.05  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 6    P_BAD0     0    0.06  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 7    P_BAD0     0    0.07  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 8    P_BAD0     0    0.08  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 9    P_BAD0     0    0.09  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 10   P_BAD0     0    0.10  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 11   P_BAD0     0    0.11  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 12   P_BAD0     0    0.12  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 13   P_BAD0     0    0.13  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 14   P_BAD0     0    0.14  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 15   P_BAD0     0    0.15  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 16   P_BAD0     0    0.16  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 17   P_BAD0     0    0.17  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 18   P_BAD0     0    0.18  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 19   P_BAD0     0    0.19  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 20   P_BAD0     0    0.20  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 21   P_BAD0     0    0.21  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 22   P_BAD0     0    0.22  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 23   P_BAD0     0    0.23  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 24   P_BAD0     0    0.24  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 25   P_BAD0     0    0.25  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 26   P_BAD0     0    0.26  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 27   P_BAD0     0    0.27  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 28   P_BAD0     0    0.28  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 29   P_BAD0     0    0.29  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 30   P_BAD0     0    0.30  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 31   P_BAD0     0    0.31  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 32   P_BAD0     0    0.32  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 33   P_BAD0     0    0.33  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 34   P_BAD0     0    0.34  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 35   P_BAD0     0    0.35  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 36   P_BAD0     0    0.36  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 37   P_BAD0     0    0.37  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 38   P_BAD0     0    0.38  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 39   P_BAD0     0    0.39  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 40   P_BAD0     0    0.40  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 41   P_BAD0     0    0.41  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 42   P_BAD0     0    0.42  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 43   P_BAD0     0    0.43  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 44   P_BAD0     0    0.44  4536.0   878.0   235.0   311.0     0.950744     0.261564  0.0  0.212308  0.858213  0.738436  0.813255  0.162172  0.890722  0.664447  0.328893  0.553596  0.105065   0.186745  0.049256\n",
       " 45   P_BAD0     0    0.45  4536.0   878.0   235.0   311.0     0.950744     0.261564  0.0  0.212308  0.858213  0.738436  0.813255  0.162172  0.890722  0.664447  0.328893  0.553596  0.105065   0.186745  0.049256\n",
       " 46   P_BAD0     0    0.46  4536.0   878.0   235.0   311.0     0.950744     0.261564  0.0  0.212308  0.858213  0.738436  0.813255  0.162172  0.890722  0.664447  0.328893  0.553596  0.105065   0.186745  0.049256\n",
       " 47   P_BAD0     0    0.47  4536.0   878.0   235.0   311.0     0.950744     0.261564  0.0  0.212308  0.858213  0.738436  0.813255  0.162172  0.890722  0.664447  0.328893  0.553596  0.105065   0.186745  0.049256\n",
       " 48   P_BAD0     0    0.48  4536.0   878.0   235.0   311.0     0.950744     0.261564  0.0  0.212308  0.858213  0.738436  0.813255  0.162172  0.890722  0.664447  0.328893  0.553596  0.105065   0.186745  0.049256\n",
       " 49   P_BAD0     0    0.49  4536.0   878.0   235.0   311.0     0.950744     0.261564  0.0  0.212308  0.858213  0.738436  0.813255  0.162172  0.890722  0.664447  0.328893  0.553596  0.105065   0.186745  0.049256\n",
       " 50   P_BAD0     0    0.50  4536.0   878.0   235.0   311.0     0.950744     0.261564  0.0  0.212308  0.858213  0.738436  0.813255  0.162172  0.890722  0.664447  0.328893  0.553596  0.105065   0.186745  0.049256\n",
       " 51   P_BAD0     0    0.51  4536.0   878.0   235.0   311.0     0.950744     0.261564  0.0  0.212308  0.858213  0.738436  0.813255  0.162172  0.890722  0.664447  0.328893  0.553596  0.105065   0.186745  0.049256\n",
       " 52   P_BAD0     0    0.52  4536.0   878.0   235.0   311.0     0.950744     0.261564  0.0  0.212308  0.858213  0.738436  0.813255  0.162172  0.890722  0.664447  0.328893  0.553596  0.105065   0.186745  0.049256\n",
       " 53   P_BAD0     0    0.53  4536.0   878.0   235.0   311.0     0.950744     0.261564  0.0  0.212308  0.858213  0.738436  0.813255  0.162172  0.890722  0.664447  0.328893  0.553596  0.105065   0.186745  0.049256\n",
       " 54   P_BAD0     0    0.54  4536.0   878.0   235.0   311.0     0.950744     0.261564  0.0  0.212308  0.858213  0.738436  0.813255  0.162172  0.890722  0.664447  0.328893  0.553596  0.105065   0.186745  0.049256\n",
       " 55   P_BAD0     0    0.55  4536.0   878.0   235.0   311.0     0.950744     0.261564  0.0  0.212308  0.858213  0.738436  0.813255  0.162172  0.890722  0.664447  0.328893  0.553596  0.105065   0.186745  0.049256\n",
       " 56   P_BAD0     0    0.56  4536.0   878.0   235.0   311.0     0.950744     0.261564  0.0  0.212308  0.858213  0.738436  0.813255  0.162172  0.890722  0.664447  0.328893  0.553596  0.105065   0.186745  0.049256\n",
       " 57   P_BAD0     0    0.57  4536.0   878.0   235.0   311.0     0.950744     0.261564  0.0  0.212308  0.858213  0.738436  0.813255  0.162172  0.890722  0.664447  0.328893  0.553596  0.105065   0.186745  0.049256\n",
       " 58   P_BAD0     0    0.58  4536.0   878.0   235.0   311.0     0.950744     0.261564  0.0  0.212308  0.858213  0.738436  0.813255  0.162172  0.890722  0.664447  0.328893  0.553596  0.105065   0.186745  0.049256\n",
       " 59   P_BAD0     0    0.59  4536.0   878.0   235.0   311.0     0.950744     0.261564  0.0  0.212308  0.858213  0.738436  0.813255  0.162172  0.890722  0.664447  0.328893  0.553596  0.105065   0.186745  0.049256\n",
       " 60   P_BAD0     0    0.60  4536.0   878.0   235.0   311.0     0.950744     0.261564  0.0  0.212308  0.858213  0.738436  0.813255  0.162172  0.890722  0.664447  0.328893  0.553596  0.105065   0.186745  0.049256\n",
       " 61   P_BAD0     0    0.61  4536.0   878.0   235.0   311.0     0.950744     0.261564  0.0  0.212308  0.858213  0.738436  0.813255  0.162172  0.890722  0.664447  0.328893  0.553596  0.105065   0.186745  0.049256\n",
       " 62   P_BAD0     0    0.62  4536.0   878.0   235.0   311.0     0.950744     0.261564  0.0  0.212308  0.858213  0.738436  0.813255  0.162172  0.890722  0.664447  0.328893  0.553596  0.105065   0.186745  0.049256\n",
       " 63   P_BAD0     0    0.63  4536.0   878.0   235.0   311.0     0.950744     0.261564  0.0  0.212308  0.858213  0.738436  0.813255  0.162172  0.890722  0.664447  0.328893  0.553596  0.105065   0.186745  0.049256\n",
       " 64   P_BAD0     0    0.64  4536.0   878.0   235.0   311.0     0.950744     0.261564  0.0  0.212308  0.858213  0.738436  0.813255  0.162172  0.890722  0.664447  0.328893  0.553596  0.105065   0.186745  0.049256\n",
       " 65   P_BAD0     0    0.65  4536.0   878.0   235.0   311.0     0.950744     0.261564  0.0  0.212308  0.858213  0.738436  0.813255  0.162172  0.890722  0.664447  0.328893  0.553596  0.105065   0.186745  0.049256\n",
       " 66   P_BAD0     0    0.66  4536.0   878.0   235.0   311.0     0.950744     0.261564  0.0  0.212308  0.858213  0.738436  0.813255  0.162172  0.890722  0.664447  0.328893  0.553596  0.105065   0.186745  0.049256\n",
       " 67   P_BAD0     0    0.67  4104.0   656.0   667.0   533.0     0.860197     0.448276  1.0  0.308473  0.861787  0.551724  0.778020  0.137815  0.861190  0.664447  0.328893  0.553596  0.105065   0.221980  0.139803\n",
       " 68   P_BAD0     0    0.68  4104.0   656.0   667.0   533.0     0.860197     0.448276  0.0  0.308473  0.861787  0.551724  0.778020  0.137815  0.861190  0.664447  0.328893  0.553596  0.105065   0.221980  0.139803\n",
       " 69   P_BAD0     0    0.69  4104.0   656.0   667.0   533.0     0.860197     0.448276  0.0  0.308473  0.861787  0.551724  0.778020  0.137815  0.861190  0.664447  0.328893  0.553596  0.105065   0.221980  0.139803\n",
       " 70   P_BAD0     0    0.70  4104.0   656.0   667.0   533.0     0.860197     0.448276  0.0  0.308473  0.861787  0.551724  0.778020  0.137815  0.861190  0.664447  0.328893  0.553596  0.105065   0.221980  0.139803\n",
       " 71   P_BAD0     0    0.71  4104.0   656.0   667.0   533.0     0.860197     0.448276  0.0  0.308473  0.861787  0.551724  0.778020  0.137815  0.861190  0.664447  0.328893  0.553596  0.105065   0.221980  0.139803\n",
       " 72   P_BAD0     0    0.72  4104.0   656.0   667.0   533.0     0.860197     0.448276  0.0  0.308473  0.861787  0.551724  0.778020  0.137815  0.861190  0.664447  0.328893  0.553596  0.105065   0.221980  0.139803\n",
       " 73   P_BAD0     0    0.73  4104.0   656.0   667.0   533.0     0.860197     0.448276  0.0  0.308473  0.861787  0.551724  0.778020  0.137815  0.861190  0.664447  0.328893  0.553596  0.105065   0.221980  0.139803\n",
       " 74   P_BAD0     0    0.74  4104.0   656.0   667.0   533.0     0.860197     0.448276  0.0  0.308473  0.861787  0.551724  0.778020  0.137815  0.861190  0.664447  0.328893  0.553596  0.105065   0.221980  0.139803\n",
       " 75   P_BAD0     0    0.75  4104.0   656.0   667.0   533.0     0.860197     0.448276  0.0  0.308473  0.861787  0.551724  0.778020  0.137815  0.861190  0.664447  0.328893  0.553596  0.105065   0.221980  0.139803\n",
       " 76   P_BAD0     0    0.76  4104.0   656.0   667.0   533.0     0.860197     0.448276  0.0  0.308473  0.861787  0.551724  0.778020  0.137815  0.861190  0.664447  0.328893  0.553596  0.105065   0.221980  0.139803\n",
       " 77   P_BAD0     0    0.77  4104.0   656.0   667.0   533.0     0.860197     0.448276  0.0  0.308473  0.861787  0.551724  0.778020  0.137815  0.861190  0.664447  0.328893  0.553596  0.105065   0.221980  0.139803\n",
       " 78   P_BAD0     0    0.78  4104.0   656.0   667.0   533.0     0.860197     0.448276  0.0  0.308473  0.861787  0.551724  0.778020  0.137815  0.861190  0.664447  0.328893  0.553596  0.105065   0.221980  0.139803\n",
       " 79   P_BAD0     0    0.79  4104.0   656.0   667.0   533.0     0.860197     0.448276  0.0  0.308473  0.861787  0.551724  0.778020  0.137815  0.861190  0.664447  0.328893  0.553596  0.105065   0.221980  0.139803\n",
       " 80   P_BAD0     0    0.80  4104.0   656.0   667.0   533.0     0.860197     0.448276  0.0  0.308473  0.861787  0.551724  0.778020  0.137815  0.861190  0.664447  0.328893  0.553596  0.105065   0.221980  0.139803\n",
       " 81   P_BAD0     0    0.81  4104.0   656.0   667.0   533.0     0.860197     0.448276  0.0  0.308473  0.861787  0.551724  0.778020  0.137815  0.861190  0.664447  0.328893  0.553596  0.105065   0.221980  0.139803\n",
       " 82   P_BAD0     0    0.82  4104.0   656.0   667.0   533.0     0.860197     0.448276  0.0  0.308473  0.861787  0.551724  0.778020  0.137815  0.861190  0.664447  0.328893  0.553596  0.105065   0.221980  0.139803\n",
       " 83   P_BAD0     0    0.83  4104.0   656.0   667.0   533.0     0.860197     0.448276  0.0  0.308473  0.861787  0.551724  0.778020  0.137815  0.861190  0.664447  0.328893  0.553596  0.105065   0.221980  0.139803\n",
       " 84   P_BAD0     0    0.84  4104.0   656.0   667.0   533.0     0.860197     0.448276  0.0  0.308473  0.861787  0.551724  0.778020  0.137815  0.861190  0.664447  0.328893  0.553596  0.105065   0.221980  0.139803\n",
       " 85   P_BAD0     0    0.85  4104.0   656.0   667.0   533.0     0.860197     0.448276  0.0  0.308473  0.861787  0.551724  0.778020  0.137815  0.861190  0.664447  0.328893  0.553596  0.105065   0.221980  0.139803\n",
       " 86   P_BAD0     0    0.86  4104.0   656.0   667.0   533.0     0.860197     0.448276  0.0  0.308473  0.861787  0.551724  0.778020  0.137815  0.861190  0.664447  0.328893  0.553596  0.105065   0.221980  0.139803\n",
       " 87   P_BAD0     0    0.87   508.0    73.0  4263.0  1116.0     0.106477     0.938604  0.0  0.045080  0.357999  0.061396  0.272483  0.125645  0.189836  0.664447  0.328893  0.553596  0.105065   0.727517  0.893523\n",
       " 88   P_BAD0     0    0.88     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.664447  0.328893  0.553596  0.105065   0.800503  1.000000\n",
       " 89   P_BAD0     0    0.89     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.664447  0.328893  0.553596  0.105065   0.800503  1.000000\n",
       " 90   P_BAD0     0    0.90     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.664447  0.328893  0.553596  0.105065   0.800503  1.000000\n",
       " 91   P_BAD0     0    0.91     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.664447  0.328893  0.553596  0.105065   0.800503  1.000000\n",
       " 92   P_BAD0     0    0.92     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.664447  0.328893  0.553596  0.105065   0.800503  1.000000\n",
       " 93   P_BAD0     0    0.93     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.664447  0.328893  0.553596  0.105065   0.800503  1.000000\n",
       " 94   P_BAD0     0    0.94     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.664447  0.328893  0.553596  0.105065   0.800503  1.000000\n",
       " 95   P_BAD0     0    0.95     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.664447  0.328893  0.553596  0.105065   0.800503  1.000000\n",
       " 96   P_BAD0     0    0.96     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.664447  0.328893  0.553596  0.105065   0.800503  1.000000\n",
       " 97   P_BAD0     0    0.97     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.664447  0.328893  0.553596  0.105065   0.800503  1.000000\n",
       " 98   P_BAD0     0    0.98     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.664447  0.328893  0.553596  0.105065   0.800503  1.000000\n",
       " 99   P_BAD0     0    0.99     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.664447  0.328893  0.553596  0.105065   0.800503  1.000000,\n",
       "  Fit Statistics for _AUTOTUNE_DEFAULT_SCORE_TABLE_\n",
       " \n",
       "      NOBS       ASE     DIV      RASE       MCE      MCLL\n",
       " 0  5960.0  0.141945  5960.0  0.376756  0.186745  0.453084,\n",
       "  Tuner Information\n",
       " \n",
       "                            Parameter              Value\n",
       " 0                         Model Type      Decision Tree\n",
       " 1           Tuner Objective Function  Misclassification\n",
       " 2                      Search Method               GRID\n",
       " 3              Number of Grid Points                  6\n",
       " 4     Maximum Tuning Time in Seconds              36000\n",
       " 5                    Validation Type   Cross-Validation\n",
       " 6      Num Folds in Cross-Validation                  5\n",
       " 7                          Log Level                  0\n",
       " 8                               Seed         1876918040\n",
       " 9     Number of Parallel Evaluations                  4\n",
       " 10  Number of Workers per Subsession                  0,\n",
       "  Tuner Results\n",
       " \n",
       "    Evaluation  MAXLEVEL       CRIT  MeanConseqError  EvaluationTime\n",
       " 0           0        11  gainRatio         0.186747        0.307288\n",
       " 1           1         5  gainRatio         0.186747        0.312266\n",
       " 2           2        10       gain         0.186747        0.466998\n",
       " 3           3        10  gainRatio         0.186747        0.467011\n",
       " 4           4        15       gain         0.186747        0.706889\n",
       " 5           5        15  gainRatio         0.186747        0.454053\n",
       " 6           6         5       gain         0.186747        0.299689,\n",
       "  Tuner Iteration History\n",
       " \n",
       "    Iteration  Evaluations  Best_obj  Time_sec\n",
       " 0          0            1  0.186747  0.307288\n",
       " 1          1            7  0.186747  1.073706,\n",
       "  Tuner Evaluation History\n",
       " \n",
       "    Evaluation  Iteration  MAXLEVEL       CRIT  MeanConseqError  EvaluationTime\n",
       " 0           0          0        11  gainRatio         0.186747        0.307288\n",
       " 1           1          1         5  gainRatio         0.186747        0.312266\n",
       " 2           2          1        10       gain         0.186747        0.466998\n",
       " 3           3          1        10  gainRatio         0.186747        0.467011\n",
       " 4           4          1        15       gain         0.186747        0.706889\n",
       " 5           5          1        15  gainRatio         0.186747        0.454053\n",
       " 6           6          1         5       gain         0.186747        0.299689,\n",
       "  Best Configuration\n",
       " \n",
       "              Parameter        Name         Value\n",
       " 0           Evaluation  Evaluation             0\n",
       " 1  Maximum Tree Levels    MAXLEVEL            11\n",
       " 2            Criterion        CRIT     gainRatio\n",
       " 3    Misclassification   Objective  0.1867467085,\n",
       "  Tuner Summary\n",
       " \n",
       "                                           Parameter     Value\n",
       " 0             Initial Configuration Objective Value  0.186747\n",
       " 1                Best Configuration Objective Value  0.186747\n",
       " 2               Worst Configuration Objective Value  0.186747\n",
       " 3  Initial Configuration Evaluation Time in Seconds  0.307288\n",
       " 4     Best Configuration Evaluation Time in Seconds  0.307288\n",
       " 5                 Number of Improved Configurations  0.000000\n",
       " 6                Number of Evaluated Configurations  7.000000\n",
       " 7                      Total Tuning Time in Seconds  1.115528\n",
       " 8                           Parallel Tuning Speedup  1.927359,\n",
       "  Tuner Task Timing\n",
       " \n",
       "                           Task  Time_sec  Time_percent\n",
       " 0               Model Training  0.690982     32.138362\n",
       " 1                Model Scoring  0.658662     30.635122\n",
       " 2  Total Objective Evaluations  1.508758     70.174051\n",
       " 3                        Tuner  0.641265     29.825949\n",
       " 4               Total CPU Time  2.150023    100.000000,\n",
       "  Gradient Boosting Tree for __TEMP_FEATURE_MACHINE_CASOUT___AUTOTUNE_DATA_11FA4B25-9848-604F-9F45-7E73830B6354\n",
       " \n",
       "                                   Descr         Value\n",
       " 0                       Number of Trees  1.500000e+02\n",
       " 1                          Distribution  2.000000e+00\n",
       " 2                         Learning Rate  5.000000e-02\n",
       " 3                      Subsampling Rate  6.000000e-01\n",
       " 4      Number of Selected Variables (M)  1.000000e+00\n",
       " 5                        Number of Bins  5.000000e+01\n",
       " 6                   Number of Variables  1.000000e+00\n",
       " 7              Max Number of Tree Nodes  5.000000e+00\n",
       " 8              Min Number of Tree Nodes  5.000000e+00\n",
       " 9                Max Number of Branches  2.000000e+00\n",
       " 10               Min Number of Branches  2.000000e+00\n",
       " 11                 Max Number of Levels  3.000000e+00\n",
       " 12                 Min Number of Levels  3.000000e+00\n",
       " 13                 Max Number of Leaves  3.000000e+00\n",
       " 14                 Min Number of Leaves  3.000000e+00\n",
       " 15               Maximum Size of Leaves  2.829000e+03\n",
       " 16               Minimum Size of Leaves  3.380000e+02\n",
       " 17                   Random Number Seed  1.876918e+09\n",
       " 18                   Lasso (L1) penalty  5.000000e-01\n",
       " 19                   Ridge (L2) penalty  0.000000e+00\n",
       " 20               Actual Number of Trees  1.000000e+00\n",
       " 21             Average number of Leaves  3.000000e+00\n",
       " 22            Early stopping stagnation  4.000000e+00\n",
       " 23             Early stopping threshold  0.000000e+00\n",
       " 24  Early stopping threshold iterations  0.000000e+00\n",
       " 25             Early stopping tolerance  0.000000e+00,\n",
       "     Progress    Metric\n",
       " 0       1.0  0.199497,\n",
       "                           Descr                             Value\n",
       " 0  Number of Observations Read                              5960\n",
       " 1  Number of Observations Used                              5960\n",
       " 2  Misclassification Error (%)                       19.94966443,\n",
       "     TreeID  Trees  NLeaves       MCR  LogLoss       ASE      RASE     MAXAE\n",
       " 0     0.0    1.0      3.0  0.199497  0.49413  0.157872  0.397331  0.803768,\n",
       "          LEVNAME  LEVINDEX VARNAME\n",
       " 0             1         0  P_BAD1\n",
       " 1             0         1  P_BAD0,\n",
       "    LEVNAME  LEVINDEX VARNAME\n",
       " 0                 0   I_BAD,\n",
       "  ROC Information for _AUTOTUNE_DEFAULT_SCORE_TABLE_\n",
       " \n",
       "    Variable Event  CutOff      TP      FP      FN      TN  Sensitivity  Specificity   KS       KS2    F_HALF       FPR       ACC       FDR        F1        C     Gini    Gamma       Tau  MISCEVENT       FNR\n",
       " 0    P_BAD0     0    0.00  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 1    P_BAD0     0    0.01  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 2    P_BAD0     0    0.02  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 3    P_BAD0     0    0.03  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 4    P_BAD0     0    0.04  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 5    P_BAD0     0    0.05  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 6    P_BAD0     0    0.06  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 7    P_BAD0     0    0.07  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 8    P_BAD0     0    0.08  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 9    P_BAD0     0    0.09  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 10   P_BAD0     0    0.10  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 11   P_BAD0     0    0.11  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 12   P_BAD0     0    0.12  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 13   P_BAD0     0    0.13  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 14   P_BAD0     0    0.14  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 15   P_BAD0     0    0.15  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 16   P_BAD0     0    0.16  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 17   P_BAD0     0    0.17  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 18   P_BAD0     0    0.18  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 19   P_BAD0     0    0.19  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 20   P_BAD0     0    0.20  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 21   P_BAD0     0    0.21  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 22   P_BAD0     0    0.22  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 23   P_BAD0     0    0.23  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 24   P_BAD0     0    0.24  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 25   P_BAD0     0    0.25  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 26   P_BAD0     0    0.26  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 27   P_BAD0     0    0.27  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 28   P_BAD0     0    0.28  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 29   P_BAD0     0    0.29  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 30   P_BAD0     0    0.30  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 31   P_BAD0     0    0.31  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 32   P_BAD0     0    0.32  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 33   P_BAD0     0    0.33  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 34   P_BAD0     0    0.34  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 35   P_BAD0     0    0.35  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 36   P_BAD0     0    0.36  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 37   P_BAD0     0    0.37  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 38   P_BAD0     0    0.38  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 39   P_BAD0     0    0.39  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 40   P_BAD0     0    0.40  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 41   P_BAD0     0    0.41  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 42   P_BAD0     0    0.42  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 43   P_BAD0     0    0.43  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 44   P_BAD0     0    0.44  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 45   P_BAD0     0    0.45  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 46   P_BAD0     0    0.46  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 47   P_BAD0     0    0.47  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 48   P_BAD0     0    0.48  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 49   P_BAD0     0    0.49  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 50   P_BAD0     0    0.50  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 51   P_BAD0     0    0.51  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 52   P_BAD0     0    0.52  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 53   P_BAD0     0    0.53  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 54   P_BAD0     0    0.54  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 55   P_BAD0     0    0.55  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 56   P_BAD0     0    0.56  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 57   P_BAD0     0    0.57  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 58   P_BAD0     0    0.58  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 59   P_BAD0     0    0.59  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 60   P_BAD0     0    0.60  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 61   P_BAD0     0    0.61  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 62   P_BAD0     0    0.62  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 63   P_BAD0     0    0.63  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 64   P_BAD0     0    0.64  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 65   P_BAD0     0    0.65  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 66   P_BAD0     0    0.66  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 67   P_BAD0     0    0.67  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 68   P_BAD0     0    0.68  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 69   P_BAD0     0    0.69  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 70   P_BAD0     0    0.70  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 71   P_BAD0     0    0.71  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 72   P_BAD0     0    0.72  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 73   P_BAD0     0    0.73  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 74   P_BAD0     0    0.74  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 75   P_BAD0     0    0.75  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 76   P_BAD0     0    0.76  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 77   P_BAD0     0    0.77  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 78   P_BAD0     0    0.78  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 79   P_BAD0     0    0.79  4536.0   878.0   235.0   311.0     0.950744     0.261564  0.0  0.212308  0.858213  0.738436  0.813255  0.162172  0.890722  0.66148  0.32296  0.65163  0.103169   0.186745  0.049256\n",
       " 80   P_BAD0     0    0.80  4104.0   656.0   667.0   533.0     0.860197     0.448276  1.0  0.308473  0.861787  0.551724  0.778020  0.137815  0.861190  0.66148  0.32296  0.65163  0.103169   0.221980  0.139803\n",
       " 81   P_BAD0     0    0.81     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.66148  0.32296  0.65163  0.103169   0.800503  1.000000\n",
       " 82   P_BAD0     0    0.82     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.66148  0.32296  0.65163  0.103169   0.800503  1.000000\n",
       " 83   P_BAD0     0    0.83     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.66148  0.32296  0.65163  0.103169   0.800503  1.000000\n",
       " 84   P_BAD0     0    0.84     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.66148  0.32296  0.65163  0.103169   0.800503  1.000000\n",
       " 85   P_BAD0     0    0.85     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.66148  0.32296  0.65163  0.103169   0.800503  1.000000\n",
       " 86   P_BAD0     0    0.86     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.66148  0.32296  0.65163  0.103169   0.800503  1.000000\n",
       " 87   P_BAD0     0    0.87     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.66148  0.32296  0.65163  0.103169   0.800503  1.000000\n",
       " 88   P_BAD0     0    0.88     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.66148  0.32296  0.65163  0.103169   0.800503  1.000000\n",
       " 89   P_BAD0     0    0.89     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.66148  0.32296  0.65163  0.103169   0.800503  1.000000\n",
       " 90   P_BAD0     0    0.90     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.66148  0.32296  0.65163  0.103169   0.800503  1.000000\n",
       " 91   P_BAD0     0    0.91     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.66148  0.32296  0.65163  0.103169   0.800503  1.000000\n",
       " 92   P_BAD0     0    0.92     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.66148  0.32296  0.65163  0.103169   0.800503  1.000000\n",
       " 93   P_BAD0     0    0.93     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.66148  0.32296  0.65163  0.103169   0.800503  1.000000\n",
       " 94   P_BAD0     0    0.94     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.66148  0.32296  0.65163  0.103169   0.800503  1.000000\n",
       " 95   P_BAD0     0    0.95     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.66148  0.32296  0.65163  0.103169   0.800503  1.000000\n",
       " 96   P_BAD0     0    0.96     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.66148  0.32296  0.65163  0.103169   0.800503  1.000000\n",
       " 97   P_BAD0     0    0.97     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.66148  0.32296  0.65163  0.103169   0.800503  1.000000\n",
       " 98   P_BAD0     0    0.98     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.66148  0.32296  0.65163  0.103169   0.800503  1.000000\n",
       " 99   P_BAD0     0    0.99     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.66148  0.32296  0.65163  0.103169   0.800503  1.000000,\n",
       "  Fit Statistics for _AUTOTUNE_DEFAULT_SCORE_TABLE_\n",
       " \n",
       "      NOBS       ASE     DIV      RASE       MCE     MCLL\n",
       " 0  5960.0  0.157872  5960.0  0.397331  0.199497  0.49413,\n",
       "  Tuner Information\n",
       " \n",
       "                            Parameter                   Value\n",
       " 0                         Model Type  Gradient Boosting Tree\n",
       " 1           Tuner Objective Function       Misclassification\n",
       " 2                      Search Method                    GRID\n",
       " 3              Number of Grid Points                      16\n",
       " 4     Maximum Tuning Time in Seconds                   36000\n",
       " 5                    Validation Type        Cross-Validation\n",
       " 6      Num Folds in Cross-Validation                       5\n",
       " 7                          Log Level                       0\n",
       " 8                               Seed              1876917928\n",
       " 9     Number of Parallel Evaluations                       4\n",
       " 10  Number of Workers per Subsession                       0,\n",
       "  Tuner Results\n",
       " \n",
       "     Evaluation  M  LEARNINGRATE  SUBSAMPLERATE  LASSO  RIDGE  MAXLEVEL  MeanConseqError  EvaluationTime\n",
       " 0            0  1          0.10            0.5    0.0    1.0         5         0.199497        0.585741\n",
       " 1            7  1          0.05            0.6    0.5    0.0         7         0.199329        1.402759\n",
       " 2           11  1          0.10            0.6    0.5    0.0         5         0.199362        1.312134\n",
       " 3           12  1          0.10            0.8    0.0    0.0         7         0.199362        1.302134\n",
       " 4            1  1          0.10            0.8    0.5    0.0         5         0.199463        2.065594\n",
       " 5            2  1          0.10            0.6    0.0    0.0         7         0.199463        0.711724\n",
       " 6           10  1          0.05            0.6    0.5    0.0         5         0.199463        1.398297\n",
       " 7            9  1          0.05            0.8    0.5    0.0         5         0.199497        1.875132\n",
       " 8            3  1          0.05            0.8    0.5    0.0         7         0.199497        1.575085\n",
       " 9           15  1          0.05            0.6    0.0    0.0         5         0.199497        0.797184\n",
       " 10          13  1          0.05            0.6    0.0    0.0         7         0.199530        1.007869,\n",
       "  Tuner Iteration History\n",
       " \n",
       "    Iteration  Evaluations  Best_obj  Time_sec\n",
       " 0          0            1  0.199497  0.585741\n",
       " 1          1           17  0.199329  6.279187,\n",
       "  Tuner Evaluation History\n",
       " \n",
       "     Evaluation  Iteration  M  LEARNINGRATE  SUBSAMPLERATE  LASSO  RIDGE  MAXLEVEL  MeanConseqError  EvaluationTime\n",
       " 0            0          0  1          0.10            0.5    0.0    1.0         5         0.199497        0.585741\n",
       " 1            1          1  1          0.10            0.8    0.5    0.0         5         0.199463        2.065594\n",
       " 2            2          1  1          0.10            0.6    0.0    0.0         7         0.199463        0.711724\n",
       " 3            3          1  1          0.05            0.8    0.5    0.0         7         0.199497        1.575085\n",
       " 4            4          1  1          0.10            0.8    0.0    0.0         5         0.199564        2.081283\n",
       " 5            5          1  1          0.05            0.8    0.0    0.0         7         0.199597        1.484827\n",
       " 6            6          1  1          0.10            0.8    0.5    0.0         7         0.199597        1.509942\n",
       " 7            7          1  1          0.05            0.6    0.5    0.0         7         0.199329        1.402759\n",
       " 8            8          1  1          0.05            0.8    0.0    0.0         5         0.199597        1.690688\n",
       " 9            9          1  1          0.05            0.8    0.5    0.0         5         0.199497        1.875132\n",
       " 10          10          1  1          0.05            0.6    0.5    0.0         5         0.199463        1.398297\n",
       " 11          11          1  1          0.10            0.6    0.5    0.0         5         0.199362        1.312134\n",
       " 12          12          1  1          0.10            0.8    0.0    0.0         7         0.199362        1.302134\n",
       " 13          13          1  1          0.05            0.6    0.0    0.0         7         0.199530        1.007869\n",
       " 14          14          1  1          0.10            0.6    0.0    0.0         5         0.199530        1.003341\n",
       " 15          15          1  1          0.05            0.6    0.0    0.0         5         0.199497        0.797184\n",
       " 16          16          1  1          0.10            0.6    0.5    0.0         7         0.199664        0.619296,\n",
       "  Best Configuration\n",
       " \n",
       "                     Parameter           Name         Value\n",
       " 0                  Evaluation     Evaluation             7\n",
       " 1  Number of Variables to Try              M             1\n",
       " 2               Learning Rate   LEARNINGRATE          0.05\n",
       " 3               Sampling Rate  SUBSAMPLERATE           0.6\n",
       " 4                       Lasso          LASSO           0.5\n",
       " 5                       Ridge          RIDGE             0\n",
       " 6         Maximum Tree Levels       MAXLEVEL             7\n",
       " 7           Misclassification      Objective  0.1993286897,\n",
       "  Tuner Summary\n",
       " \n",
       "                                           Parameter      Value\n",
       " 0             Initial Configuration Objective Value   0.199497\n",
       " 1                Best Configuration Objective Value   0.199329\n",
       " 2               Worst Configuration Objective Value   0.199664\n",
       " 3  Initial Configuration Evaluation Time in Seconds   0.585741\n",
       " 4     Best Configuration Evaluation Time in Seconds   1.402750\n",
       " 5                 Number of Improved Configurations   2.000000\n",
       " 6                Number of Evaluated Configurations  17.000000\n",
       " 7                      Total Tuning Time in Seconds   6.379699\n",
       " 8                           Parallel Tuning Speedup   3.515300,\n",
       "  Tuner Task Timing\n",
       " \n",
       "                           Task   Time_sec  Time_percent\n",
       " 0               Model Training  18.614787     83.003326\n",
       " 1                Model Scoring   2.298753     10.250140\n",
       " 2  Total Objective Evaluations  21.436752     95.586467\n",
       " 3                        Tuner   0.989803      4.413533\n",
       " 4               Total CPU Time  22.426555    100.000000,\n",
       "  Hyperparameter Importance\n",
       " \n",
       "   Hyperparameter  RelImportance\n",
       " 0  SUBSAMPLERATE       1.000000\n",
       " 1          LASSO       0.603883\n",
       " 2       MAXLEVEL       0.043346\n",
       " 3              M       0.000000\n",
       " 4   LEARNINGRATE       0.000000\n",
       " 5          RIDGE       0.000000,\n",
       "  TuneAll Results Summary\n",
       " \n",
       "           ModelID               ModelType  Evaluations  BestObjective  AverageObjective  StdDevObjective  BestObjTime  AverageTime  StdDevTime\n",
       " 0  1_DecisionTree           Decision Tree            6       0.186747          0.186747         0.000000     0.307288     0.451151    0.147067\n",
       " 1     2_GradBoost  Gradient Boosting Tree           16       0.199329          0.211172         0.012055     1.402759     1.393028    0.460606,\n",
       "  TuneAll Best Models\n",
       " \n",
       "           ModelID  Evaluation  MeanConseqError  EvaluationTime\n",
       " 0  1_DecisionTree           6         0.186747        0.299689\n",
       " 1  1_DecisionTree           0         0.186747        0.307288\n",
       " 2  1_DecisionTree           1         0.186747        0.312266\n",
       " 3  1_DecisionTree           5         0.186747        0.454053\n",
       " 4  1_DecisionTree           2         0.186747        0.466998\n",
       " 5  1_DecisionTree           3         0.186747        0.467011\n",
       " 6  1_DecisionTree           4         0.186747        0.706889\n",
       " 7     2_GradBoost           7         0.199329        1.402759\n",
       " 8     2_GradBoost          12         0.199362        1.302134\n",
       " 9     2_GradBoost          11         0.199362        1.312134,\n",
       "  TuneAll CAS Output Tables\n",
       " \n",
       " Empty SASDataFrame\n",
       " Columns: [ModelID, CAS_Library, Name, Rows, Columns]\n",
       " Index: [],\n",
       "  Decision Tree for __TEMP_FEATURE_MACHINE_CASOUT___AUTOTUNE_DATA_11FA4B25-9848-604F-9F45-7E73830B6354\n",
       " \n",
       "                            Descr        Value\n",
       " 0           Number of Tree Nodes     7.000000\n",
       " 1         Max Number of Branches     2.000000\n",
       " 2               Number of Levels     4.000000\n",
       " 3               Number of Leaves     4.000000\n",
       " 4                 Number of Bins    50.000000\n",
       " 5         Minimum Size of Leaves   546.000000\n",
       " 6         Maximum Size of Leaves  4179.000000\n",
       " 7            Number of Variables     1.000000\n",
       " 8   Confidence Level for Pruning     0.250000\n",
       " 9    Number of Observations Used  5960.000000\n",
       " 10   Misclassification Error (%)    18.674497,\n",
       "                           Descr                             Value\n",
       " 0  Number of Observations Read                              5960\n",
       " 1  Number of Observations Used                              5960\n",
       " 2  Misclassification Error (%)                      18.674496644,\n",
       "          LEVNAME  LEVINDEX VARNAME\n",
       " 0             1         0  P_BAD1\n",
       " 1             0         1  P_BAD0,\n",
       "    LEVNAME  LEVINDEX VARNAME\n",
       " 0                 0   I_BAD,\n",
       "  ROC Information for _AUTOTUNE_DEFAULT_SCORE_TABLE_\n",
       " \n",
       "    Variable Event  CutOff      TP      FP      FN      TN  Sensitivity  Specificity   KS       KS2    F_HALF       FPR       ACC       FDR        F1         C      Gini     Gamma       Tau  MISCEVENT       FNR\n",
       " 0    P_BAD0     0    0.00  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 1    P_BAD0     0    0.01  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 2    P_BAD0     0    0.02  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 3    P_BAD0     0    0.03  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 4    P_BAD0     0    0.04  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 5    P_BAD0     0    0.05  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 6    P_BAD0     0    0.06  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 7    P_BAD0     0    0.07  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 8    P_BAD0     0    0.08  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 9    P_BAD0     0    0.09  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 10   P_BAD0     0    0.10  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 11   P_BAD0     0    0.11  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 12   P_BAD0     0    0.12  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 13   P_BAD0     0    0.13  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 14   P_BAD0     0    0.14  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 15   P_BAD0     0    0.15  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 16   P_BAD0     0    0.16  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 17   P_BAD0     0    0.17  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 18   P_BAD0     0    0.18  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 19   P_BAD0     0    0.19  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 20   P_BAD0     0    0.20  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 21   P_BAD0     0    0.21  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 22   P_BAD0     0    0.22  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 23   P_BAD0     0    0.23  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 24   P_BAD0     0    0.24  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 25   P_BAD0     0    0.25  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 26   P_BAD0     0    0.26  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 27   P_BAD0     0    0.27  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 28   P_BAD0     0    0.28  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 29   P_BAD0     0    0.29  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 30   P_BAD0     0    0.30  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 31   P_BAD0     0    0.31  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 32   P_BAD0     0    0.32  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 33   P_BAD0     0    0.33  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 34   P_BAD0     0    0.34  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 35   P_BAD0     0    0.35  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 36   P_BAD0     0    0.36  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 37   P_BAD0     0    0.37  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 38   P_BAD0     0    0.38  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 39   P_BAD0     0    0.39  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 40   P_BAD0     0    0.40  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 41   P_BAD0     0    0.41  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 42   P_BAD0     0    0.42  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 43   P_BAD0     0    0.43  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.664447  0.328893  0.553596  0.105065   0.199497  0.000000\n",
       " 44   P_BAD0     0    0.44  4536.0   878.0   235.0   311.0     0.950744     0.261564  0.0  0.212308  0.858213  0.738436  0.813255  0.162172  0.890722  0.664447  0.328893  0.553596  0.105065   0.186745  0.049256\n",
       " 45   P_BAD0     0    0.45  4536.0   878.0   235.0   311.0     0.950744     0.261564  0.0  0.212308  0.858213  0.738436  0.813255  0.162172  0.890722  0.664447  0.328893  0.553596  0.105065   0.186745  0.049256\n",
       " 46   P_BAD0     0    0.46  4536.0   878.0   235.0   311.0     0.950744     0.261564  0.0  0.212308  0.858213  0.738436  0.813255  0.162172  0.890722  0.664447  0.328893  0.553596  0.105065   0.186745  0.049256\n",
       " 47   P_BAD0     0    0.47  4536.0   878.0   235.0   311.0     0.950744     0.261564  0.0  0.212308  0.858213  0.738436  0.813255  0.162172  0.890722  0.664447  0.328893  0.553596  0.105065   0.186745  0.049256\n",
       " 48   P_BAD0     0    0.48  4536.0   878.0   235.0   311.0     0.950744     0.261564  0.0  0.212308  0.858213  0.738436  0.813255  0.162172  0.890722  0.664447  0.328893  0.553596  0.105065   0.186745  0.049256\n",
       " 49   P_BAD0     0    0.49  4536.0   878.0   235.0   311.0     0.950744     0.261564  0.0  0.212308  0.858213  0.738436  0.813255  0.162172  0.890722  0.664447  0.328893  0.553596  0.105065   0.186745  0.049256\n",
       " 50   P_BAD0     0    0.50  4536.0   878.0   235.0   311.0     0.950744     0.261564  0.0  0.212308  0.858213  0.738436  0.813255  0.162172  0.890722  0.664447  0.328893  0.553596  0.105065   0.186745  0.049256\n",
       " 51   P_BAD0     0    0.51  4536.0   878.0   235.0   311.0     0.950744     0.261564  0.0  0.212308  0.858213  0.738436  0.813255  0.162172  0.890722  0.664447  0.328893  0.553596  0.105065   0.186745  0.049256\n",
       " 52   P_BAD0     0    0.52  4536.0   878.0   235.0   311.0     0.950744     0.261564  0.0  0.212308  0.858213  0.738436  0.813255  0.162172  0.890722  0.664447  0.328893  0.553596  0.105065   0.186745  0.049256\n",
       " 53   P_BAD0     0    0.53  4536.0   878.0   235.0   311.0     0.950744     0.261564  0.0  0.212308  0.858213  0.738436  0.813255  0.162172  0.890722  0.664447  0.328893  0.553596  0.105065   0.186745  0.049256\n",
       " 54   P_BAD0     0    0.54  4536.0   878.0   235.0   311.0     0.950744     0.261564  0.0  0.212308  0.858213  0.738436  0.813255  0.162172  0.890722  0.664447  0.328893  0.553596  0.105065   0.186745  0.049256\n",
       " 55   P_BAD0     0    0.55  4536.0   878.0   235.0   311.0     0.950744     0.261564  0.0  0.212308  0.858213  0.738436  0.813255  0.162172  0.890722  0.664447  0.328893  0.553596  0.105065   0.186745  0.049256\n",
       " 56   P_BAD0     0    0.56  4536.0   878.0   235.0   311.0     0.950744     0.261564  0.0  0.212308  0.858213  0.738436  0.813255  0.162172  0.890722  0.664447  0.328893  0.553596  0.105065   0.186745  0.049256\n",
       " 57   P_BAD0     0    0.57  4536.0   878.0   235.0   311.0     0.950744     0.261564  0.0  0.212308  0.858213  0.738436  0.813255  0.162172  0.890722  0.664447  0.328893  0.553596  0.105065   0.186745  0.049256\n",
       " 58   P_BAD0     0    0.58  4536.0   878.0   235.0   311.0     0.950744     0.261564  0.0  0.212308  0.858213  0.738436  0.813255  0.162172  0.890722  0.664447  0.328893  0.553596  0.105065   0.186745  0.049256\n",
       " 59   P_BAD0     0    0.59  4536.0   878.0   235.0   311.0     0.950744     0.261564  0.0  0.212308  0.858213  0.738436  0.813255  0.162172  0.890722  0.664447  0.328893  0.553596  0.105065   0.186745  0.049256\n",
       " 60   P_BAD0     0    0.60  4536.0   878.0   235.0   311.0     0.950744     0.261564  0.0  0.212308  0.858213  0.738436  0.813255  0.162172  0.890722  0.664447  0.328893  0.553596  0.105065   0.186745  0.049256\n",
       " 61   P_BAD0     0    0.61  4536.0   878.0   235.0   311.0     0.950744     0.261564  0.0  0.212308  0.858213  0.738436  0.813255  0.162172  0.890722  0.664447  0.328893  0.553596  0.105065   0.186745  0.049256\n",
       " 62   P_BAD0     0    0.62  4536.0   878.0   235.0   311.0     0.950744     0.261564  0.0  0.212308  0.858213  0.738436  0.813255  0.162172  0.890722  0.664447  0.328893  0.553596  0.105065   0.186745  0.049256\n",
       " 63   P_BAD0     0    0.63  4536.0   878.0   235.0   311.0     0.950744     0.261564  0.0  0.212308  0.858213  0.738436  0.813255  0.162172  0.890722  0.664447  0.328893  0.553596  0.105065   0.186745  0.049256\n",
       " 64   P_BAD0     0    0.64  4536.0   878.0   235.0   311.0     0.950744     0.261564  0.0  0.212308  0.858213  0.738436  0.813255  0.162172  0.890722  0.664447  0.328893  0.553596  0.105065   0.186745  0.049256\n",
       " 65   P_BAD0     0    0.65  4536.0   878.0   235.0   311.0     0.950744     0.261564  0.0  0.212308  0.858213  0.738436  0.813255  0.162172  0.890722  0.664447  0.328893  0.553596  0.105065   0.186745  0.049256\n",
       " 66   P_BAD0     0    0.66  4536.0   878.0   235.0   311.0     0.950744     0.261564  0.0  0.212308  0.858213  0.738436  0.813255  0.162172  0.890722  0.664447  0.328893  0.553596  0.105065   0.186745  0.049256\n",
       " 67   P_BAD0     0    0.67  4104.0   656.0   667.0   533.0     0.860197     0.448276  1.0  0.308473  0.861787  0.551724  0.778020  0.137815  0.861190  0.664447  0.328893  0.553596  0.105065   0.221980  0.139803\n",
       " 68   P_BAD0     0    0.68  4104.0   656.0   667.0   533.0     0.860197     0.448276  0.0  0.308473  0.861787  0.551724  0.778020  0.137815  0.861190  0.664447  0.328893  0.553596  0.105065   0.221980  0.139803\n",
       " 69   P_BAD0     0    0.69  4104.0   656.0   667.0   533.0     0.860197     0.448276  0.0  0.308473  0.861787  0.551724  0.778020  0.137815  0.861190  0.664447  0.328893  0.553596  0.105065   0.221980  0.139803\n",
       " 70   P_BAD0     0    0.70  4104.0   656.0   667.0   533.0     0.860197     0.448276  0.0  0.308473  0.861787  0.551724  0.778020  0.137815  0.861190  0.664447  0.328893  0.553596  0.105065   0.221980  0.139803\n",
       " 71   P_BAD0     0    0.71  4104.0   656.0   667.0   533.0     0.860197     0.448276  0.0  0.308473  0.861787  0.551724  0.778020  0.137815  0.861190  0.664447  0.328893  0.553596  0.105065   0.221980  0.139803\n",
       " 72   P_BAD0     0    0.72  4104.0   656.0   667.0   533.0     0.860197     0.448276  0.0  0.308473  0.861787  0.551724  0.778020  0.137815  0.861190  0.664447  0.328893  0.553596  0.105065   0.221980  0.139803\n",
       " 73   P_BAD0     0    0.73  4104.0   656.0   667.0   533.0     0.860197     0.448276  0.0  0.308473  0.861787  0.551724  0.778020  0.137815  0.861190  0.664447  0.328893  0.553596  0.105065   0.221980  0.139803\n",
       " 74   P_BAD0     0    0.74  4104.0   656.0   667.0   533.0     0.860197     0.448276  0.0  0.308473  0.861787  0.551724  0.778020  0.137815  0.861190  0.664447  0.328893  0.553596  0.105065   0.221980  0.139803\n",
       " 75   P_BAD0     0    0.75  4104.0   656.0   667.0   533.0     0.860197     0.448276  0.0  0.308473  0.861787  0.551724  0.778020  0.137815  0.861190  0.664447  0.328893  0.553596  0.105065   0.221980  0.139803\n",
       " 76   P_BAD0     0    0.76  4104.0   656.0   667.0   533.0     0.860197     0.448276  0.0  0.308473  0.861787  0.551724  0.778020  0.137815  0.861190  0.664447  0.328893  0.553596  0.105065   0.221980  0.139803\n",
       " 77   P_BAD0     0    0.77  4104.0   656.0   667.0   533.0     0.860197     0.448276  0.0  0.308473  0.861787  0.551724  0.778020  0.137815  0.861190  0.664447  0.328893  0.553596  0.105065   0.221980  0.139803\n",
       " 78   P_BAD0     0    0.78  4104.0   656.0   667.0   533.0     0.860197     0.448276  0.0  0.308473  0.861787  0.551724  0.778020  0.137815  0.861190  0.664447  0.328893  0.553596  0.105065   0.221980  0.139803\n",
       " 79   P_BAD0     0    0.79  4104.0   656.0   667.0   533.0     0.860197     0.448276  0.0  0.308473  0.861787  0.551724  0.778020  0.137815  0.861190  0.664447  0.328893  0.553596  0.105065   0.221980  0.139803\n",
       " 80   P_BAD0     0    0.80  4104.0   656.0   667.0   533.0     0.860197     0.448276  0.0  0.308473  0.861787  0.551724  0.778020  0.137815  0.861190  0.664447  0.328893  0.553596  0.105065   0.221980  0.139803\n",
       " 81   P_BAD0     0    0.81  4104.0   656.0   667.0   533.0     0.860197     0.448276  0.0  0.308473  0.861787  0.551724  0.778020  0.137815  0.861190  0.664447  0.328893  0.553596  0.105065   0.221980  0.139803\n",
       " 82   P_BAD0     0    0.82  4104.0   656.0   667.0   533.0     0.860197     0.448276  0.0  0.308473  0.861787  0.551724  0.778020  0.137815  0.861190  0.664447  0.328893  0.553596  0.105065   0.221980  0.139803\n",
       " 83   P_BAD0     0    0.83  4104.0   656.0   667.0   533.0     0.860197     0.448276  0.0  0.308473  0.861787  0.551724  0.778020  0.137815  0.861190  0.664447  0.328893  0.553596  0.105065   0.221980  0.139803\n",
       " 84   P_BAD0     0    0.84  4104.0   656.0   667.0   533.0     0.860197     0.448276  0.0  0.308473  0.861787  0.551724  0.778020  0.137815  0.861190  0.664447  0.328893  0.553596  0.105065   0.221980  0.139803\n",
       " 85   P_BAD0     0    0.85  4104.0   656.0   667.0   533.0     0.860197     0.448276  0.0  0.308473  0.861787  0.551724  0.778020  0.137815  0.861190  0.664447  0.328893  0.553596  0.105065   0.221980  0.139803\n",
       " 86   P_BAD0     0    0.86  4104.0   656.0   667.0   533.0     0.860197     0.448276  0.0  0.308473  0.861787  0.551724  0.778020  0.137815  0.861190  0.664447  0.328893  0.553596  0.105065   0.221980  0.139803\n",
       " 87   P_BAD0     0    0.87   508.0    73.0  4263.0  1116.0     0.106477     0.938604  0.0  0.045080  0.357999  0.061396  0.272483  0.125645  0.189836  0.664447  0.328893  0.553596  0.105065   0.727517  0.893523\n",
       " 88   P_BAD0     0    0.88     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.664447  0.328893  0.553596  0.105065   0.800503  1.000000\n",
       " 89   P_BAD0     0    0.89     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.664447  0.328893  0.553596  0.105065   0.800503  1.000000\n",
       " 90   P_BAD0     0    0.90     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.664447  0.328893  0.553596  0.105065   0.800503  1.000000\n",
       " 91   P_BAD0     0    0.91     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.664447  0.328893  0.553596  0.105065   0.800503  1.000000\n",
       " 92   P_BAD0     0    0.92     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.664447  0.328893  0.553596  0.105065   0.800503  1.000000\n",
       " 93   P_BAD0     0    0.93     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.664447  0.328893  0.553596  0.105065   0.800503  1.000000\n",
       " 94   P_BAD0     0    0.94     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.664447  0.328893  0.553596  0.105065   0.800503  1.000000\n",
       " 95   P_BAD0     0    0.95     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.664447  0.328893  0.553596  0.105065   0.800503  1.000000\n",
       " 96   P_BAD0     0    0.96     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.664447  0.328893  0.553596  0.105065   0.800503  1.000000\n",
       " 97   P_BAD0     0    0.97     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.664447  0.328893  0.553596  0.105065   0.800503  1.000000\n",
       " 98   P_BAD0     0    0.98     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.664447  0.328893  0.553596  0.105065   0.800503  1.000000\n",
       " 99   P_BAD0     0    0.99     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.664447  0.328893  0.553596  0.105065   0.800503  1.000000,\n",
       "  Fit Statistics for _AUTOTUNE_DEFAULT_SCORE_TABLE_\n",
       " \n",
       "      NOBS       ASE     DIV      RASE       MCE      MCLL\n",
       " 0  5960.0  0.141945  5960.0  0.376756  0.186745  0.453084,\n",
       "  Tuner Information\n",
       " \n",
       "                            Parameter              Value\n",
       " 0                         Model Type      Decision Tree\n",
       " 1           Tuner Objective Function  Misclassification\n",
       " 2                      Search Method               GRID\n",
       " 3              Number of Grid Points                  6\n",
       " 4     Maximum Tuning Time in Seconds              36000\n",
       " 5                    Validation Type   Cross-Validation\n",
       " 6      Num Folds in Cross-Validation                  5\n",
       " 7                          Log Level                  0\n",
       " 8                               Seed         1876917257\n",
       " 9     Number of Parallel Evaluations                  4\n",
       " 10  Number of Workers per Subsession                  0,\n",
       "  Tuner Results\n",
       " \n",
       "    Evaluation  MAXLEVEL       CRIT  MeanConseqError  EvaluationTime\n",
       " 0           0        11  gainRatio         0.186743        0.267086\n",
       " 1           1        10  gainRatio         0.186743        0.328704\n",
       " 2           2        15  gainRatio         0.186743        0.496010\n",
       " 3           3         5       gain         0.186743        0.495985\n",
       " 4           4        10       gain         0.186743        0.686710\n",
       " 5           5        15       gain         0.186743        0.345324\n",
       " 6           6         5  gainRatio         0.186743        0.188794,\n",
       "  Tuner Iteration History\n",
       " \n",
       "    Iteration  Evaluations  Best_obj  Time_sec\n",
       " 0          0            1  0.186743  0.267086\n",
       " 1          1            7  0.186743  0.952953,\n",
       "  Tuner Evaluation History\n",
       " \n",
       "    Evaluation  Iteration  MAXLEVEL       CRIT  MeanConseqError  EvaluationTime\n",
       " 0           0          0        11  gainRatio         0.186743        0.267086\n",
       " 1           1          1        10  gainRatio         0.186743        0.328704\n",
       " 2           2          1        15  gainRatio         0.186743        0.496010\n",
       " 3           3          1         5       gain         0.186743        0.495985\n",
       " 4           4          1        10       gain         0.186743        0.686710\n",
       " 5           5          1        15       gain         0.186743        0.345324\n",
       " 6           6          1         5  gainRatio         0.186743        0.188794,\n",
       "  Best Configuration\n",
       " \n",
       "              Parameter        Name         Value\n",
       " 0           Evaluation  Evaluation             0\n",
       " 1  Maximum Tree Levels    MAXLEVEL            11\n",
       " 2            Criterion        CRIT     gainRatio\n",
       " 3    Misclassification   Objective  0.1867431912,\n",
       "  Tuner Summary\n",
       " \n",
       "                                           Parameter     Value\n",
       " 0             Initial Configuration Objective Value  0.186743\n",
       " 1                Best Configuration Objective Value  0.186743\n",
       " 2               Worst Configuration Objective Value  0.186743\n",
       " 3  Initial Configuration Evaluation Time in Seconds  0.267086\n",
       " 4     Best Configuration Evaluation Time in Seconds  0.267086\n",
       " 5                 Number of Improved Configurations  0.000000\n",
       " 6                Number of Evaluated Configurations  7.000000\n",
       " 7                      Total Tuning Time in Seconds  0.994613\n",
       " 8                           Parallel Tuning Speedup  1.967282,\n",
       "  Tuner Task Timing\n",
       " \n",
       "                           Task  Time_sec  Time_percent\n",
       " 0               Model Training  0.475226     24.287303\n",
       " 1                Model Scoring  0.626626     32.024914\n",
       " 2  Total Objective Evaluations  1.273642     65.091863\n",
       " 3                        Tuner  0.683042     34.908137\n",
       " 4               Total CPU Time  1.956684    100.000000,\n",
       "  Gradient Boosting Tree for __TEMP_FEATURE_MACHINE_CASOUT___AUTOTUNE_DATA_11FA4B25-9848-604F-9F45-7E73830B6354\n",
       " \n",
       "                                   Descr         Value\n",
       " 0                       Number of Trees  1.500000e+02\n",
       " 1                          Distribution  2.000000e+00\n",
       " 2                         Learning Rate  1.000000e-01\n",
       " 3                      Subsampling Rate  6.000000e-01\n",
       " 4      Number of Selected Variables (M)  1.000000e+00\n",
       " 5                        Number of Bins  5.000000e+01\n",
       " 6                   Number of Variables  1.000000e+00\n",
       " 7              Max Number of Tree Nodes  7.000000e+00\n",
       " 8              Min Number of Tree Nodes  7.000000e+00\n",
       " 9                Max Number of Branches  2.000000e+00\n",
       " 10               Min Number of Branches  2.000000e+00\n",
       " 11                 Max Number of Levels  3.000000e+00\n",
       " 12                 Min Number of Levels  3.000000e+00\n",
       " 13                 Max Number of Leaves  4.000000e+00\n",
       " 14                 Min Number of Leaves  4.000000e+00\n",
       " 15               Maximum Size of Leaves  2.469000e+03\n",
       " 16               Minimum Size of Leaves  3.360000e+02\n",
       " 17                   Random Number Seed  1.876917e+09\n",
       " 18                   Lasso (L1) penalty  5.000000e-01\n",
       " 19                   Ridge (L2) penalty  0.000000e+00\n",
       " 20               Actual Number of Trees  1.000000e+00\n",
       " 21             Average number of Leaves  4.000000e+00\n",
       " 22            Early stopping stagnation  4.000000e+00\n",
       " 23             Early stopping threshold  0.000000e+00\n",
       " 24  Early stopping threshold iterations  0.000000e+00\n",
       " 25             Early stopping tolerance  0.000000e+00,\n",
       "     Progress    Metric\n",
       " 0       1.0  0.199497,\n",
       "                           Descr                             Value\n",
       " 0  Number of Observations Read                              5960\n",
       " 1  Number of Observations Used                              5960\n",
       " 2  Misclassification Error (%)                       19.94966443,\n",
       "     TreeID  Trees  NLeaves       MCR   LogLoss       ASE      RASE     MAXAE\n",
       " 0     0.0    1.0      4.0  0.199497  0.488979  0.156099  0.395093  0.809417,\n",
       "          LEVNAME  LEVINDEX VARNAME\n",
       " 0             1         0  P_BAD1\n",
       " 1             0         1  P_BAD0,\n",
       "    LEVNAME  LEVINDEX VARNAME\n",
       " 0                 0   I_BAD,\n",
       "  ROC Information for _AUTOTUNE_DEFAULT_SCORE_TABLE_\n",
       " \n",
       "    Variable Event  CutOff      TP      FP      FN      TN  Sensitivity  Specificity   KS       KS2    F_HALF       FPR       ACC       FDR        F1        C     Gini    Gamma       Tau  MISCEVENT       FNR\n",
       " 0    P_BAD0     0    0.00  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 1    P_BAD0     0    0.01  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 2    P_BAD0     0    0.02  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 3    P_BAD0     0    0.03  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 4    P_BAD0     0    0.04  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 5    P_BAD0     0    0.05  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 6    P_BAD0     0    0.06  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 7    P_BAD0     0    0.07  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 8    P_BAD0     0    0.08  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 9    P_BAD0     0    0.09  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 10   P_BAD0     0    0.10  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 11   P_BAD0     0    0.11  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 12   P_BAD0     0    0.12  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 13   P_BAD0     0    0.13  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 14   P_BAD0     0    0.14  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 15   P_BAD0     0    0.15  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 16   P_BAD0     0    0.16  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 17   P_BAD0     0    0.17  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 18   P_BAD0     0    0.18  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 19   P_BAD0     0    0.19  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 20   P_BAD0     0    0.20  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 21   P_BAD0     0    0.21  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 22   P_BAD0     0    0.22  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 23   P_BAD0     0    0.23  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 24   P_BAD0     0    0.24  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 25   P_BAD0     0    0.25  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 26   P_BAD0     0    0.26  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 27   P_BAD0     0    0.27  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 28   P_BAD0     0    0.28  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 29   P_BAD0     0    0.29  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 30   P_BAD0     0    0.30  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 31   P_BAD0     0    0.31  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 32   P_BAD0     0    0.32  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 33   P_BAD0     0    0.33  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 34   P_BAD0     0    0.34  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 35   P_BAD0     0    0.35  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 36   P_BAD0     0    0.36  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 37   P_BAD0     0    0.37  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 38   P_BAD0     0    0.38  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 39   P_BAD0     0    0.39  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 40   P_BAD0     0    0.40  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 41   P_BAD0     0    0.41  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 42   P_BAD0     0    0.42  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 43   P_BAD0     0    0.43  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 44   P_BAD0     0    0.44  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 45   P_BAD0     0    0.45  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 46   P_BAD0     0    0.46  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 47   P_BAD0     0    0.47  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 48   P_BAD0     0    0.48  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 49   P_BAD0     0    0.49  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 50   P_BAD0     0    0.50  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 51   P_BAD0     0    0.51  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 52   P_BAD0     0    0.52  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 53   P_BAD0     0    0.53  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 54   P_BAD0     0    0.54  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 55   P_BAD0     0    0.55  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 56   P_BAD0     0    0.56  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 57   P_BAD0     0    0.57  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 58   P_BAD0     0    0.58  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 59   P_BAD0     0    0.59  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 60   P_BAD0     0    0.60  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 61   P_BAD0     0    0.61  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 62   P_BAD0     0    0.62  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 63   P_BAD0     0    0.63  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 64   P_BAD0     0    0.64  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 65   P_BAD0     0    0.65  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 66   P_BAD0     0    0.66  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 67   P_BAD0     0    0.67  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 68   P_BAD0     0    0.68  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 69   P_BAD0     0    0.69  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 70   P_BAD0     0    0.70  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 71   P_BAD0     0    0.71  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 72   P_BAD0     0    0.72  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 73   P_BAD0     0    0.73  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 74   P_BAD0     0    0.74  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 75   P_BAD0     0    0.75  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.66148  0.32296  0.65163  0.103169   0.199497  0.000000\n",
       " 76   P_BAD0     0    0.76  4536.0   878.0   235.0   311.0     0.950744     0.261564  0.0  0.212308  0.858213  0.738436  0.813255  0.162172  0.890722  0.66148  0.32296  0.65163  0.103169   0.186745  0.049256\n",
       " 77   P_BAD0     0    0.77  4536.0   878.0   235.0   311.0     0.950744     0.261564  0.0  0.212308  0.858213  0.738436  0.813255  0.162172  0.890722  0.66148  0.32296  0.65163  0.103169   0.186745  0.049256\n",
       " 78   P_BAD0     0    0.78  4536.0   878.0   235.0   311.0     0.950744     0.261564  0.0  0.212308  0.858213  0.738436  0.813255  0.162172  0.890722  0.66148  0.32296  0.65163  0.103169   0.186745  0.049256\n",
       " 79   P_BAD0     0    0.79  4104.0   656.0   667.0   533.0     0.860197     0.448276  1.0  0.308473  0.861787  0.551724  0.778020  0.137815  0.861190  0.66148  0.32296  0.65163  0.103169   0.221980  0.139803\n",
       " 80   P_BAD0     0    0.80  4104.0   656.0   667.0   533.0     0.860197     0.448276  0.0  0.308473  0.861787  0.551724  0.778020  0.137815  0.861190  0.66148  0.32296  0.65163  0.103169   0.221980  0.139803\n",
       " 81   P_BAD0     0    0.81     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.66148  0.32296  0.65163  0.103169   0.800503  1.000000\n",
       " 82   P_BAD0     0    0.82     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.66148  0.32296  0.65163  0.103169   0.800503  1.000000\n",
       " 83   P_BAD0     0    0.83     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.66148  0.32296  0.65163  0.103169   0.800503  1.000000\n",
       " 84   P_BAD0     0    0.84     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.66148  0.32296  0.65163  0.103169   0.800503  1.000000\n",
       " 85   P_BAD0     0    0.85     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.66148  0.32296  0.65163  0.103169   0.800503  1.000000\n",
       " 86   P_BAD0     0    0.86     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.66148  0.32296  0.65163  0.103169   0.800503  1.000000\n",
       " 87   P_BAD0     0    0.87     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.66148  0.32296  0.65163  0.103169   0.800503  1.000000\n",
       " 88   P_BAD0     0    0.88     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.66148  0.32296  0.65163  0.103169   0.800503  1.000000\n",
       " 89   P_BAD0     0    0.89     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.66148  0.32296  0.65163  0.103169   0.800503  1.000000\n",
       " 90   P_BAD0     0    0.90     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.66148  0.32296  0.65163  0.103169   0.800503  1.000000\n",
       " 91   P_BAD0     0    0.91     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.66148  0.32296  0.65163  0.103169   0.800503  1.000000\n",
       " 92   P_BAD0     0    0.92     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.66148  0.32296  0.65163  0.103169   0.800503  1.000000\n",
       " 93   P_BAD0     0    0.93     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.66148  0.32296  0.65163  0.103169   0.800503  1.000000\n",
       " 94   P_BAD0     0    0.94     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.66148  0.32296  0.65163  0.103169   0.800503  1.000000\n",
       " 95   P_BAD0     0    0.95     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.66148  0.32296  0.65163  0.103169   0.800503  1.000000\n",
       " 96   P_BAD0     0    0.96     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.66148  0.32296  0.65163  0.103169   0.800503  1.000000\n",
       " 97   P_BAD0     0    0.97     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.66148  0.32296  0.65163  0.103169   0.800503  1.000000\n",
       " 98   P_BAD0     0    0.98     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.66148  0.32296  0.65163  0.103169   0.800503  1.000000\n",
       " 99   P_BAD0     0    0.99     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.66148  0.32296  0.65163  0.103169   0.800503  1.000000,\n",
       "  Fit Statistics for _AUTOTUNE_DEFAULT_SCORE_TABLE_\n",
       " \n",
       "      NOBS       ASE     DIV      RASE       MCE      MCLL\n",
       " 0  5960.0  0.156099  5960.0  0.395093  0.199497  0.488979,\n",
       "  Tuner Information\n",
       " \n",
       "                            Parameter                   Value\n",
       " 0                         Model Type  Gradient Boosting Tree\n",
       " 1           Tuner Objective Function       Misclassification\n",
       " 2                      Search Method                    GRID\n",
       " 3              Number of Grid Points                      16\n",
       " 4     Maximum Tuning Time in Seconds                   36000\n",
       " 5                    Validation Type        Cross-Validation\n",
       " 6      Num Folds in Cross-Validation                       5\n",
       " 7                          Log Level                       0\n",
       " 8                               Seed              1876917156\n",
       " 9     Number of Parallel Evaluations                       4\n",
       " 10  Number of Workers per Subsession                       0,\n",
       "  Tuner Results\n",
       " \n",
       "     Evaluation  M  LEARNINGRATE  SUBSAMPLERATE  LASSO  RIDGE  MAXLEVEL  MeanConseqError  EvaluationTime\n",
       " 0            0  1          0.10            0.5    0.0    1.0         5         0.199497        0.582387\n",
       " 1            9  1          0.10            0.6    0.5    0.0         5         0.199261        2.387442\n",
       " 2           14  1          0.05            0.8    0.0    0.0         7         0.199295        1.889176\n",
       " 3            1  1          0.10            0.8    0.5    0.0         7         0.199329        0.513950\n",
       " 4            8  1          0.10            0.8    0.5    0.0         5         0.199329        2.715832\n",
       " 5            6  1          0.05            0.6    0.0    0.0         7         0.199362        3.104644\n",
       " 6            7  1          0.10            0.6    0.0    0.0         5         0.199362        2.890419\n",
       " 7           10  1          0.10            0.8    0.0    0.0         7         0.199396        1.612668\n",
       " 8           12  1          0.10            0.6    0.0    0.0         7         0.199463        1.876585\n",
       " 9           13  1          0.05            0.6    0.0    0.0         5         0.199463        1.723545\n",
       " 10           3  1          0.05            0.8    0.5    0.0         5         0.199497        2.959303,\n",
       "  Tuner Iteration History\n",
       " \n",
       "    Iteration  Evaluations  Best_obj  Time_sec\n",
       " 0          0            1  0.199497  0.582387\n",
       " 1          1           17  0.199261  8.218669,\n",
       "  Tuner Evaluation History\n",
       " \n",
       "     Evaluation  Iteration  M  LEARNINGRATE  SUBSAMPLERATE  LASSO  RIDGE  MAXLEVEL  MeanConseqError  EvaluationTime\n",
       " 0            0          0  1          0.10            0.5    0.0    1.0         5         0.199497        0.582387\n",
       " 1            1          1  1          0.10            0.8    0.5    0.0         7         0.199329        0.513950\n",
       " 2            2          1  1          0.05            0.6    0.5    0.0         7         0.199631        2.073624\n",
       " 3            3          1  1          0.05            0.8    0.5    0.0         5         0.199497        2.959303\n",
       " 4            4          1  1          0.05            0.8    0.5    0.0         7         0.199497        0.755577\n",
       " 5            5          1  1          0.10            0.8    0.0    0.0         5         0.199631        1.837338\n",
       " 6            6          1  1          0.05            0.6    0.0    0.0         7         0.199362        3.104644\n",
       " 7            7          1  1          0.10            0.6    0.0    0.0         5         0.199362        2.890419\n",
       " 8            8          1  1          0.10            0.8    0.5    0.0         5         0.199329        2.715832\n",
       " 9            9          1  1          0.10            0.6    0.5    0.0         5         0.199261        2.387442\n",
       " 10          10          1  1          0.10            0.8    0.0    0.0         7         0.199396        1.612668\n",
       " 11          11          1  1          0.10            0.6    0.5    0.0         7         0.199597        1.594160\n",
       " 12          12          1  1          0.10            0.6    0.0    0.0         7         0.199463        1.876585\n",
       " 13          13          1  1          0.05            0.6    0.0    0.0         5         0.199463        1.723545\n",
       " 14          14          1  1          0.05            0.8    0.0    0.0         7         0.199295        1.889176\n",
       " 15          15          1  1          0.05            0.6    0.5    0.0         5         0.199497        1.003774\n",
       " 16          16          1  1          0.05            0.8    0.0    0.0         5         0.199530        0.693229,\n",
       "  Best Configuration\n",
       " \n",
       "                     Parameter           Name         Value\n",
       " 0                  Evaluation     Evaluation             9\n",
       " 1  Number of Variables to Try              M             1\n",
       " 2               Learning Rate   LEARNINGRATE           0.1\n",
       " 3               Sampling Rate  SUBSAMPLERATE           0.6\n",
       " 4                       Lasso          LASSO           0.5\n",
       " 5                       Ridge          RIDGE             0\n",
       " 6         Maximum Tree Levels       MAXLEVEL             5\n",
       " 7           Misclassification      Objective  0.1992612378,\n",
       "  Tuner Summary\n",
       " \n",
       "                                           Parameter      Value\n",
       " 0             Initial Configuration Objective Value   0.199497\n",
       " 1                Best Configuration Objective Value   0.199261\n",
       " 2               Worst Configuration Objective Value   0.199631\n",
       " 3  Initial Configuration Evaluation Time in Seconds   0.582387\n",
       " 4     Best Configuration Evaluation Time in Seconds   2.387434\n",
       " 5                 Number of Improved Configurations   2.000000\n",
       " 6                Number of Evaluated Configurations  17.000000\n",
       " 7                      Total Tuning Time in Seconds   8.323090\n",
       " 8                           Parallel Tuning Speedup   3.558607,\n",
       "  Tuner Task Timing\n",
       " \n",
       "                           Task   Time_sec  Time_percent\n",
       " 0               Model Training  26.135432     88.239914\n",
       " 1                Model Scoring   2.934760      9.908503\n",
       " 2  Total Objective Evaluations  29.081164     98.185457\n",
       " 3                        Tuner   0.537442      1.814543\n",
       " 4               Total CPU Time  29.618606    100.000000,\n",
       "  Hyperparameter Importance\n",
       " \n",
       "   Hyperparameter  RelImportance\n",
       " 0   LEARNINGRATE       1.000000\n",
       " 1  SUBSAMPLERATE       0.261105\n",
       " 2          LASSO       0.059784\n",
       " 3       MAXLEVEL       0.017375\n",
       " 4              M       0.000000\n",
       " 5          RIDGE       0.000000,\n",
       "  TuneAll Results Summary\n",
       " \n",
       "           ModelID               ModelType  Evaluations  BestObjective  AverageObjective  StdDevObjective  BestObjTime  AverageTime  StdDevTime\n",
       " 0  1_DecisionTree           Decision Tree            6       0.186743          0.186743     3.040471e-17     0.267086     0.423588    0.173191\n",
       " 1     2_GradBoost  Gradient Boosting Tree           16       0.199261          0.211118     1.205480e-02     2.387442     1.878428    0.830149,\n",
       "  TuneAll Best Models\n",
       " \n",
       "           ModelID  Evaluation  MeanConseqError  EvaluationTime\n",
       " 0  1_DecisionTree           6         0.186743        0.188794\n",
       " 1  1_DecisionTree           0         0.186743        0.267086\n",
       " 2  1_DecisionTree           1         0.186743        0.328704\n",
       " 3  1_DecisionTree           5         0.186743        0.345324\n",
       " 4  1_DecisionTree           3         0.186743        0.495985\n",
       " 5  1_DecisionTree           2         0.186743        0.496010\n",
       " 6  1_DecisionTree           4         0.186743        0.686710\n",
       " 7     2_GradBoost           9         0.199261        2.387442\n",
       " 8     2_GradBoost          14         0.199295        1.889176\n",
       " 9     2_GradBoost           1         0.199329        0.513950,\n",
       "  TuneAll CAS Output Tables\n",
       " \n",
       " Empty SASDataFrame\n",
       " Columns: [ModelID, CAS_Library, Name, Rows, Columns]\n",
       " Index: [],\n",
       "  Decision Tree for __TEMP_FEATURE_MACHINE_CASOUT___AUTOTUNE_DATA_11FA4B25-9848-604F-9F45-7E73830B6354\n",
       " \n",
       "                            Descr        Value\n",
       " 0           Number of Tree Nodes    39.000000\n",
       " 1         Max Number of Branches     2.000000\n",
       " 2               Number of Levels     7.000000\n",
       " 3               Number of Leaves    20.000000\n",
       " 4                 Number of Bins    50.000000\n",
       " 5         Minimum Size of Leaves    22.000000\n",
       " 6         Maximum Size of Leaves  1300.000000\n",
       " 7            Number of Variables     3.000000\n",
       " 8   Confidence Level for Pruning     0.250000\n",
       " 9    Number of Observations Used  5960.000000\n",
       " 10   Misclassification Error (%)    15.587248,\n",
       "                           Descr                             Value\n",
       " 0  Number of Observations Read                              5960\n",
       " 1  Number of Observations Used                              5960\n",
       " 2  Misclassification Error (%)                      15.587248322,\n",
       "          LEVNAME  LEVINDEX VARNAME\n",
       " 0             1         0  P_BAD1\n",
       " 1             0         1  P_BAD0,\n",
       "    LEVNAME  LEVINDEX VARNAME\n",
       " 0                 0   I_BAD,\n",
       "  ROC Information for _AUTOTUNE_DEFAULT_SCORE_TABLE_\n",
       " \n",
       "    Variable Event  CutOff      TP      FP      FN      TN  Sensitivity  Specificity   KS       KS2    F_HALF       FPR       ACC       FDR        F1         C      Gini     Gamma       Tau  MISCEVENT       FNR\n",
       " 0    P_BAD0     0    0.00  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.830114  0.660229  0.728748  0.210909   0.199497  0.000000\n",
       " 1    P_BAD0     0    0.01  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.830114  0.660229  0.728748  0.210909   0.199497  0.000000\n",
       " 2    P_BAD0     0    0.02  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.830114  0.660229  0.728748  0.210909   0.199497  0.000000\n",
       " 3    P_BAD0     0    0.03  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.830114  0.660229  0.728748  0.210909   0.199497  0.000000\n",
       " 4    P_BAD0     0    0.04  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.830114  0.660229  0.728748  0.210909   0.199497  0.000000\n",
       " 5    P_BAD0     0    0.05  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.830114  0.660229  0.728748  0.210909   0.199497  0.000000\n",
       " 6    P_BAD0     0    0.06  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.830114  0.660229  0.728748  0.210909   0.199497  0.000000\n",
       " 7    P_BAD0     0    0.07  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.830114  0.660229  0.728748  0.210909   0.199497  0.000000\n",
       " 8    P_BAD0     0    0.08  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.830114  0.660229  0.728748  0.210909   0.199497  0.000000\n",
       " 9    P_BAD0     0    0.09  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.830114  0.660229  0.728748  0.210909   0.199497  0.000000\n",
       " 10   P_BAD0     0    0.10  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.830114  0.660229  0.728748  0.210909   0.199497  0.000000\n",
       " 11   P_BAD0     0    0.11  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.830114  0.660229  0.728748  0.210909   0.199497  0.000000\n",
       " 12   P_BAD0     0    0.12  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.830114  0.660229  0.728748  0.210909   0.199497  0.000000\n",
       " 13   P_BAD0     0    0.13  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.830114  0.660229  0.728748  0.210909   0.199497  0.000000\n",
       " 14   P_BAD0     0    0.14  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.830114  0.660229  0.728748  0.210909   0.199497  0.000000\n",
       " 15   P_BAD0     0    0.15  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.830114  0.660229  0.728748  0.210909   0.199497  0.000000\n",
       " 16   P_BAD0     0    0.16  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.830114  0.660229  0.728748  0.210909   0.199497  0.000000\n",
       " 17   P_BAD0     0    0.17  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.830114  0.660229  0.728748  0.210909   0.199497  0.000000\n",
       " 18   P_BAD0     0    0.18  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.830114  0.660229  0.728748  0.210909   0.199497  0.000000\n",
       " 19   P_BAD0     0    0.19  4721.0   963.0    50.0   226.0     0.989520     0.190076  0.0  0.179596  0.858145  0.809924  0.830034  0.169423  0.903109  0.830114  0.660229  0.728748  0.210909   0.169966  0.010480\n",
       " 20   P_BAD0     0    0.20  4721.0   963.0    50.0   226.0     0.989520     0.190076  0.0  0.179596  0.858145  0.809924  0.830034  0.169423  0.903109  0.830114  0.660229  0.728748  0.210909   0.169966  0.010480\n",
       " 21   P_BAD0     0    0.21  4721.0   963.0    50.0   226.0     0.989520     0.190076  0.0  0.179596  0.858145  0.809924  0.830034  0.169423  0.903109  0.830114  0.660229  0.728748  0.210909   0.169966  0.010480\n",
       " 22   P_BAD0     0    0.22  4721.0   963.0    50.0   226.0     0.989520     0.190076  0.0  0.179596  0.858145  0.809924  0.830034  0.169423  0.903109  0.830114  0.660229  0.728748  0.210909   0.169966  0.010480\n",
       " 23   P_BAD0     0    0.23  4721.0   963.0    50.0   226.0     0.989520     0.190076  0.0  0.179596  0.858145  0.809924  0.830034  0.169423  0.903109  0.830114  0.660229  0.728748  0.210909   0.169966  0.010480\n",
       " 24   P_BAD0     0    0.24  4721.0   963.0    50.0   226.0     0.989520     0.190076  0.0  0.179596  0.858145  0.809924  0.830034  0.169423  0.903109  0.830114  0.660229  0.728748  0.210909   0.169966  0.010480\n",
       " 25   P_BAD0     0    0.25  4721.0   963.0    50.0   226.0     0.989520     0.190076  0.0  0.179596  0.858145  0.809924  0.830034  0.169423  0.903109  0.830114  0.660229  0.728748  0.210909   0.169966  0.010480\n",
       " 26   P_BAD0     0    0.26  4721.0   963.0    50.0   226.0     0.989520     0.190076  0.0  0.179596  0.858145  0.809924  0.830034  0.169423  0.903109  0.830114  0.660229  0.728748  0.210909   0.169966  0.010480\n",
       " 27   P_BAD0     0    0.27  4721.0   963.0    50.0   226.0     0.989520     0.190076  0.0  0.179596  0.858145  0.809924  0.830034  0.169423  0.903109  0.830114  0.660229  0.728748  0.210909   0.169966  0.010480\n",
       " 28   P_BAD0     0    0.28  4721.0   963.0    50.0   226.0     0.989520     0.190076  0.0  0.179596  0.858145  0.809924  0.830034  0.169423  0.903109  0.830114  0.660229  0.728748  0.210909   0.169966  0.010480\n",
       " 29   P_BAD0     0    0.29  4721.0   963.0    50.0   226.0     0.989520     0.190076  0.0  0.179596  0.858145  0.809924  0.830034  0.169423  0.903109  0.830114  0.660229  0.728748  0.210909   0.169966  0.010480\n",
       " 30   P_BAD0     0    0.30  4721.0   963.0    50.0   226.0     0.989520     0.190076  0.0  0.179596  0.858145  0.809924  0.830034  0.169423  0.903109  0.830114  0.660229  0.728748  0.210909   0.169966  0.010480\n",
       " 31   P_BAD0     0    0.31  4721.0   963.0    50.0   226.0     0.989520     0.190076  0.0  0.179596  0.858145  0.809924  0.830034  0.169423  0.903109  0.830114  0.660229  0.728748  0.210909   0.169966  0.010480\n",
       " 32   P_BAD0     0    0.32  4721.0   963.0    50.0   226.0     0.989520     0.190076  0.0  0.179596  0.858145  0.809924  0.830034  0.169423  0.903109  0.830114  0.660229  0.728748  0.210909   0.169966  0.010480\n",
       " 33   P_BAD0     0    0.33  4721.0   963.0    50.0   226.0     0.989520     0.190076  0.0  0.179596  0.858145  0.809924  0.830034  0.169423  0.903109  0.830114  0.660229  0.728748  0.210909   0.169966  0.010480\n",
       " 34   P_BAD0     0    0.34  4721.0   963.0    50.0   226.0     0.989520     0.190076  0.0  0.179596  0.858145  0.809924  0.830034  0.169423  0.903109  0.830114  0.660229  0.728748  0.210909   0.169966  0.010480\n",
       " 35   P_BAD0     0    0.35  4721.0   963.0    50.0   226.0     0.989520     0.190076  0.0  0.179596  0.858145  0.809924  0.830034  0.169423  0.903109  0.830114  0.660229  0.728748  0.210909   0.169966  0.010480\n",
       " 36   P_BAD0     0    0.36  4721.0   963.0    50.0   226.0     0.989520     0.190076  0.0  0.179596  0.858145  0.809924  0.830034  0.169423  0.903109  0.830114  0.660229  0.728748  0.210909   0.169966  0.010480\n",
       " 37   P_BAD0     0    0.37  4626.0   795.0   145.0   394.0     0.969608     0.331371  0.0  0.300979  0.874315  0.668629  0.842282  0.146652  0.907771  0.830114  0.660229  0.728748  0.210909   0.157718  0.030392\n",
       " 38   P_BAD0     0    0.38  4626.0   795.0   145.0   394.0     0.969608     0.331371  0.0  0.300979  0.874315  0.668629  0.842282  0.146652  0.907771  0.830114  0.660229  0.728748  0.210909   0.157718  0.030392\n",
       " 39   P_BAD0     0    0.39  4626.0   795.0   145.0   394.0     0.969608     0.331371  0.0  0.300979  0.874315  0.668629  0.842282  0.146652  0.907771  0.830114  0.660229  0.728748  0.210909   0.157718  0.030392\n",
       " 40   P_BAD0     0    0.40  4609.0   769.0   162.0   420.0     0.966045     0.353238  0.0  0.319283  0.876802  0.646762  0.843792  0.142990  0.908267  0.830114  0.660229  0.728748  0.210909   0.156208  0.033955\n",
       " 41   P_BAD0     0    0.41  4609.0   769.0   162.0   420.0     0.966045     0.353238  0.0  0.319283  0.876802  0.646762  0.843792  0.142990  0.908267  0.830114  0.660229  0.728748  0.210909   0.156208  0.033955\n",
       " 42   P_BAD0     0    0.42  4609.0   769.0   162.0   420.0     0.966045     0.353238  0.0  0.319283  0.876802  0.646762  0.843792  0.142990  0.908267  0.830114  0.660229  0.728748  0.210909   0.156208  0.033955\n",
       " 43   P_BAD0     0    0.43  4609.0   769.0   162.0   420.0     0.966045     0.353238  0.0  0.319283  0.876802  0.646762  0.843792  0.142990  0.908267  0.830114  0.660229  0.728748  0.210909   0.156208  0.033955\n",
       " 44   P_BAD0     0    0.44  4609.0   769.0   162.0   420.0     0.966045     0.353238  0.0  0.319283  0.876802  0.646762  0.843792  0.142990  0.908267  0.830114  0.660229  0.728748  0.210909   0.156208  0.033955\n",
       " 45   P_BAD0     0    0.45  4609.0   769.0   162.0   420.0     0.966045     0.353238  0.0  0.319283  0.876802  0.646762  0.843792  0.142990  0.908267  0.830114  0.660229  0.728748  0.210909   0.156208  0.033955\n",
       " 46   P_BAD0     0    0.46  4599.0   757.0   172.0   432.0     0.963949     0.363331  0.0  0.327279  0.877839  0.636669  0.844128  0.141337  0.908265  0.830114  0.660229  0.728748  0.210909   0.155872  0.036051\n",
       " 47   P_BAD0     0    0.47  4599.0   757.0   172.0   432.0     0.963949     0.363331  0.0  0.327279  0.877839  0.636669  0.844128  0.141337  0.908265  0.830114  0.660229  0.728748  0.210909   0.155872  0.036051\n",
       " 48   P_BAD0     0    0.48  4599.0   757.0   172.0   432.0     0.963949     0.363331  0.0  0.327279  0.877839  0.636669  0.844128  0.141337  0.908265  0.830114  0.660229  0.728748  0.210909   0.155872  0.036051\n",
       " 49   P_BAD0     0    0.49  4599.0   757.0   172.0   432.0     0.963949     0.363331  0.0  0.327279  0.877839  0.636669  0.844128  0.141337  0.908265  0.830114  0.660229  0.728748  0.210909   0.155872  0.036051\n",
       " 50   P_BAD0     0    0.50  4599.0   757.0   172.0   432.0     0.963949     0.363331  0.0  0.327279  0.877839  0.636669  0.844128  0.141337  0.908265  0.830114  0.660229  0.728748  0.210909   0.155872  0.036051\n",
       " 51   P_BAD0     0    0.51  4599.0   757.0   172.0   432.0     0.963949     0.363331  0.0  0.327279  0.877839  0.636669  0.844128  0.141337  0.908265  0.830114  0.660229  0.728748  0.210909   0.155872  0.036051\n",
       " 52   P_BAD0     0    0.52  4599.0   757.0   172.0   432.0     0.963949     0.363331  0.0  0.327279  0.877839  0.636669  0.844128  0.141337  0.908265  0.830114  0.660229  0.728748  0.210909   0.155872  0.036051\n",
       " 53   P_BAD0     0    0.53  4599.0   757.0   172.0   432.0     0.963949     0.363331  0.0  0.327279  0.877839  0.636669  0.844128  0.141337  0.908265  0.830114  0.660229  0.728748  0.210909   0.155872  0.036051\n",
       " 54   P_BAD0     0    0.54  4599.0   757.0   172.0   432.0     0.963949     0.363331  0.0  0.327279  0.877839  0.636669  0.844128  0.141337  0.908265  0.830114  0.660229  0.728748  0.210909   0.155872  0.036051\n",
       " 55   P_BAD0     0    0.55  4599.0   757.0   172.0   432.0     0.963949     0.363331  0.0  0.327279  0.877839  0.636669  0.844128  0.141337  0.908265  0.830114  0.660229  0.728748  0.210909   0.155872  0.036051\n",
       " 56   P_BAD0     0    0.56  4599.0   757.0   172.0   432.0     0.963949     0.363331  0.0  0.327279  0.877839  0.636669  0.844128  0.141337  0.908265  0.830114  0.660229  0.728748  0.210909   0.155872  0.036051\n",
       " 57   P_BAD0     0    0.57  4599.0   757.0   172.0   432.0     0.963949     0.363331  0.0  0.327279  0.877839  0.636669  0.844128  0.141337  0.908265  0.830114  0.660229  0.728748  0.210909   0.155872  0.036051\n",
       " 58   P_BAD0     0    0.58  4599.0   757.0   172.0   432.0     0.963949     0.363331  0.0  0.327279  0.877839  0.636669  0.844128  0.141337  0.908265  0.830114  0.660229  0.728748  0.210909   0.155872  0.036051\n",
       " 59   P_BAD0     0    0.59  4599.0   757.0   172.0   432.0     0.963949     0.363331  0.0  0.327279  0.877839  0.636669  0.844128  0.141337  0.908265  0.830114  0.660229  0.728748  0.210909   0.155872  0.036051\n",
       " 60   P_BAD0     0    0.60  4599.0   757.0   172.0   432.0     0.963949     0.363331  0.0  0.327279  0.877839  0.636669  0.844128  0.141337  0.908265  0.830114  0.660229  0.728748  0.210909   0.155872  0.036051\n",
       " 61   P_BAD0     0    0.61  4599.0   757.0   172.0   432.0     0.963949     0.363331  0.0  0.327279  0.877839  0.636669  0.844128  0.141337  0.908265  0.830114  0.660229  0.728748  0.210909   0.155872  0.036051\n",
       " 62   P_BAD0     0    0.62  4599.0   757.0   172.0   432.0     0.963949     0.363331  0.0  0.327279  0.877839  0.636669  0.844128  0.141337  0.908265  0.830114  0.660229  0.728748  0.210909   0.155872  0.036051\n",
       " 63   P_BAD0     0    0.63  4599.0   757.0   172.0   432.0     0.963949     0.363331  0.0  0.327279  0.877839  0.636669  0.844128  0.141337  0.908265  0.830114  0.660229  0.728748  0.210909   0.155872  0.036051\n",
       " 64   P_BAD0     0    0.64  4507.0   704.0   264.0   485.0     0.944666     0.407906  0.0  0.352571  0.879758  0.592094  0.837584  0.135099  0.903025  0.830114  0.660229  0.728748  0.210909   0.162416  0.055334\n",
       " 65   P_BAD0     0    0.65  4469.0   683.0   302.0   506.0     0.936701     0.425568  0.0  0.362269  0.880452  0.574432  0.834732  0.132570  0.900736  0.830114  0.660229  0.728748  0.210909   0.165268  0.063299\n",
       " 66   P_BAD0     0    0.66  4469.0   683.0   302.0   506.0     0.936701     0.425568  0.0  0.362269  0.880452  0.574432  0.834732  0.132570  0.900736  0.830114  0.660229  0.728748  0.210909   0.165268  0.063299\n",
       " 67   P_BAD0     0    0.67  3754.0   317.0  1017.0   872.0     0.786837     0.733389  0.0  0.520227  0.891475  0.266611  0.776174  0.077868  0.849129  0.830114  0.660229  0.728748  0.210909   0.223826  0.213163\n",
       " 68   P_BAD0     0    0.68  3754.0   317.0  1017.0   872.0     0.786837     0.733389  0.0  0.520227  0.891475  0.266611  0.776174  0.077868  0.849129  0.830114  0.660229  0.728748  0.210909   0.223826  0.213163\n",
       " 69   P_BAD0     0    0.69  3754.0   317.0  1017.0   872.0     0.786837     0.733389  0.0  0.520227  0.891475  0.266611  0.776174  0.077868  0.849129  0.830114  0.660229  0.728748  0.210909   0.223826  0.213163\n",
       " 70   P_BAD0     0    0.70  3754.0   317.0  1017.0   872.0     0.786837     0.733389  0.0  0.520227  0.891475  0.266611  0.776174  0.077868  0.849129  0.830114  0.660229  0.728748  0.210909   0.223826  0.213163\n",
       " 71   P_BAD0     0    0.71  3754.0   317.0  1017.0   872.0     0.786837     0.733389  0.0  0.520227  0.891475  0.266611  0.776174  0.077868  0.849129  0.830114  0.660229  0.728748  0.210909   0.223826  0.213163\n",
       " 72   P_BAD0     0    0.72  3754.0   317.0  1017.0   872.0     0.786837     0.733389  0.0  0.520227  0.891475  0.266611  0.776174  0.077868  0.849129  0.830114  0.660229  0.728748  0.210909   0.223826  0.213163\n",
       " 73   P_BAD0     0    0.73  3754.0   317.0  1017.0   872.0     0.786837     0.733389  0.0  0.520227  0.891475  0.266611  0.776174  0.077868  0.849129  0.830114  0.660229  0.728748  0.210909   0.223826  0.213163\n",
       " 74   P_BAD0     0    0.74  3754.0   317.0  1017.0   872.0     0.786837     0.733389  0.0  0.520227  0.891475  0.266611  0.776174  0.077868  0.849129  0.830114  0.660229  0.728748  0.210909   0.223826  0.213163\n",
       " 75   P_BAD0     0    0.75  3754.0   317.0  1017.0   872.0     0.786837     0.733389  0.0  0.520227  0.891475  0.266611  0.776174  0.077868  0.849129  0.830114  0.660229  0.728748  0.210909   0.223826  0.213163\n",
       " 76   P_BAD0     0    0.76  3754.0   317.0  1017.0   872.0     0.786837     0.733389  0.0  0.520227  0.891475  0.266611  0.776174  0.077868  0.849129  0.830114  0.660229  0.728748  0.210909   0.223826  0.213163\n",
       " 77   P_BAD0     0    0.77  3641.0   282.0  1130.0   907.0     0.763152     0.762826  0.0  0.525978  0.889654  0.237174  0.763087  0.071884  0.837589  0.830114  0.660229  0.728748  0.210909   0.236913  0.236848\n",
       " 78   P_BAD0     0    0.78  3259.0   173.0  1512.0  1016.0     0.683085     0.854500  1.0  0.537585  0.880858  0.145500  0.717282  0.050408  0.794587  0.830114  0.660229  0.728748  0.210909   0.282718  0.316915\n",
       " 79   P_BAD0     0    0.79  3259.0   173.0  1512.0  1016.0     0.683085     0.854500  0.0  0.537585  0.880858  0.145500  0.717282  0.050408  0.794587  0.830114  0.660229  0.728748  0.210909   0.282718  0.316915\n",
       " 80   P_BAD0     0    0.80  3259.0   173.0  1512.0  1016.0     0.683085     0.854500  0.0  0.537585  0.880858  0.145500  0.717282  0.050408  0.794587  0.830114  0.660229  0.728748  0.210909   0.282718  0.316915\n",
       " 81   P_BAD0     0    0.81  3259.0   173.0  1512.0  1016.0     0.683085     0.854500  0.0  0.537585  0.880858  0.145500  0.717282  0.050408  0.794587  0.830114  0.660229  0.728748  0.210909   0.282718  0.316915\n",
       " 82   P_BAD0     0    0.82  3259.0   173.0  1512.0  1016.0     0.683085     0.854500  0.0  0.537585  0.880858  0.145500  0.717282  0.050408  0.794587  0.830114  0.660229  0.728748  0.210909   0.282718  0.316915\n",
       " 83   P_BAD0     0    0.83  3259.0   173.0  1512.0  1016.0     0.683085     0.854500  0.0  0.537585  0.880858  0.145500  0.717282  0.050408  0.794587  0.830114  0.660229  0.728748  0.210909   0.282718  0.316915\n",
       " 84   P_BAD0     0    0.84  3259.0   173.0  1512.0  1016.0     0.683085     0.854500  0.0  0.537585  0.880858  0.145500  0.717282  0.050408  0.794587  0.830114  0.660229  0.728748  0.210909   0.282718  0.316915\n",
       " 85   P_BAD0     0    0.85  3259.0   173.0  1512.0  1016.0     0.683085     0.854500  0.0  0.537585  0.880858  0.145500  0.717282  0.050408  0.794587  0.830114  0.660229  0.728748  0.210909   0.282718  0.316915\n",
       " 86   P_BAD0     0    0.86  3259.0   173.0  1512.0  1016.0     0.683085     0.854500  0.0  0.537585  0.880858  0.145500  0.717282  0.050408  0.794587  0.830114  0.660229  0.728748  0.210909   0.282718  0.316915\n",
       " 87   P_BAD0     0    0.87  3259.0   173.0  1512.0  1016.0     0.683085     0.854500  0.0  0.537585  0.880858  0.145500  0.717282  0.050408  0.794587  0.830114  0.660229  0.728748  0.210909   0.282718  0.316915\n",
       " 88   P_BAD0     0    0.88  3259.0   173.0  1512.0  1016.0     0.683085     0.854500  0.0  0.537585  0.880858  0.145500  0.717282  0.050408  0.794587  0.830114  0.660229  0.728748  0.210909   0.282718  0.316915\n",
       " 89   P_BAD0     0    0.89  3063.0   148.0  1708.0  1041.0     0.642004     0.875526  0.0  0.517529  0.869429  0.124474  0.688591  0.046092  0.767477  0.830114  0.660229  0.728748  0.210909   0.311409  0.357996\n",
       " 90   P_BAD0     0    0.90  3063.0   148.0  1708.0  1041.0     0.642004     0.875526  0.0  0.517529  0.869429  0.124474  0.688591  0.046092  0.767477  0.830114  0.660229  0.728748  0.210909   0.311409  0.357996\n",
       " 91   P_BAD0     0    0.91  3063.0   148.0  1708.0  1041.0     0.642004     0.875526  0.0  0.517529  0.869429  0.124474  0.688591  0.046092  0.767477  0.830114  0.660229  0.728748  0.210909   0.311409  0.357996\n",
       " 92   P_BAD0     0    0.92  3063.0   148.0  1708.0  1041.0     0.642004     0.875526  0.0  0.517529  0.869429  0.124474  0.688591  0.046092  0.767477  0.830114  0.660229  0.728748  0.210909   0.311409  0.357996\n",
       " 93   P_BAD0     0    0.93  3063.0   148.0  1708.0  1041.0     0.642004     0.875526  0.0  0.517529  0.869429  0.124474  0.688591  0.046092  0.767477  0.830114  0.660229  0.728748  0.210909   0.311409  0.357996\n",
       " 94   P_BAD0     0    0.94  3063.0   148.0  1708.0  1041.0     0.642004     0.875526  0.0  0.517529  0.869429  0.124474  0.688591  0.046092  0.767477  0.830114  0.660229  0.728748  0.210909   0.311409  0.357996\n",
       " 95   P_BAD0     0    0.95  1524.0    61.0  3247.0  1128.0     0.319430     0.948696  0.0  0.268126  0.685807  0.051304  0.444966  0.038486  0.479547  0.830114  0.660229  0.728748  0.210909   0.555034  0.680570\n",
       " 96   P_BAD0     0    0.96   474.0    13.0  4297.0  1176.0     0.099350     0.989066  0.0  0.088417  0.352731  0.010934  0.276846  0.026694  0.180297  0.830114  0.660229  0.728748  0.210909   0.723154  0.900650\n",
       " 97   P_BAD0     0    0.97   192.0     3.0  4579.0  1186.0     0.040243     0.997477  0.0  0.037720  0.172942  0.002523  0.231208  0.015385  0.077326  0.830114  0.660229  0.728748  0.210909   0.768792  0.959757\n",
       " 98   P_BAD0     0    0.98   192.0     3.0  4579.0  1186.0     0.040243     0.997477  0.0  0.037720  0.172942  0.002523  0.231208  0.015385  0.077326  0.830114  0.660229  0.728748  0.210909   0.768792  0.959757\n",
       " 99   P_BAD0     0    0.99     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.830114  0.660229  0.728748  0.210909   0.800503  1.000000,\n",
       "  Fit Statistics for _AUTOTUNE_DEFAULT_SCORE_TABLE_\n",
       " \n",
       "      NOBS       ASE     DIV      RASE       MCE      MCLL\n",
       " 0  5960.0  0.114286  5960.0  0.338062  0.155872  0.366889,\n",
       "  Tuner Information\n",
       " \n",
       "                            Parameter              Value\n",
       " 0                         Model Type      Decision Tree\n",
       " 1           Tuner Objective Function  Misclassification\n",
       " 2                      Search Method               GRID\n",
       " 3              Number of Grid Points                  6\n",
       " 4     Maximum Tuning Time in Seconds              36000\n",
       " 5                    Validation Type   Cross-Validation\n",
       " 6      Num Folds in Cross-Validation                  5\n",
       " 7                          Log Level                  0\n",
       " 8                               Seed         1876916290\n",
       " 9     Number of Parallel Evaluations                  4\n",
       " 10  Number of Workers per Subsession                  0,\n",
       "  Tuner Results\n",
       " \n",
       "    Evaluation  MAXLEVEL       CRIT  MeanConseqError  EvaluationTime\n",
       " 0           0        11  gainRatio         0.156877        0.341418\n",
       " 1           6        15       gain         0.154696        0.470920\n",
       " 2           1         5       gain         0.156877        0.311942\n",
       " 3           3         5  gainRatio         0.156877        0.472439\n",
       " 4           4        10  gainRatio         0.156877        0.927789\n",
       " 5           5        15  gainRatio         0.157213        0.634979\n",
       " 6           2        10       gain         0.157689        0.472432,\n",
       "  Tuner Iteration History\n",
       " \n",
       "    Iteration  Evaluations  Best_obj  Time_sec\n",
       " 0          0            1  0.156877  0.341418\n",
       " 1          1            7  0.154696  1.288053,\n",
       "  Tuner Evaluation History\n",
       " \n",
       "    Evaluation  Iteration  MAXLEVEL       CRIT  MeanConseqError  EvaluationTime\n",
       " 0           0          0        11  gainRatio         0.156877        0.341418\n",
       " 1           1          1         5       gain         0.156877        0.311942\n",
       " 2           2          1        10       gain         0.157689        0.472432\n",
       " 3           3          1         5  gainRatio         0.156877        0.472439\n",
       " 4           4          1        10  gainRatio         0.156877        0.927789\n",
       " 5           5          1        15  gainRatio         0.157213        0.634979\n",
       " 6           6          1        15       gain         0.154696        0.470920,\n",
       "  Best Configuration\n",
       " \n",
       "              Parameter        Name         Value\n",
       " 0           Evaluation  Evaluation             6\n",
       " 1  Maximum Tree Levels    MAXLEVEL            15\n",
       " 2            Criterion        CRIT          gain\n",
       " 3    Misclassification   Objective  0.1546962005,\n",
       "  Tuner Summary\n",
       " \n",
       "                                           Parameter     Value\n",
       " 0             Initial Configuration Objective Value  0.156877\n",
       " 1                Best Configuration Objective Value  0.154696\n",
       " 2               Worst Configuration Objective Value  0.157689\n",
       " 3  Initial Configuration Evaluation Time in Seconds  0.341418\n",
       " 4     Best Configuration Evaluation Time in Seconds  0.470913\n",
       " 5                 Number of Improved Configurations  1.000000\n",
       " 6                Number of Evaluated Configurations  7.000000\n",
       " 7                      Total Tuning Time in Seconds  1.334475\n",
       " 8                           Parallel Tuning Speedup  2.160148,\n",
       "  Tuner Task Timing\n",
       " \n",
       "                           Task  Time_sec  Time_percent\n",
       " 0               Model Training  1.218875     42.282950\n",
       " 1                Model Scoring  0.844904     29.309853\n",
       " 2  Total Objective Evaluations  2.228993     77.324077\n",
       " 3                        Tuner  0.653671     22.675923\n",
       " 4               Total CPU Time  2.882663    100.000000,\n",
       "  Hyperparameter Importance\n",
       " \n",
       "   Hyperparameter  RelImportance\n",
       " 0       MAXLEVEL       1.000000\n",
       " 1           CRIT       0.282713,\n",
       "  Gradient Boosting Tree for __TEMP_FEATURE_MACHINE_CASOUT___AUTOTUNE_DATA_11FA4B25-9848-604F-9F45-7E73830B6354\n",
       " \n",
       "                                   Descr         Value\n",
       " 0                       Number of Trees  1.500000e+02\n",
       " 1                          Distribution  2.000000e+00\n",
       " 2                         Learning Rate  1.000000e-01\n",
       " 3                      Subsampling Rate  6.000000e-01\n",
       " 4      Number of Selected Variables (M)  3.000000e+00\n",
       " 5                        Number of Bins  5.000000e+01\n",
       " 6                   Number of Variables  3.000000e+00\n",
       " 7              Max Number of Tree Nodes  1.900000e+01\n",
       " 8              Min Number of Tree Nodes  1.900000e+01\n",
       " 9                Max Number of Branches  2.000000e+00\n",
       " 10               Min Number of Branches  2.000000e+00\n",
       " 11                 Max Number of Levels  5.000000e+00\n",
       " 12                 Min Number of Levels  5.000000e+00\n",
       " 13                 Max Number of Leaves  1.000000e+01\n",
       " 14                 Min Number of Leaves  1.000000e+01\n",
       " 15               Maximum Size of Leaves  1.844000e+03\n",
       " 16               Minimum Size of Leaves  2.400000e+01\n",
       " 17                   Random Number Seed  1.876916e+09\n",
       " 18                   Lasso (L1) penalty  5.000000e-01\n",
       " 19                   Ridge (L2) penalty  0.000000e+00\n",
       " 20               Actual Number of Trees  1.000000e+00\n",
       " 21             Average number of Leaves  1.000000e+01\n",
       " 22            Early stopping stagnation  4.000000e+00\n",
       " 23             Early stopping threshold  0.000000e+00\n",
       " 24  Early stopping threshold iterations  0.000000e+00\n",
       " 25             Early stopping tolerance  0.000000e+00,\n",
       "     Progress    Metric\n",
       " 0       1.0  0.199497,\n",
       "                           Descr                             Value\n",
       " 0  Number of Observations Read                              5960\n",
       " 1  Number of Observations Used                              5960\n",
       " 2  Misclassification Error (%)                       19.94966443,\n",
       "     TreeID  Trees  NLeaves       MCR   LogLoss       ASE     RASE     MAXAE\n",
       " 0     0.0    1.0     10.0  0.199497  0.473837  0.150956  0.38853  0.814711,\n",
       "          LEVNAME  LEVINDEX VARNAME\n",
       " 0             1         0  P_BAD1\n",
       " 1             0         1  P_BAD0,\n",
       "    LEVNAME  LEVINDEX VARNAME\n",
       " 0                 0   I_BAD,\n",
       "  ROC Information for _AUTOTUNE_DEFAULT_SCORE_TABLE_\n",
       " \n",
       "    Variable Event  CutOff      TP      FP      FN      TN  Sensitivity  Specificity   KS       KS2    F_HALF       FPR       ACC       FDR        F1         C      Gini     Gamma       Tau  MISCEVENT       FNR\n",
       " 0    P_BAD0     0    0.00  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 1    P_BAD0     0    0.01  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 2    P_BAD0     0    0.02  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 3    P_BAD0     0    0.03  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 4    P_BAD0     0    0.04  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 5    P_BAD0     0    0.05  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 6    P_BAD0     0    0.06  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 7    P_BAD0     0    0.07  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 8    P_BAD0     0    0.08  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 9    P_BAD0     0    0.09  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 10   P_BAD0     0    0.10  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 11   P_BAD0     0    0.11  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 12   P_BAD0     0    0.12  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 13   P_BAD0     0    0.13  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 14   P_BAD0     0    0.14  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 15   P_BAD0     0    0.15  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 16   P_BAD0     0    0.16  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 17   P_BAD0     0    0.17  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 18   P_BAD0     0    0.18  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 19   P_BAD0     0    0.19  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 20   P_BAD0     0    0.20  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 21   P_BAD0     0    0.21  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 22   P_BAD0     0    0.22  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 23   P_BAD0     0    0.23  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 24   P_BAD0     0    0.24  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 25   P_BAD0     0    0.25  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 26   P_BAD0     0    0.26  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 27   P_BAD0     0    0.27  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 28   P_BAD0     0    0.28  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 29   P_BAD0     0    0.29  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 30   P_BAD0     0    0.30  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 31   P_BAD0     0    0.31  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 32   P_BAD0     0    0.32  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 33   P_BAD0     0    0.33  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 34   P_BAD0     0    0.34  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 35   P_BAD0     0    0.35  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 36   P_BAD0     0    0.36  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 37   P_BAD0     0    0.37  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 38   P_BAD0     0    0.38  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 39   P_BAD0     0    0.39  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 40   P_BAD0     0    0.40  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 41   P_BAD0     0    0.41  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 42   P_BAD0     0    0.42  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 43   P_BAD0     0    0.43  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 44   P_BAD0     0    0.44  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 45   P_BAD0     0    0.45  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 46   P_BAD0     0    0.46  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 47   P_BAD0     0    0.47  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 48   P_BAD0     0    0.48  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 49   P_BAD0     0    0.49  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 50   P_BAD0     0    0.50  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 51   P_BAD0     0    0.51  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 52   P_BAD0     0    0.52  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 53   P_BAD0     0    0.53  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 54   P_BAD0     0    0.54  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 55   P_BAD0     0    0.55  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 56   P_BAD0     0    0.56  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 57   P_BAD0     0    0.57  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 58   P_BAD0     0    0.58  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 59   P_BAD0     0    0.59  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 60   P_BAD0     0    0.60  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 61   P_BAD0     0    0.61  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 62   P_BAD0     0    0.62  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 63   P_BAD0     0    0.63  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 64   P_BAD0     0    0.64  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 65   P_BAD0     0    0.65  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 66   P_BAD0     0    0.66  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 67   P_BAD0     0    0.67  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 68   P_BAD0     0    0.68  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 69   P_BAD0     0    0.69  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 70   P_BAD0     0    0.70  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 71   P_BAD0     0    0.71  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 72   P_BAD0     0    0.72  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 73   P_BAD0     0    0.73  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 74   P_BAD0     0    0.74  4721.0   964.0    50.0   225.0     0.989520     0.189235  0.0  0.178755  0.858020  0.810765  0.829866  0.169569  0.903022  0.819014  0.638027  0.777591  0.203817   0.170134  0.010480\n",
       " 75   P_BAD0     0    0.75  4721.0   964.0    50.0   225.0     0.989520     0.189235  0.0  0.178755  0.858020  0.810765  0.829866  0.169569  0.903022  0.819014  0.638027  0.777591  0.203817   0.170134  0.010480\n",
       " 76   P_BAD0     0    0.76  4626.0   796.0   145.0   393.0     0.969608     0.330530  0.0  0.300138  0.874183  0.669470  0.842114  0.146809  0.907682  0.819014  0.638027  0.777591  0.203817   0.157886  0.030392\n",
       " 77   P_BAD0     0    0.77  4599.0   758.0   172.0   431.0     0.963949     0.362489  0.0  0.326438  0.877705  0.637511  0.843960  0.141497  0.908175  0.819014  0.638027  0.777591  0.203817   0.156040  0.036051\n",
       " 78   P_BAD0     0    0.78  4599.0   758.0   172.0   431.0     0.963949     0.362489  0.0  0.326438  0.877705  0.637511  0.843960  0.141497  0.908175  0.819014  0.638027  0.777591  0.203817   0.156040  0.036051\n",
       " 79   P_BAD0     0    0.79  3792.0   338.0   979.0   851.0     0.794802     0.715728  0.0  0.510529  0.890517  0.284272  0.779027  0.081840  0.852039  0.819014  0.638027  0.777591  0.203817   0.220973  0.205198\n",
       " 80   P_BAD0     0    0.80  3342.0   198.0  1429.0   991.0     0.700482     0.833474  0.0  0.533956  0.882679  0.166526  0.727013  0.055932  0.804235  0.819014  0.638027  0.777591  0.203817   0.272987  0.299518\n",
       " 81   P_BAD0     0    0.81  3278.0   179.0  1493.0  1010.0     0.687068     0.849453  1.0  0.536521  0.881230  0.150547  0.719463  0.051779  0.796791  0.819014  0.638027  0.777591  0.203817   0.280537  0.312932\n",
       " 82   P_BAD0     0    0.82     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.819014  0.638027  0.777591  0.203817   0.800503  1.000000\n",
       " 83   P_BAD0     0    0.83     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.819014  0.638027  0.777591  0.203817   0.800503  1.000000\n",
       " 84   P_BAD0     0    0.84     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.819014  0.638027  0.777591  0.203817   0.800503  1.000000\n",
       " 85   P_BAD0     0    0.85     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.819014  0.638027  0.777591  0.203817   0.800503  1.000000\n",
       " 86   P_BAD0     0    0.86     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.819014  0.638027  0.777591  0.203817   0.800503  1.000000\n",
       " 87   P_BAD0     0    0.87     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.819014  0.638027  0.777591  0.203817   0.800503  1.000000\n",
       " 88   P_BAD0     0    0.88     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.819014  0.638027  0.777591  0.203817   0.800503  1.000000\n",
       " 89   P_BAD0     0    0.89     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.819014  0.638027  0.777591  0.203817   0.800503  1.000000\n",
       " 90   P_BAD0     0    0.90     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.819014  0.638027  0.777591  0.203817   0.800503  1.000000\n",
       " 91   P_BAD0     0    0.91     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.819014  0.638027  0.777591  0.203817   0.800503  1.000000\n",
       " 92   P_BAD0     0    0.92     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.819014  0.638027  0.777591  0.203817   0.800503  1.000000\n",
       " 93   P_BAD0     0    0.93     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.819014  0.638027  0.777591  0.203817   0.800503  1.000000\n",
       " 94   P_BAD0     0    0.94     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.819014  0.638027  0.777591  0.203817   0.800503  1.000000\n",
       " 95   P_BAD0     0    0.95     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.819014  0.638027  0.777591  0.203817   0.800503  1.000000\n",
       " 96   P_BAD0     0    0.96     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.819014  0.638027  0.777591  0.203817   0.800503  1.000000\n",
       " 97   P_BAD0     0    0.97     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.819014  0.638027  0.777591  0.203817   0.800503  1.000000\n",
       " 98   P_BAD0     0    0.98     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.819014  0.638027  0.777591  0.203817   0.800503  1.000000\n",
       " 99   P_BAD0     0    0.99     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.819014  0.638027  0.777591  0.203817   0.800503  1.000000,\n",
       "  Fit Statistics for _AUTOTUNE_DEFAULT_SCORE_TABLE_\n",
       " \n",
       "      NOBS       ASE     DIV     RASE       MCE      MCLL\n",
       " 0  5960.0  0.150956  5960.0  0.38853  0.199497  0.473837,\n",
       "  Tuner Information\n",
       " \n",
       "                            Parameter                   Value\n",
       " 0                         Model Type  Gradient Boosting Tree\n",
       " 1           Tuner Objective Function       Misclassification\n",
       " 2                      Search Method                    GRID\n",
       " 3              Number of Grid Points                      16\n",
       " 4     Maximum Tuning Time in Seconds                   36000\n",
       " 5                    Validation Type        Cross-Validation\n",
       " 6      Num Folds in Cross-Validation                       5\n",
       " 7                          Log Level                       0\n",
       " 8                               Seed              1876916155\n",
       " 9     Number of Parallel Evaluations                       4\n",
       " 10  Number of Workers per Subsession                       0,\n",
       "  Tuner Results\n",
       " \n",
       "     Evaluation  M  LEARNINGRATE  SUBSAMPLERATE  LASSO  RIDGE  MAXLEVEL  MeanConseqError  EvaluationTime\n",
       " 0            0  3          0.10            0.5    0.0    1.0         5         0.199497        0.632475\n",
       " 1            3  3          0.10            0.6    0.5    0.0         5         0.199295        1.205958\n",
       " 2           15  3          0.05            0.6    0.0    0.0         7         0.199396        2.912694\n",
       " 3            9  3          0.10            0.8    0.0    0.0         5         0.199463        3.570540\n",
       " 4            2  3          0.05            0.8    0.0    0.0         7         0.199497        2.310202\n",
       " 5            4  3          0.10            0.8    0.5    0.0         7         0.199497        3.389764\n",
       " 6           11  3          0.05            0.6    0.0    0.0         5         0.199497        3.021106\n",
       " 7           13  3          0.05            0.6    0.5    0.0         7         0.199497        4.320703\n",
       " 8           14  3          0.05            0.8    0.5    0.0         5         0.199497        3.079410\n",
       " 9           10  3          0.10            0.6    0.0    0.0         5         0.199530        3.303823\n",
       " 10           8  3          0.05            0.8    0.5    0.0         7         0.199597        3.797840,\n",
       "  Tuner Iteration History\n",
       " \n",
       "    Iteration  Evaluations  Best_obj   Time_sec\n",
       " 0          0            1  0.199497   0.632475\n",
       " 1          1           17  0.199295  13.840101,\n",
       "  Tuner Evaluation History\n",
       " \n",
       "     Evaluation  Iteration  M  LEARNINGRATE  SUBSAMPLERATE  LASSO  RIDGE  MAXLEVEL  MeanConseqError  EvaluationTime\n",
       " 0            0          0  3          0.10            0.5    0.0    1.0         5         0.199497        0.632475\n",
       " 1            1          1  3          0.05            0.8    0.0    0.0         5         0.199664        3.318110\n",
       " 2            2          1  3          0.05            0.8    0.0    0.0         7         0.199497        2.310202\n",
       " 3            3          1  3          0.10            0.6    0.5    0.0         5         0.199295        1.205958\n",
       " 4            4          1  3          0.10            0.8    0.5    0.0         7         0.199497        3.389764\n",
       " 5            5          1  3          0.05            0.6    0.5    0.0         5         0.199631        2.916148\n",
       " 6            6          1  3          0.10            0.6    0.0    0.0         7         0.199631        4.396203\n",
       " 7            7          1  3          0.10            0.6    0.5    0.0         7         0.199631        4.185158\n",
       " 8            8          1  3          0.05            0.8    0.5    0.0         7         0.199597        3.797840\n",
       " 9            9          1  3          0.10            0.8    0.0    0.0         5         0.199463        3.570540\n",
       " 10          10          1  3          0.10            0.6    0.0    0.0         5         0.199530        3.303823\n",
       " 11          11          1  3          0.05            0.6    0.0    0.0         5         0.199497        3.021106\n",
       " 12          12          1  3          0.10            0.8    0.5    0.0         5         0.199631        2.794894\n",
       " 13          13          1  3          0.05            0.6    0.5    0.0         7         0.199497        4.320703\n",
       " 14          14          1  3          0.05            0.8    0.5    0.0         5         0.199497        3.079410\n",
       " 15          15          1  3          0.05            0.6    0.0    0.0         7         0.199396        2.912694\n",
       " 16          16          1  3          0.10            0.8    0.0    0.0         7         0.199664        2.909528,\n",
       "  Best Configuration\n",
       " \n",
       "                     Parameter           Name         Value\n",
       " 0                  Evaluation     Evaluation             3\n",
       " 1  Number of Variables to Try              M             3\n",
       " 2               Learning Rate   LEARNINGRATE           0.1\n",
       " 3               Sampling Rate  SUBSAMPLERATE           0.6\n",
       " 4                       Lasso          LASSO           0.5\n",
       " 5                       Ridge          RIDGE             0\n",
       " 6         Maximum Tree Levels       MAXLEVEL             5\n",
       " 7           Misclassification      Objective  0.1992952171,\n",
       "  Tuner Summary\n",
       " \n",
       "                                           Parameter      Value\n",
       " 0             Initial Configuration Objective Value   0.199497\n",
       " 1                Best Configuration Objective Value   0.199295\n",
       " 2               Worst Configuration Objective Value   0.199664\n",
       " 3  Initial Configuration Evaluation Time in Seconds   0.632475\n",
       " 4     Best Configuration Evaluation Time in Seconds   1.060541\n",
       " 5                 Number of Improved Configurations   1.000000\n",
       " 6                Number of Evaluated Configurations  17.000000\n",
       " 7                      Total Tuning Time in Seconds  13.954578\n",
       " 8                           Parallel Tuning Speedup   3.732452,\n",
       "  Tuner Task Timing\n",
       " \n",
       "                           Task   Time_sec  Time_percent\n",
       " 0               Model Training  46.442489     89.167079\n",
       " 1                Model Scoring   4.103261      7.878041\n",
       " 2  Total Objective Evaluations  51.058608     98.029780\n",
       " 3                        Tuner   1.026185      1.970220\n",
       " 4               Total CPU Time  52.084793    100.000000,\n",
       "  Hyperparameter Importance\n",
       " \n",
       "   Hyperparameter  RelImportance\n",
       " 0  SUBSAMPLERATE       1.000000\n",
       " 1       MAXLEVEL       0.296013\n",
       " 2   LEARNINGRATE       0.003978\n",
       " 3          LASSO       0.003695\n",
       " 4              M       0.000000\n",
       " 5          RIDGE       0.000000,\n",
       "  TuneAll Results Summary\n",
       " \n",
       "           ModelID               ModelType  Evaluations  BestObjective  AverageObjective  StdDevObjective  BestObjTime  AverageTime  StdDevTime\n",
       " 0  1_DecisionTree           Decision Tree            6       0.154696          0.156705         0.001035     0.470920     0.548417    0.212080\n",
       " 1     2_GradBoost  Gradient Boosting Tree           16       0.199295          0.209333         0.013088     1.205958     3.248781    0.802765,\n",
       "  TuneAll Best Models\n",
       " \n",
       "           ModelID  Evaluation  MeanConseqError  EvaluationTime\n",
       " 0  1_DecisionTree           6         0.154696        0.470920\n",
       " 1  1_DecisionTree           1         0.156877        0.311942\n",
       " 2  1_DecisionTree           0         0.156877        0.341418\n",
       " 3  1_DecisionTree           3         0.156877        0.472439\n",
       " 4  1_DecisionTree           4         0.156877        0.927789\n",
       " 5  1_DecisionTree           5         0.157213        0.634979\n",
       " 6  1_DecisionTree           2         0.157689        0.472432\n",
       " 7     2_GradBoost           3         0.199295        1.205958\n",
       " 8     2_GradBoost          15         0.199396        2.912694\n",
       " 9     2_GradBoost           9         0.199463        3.570540,\n",
       "  TuneAll CAS Output Tables\n",
       " \n",
       " Empty SASDataFrame\n",
       " Columns: [ModelID, CAS_Library, Name, Rows, Columns]\n",
       " Index: [],\n",
       "               casLib                   Name  Rows  Columns                                           casTable\n",
       " 0  CASUSER(sasdemo)        PIPELINE_OUT_PY    10       19  CASTable('PIPELINE_OUT_PY', caslib='CASUSER(sa...\n",
       " 1  CASUSER(sasdemo)  TRANSFORMATION_OUT_PY     7       21  CASTable('TRANSFORMATION_OUT_PY', caslib='CASU...\n",
       " 2  CASUSER(sasdemo)         FEATURE_OUT_PY    14       15  CASTable('FEATURE_OUT_PY', caslib='CASUSER(sas...\n",
       " 3  CASUSER(sasdemo)          ASTORE_OUT_PY     1        2  CASTable('ASTORE_OUT_PY', caslib='CASUSER(sasd...]\n",
       "\n",
       "[keyedList]\n",
       "\n",
       " {'BestConfiguration_1_DecisionTree': Best Configuration\n",
       " \n",
       "              Parameter        Name         Value\n",
       " 0           Evaluation  Evaluation             6\n",
       " 1  Maximum Tree Levels    MAXLEVEL            15\n",
       " 2            Criterion        CRIT          gain\n",
       " 3    Misclassification   Objective  0.1546962005,\n",
       "  'BestConfiguration_2_GradBoost': Best Configuration\n",
       " \n",
       "                     Parameter           Name         Value\n",
       " 0                  Evaluation     Evaluation             3\n",
       " 1  Number of Variables to Try              M             3\n",
       " 2               Learning Rate   LEARNINGRATE           0.1\n",
       " 3               Sampling Rate  SUBSAMPLERATE           0.6\n",
       " 4                       Lasso          LASSO           0.5\n",
       " 5                       Ridge          RIDGE             0\n",
       " 6         Maximum Tree Levels       MAXLEVEL             5\n",
       " 7           Misclassification      Objective  0.1992952171,\n",
       "  'EncodedName_1_DecisionTree':         LEVNAME  LEVINDEX VARNAME\n",
       " 0             1         0  P_BAD1\n",
       " 1             0         1  P_BAD0,\n",
       "  'EncodedName_2_GradBoost':         LEVNAME  LEVINDEX VARNAME\n",
       " 0             1         0  P_BAD1\n",
       " 1             0         1  P_BAD0,\n",
       "  'EncodedTargetName_1_DecisionTree':   LEVNAME  LEVINDEX VARNAME\n",
       " 0                 0   I_BAD,\n",
       "  'EncodedTargetName_2_GradBoost':   LEVNAME  LEVINDEX VARNAME\n",
       " 0                 0   I_BAD,\n",
       "  'ErrorMetricInfo_2_GradBoost':    TreeID  Trees  NLeaves       MCR   LogLoss       ASE     RASE     MAXAE\n",
       " 0     0.0    1.0     10.0  0.199497  0.473837  0.150956  0.38853  0.814711,\n",
       "  'EvalMetricInfo_2_GradBoost':    Progress    Metric\n",
       " 0       1.0  0.199497,\n",
       "  'EvaluationHistory_1_DecisionTree': Tuner Evaluation History\n",
       " \n",
       "    Evaluation  Iteration  MAXLEVEL       CRIT  MeanConseqError  EvaluationTime\n",
       " 0           0          0        11  gainRatio         0.156877        0.341418\n",
       " 1           1          1         5       gain         0.156877        0.311942\n",
       " 2           2          1        10       gain         0.157689        0.472432\n",
       " 3           3          1         5  gainRatio         0.156877        0.472439\n",
       " 4           4          1        10  gainRatio         0.156877        0.927789\n",
       " 5           5          1        15  gainRatio         0.157213        0.634979\n",
       " 6           6          1        15       gain         0.154696        0.470920,\n",
       "  'EvaluationHistory_2_GradBoost': Tuner Evaluation History\n",
       " \n",
       "     Evaluation  Iteration  M  LEARNINGRATE  SUBSAMPLERATE  LASSO  RIDGE  MAXLEVEL  MeanConseqError  EvaluationTime\n",
       " 0            0          0  3          0.10            0.5    0.0    1.0         5         0.199497        0.632475\n",
       " 1            1          1  3          0.05            0.8    0.0    0.0         5         0.199664        3.318110\n",
       " 2            2          1  3          0.05            0.8    0.0    0.0         7         0.199497        2.310202\n",
       " 3            3          1  3          0.10            0.6    0.5    0.0         5         0.199295        1.205958\n",
       " 4            4          1  3          0.10            0.8    0.5    0.0         7         0.199497        3.389764\n",
       " 5            5          1  3          0.05            0.6    0.5    0.0         5         0.199631        2.916148\n",
       " 6            6          1  3          0.10            0.6    0.0    0.0         7         0.199631        4.396203\n",
       " 7            7          1  3          0.10            0.6    0.5    0.0         7         0.199631        4.185158\n",
       " 8            8          1  3          0.05            0.8    0.5    0.0         7         0.199597        3.797840\n",
       " 9            9          1  3          0.10            0.8    0.0    0.0         5         0.199463        3.570540\n",
       " 10          10          1  3          0.10            0.6    0.0    0.0         5         0.199530        3.303823\n",
       " 11          11          1  3          0.05            0.6    0.0    0.0         5         0.199497        3.021106\n",
       " 12          12          1  3          0.10            0.8    0.5    0.0         5         0.199631        2.794894\n",
       " 13          13          1  3          0.05            0.6    0.5    0.0         7         0.199497        4.320703\n",
       " 14          14          1  3          0.05            0.8    0.5    0.0         5         0.199497        3.079410\n",
       " 15          15          1  3          0.05            0.6    0.0    0.0         7         0.199396        2.912694\n",
       " 16          16          1  3          0.10            0.8    0.0    0.0         7         0.199664        2.909528,\n",
       "  'FitStat_1_DecisionTree': Fit Statistics for _AUTOTUNE_DEFAULT_SCORE_TABLE_\n",
       " \n",
       "      NOBS       ASE     DIV      RASE       MCE      MCLL\n",
       " 0  5960.0  0.114286  5960.0  0.338062  0.155872  0.366889,\n",
       "  'FitStat_2_GradBoost': Fit Statistics for _AUTOTUNE_DEFAULT_SCORE_TABLE_\n",
       " \n",
       "      NOBS       ASE     DIV     RASE       MCE      MCLL\n",
       " 0  5960.0  0.150956  5960.0  0.38853  0.199497  0.473837,\n",
       "  'HyperparameterImportance_1_DecisionTree': Hyperparameter Importance\n",
       " \n",
       "   Hyperparameter  RelImportance\n",
       " 0       MAXLEVEL       1.000000\n",
       " 1           CRIT       0.282713,\n",
       "  'HyperparameterImportance_2_GradBoost': Hyperparameter Importance\n",
       " \n",
       "   Hyperparameter  RelImportance\n",
       " 0  SUBSAMPLERATE       1.000000\n",
       " 1       MAXLEVEL       0.296013\n",
       " 2   LEARNINGRATE       0.003978\n",
       " 3          LASSO       0.003695\n",
       " 4              M       0.000000\n",
       " 5          RIDGE       0.000000,\n",
       "  'IterationHistory_1_DecisionTree': Tuner Iteration History\n",
       " \n",
       "    Iteration  Evaluations  Best_obj  Time_sec\n",
       " 0          0            1  0.156877  0.341418\n",
       " 1          1            7  0.154696  1.288053,\n",
       "  'IterationHistory_2_GradBoost': Tuner Iteration History\n",
       " \n",
       "    Iteration  Evaluations  Best_obj   Time_sec\n",
       " 0          0            1  0.199497   0.632475\n",
       " 1          1           17  0.199295  13.840101,\n",
       "  'ModelInfo_1_DecisionTree': Decision Tree for __TEMP_FEATURE_MACHINE_CASOUT___AUTOTUNE_DATA_11FA4B25-9848-604F-9F45-7E73830B6354\n",
       " \n",
       "                            Descr        Value\n",
       " 0           Number of Tree Nodes    39.000000\n",
       " 1         Max Number of Branches     2.000000\n",
       " 2               Number of Levels     7.000000\n",
       " 3               Number of Leaves    20.000000\n",
       " 4                 Number of Bins    50.000000\n",
       " 5         Minimum Size of Leaves    22.000000\n",
       " 6         Maximum Size of Leaves  1300.000000\n",
       " 7            Number of Variables     3.000000\n",
       " 8   Confidence Level for Pruning     0.250000\n",
       " 9    Number of Observations Used  5960.000000\n",
       " 10   Misclassification Error (%)    15.587248,\n",
       "  'ModelInfo_2_GradBoost': Gradient Boosting Tree for __TEMP_FEATURE_MACHINE_CASOUT___AUTOTUNE_DATA_11FA4B25-9848-604F-9F45-7E73830B6354\n",
       " \n",
       "                                   Descr         Value\n",
       " 0                       Number of Trees  1.500000e+02\n",
       " 1                          Distribution  2.000000e+00\n",
       " 2                         Learning Rate  1.000000e-01\n",
       " 3                      Subsampling Rate  6.000000e-01\n",
       " 4      Number of Selected Variables (M)  3.000000e+00\n",
       " 5                        Number of Bins  5.000000e+01\n",
       " 6                   Number of Variables  3.000000e+00\n",
       " 7              Max Number of Tree Nodes  1.900000e+01\n",
       " 8              Min Number of Tree Nodes  1.900000e+01\n",
       " 9                Max Number of Branches  2.000000e+00\n",
       " 10               Min Number of Branches  2.000000e+00\n",
       " 11                 Max Number of Levels  5.000000e+00\n",
       " 12                 Min Number of Levels  5.000000e+00\n",
       " 13                 Max Number of Leaves  1.000000e+01\n",
       " 14                 Min Number of Leaves  1.000000e+01\n",
       " 15               Maximum Size of Leaves  1.844000e+03\n",
       " 16               Minimum Size of Leaves  2.400000e+01\n",
       " 17                   Random Number Seed  1.876916e+09\n",
       " 18                   Lasso (L1) penalty  5.000000e-01\n",
       " 19                   Ridge (L2) penalty  0.000000e+00\n",
       " 20               Actual Number of Trees  1.000000e+00\n",
       " 21             Average number of Leaves  1.000000e+01\n",
       " 22            Early stopping stagnation  4.000000e+00\n",
       " 23             Early stopping threshold  0.000000e+00\n",
       " 24  Early stopping threshold iterations  0.000000e+00\n",
       " 25             Early stopping tolerance  0.000000e+00,\n",
       "  'OutputCasTables':              casLib                   Name  Rows  Columns                                           casTable\n",
       " 0  CASUSER(sasdemo)        PIPELINE_OUT_PY    10       19  CASTable('PIPELINE_OUT_PY', caslib='CASUSER(sa...\n",
       " 1  CASUSER(sasdemo)  TRANSFORMATION_OUT_PY     7       21  CASTable('TRANSFORMATION_OUT_PY', caslib='CASU...\n",
       " 2  CASUSER(sasdemo)         FEATURE_OUT_PY    14       15  CASTable('FEATURE_OUT_PY', caslib='CASUSER(sas...\n",
       " 3  CASUSER(sasdemo)          ASTORE_OUT_PY     1        2  CASTable('ASTORE_OUT_PY', caslib='CASUSER(sasd...,\n",
       "  'ROCInfo_1_DecisionTree': ROC Information for _AUTOTUNE_DEFAULT_SCORE_TABLE_\n",
       " \n",
       "    Variable Event  CutOff      TP      FP      FN      TN  Sensitivity  Specificity   KS       KS2    F_HALF       FPR       ACC       FDR        F1         C      Gini     Gamma       Tau  MISCEVENT       FNR\n",
       " 0    P_BAD0     0    0.00  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.830114  0.660229  0.728748  0.210909   0.199497  0.000000\n",
       " 1    P_BAD0     0    0.01  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.830114  0.660229  0.728748  0.210909   0.199497  0.000000\n",
       " 2    P_BAD0     0    0.02  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.830114  0.660229  0.728748  0.210909   0.199497  0.000000\n",
       " 3    P_BAD0     0    0.03  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.830114  0.660229  0.728748  0.210909   0.199497  0.000000\n",
       " 4    P_BAD0     0    0.04  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.830114  0.660229  0.728748  0.210909   0.199497  0.000000\n",
       " 5    P_BAD0     0    0.05  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.830114  0.660229  0.728748  0.210909   0.199497  0.000000\n",
       " 6    P_BAD0     0    0.06  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.830114  0.660229  0.728748  0.210909   0.199497  0.000000\n",
       " 7    P_BAD0     0    0.07  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.830114  0.660229  0.728748  0.210909   0.199497  0.000000\n",
       " 8    P_BAD0     0    0.08  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.830114  0.660229  0.728748  0.210909   0.199497  0.000000\n",
       " 9    P_BAD0     0    0.09  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.830114  0.660229  0.728748  0.210909   0.199497  0.000000\n",
       " 10   P_BAD0     0    0.10  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.830114  0.660229  0.728748  0.210909   0.199497  0.000000\n",
       " 11   P_BAD0     0    0.11  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.830114  0.660229  0.728748  0.210909   0.199497  0.000000\n",
       " 12   P_BAD0     0    0.12  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.830114  0.660229  0.728748  0.210909   0.199497  0.000000\n",
       " 13   P_BAD0     0    0.13  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.830114  0.660229  0.728748  0.210909   0.199497  0.000000\n",
       " 14   P_BAD0     0    0.14  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.830114  0.660229  0.728748  0.210909   0.199497  0.000000\n",
       " 15   P_BAD0     0    0.15  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.830114  0.660229  0.728748  0.210909   0.199497  0.000000\n",
       " 16   P_BAD0     0    0.16  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.830114  0.660229  0.728748  0.210909   0.199497  0.000000\n",
       " 17   P_BAD0     0    0.17  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.830114  0.660229  0.728748  0.210909   0.199497  0.000000\n",
       " 18   P_BAD0     0    0.18  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.830114  0.660229  0.728748  0.210909   0.199497  0.000000\n",
       " 19   P_BAD0     0    0.19  4721.0   963.0    50.0   226.0     0.989520     0.190076  0.0  0.179596  0.858145  0.809924  0.830034  0.169423  0.903109  0.830114  0.660229  0.728748  0.210909   0.169966  0.010480\n",
       " 20   P_BAD0     0    0.20  4721.0   963.0    50.0   226.0     0.989520     0.190076  0.0  0.179596  0.858145  0.809924  0.830034  0.169423  0.903109  0.830114  0.660229  0.728748  0.210909   0.169966  0.010480\n",
       " 21   P_BAD0     0    0.21  4721.0   963.0    50.0   226.0     0.989520     0.190076  0.0  0.179596  0.858145  0.809924  0.830034  0.169423  0.903109  0.830114  0.660229  0.728748  0.210909   0.169966  0.010480\n",
       " 22   P_BAD0     0    0.22  4721.0   963.0    50.0   226.0     0.989520     0.190076  0.0  0.179596  0.858145  0.809924  0.830034  0.169423  0.903109  0.830114  0.660229  0.728748  0.210909   0.169966  0.010480\n",
       " 23   P_BAD0     0    0.23  4721.0   963.0    50.0   226.0     0.989520     0.190076  0.0  0.179596  0.858145  0.809924  0.830034  0.169423  0.903109  0.830114  0.660229  0.728748  0.210909   0.169966  0.010480\n",
       " 24   P_BAD0     0    0.24  4721.0   963.0    50.0   226.0     0.989520     0.190076  0.0  0.179596  0.858145  0.809924  0.830034  0.169423  0.903109  0.830114  0.660229  0.728748  0.210909   0.169966  0.010480\n",
       " 25   P_BAD0     0    0.25  4721.0   963.0    50.0   226.0     0.989520     0.190076  0.0  0.179596  0.858145  0.809924  0.830034  0.169423  0.903109  0.830114  0.660229  0.728748  0.210909   0.169966  0.010480\n",
       " 26   P_BAD0     0    0.26  4721.0   963.0    50.0   226.0     0.989520     0.190076  0.0  0.179596  0.858145  0.809924  0.830034  0.169423  0.903109  0.830114  0.660229  0.728748  0.210909   0.169966  0.010480\n",
       " 27   P_BAD0     0    0.27  4721.0   963.0    50.0   226.0     0.989520     0.190076  0.0  0.179596  0.858145  0.809924  0.830034  0.169423  0.903109  0.830114  0.660229  0.728748  0.210909   0.169966  0.010480\n",
       " 28   P_BAD0     0    0.28  4721.0   963.0    50.0   226.0     0.989520     0.190076  0.0  0.179596  0.858145  0.809924  0.830034  0.169423  0.903109  0.830114  0.660229  0.728748  0.210909   0.169966  0.010480\n",
       " 29   P_BAD0     0    0.29  4721.0   963.0    50.0   226.0     0.989520     0.190076  0.0  0.179596  0.858145  0.809924  0.830034  0.169423  0.903109  0.830114  0.660229  0.728748  0.210909   0.169966  0.010480\n",
       " 30   P_BAD0     0    0.30  4721.0   963.0    50.0   226.0     0.989520     0.190076  0.0  0.179596  0.858145  0.809924  0.830034  0.169423  0.903109  0.830114  0.660229  0.728748  0.210909   0.169966  0.010480\n",
       " 31   P_BAD0     0    0.31  4721.0   963.0    50.0   226.0     0.989520     0.190076  0.0  0.179596  0.858145  0.809924  0.830034  0.169423  0.903109  0.830114  0.660229  0.728748  0.210909   0.169966  0.010480\n",
       " 32   P_BAD0     0    0.32  4721.0   963.0    50.0   226.0     0.989520     0.190076  0.0  0.179596  0.858145  0.809924  0.830034  0.169423  0.903109  0.830114  0.660229  0.728748  0.210909   0.169966  0.010480\n",
       " 33   P_BAD0     0    0.33  4721.0   963.0    50.0   226.0     0.989520     0.190076  0.0  0.179596  0.858145  0.809924  0.830034  0.169423  0.903109  0.830114  0.660229  0.728748  0.210909   0.169966  0.010480\n",
       " 34   P_BAD0     0    0.34  4721.0   963.0    50.0   226.0     0.989520     0.190076  0.0  0.179596  0.858145  0.809924  0.830034  0.169423  0.903109  0.830114  0.660229  0.728748  0.210909   0.169966  0.010480\n",
       " 35   P_BAD0     0    0.35  4721.0   963.0    50.0   226.0     0.989520     0.190076  0.0  0.179596  0.858145  0.809924  0.830034  0.169423  0.903109  0.830114  0.660229  0.728748  0.210909   0.169966  0.010480\n",
       " 36   P_BAD0     0    0.36  4721.0   963.0    50.0   226.0     0.989520     0.190076  0.0  0.179596  0.858145  0.809924  0.830034  0.169423  0.903109  0.830114  0.660229  0.728748  0.210909   0.169966  0.010480\n",
       " 37   P_BAD0     0    0.37  4626.0   795.0   145.0   394.0     0.969608     0.331371  0.0  0.300979  0.874315  0.668629  0.842282  0.146652  0.907771  0.830114  0.660229  0.728748  0.210909   0.157718  0.030392\n",
       " 38   P_BAD0     0    0.38  4626.0   795.0   145.0   394.0     0.969608     0.331371  0.0  0.300979  0.874315  0.668629  0.842282  0.146652  0.907771  0.830114  0.660229  0.728748  0.210909   0.157718  0.030392\n",
       " 39   P_BAD0     0    0.39  4626.0   795.0   145.0   394.0     0.969608     0.331371  0.0  0.300979  0.874315  0.668629  0.842282  0.146652  0.907771  0.830114  0.660229  0.728748  0.210909   0.157718  0.030392\n",
       " 40   P_BAD0     0    0.40  4609.0   769.0   162.0   420.0     0.966045     0.353238  0.0  0.319283  0.876802  0.646762  0.843792  0.142990  0.908267  0.830114  0.660229  0.728748  0.210909   0.156208  0.033955\n",
       " 41   P_BAD0     0    0.41  4609.0   769.0   162.0   420.0     0.966045     0.353238  0.0  0.319283  0.876802  0.646762  0.843792  0.142990  0.908267  0.830114  0.660229  0.728748  0.210909   0.156208  0.033955\n",
       " 42   P_BAD0     0    0.42  4609.0   769.0   162.0   420.0     0.966045     0.353238  0.0  0.319283  0.876802  0.646762  0.843792  0.142990  0.908267  0.830114  0.660229  0.728748  0.210909   0.156208  0.033955\n",
       " 43   P_BAD0     0    0.43  4609.0   769.0   162.0   420.0     0.966045     0.353238  0.0  0.319283  0.876802  0.646762  0.843792  0.142990  0.908267  0.830114  0.660229  0.728748  0.210909   0.156208  0.033955\n",
       " 44   P_BAD0     0    0.44  4609.0   769.0   162.0   420.0     0.966045     0.353238  0.0  0.319283  0.876802  0.646762  0.843792  0.142990  0.908267  0.830114  0.660229  0.728748  0.210909   0.156208  0.033955\n",
       " 45   P_BAD0     0    0.45  4609.0   769.0   162.0   420.0     0.966045     0.353238  0.0  0.319283  0.876802  0.646762  0.843792  0.142990  0.908267  0.830114  0.660229  0.728748  0.210909   0.156208  0.033955\n",
       " 46   P_BAD0     0    0.46  4599.0   757.0   172.0   432.0     0.963949     0.363331  0.0  0.327279  0.877839  0.636669  0.844128  0.141337  0.908265  0.830114  0.660229  0.728748  0.210909   0.155872  0.036051\n",
       " 47   P_BAD0     0    0.47  4599.0   757.0   172.0   432.0     0.963949     0.363331  0.0  0.327279  0.877839  0.636669  0.844128  0.141337  0.908265  0.830114  0.660229  0.728748  0.210909   0.155872  0.036051\n",
       " 48   P_BAD0     0    0.48  4599.0   757.0   172.0   432.0     0.963949     0.363331  0.0  0.327279  0.877839  0.636669  0.844128  0.141337  0.908265  0.830114  0.660229  0.728748  0.210909   0.155872  0.036051\n",
       " 49   P_BAD0     0    0.49  4599.0   757.0   172.0   432.0     0.963949     0.363331  0.0  0.327279  0.877839  0.636669  0.844128  0.141337  0.908265  0.830114  0.660229  0.728748  0.210909   0.155872  0.036051\n",
       " 50   P_BAD0     0    0.50  4599.0   757.0   172.0   432.0     0.963949     0.363331  0.0  0.327279  0.877839  0.636669  0.844128  0.141337  0.908265  0.830114  0.660229  0.728748  0.210909   0.155872  0.036051\n",
       " 51   P_BAD0     0    0.51  4599.0   757.0   172.0   432.0     0.963949     0.363331  0.0  0.327279  0.877839  0.636669  0.844128  0.141337  0.908265  0.830114  0.660229  0.728748  0.210909   0.155872  0.036051\n",
       " 52   P_BAD0     0    0.52  4599.0   757.0   172.0   432.0     0.963949     0.363331  0.0  0.327279  0.877839  0.636669  0.844128  0.141337  0.908265  0.830114  0.660229  0.728748  0.210909   0.155872  0.036051\n",
       " 53   P_BAD0     0    0.53  4599.0   757.0   172.0   432.0     0.963949     0.363331  0.0  0.327279  0.877839  0.636669  0.844128  0.141337  0.908265  0.830114  0.660229  0.728748  0.210909   0.155872  0.036051\n",
       " 54   P_BAD0     0    0.54  4599.0   757.0   172.0   432.0     0.963949     0.363331  0.0  0.327279  0.877839  0.636669  0.844128  0.141337  0.908265  0.830114  0.660229  0.728748  0.210909   0.155872  0.036051\n",
       " 55   P_BAD0     0    0.55  4599.0   757.0   172.0   432.0     0.963949     0.363331  0.0  0.327279  0.877839  0.636669  0.844128  0.141337  0.908265  0.830114  0.660229  0.728748  0.210909   0.155872  0.036051\n",
       " 56   P_BAD0     0    0.56  4599.0   757.0   172.0   432.0     0.963949     0.363331  0.0  0.327279  0.877839  0.636669  0.844128  0.141337  0.908265  0.830114  0.660229  0.728748  0.210909   0.155872  0.036051\n",
       " 57   P_BAD0     0    0.57  4599.0   757.0   172.0   432.0     0.963949     0.363331  0.0  0.327279  0.877839  0.636669  0.844128  0.141337  0.908265  0.830114  0.660229  0.728748  0.210909   0.155872  0.036051\n",
       " 58   P_BAD0     0    0.58  4599.0   757.0   172.0   432.0     0.963949     0.363331  0.0  0.327279  0.877839  0.636669  0.844128  0.141337  0.908265  0.830114  0.660229  0.728748  0.210909   0.155872  0.036051\n",
       " 59   P_BAD0     0    0.59  4599.0   757.0   172.0   432.0     0.963949     0.363331  0.0  0.327279  0.877839  0.636669  0.844128  0.141337  0.908265  0.830114  0.660229  0.728748  0.210909   0.155872  0.036051\n",
       " 60   P_BAD0     0    0.60  4599.0   757.0   172.0   432.0     0.963949     0.363331  0.0  0.327279  0.877839  0.636669  0.844128  0.141337  0.908265  0.830114  0.660229  0.728748  0.210909   0.155872  0.036051\n",
       " 61   P_BAD0     0    0.61  4599.0   757.0   172.0   432.0     0.963949     0.363331  0.0  0.327279  0.877839  0.636669  0.844128  0.141337  0.908265  0.830114  0.660229  0.728748  0.210909   0.155872  0.036051\n",
       " 62   P_BAD0     0    0.62  4599.0   757.0   172.0   432.0     0.963949     0.363331  0.0  0.327279  0.877839  0.636669  0.844128  0.141337  0.908265  0.830114  0.660229  0.728748  0.210909   0.155872  0.036051\n",
       " 63   P_BAD0     0    0.63  4599.0   757.0   172.0   432.0     0.963949     0.363331  0.0  0.327279  0.877839  0.636669  0.844128  0.141337  0.908265  0.830114  0.660229  0.728748  0.210909   0.155872  0.036051\n",
       " 64   P_BAD0     0    0.64  4507.0   704.0   264.0   485.0     0.944666     0.407906  0.0  0.352571  0.879758  0.592094  0.837584  0.135099  0.903025  0.830114  0.660229  0.728748  0.210909   0.162416  0.055334\n",
       " 65   P_BAD0     0    0.65  4469.0   683.0   302.0   506.0     0.936701     0.425568  0.0  0.362269  0.880452  0.574432  0.834732  0.132570  0.900736  0.830114  0.660229  0.728748  0.210909   0.165268  0.063299\n",
       " 66   P_BAD0     0    0.66  4469.0   683.0   302.0   506.0     0.936701     0.425568  0.0  0.362269  0.880452  0.574432  0.834732  0.132570  0.900736  0.830114  0.660229  0.728748  0.210909   0.165268  0.063299\n",
       " 67   P_BAD0     0    0.67  3754.0   317.0  1017.0   872.0     0.786837     0.733389  0.0  0.520227  0.891475  0.266611  0.776174  0.077868  0.849129  0.830114  0.660229  0.728748  0.210909   0.223826  0.213163\n",
       " 68   P_BAD0     0    0.68  3754.0   317.0  1017.0   872.0     0.786837     0.733389  0.0  0.520227  0.891475  0.266611  0.776174  0.077868  0.849129  0.830114  0.660229  0.728748  0.210909   0.223826  0.213163\n",
       " 69   P_BAD0     0    0.69  3754.0   317.0  1017.0   872.0     0.786837     0.733389  0.0  0.520227  0.891475  0.266611  0.776174  0.077868  0.849129  0.830114  0.660229  0.728748  0.210909   0.223826  0.213163\n",
       " 70   P_BAD0     0    0.70  3754.0   317.0  1017.0   872.0     0.786837     0.733389  0.0  0.520227  0.891475  0.266611  0.776174  0.077868  0.849129  0.830114  0.660229  0.728748  0.210909   0.223826  0.213163\n",
       " 71   P_BAD0     0    0.71  3754.0   317.0  1017.0   872.0     0.786837     0.733389  0.0  0.520227  0.891475  0.266611  0.776174  0.077868  0.849129  0.830114  0.660229  0.728748  0.210909   0.223826  0.213163\n",
       " 72   P_BAD0     0    0.72  3754.0   317.0  1017.0   872.0     0.786837     0.733389  0.0  0.520227  0.891475  0.266611  0.776174  0.077868  0.849129  0.830114  0.660229  0.728748  0.210909   0.223826  0.213163\n",
       " 73   P_BAD0     0    0.73  3754.0   317.0  1017.0   872.0     0.786837     0.733389  0.0  0.520227  0.891475  0.266611  0.776174  0.077868  0.849129  0.830114  0.660229  0.728748  0.210909   0.223826  0.213163\n",
       " 74   P_BAD0     0    0.74  3754.0   317.0  1017.0   872.0     0.786837     0.733389  0.0  0.520227  0.891475  0.266611  0.776174  0.077868  0.849129  0.830114  0.660229  0.728748  0.210909   0.223826  0.213163\n",
       " 75   P_BAD0     0    0.75  3754.0   317.0  1017.0   872.0     0.786837     0.733389  0.0  0.520227  0.891475  0.266611  0.776174  0.077868  0.849129  0.830114  0.660229  0.728748  0.210909   0.223826  0.213163\n",
       " 76   P_BAD0     0    0.76  3754.0   317.0  1017.0   872.0     0.786837     0.733389  0.0  0.520227  0.891475  0.266611  0.776174  0.077868  0.849129  0.830114  0.660229  0.728748  0.210909   0.223826  0.213163\n",
       " 77   P_BAD0     0    0.77  3641.0   282.0  1130.0   907.0     0.763152     0.762826  0.0  0.525978  0.889654  0.237174  0.763087  0.071884  0.837589  0.830114  0.660229  0.728748  0.210909   0.236913  0.236848\n",
       " 78   P_BAD0     0    0.78  3259.0   173.0  1512.0  1016.0     0.683085     0.854500  1.0  0.537585  0.880858  0.145500  0.717282  0.050408  0.794587  0.830114  0.660229  0.728748  0.210909   0.282718  0.316915\n",
       " 79   P_BAD0     0    0.79  3259.0   173.0  1512.0  1016.0     0.683085     0.854500  0.0  0.537585  0.880858  0.145500  0.717282  0.050408  0.794587  0.830114  0.660229  0.728748  0.210909   0.282718  0.316915\n",
       " 80   P_BAD0     0    0.80  3259.0   173.0  1512.0  1016.0     0.683085     0.854500  0.0  0.537585  0.880858  0.145500  0.717282  0.050408  0.794587  0.830114  0.660229  0.728748  0.210909   0.282718  0.316915\n",
       " 81   P_BAD0     0    0.81  3259.0   173.0  1512.0  1016.0     0.683085     0.854500  0.0  0.537585  0.880858  0.145500  0.717282  0.050408  0.794587  0.830114  0.660229  0.728748  0.210909   0.282718  0.316915\n",
       " 82   P_BAD0     0    0.82  3259.0   173.0  1512.0  1016.0     0.683085     0.854500  0.0  0.537585  0.880858  0.145500  0.717282  0.050408  0.794587  0.830114  0.660229  0.728748  0.210909   0.282718  0.316915\n",
       " 83   P_BAD0     0    0.83  3259.0   173.0  1512.0  1016.0     0.683085     0.854500  0.0  0.537585  0.880858  0.145500  0.717282  0.050408  0.794587  0.830114  0.660229  0.728748  0.210909   0.282718  0.316915\n",
       " 84   P_BAD0     0    0.84  3259.0   173.0  1512.0  1016.0     0.683085     0.854500  0.0  0.537585  0.880858  0.145500  0.717282  0.050408  0.794587  0.830114  0.660229  0.728748  0.210909   0.282718  0.316915\n",
       " 85   P_BAD0     0    0.85  3259.0   173.0  1512.0  1016.0     0.683085     0.854500  0.0  0.537585  0.880858  0.145500  0.717282  0.050408  0.794587  0.830114  0.660229  0.728748  0.210909   0.282718  0.316915\n",
       " 86   P_BAD0     0    0.86  3259.0   173.0  1512.0  1016.0     0.683085     0.854500  0.0  0.537585  0.880858  0.145500  0.717282  0.050408  0.794587  0.830114  0.660229  0.728748  0.210909   0.282718  0.316915\n",
       " 87   P_BAD0     0    0.87  3259.0   173.0  1512.0  1016.0     0.683085     0.854500  0.0  0.537585  0.880858  0.145500  0.717282  0.050408  0.794587  0.830114  0.660229  0.728748  0.210909   0.282718  0.316915\n",
       " 88   P_BAD0     0    0.88  3259.0   173.0  1512.0  1016.0     0.683085     0.854500  0.0  0.537585  0.880858  0.145500  0.717282  0.050408  0.794587  0.830114  0.660229  0.728748  0.210909   0.282718  0.316915\n",
       " 89   P_BAD0     0    0.89  3063.0   148.0  1708.0  1041.0     0.642004     0.875526  0.0  0.517529  0.869429  0.124474  0.688591  0.046092  0.767477  0.830114  0.660229  0.728748  0.210909   0.311409  0.357996\n",
       " 90   P_BAD0     0    0.90  3063.0   148.0  1708.0  1041.0     0.642004     0.875526  0.0  0.517529  0.869429  0.124474  0.688591  0.046092  0.767477  0.830114  0.660229  0.728748  0.210909   0.311409  0.357996\n",
       " 91   P_BAD0     0    0.91  3063.0   148.0  1708.0  1041.0     0.642004     0.875526  0.0  0.517529  0.869429  0.124474  0.688591  0.046092  0.767477  0.830114  0.660229  0.728748  0.210909   0.311409  0.357996\n",
       " 92   P_BAD0     0    0.92  3063.0   148.0  1708.0  1041.0     0.642004     0.875526  0.0  0.517529  0.869429  0.124474  0.688591  0.046092  0.767477  0.830114  0.660229  0.728748  0.210909   0.311409  0.357996\n",
       " 93   P_BAD0     0    0.93  3063.0   148.0  1708.0  1041.0     0.642004     0.875526  0.0  0.517529  0.869429  0.124474  0.688591  0.046092  0.767477  0.830114  0.660229  0.728748  0.210909   0.311409  0.357996\n",
       " 94   P_BAD0     0    0.94  3063.0   148.0  1708.0  1041.0     0.642004     0.875526  0.0  0.517529  0.869429  0.124474  0.688591  0.046092  0.767477  0.830114  0.660229  0.728748  0.210909   0.311409  0.357996\n",
       " 95   P_BAD0     0    0.95  1524.0    61.0  3247.0  1128.0     0.319430     0.948696  0.0  0.268126  0.685807  0.051304  0.444966  0.038486  0.479547  0.830114  0.660229  0.728748  0.210909   0.555034  0.680570\n",
       " 96   P_BAD0     0    0.96   474.0    13.0  4297.0  1176.0     0.099350     0.989066  0.0  0.088417  0.352731  0.010934  0.276846  0.026694  0.180297  0.830114  0.660229  0.728748  0.210909   0.723154  0.900650\n",
       " 97   P_BAD0     0    0.97   192.0     3.0  4579.0  1186.0     0.040243     0.997477  0.0  0.037720  0.172942  0.002523  0.231208  0.015385  0.077326  0.830114  0.660229  0.728748  0.210909   0.768792  0.959757\n",
       " 98   P_BAD0     0    0.98   192.0     3.0  4579.0  1186.0     0.040243     0.997477  0.0  0.037720  0.172942  0.002523  0.231208  0.015385  0.077326  0.830114  0.660229  0.728748  0.210909   0.768792  0.959757\n",
       " 99   P_BAD0     0    0.99     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.830114  0.660229  0.728748  0.210909   0.800503  1.000000,\n",
       "  'ROCInfo_2_GradBoost': ROC Information for _AUTOTUNE_DEFAULT_SCORE_TABLE_\n",
       " \n",
       "    Variable Event  CutOff      TP      FP      FN      TN  Sensitivity  Specificity   KS       KS2    F_HALF       FPR       ACC       FDR        F1         C      Gini     Gamma       Tau  MISCEVENT       FNR\n",
       " 0    P_BAD0     0    0.00  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 1    P_BAD0     0    0.01  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 2    P_BAD0     0    0.02  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 3    P_BAD0     0    0.03  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 4    P_BAD0     0    0.04  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 5    P_BAD0     0    0.05  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 6    P_BAD0     0    0.06  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 7    P_BAD0     0    0.07  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 8    P_BAD0     0    0.08  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 9    P_BAD0     0    0.09  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 10   P_BAD0     0    0.10  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 11   P_BAD0     0    0.11  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 12   P_BAD0     0    0.12  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 13   P_BAD0     0    0.13  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 14   P_BAD0     0    0.14  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 15   P_BAD0     0    0.15  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 16   P_BAD0     0    0.16  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 17   P_BAD0     0    0.17  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 18   P_BAD0     0    0.18  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 19   P_BAD0     0    0.19  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 20   P_BAD0     0    0.20  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 21   P_BAD0     0    0.21  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 22   P_BAD0     0    0.22  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 23   P_BAD0     0    0.23  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 24   P_BAD0     0    0.24  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 25   P_BAD0     0    0.25  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 26   P_BAD0     0    0.26  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 27   P_BAD0     0    0.27  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 28   P_BAD0     0    0.28  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 29   P_BAD0     0    0.29  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 30   P_BAD0     0    0.30  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 31   P_BAD0     0    0.31  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 32   P_BAD0     0    0.32  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 33   P_BAD0     0    0.33  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 34   P_BAD0     0    0.34  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 35   P_BAD0     0    0.35  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 36   P_BAD0     0    0.36  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 37   P_BAD0     0    0.37  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 38   P_BAD0     0    0.38  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 39   P_BAD0     0    0.39  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 40   P_BAD0     0    0.40  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 41   P_BAD0     0    0.41  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 42   P_BAD0     0    0.42  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 43   P_BAD0     0    0.43  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 44   P_BAD0     0    0.44  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 45   P_BAD0     0    0.45  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 46   P_BAD0     0    0.46  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 47   P_BAD0     0    0.47  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 48   P_BAD0     0    0.48  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 49   P_BAD0     0    0.49  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 50   P_BAD0     0    0.50  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 51   P_BAD0     0    0.51  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 52   P_BAD0     0    0.52  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 53   P_BAD0     0    0.53  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 54   P_BAD0     0    0.54  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 55   P_BAD0     0    0.55  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 56   P_BAD0     0    0.56  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 57   P_BAD0     0    0.57  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 58   P_BAD0     0    0.58  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 59   P_BAD0     0    0.59  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 60   P_BAD0     0    0.60  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 61   P_BAD0     0    0.61  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 62   P_BAD0     0    0.62  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 63   P_BAD0     0    0.63  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 64   P_BAD0     0    0.64  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 65   P_BAD0     0    0.65  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 66   P_BAD0     0    0.66  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 67   P_BAD0     0    0.67  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 68   P_BAD0     0    0.68  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 69   P_BAD0     0    0.69  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 70   P_BAD0     0    0.70  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 71   P_BAD0     0    0.71  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 72   P_BAD0     0    0.72  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 73   P_BAD0     0    0.73  4771.0  1189.0     0.0     0.0     1.000000     0.000000  0.0  0.000000  0.833770  1.000000  0.800503  0.199497  0.889200  0.819014  0.638027  0.777591  0.203817   0.199497  0.000000\n",
       " 74   P_BAD0     0    0.74  4721.0   964.0    50.0   225.0     0.989520     0.189235  0.0  0.178755  0.858020  0.810765  0.829866  0.169569  0.903022  0.819014  0.638027  0.777591  0.203817   0.170134  0.010480\n",
       " 75   P_BAD0     0    0.75  4721.0   964.0    50.0   225.0     0.989520     0.189235  0.0  0.178755  0.858020  0.810765  0.829866  0.169569  0.903022  0.819014  0.638027  0.777591  0.203817   0.170134  0.010480\n",
       " 76   P_BAD0     0    0.76  4626.0   796.0   145.0   393.0     0.969608     0.330530  0.0  0.300138  0.874183  0.669470  0.842114  0.146809  0.907682  0.819014  0.638027  0.777591  0.203817   0.157886  0.030392\n",
       " 77   P_BAD0     0    0.77  4599.0   758.0   172.0   431.0     0.963949     0.362489  0.0  0.326438  0.877705  0.637511  0.843960  0.141497  0.908175  0.819014  0.638027  0.777591  0.203817   0.156040  0.036051\n",
       " 78   P_BAD0     0    0.78  4599.0   758.0   172.0   431.0     0.963949     0.362489  0.0  0.326438  0.877705  0.637511  0.843960  0.141497  0.908175  0.819014  0.638027  0.777591  0.203817   0.156040  0.036051\n",
       " 79   P_BAD0     0    0.79  3792.0   338.0   979.0   851.0     0.794802     0.715728  0.0  0.510529  0.890517  0.284272  0.779027  0.081840  0.852039  0.819014  0.638027  0.777591  0.203817   0.220973  0.205198\n",
       " 80   P_BAD0     0    0.80  3342.0   198.0  1429.0   991.0     0.700482     0.833474  0.0  0.533956  0.882679  0.166526  0.727013  0.055932  0.804235  0.819014  0.638027  0.777591  0.203817   0.272987  0.299518\n",
       " 81   P_BAD0     0    0.81  3278.0   179.0  1493.0  1010.0     0.687068     0.849453  1.0  0.536521  0.881230  0.150547  0.719463  0.051779  0.796791  0.819014  0.638027  0.777591  0.203817   0.280537  0.312932\n",
       " 82   P_BAD0     0    0.82     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.819014  0.638027  0.777591  0.203817   0.800503  1.000000\n",
       " 83   P_BAD0     0    0.83     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.819014  0.638027  0.777591  0.203817   0.800503  1.000000\n",
       " 84   P_BAD0     0    0.84     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.819014  0.638027  0.777591  0.203817   0.800503  1.000000\n",
       " 85   P_BAD0     0    0.85     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.819014  0.638027  0.777591  0.203817   0.800503  1.000000\n",
       " 86   P_BAD0     0    0.86     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.819014  0.638027  0.777591  0.203817   0.800503  1.000000\n",
       " 87   P_BAD0     0    0.87     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.819014  0.638027  0.777591  0.203817   0.800503  1.000000\n",
       " 88   P_BAD0     0    0.88     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.819014  0.638027  0.777591  0.203817   0.800503  1.000000\n",
       " 89   P_BAD0     0    0.89     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.819014  0.638027  0.777591  0.203817   0.800503  1.000000\n",
       " 90   P_BAD0     0    0.90     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.819014  0.638027  0.777591  0.203817   0.800503  1.000000\n",
       " 91   P_BAD0     0    0.91     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.819014  0.638027  0.777591  0.203817   0.800503  1.000000\n",
       " 92   P_BAD0     0    0.92     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.819014  0.638027  0.777591  0.203817   0.800503  1.000000\n",
       " 93   P_BAD0     0    0.93     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.819014  0.638027  0.777591  0.203817   0.800503  1.000000\n",
       " 94   P_BAD0     0    0.94     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.819014  0.638027  0.777591  0.203817   0.800503  1.000000\n",
       " 95   P_BAD0     0    0.95     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.819014  0.638027  0.777591  0.203817   0.800503  1.000000\n",
       " 96   P_BAD0     0    0.96     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.819014  0.638027  0.777591  0.203817   0.800503  1.000000\n",
       " 97   P_BAD0     0    0.97     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.819014  0.638027  0.777591  0.203817   0.800503  1.000000\n",
       " 98   P_BAD0     0    0.98     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.819014  0.638027  0.777591  0.203817   0.800503  1.000000\n",
       " 99   P_BAD0     0    0.99     0.0     0.0  4771.0  1189.0     0.000000     1.000000  0.0  0.000000  0.000000  0.000000  0.199497       NaN  0.000000  0.819014  0.638027  0.777591  0.203817   0.800503  1.000000,\n",
       "  'ScoreInfo_1_DecisionTree':                          Descr                             Value\n",
       " 0  Number of Observations Read                              5960\n",
       " 1  Number of Observations Used                              5960\n",
       " 2  Misclassification Error (%)                      15.587248322,\n",
       "  'ScoreInfo_2_GradBoost':                          Descr                             Value\n",
       " 0  Number of Observations Read                              5960\n",
       " 1  Number of Observations Used                              5960\n",
       " 2  Misclassification Error (%)                       19.94966443,\n",
       "  'TuneAllBestModels': TuneAll Best Models\n",
       " \n",
       "           ModelID  Evaluation  MeanConseqError  EvaluationTime\n",
       " 0  1_DecisionTree           6         0.154696        0.470920\n",
       " 1  1_DecisionTree           1         0.156877        0.311942\n",
       " 2  1_DecisionTree           0         0.156877        0.341418\n",
       " 3  1_DecisionTree           3         0.156877        0.472439\n",
       " 4  1_DecisionTree           4         0.156877        0.927789\n",
       " 5  1_DecisionTree           5         0.157213        0.634979\n",
       " 6  1_DecisionTree           2         0.157689        0.472432\n",
       " 7     2_GradBoost           3         0.199295        1.205958\n",
       " 8     2_GradBoost          15         0.199396        2.912694\n",
       " 9     2_GradBoost           9         0.199463        3.570540,\n",
       "  'TuneAllCasOutputTables': TuneAll CAS Output Tables\n",
       " \n",
       " Empty SASDataFrame\n",
       " Columns: [ModelID, CAS_Library, Name, Rows, Columns]\n",
       " Index: [],\n",
       "  'TuneAllResultsSummary': TuneAll Results Summary\n",
       " \n",
       "           ModelID               ModelType  Evaluations  BestObjective  AverageObjective  StdDevObjective  BestObjTime  AverageTime  StdDevTime\n",
       " 0  1_DecisionTree           Decision Tree            6       0.154696          0.156705         0.001035     0.470920     0.548417    0.212080\n",
       " 1     2_GradBoost  Gradient Boosting Tree           16       0.199295          0.209333         0.013088     1.205958     3.248781    0.802765,\n",
       "  'TunerInfo_1_DecisionTree': Tuner Information\n",
       " \n",
       "                            Parameter              Value\n",
       " 0                         Model Type      Decision Tree\n",
       " 1           Tuner Objective Function  Misclassification\n",
       " 2                      Search Method               GRID\n",
       " 3              Number of Grid Points                  6\n",
       " 4     Maximum Tuning Time in Seconds              36000\n",
       " 5                    Validation Type   Cross-Validation\n",
       " 6      Num Folds in Cross-Validation                  5\n",
       " 7                          Log Level                  0\n",
       " 8                               Seed         1876916290\n",
       " 9     Number of Parallel Evaluations                  4\n",
       " 10  Number of Workers per Subsession                  0,\n",
       "  'TunerInfo_2_GradBoost': Tuner Information\n",
       " \n",
       "                            Parameter                   Value\n",
       " 0                         Model Type  Gradient Boosting Tree\n",
       " 1           Tuner Objective Function       Misclassification\n",
       " 2                      Search Method                    GRID\n",
       " 3              Number of Grid Points                      16\n",
       " 4     Maximum Tuning Time in Seconds                   36000\n",
       " 5                    Validation Type        Cross-Validation\n",
       " 6      Num Folds in Cross-Validation                       5\n",
       " 7                          Log Level                       0\n",
       " 8                               Seed              1876916155\n",
       " 9     Number of Parallel Evaluations                       4\n",
       " 10  Number of Workers per Subsession                       0,\n",
       "  'TunerResults_1_DecisionTree': Tuner Results\n",
       " \n",
       "    Evaluation  MAXLEVEL       CRIT  MeanConseqError  EvaluationTime\n",
       " 0           0        11  gainRatio         0.156877        0.341418\n",
       " 1           6        15       gain         0.154696        0.470920\n",
       " 2           1         5       gain         0.156877        0.311942\n",
       " 3           3         5  gainRatio         0.156877        0.472439\n",
       " 4           4        10  gainRatio         0.156877        0.927789\n",
       " 5           5        15  gainRatio         0.157213        0.634979\n",
       " 6           2        10       gain         0.157689        0.472432,\n",
       "  'TunerResults_2_GradBoost': Tuner Results\n",
       " \n",
       "     Evaluation  M  LEARNINGRATE  SUBSAMPLERATE  LASSO  RIDGE  MAXLEVEL  MeanConseqError  EvaluationTime\n",
       " 0            0  3          0.10            0.5    0.0    1.0         5         0.199497        0.632475\n",
       " 1            3  3          0.10            0.6    0.5    0.0         5         0.199295        1.205958\n",
       " 2           15  3          0.05            0.6    0.0    0.0         7         0.199396        2.912694\n",
       " 3            9  3          0.10            0.8    0.0    0.0         5         0.199463        3.570540\n",
       " 4            2  3          0.05            0.8    0.0    0.0         7         0.199497        2.310202\n",
       " 5            4  3          0.10            0.8    0.5    0.0         7         0.199497        3.389764\n",
       " 6           11  3          0.05            0.6    0.0    0.0         5         0.199497        3.021106\n",
       " 7           13  3          0.05            0.6    0.5    0.0         7         0.199497        4.320703\n",
       " 8           14  3          0.05            0.8    0.5    0.0         5         0.199497        3.079410\n",
       " 9           10  3          0.10            0.6    0.0    0.0         5         0.199530        3.303823\n",
       " 10           8  3          0.05            0.8    0.5    0.0         7         0.199597        3.797840,\n",
       "  'TunerSummary_1_DecisionTree': Tuner Summary\n",
       " \n",
       "                                           Parameter     Value\n",
       " 0             Initial Configuration Objective Value  0.156877\n",
       " 1                Best Configuration Objective Value  0.154696\n",
       " 2               Worst Configuration Objective Value  0.157689\n",
       " 3  Initial Configuration Evaluation Time in Seconds  0.341418\n",
       " 4     Best Configuration Evaluation Time in Seconds  0.470913\n",
       " 5                 Number of Improved Configurations  1.000000\n",
       " 6                Number of Evaluated Configurations  7.000000\n",
       " 7                      Total Tuning Time in Seconds  1.334475\n",
       " 8                           Parallel Tuning Speedup  2.160148,\n",
       "  'TunerSummary_2_GradBoost': Tuner Summary\n",
       " \n",
       "                                           Parameter      Value\n",
       " 0             Initial Configuration Objective Value   0.199497\n",
       " 1                Best Configuration Objective Value   0.199295\n",
       " 2               Worst Configuration Objective Value   0.199664\n",
       " 3  Initial Configuration Evaluation Time in Seconds   0.632475\n",
       " 4     Best Configuration Evaluation Time in Seconds   1.060541\n",
       " 5                 Number of Improved Configurations   1.000000\n",
       " 6                Number of Evaluated Configurations  17.000000\n",
       " 7                      Total Tuning Time in Seconds  13.954578\n",
       " 8                           Parallel Tuning Speedup   3.732452,\n",
       "  'TunerTiming_1_DecisionTree': Tuner Task Timing\n",
       " \n",
       "                           Task  Time_sec  Time_percent\n",
       " 0               Model Training  1.218875     42.282950\n",
       " 1                Model Scoring  0.844904     29.309853\n",
       " 2  Total Objective Evaluations  2.228993     77.324077\n",
       " 3                        Tuner  0.653671     22.675923\n",
       " 4               Total CPU Time  2.882663    100.000000,\n",
       "  'TunerTiming_2_GradBoost': Tuner Task Timing\n",
       " \n",
       "                           Task   Time_sec  Time_percent\n",
       " 0               Model Training  46.442489     89.167079\n",
       " 1                Model Scoring   4.103261      7.878041\n",
       " 2  Total Objective Evaluations  51.058608     98.029780\n",
       " 3                        Tuner   1.026185      1.970220\n",
       " 4               Total CPU Time  52.084793    100.000000}\n",
       "\n",
       "+ Elapsed: 100s, user: 1.56s, sys: 0.369s, mem: 0.813mb"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.dataSciencePilot.dsAutoMl(\n",
    "    table = Home_Equity,\n",
    "    target = target, \n",
    "    explorationPolicy = expo, \n",
    "    screenPolicy = scpo, \n",
    "    selectionPolicy = sepo,\n",
    "    transformationPolicy = trpo,\n",
    "     modelTypes              = [\"decisionTree\",\"gradBoost\"],\n",
    "        objective               = \"ASE\",\n",
    "        sampleSize              = 10,\n",
    "        topKPipelines           = 10,\n",
    "        kFolds                  = 5,\n",
    "        transformationOut       = {\"name\" : \"TRANSFORMATION_OUT_PY\", \"replace\" : True},\n",
    "        featureOut              = {\"name\" : \"FEATURE_OUT_PY\", \"replace\" : True},\n",
    "        pipelineOut             = {\"name\" : \"PIPELINE_OUT_PY\", \"replace\" : True},\n",
    "        saveState               = {\"name\" : \"ASTORE_OUT_PY\", \"replace\" : True} \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"cas-results-key\"><b>&#167; Fetch</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><caption>Selected Rows from Table TRANSFORMATION_OUT_PY</caption>\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"FTGPipelineId\">FTGPipelineId</th>\n",
       "      <th title=\"Name\">Name</th>\n",
       "      <th title=\"NVariables\">NVariables</th>\n",
       "      <th title=\"IsInteraction\">IsInteraction</th>\n",
       "      <th title=\"ImputeMethod\">ImputeMethod</th>\n",
       "      <th title=\"OutlierMethod\">OutlierMethod</th>\n",
       "      <th title=\"OutlierTreat\">OutlierTreat</th>\n",
       "      <th title=\"OutlierArgs\">OutlierArgs</th>\n",
       "      <th title=\"FunctionMethod\">FunctionMethod</th>\n",
       "      <th title=\"FunctionArgs\">FunctionArgs</th>\n",
       "      <th title=\"MapIntervalArgs\">MapIntervalArgs</th>\n",
       "      <th title=\"HashMethod\">HashMethod</th>\n",
       "      <th title=\"HashArgs\">HashArgs</th>\n",
       "      <th title=\"DateTimeMethod\">DateTimeMethod</th>\n",
       "      <th title=\"DiscretizeMethod\">DiscretizeMethod</th>\n",
       "      <th title=\"DiscretizeArgs\">DiscretizeArgs</th>\n",
       "      <th title=\"CatTransMethod\">CatTransMethod</th>\n",
       "      <th title=\"CatTransArgs\">CatTransArgs</th>\n",
       "      <th title=\"InteractionMethod\">InteractionMethod</th>\n",
       "      <th title=\"InteractionSynthesizer\">InteractionSynthesizer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>grp_rare2</td>\n",
       "      <td>2.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>Group Rare</td>\n",
       "      <td>5.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ho_winsor</td>\n",
       "      <td>2.0</td>\n",
       "      <td></td>\n",
       "      <td>Median</td>\n",
       "      <td>Modified IQR</td>\n",
       "      <td>Winsor</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>ho_quan_disct5</td>\n",
       "      <td>2.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Modified IQR</td>\n",
       "      <td>Trim</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>Equal-Freq (Quantile)</td>\n",
       "      <td>5.0</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>ho_quan_disct10</td>\n",
       "      <td>2.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Modified IQR</td>\n",
       "      <td>Trim</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>Equal-Freq (Quantile)</td>\n",
       "      <td>10.0</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>ho_dtree_disct5</td>\n",
       "      <td>2.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>DTree</td>\n",
       "      <td>5.0</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>ho_dtree_disct10</td>\n",
       "      <td>2.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>DTree</td>\n",
       "      <td>10.0</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>7.0</td>\n",
       "      <td>cpy_int_med_imp</td>\n",
       "      <td>2.0</td>\n",
       "      <td></td>\n",
       "      <td>Median</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-output-area\"></div>\n",
       "<p class=\"cas-results-performance\"><small><span class=\"cas-elapsed\">elapsed 0.00107s</span> &#183; <span class=\"cas-user\">user 0.00044s</span> &#183; <span class=\"cas-sys\">sys 0.000613s</span> &#183; <span class=\"cas-memory\">mem 0.926MB</span></small></p>"
      ],
      "text/plain": [
       "[Fetch]\n",
       "\n",
       " Selected Rows from Table TRANSFORMATION_OUT_PY\n",
       " \n",
       "    FTGPipelineId              Name  NVariables IsInteraction ImputeMethod OutlierMethod OutlierTreat  OutlierArgs FunctionMethod FunctionArgs MapIntervalMethod  MapIntervalArgs HashMethod  HashArgs DateTimeMethod       DiscretizeMethod  DiscretizeArgs CatTransMethod  CatTransArgs InteractionMethod InteractionSynthesizer\n",
       " 0            1.0         grp_rare2         2.0                                                                NaN                                                            NaN                  NaN                                                   NaN     Group Rare           5.0                                         \n",
       " 1            2.0         ho_winsor         2.0                     Median  Modified IQR       Winsor          0.0                                                            NaN                  NaN                                                   NaN                          NaN                                         \n",
       " 2            3.0    ho_quan_disct5         2.0                             Modified IQR         Trim          0.0                                                            NaN                  NaN                 Equal-Freq (Quantile)             5.0                          NaN                                         \n",
       " 3            4.0   ho_quan_disct10         2.0                             Modified IQR         Trim          0.0                                                            NaN                  NaN                 Equal-Freq (Quantile)            10.0                          NaN                                         \n",
       " 4            5.0   ho_dtree_disct5         2.0                                                                NaN                                                            NaN                  NaN                                 DTree             5.0                          NaN                                         \n",
       " 5            6.0  ho_dtree_disct10         2.0                                                                NaN                                                            NaN                  NaN                                 DTree            10.0                          NaN                                         \n",
       " 6            7.0   cpy_int_med_imp         2.0                     Median                                     NaN                                                            NaN                  NaN                                                   NaN                          NaN                                         \n",
       "\n",
       "+ Elapsed: 0.00107s, user: 0.00044s, sys: 0.000613s, mem: 0.926mb"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.fetch(table = {'name': 'TRANSFORMATION_OUT_PY'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"cas-results-key\"><b>&#167; Fetch</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><caption>Selected Rows from Table FEATURE_OUT_PY</caption>\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"FeatureId\">FeatureId</th>\n",
       "      <th title=\"Name\">Name</th>\n",
       "      <th title=\"IsNominal\">IsNominal</th>\n",
       "      <th title=\"FTGPipelineId\">FTGPipelineId</th>\n",
       "      <th title=\"NInputs\">NInputs</th>\n",
       "      <th title=\"InputVar1\">InputVar1</th>\n",
       "      <th title=\"InputVar2\">InputVar2</th>\n",
       "      <th title=\"InputVar3\">InputVar3</th>\n",
       "      <th title=\"Label\">Label</th>\n",
       "      <th title=\"RankCrit\">RankCrit</th>\n",
       "      <th title=\"BestTransRank\">BestTransRank</th>\n",
       "      <th title=\"GlobalIntervalRank\">GlobalIntervalRank</th>\n",
       "      <th title=\"GlobalNominalRank\">GlobalNominalRank</th>\n",
       "      <th title=\"GlobalRank\">GlobalRank</th>\n",
       "      <th title=\"IsGenerated\">IsGenerated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cpy_int_med_imp_IMP_DEBTINC</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>IMP_DEBTINC</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>IMP_DEBTINC: Low missing rate - median imputation</td>\n",
       "      <td>0.086698</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ho_dtree_disct10_IMP_DEBTINC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>IMP_DEBTINC</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>IMP_DEBTINC: High outlier - ten bin decision t...</td>\n",
       "      <td>0.074616</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>ho_dtree_disct5_IMP_DEBTINC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>IMP_DEBTINC</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>IMP_DEBTINC: High outlier - five bin decision ...</td>\n",
       "      <td>0.099038</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>ho_quan_disct10_IMP_DEBTINC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>IMP_DEBTINC</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>IMP_DEBTINC: High outlier - robust IQR + ten b...</td>\n",
       "      <td>0.085006</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>ho_quan_disct5_IMP_DEBTINC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>IMP_DEBTINC</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>IMP_DEBTINC: High outlier - robust IQR + five ...</td>\n",
       "      <td>0.095312</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>ho_winsor_IMP_DEBTINC</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>IMP_DEBTINC</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>IMP_DEBTINC: High outlier - winsorize</td>\n",
       "      <td>0.081042</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>7.0</td>\n",
       "      <td>cpy_int_med_imp_IMP_DELINQ</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>IMP_DELINQ</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>IMP_DELINQ: Low missing rate - median imputation</td>\n",
       "      <td>0.068430</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>ho_dtree_disct10_IMP_DELINQ</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>IMP_DELINQ</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>IMP_DELINQ: High outlier - ten bin decision tr...</td>\n",
       "      <td>0.065238</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>9.0</td>\n",
       "      <td>ho_dtree_disct5_IMP_DELINQ</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>IMP_DELINQ</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>IMP_DELINQ: High outlier - five bin decision t...</td>\n",
       "      <td>0.065238</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>10.0</td>\n",
       "      <td>ho_quan_disct10_IMP_DELINQ</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>IMP_DELINQ</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>IMP_DELINQ: High outlier - robust IQR + ten bi...</td>\n",
       "      <td>0.082688</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>11.0</td>\n",
       "      <td>ho_quan_disct5_IMP_DELINQ</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>IMP_DELINQ</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>IMP_DELINQ: High outlier - robust IQR + five b...</td>\n",
       "      <td>0.082688</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>12.0</td>\n",
       "      <td>ho_winsor_IMP_DELINQ</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>IMP_DELINQ</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>IMP_DELINQ: High outlier - winsorize</td>\n",
       "      <td>0.068430</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>13.0</td>\n",
       "      <td>grp_rare2_DELINQ</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>DELINQ</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>DELINQ: Very low entropy - group rare</td>\n",
       "      <td>0.065238</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>14.0</td>\n",
       "      <td>grp_rare2_DEROG</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>DEROG</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>DEROG: Very low entropy - group rare</td>\n",
       "      <td>0.047825</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-output-area\"></div>\n",
       "<p class=\"cas-results-performance\"><small><span class=\"cas-elapsed\">elapsed 0.001s</span> &#183; <span class=\"cas-user\">user 0.00041s</span> &#183; <span class=\"cas-sys\">sys 0.000573s</span> &#183; <span class=\"cas-memory\">mem 0.93MB</span></small></p>"
      ],
      "text/plain": [
       "[Fetch]\n",
       "\n",
       " Selected Rows from Table FEATURE_OUT_PY\n",
       " \n",
       "     FeatureId                          Name  IsNominal  FTGPipelineId  NInputs    InputVar1 InputVar2 InputVar3                                              Label  RankCrit  BestTransRank  GlobalIntervalRank  GlobalNominalRank  GlobalRank  IsGenerated\n",
       " 0         1.0   cpy_int_med_imp_IMP_DEBTINC        0.0            7.0      1.0  IMP_DEBTINC                      IMP_DEBTINC: Low missing rate - median imputation  0.086698            1.0                 1.0                NaN         3.0          1.0\n",
       " 1         2.0  ho_dtree_disct10_IMP_DEBTINC        1.0            6.0      1.0  IMP_DEBTINC                      IMP_DEBTINC: High outlier - ten bin decision t...  0.074616            4.0                 NaN                6.0         8.0          0.0\n",
       " 2         3.0   ho_dtree_disct5_IMP_DEBTINC        1.0            5.0      1.0  IMP_DEBTINC                      IMP_DEBTINC: High outlier - five bin decision ...  0.099038            1.0                 NaN                1.0         1.0          1.0\n",
       " 3         4.0   ho_quan_disct10_IMP_DEBTINC        1.0            4.0      1.0  IMP_DEBTINC                      IMP_DEBTINC: High outlier - robust IQR + ten b...  0.085006            3.0                 NaN                3.0         4.0          0.0\n",
       " 4         5.0    ho_quan_disct5_IMP_DEBTINC        1.0            3.0      1.0  IMP_DEBTINC                      IMP_DEBTINC: High outlier - robust IQR + five ...  0.095312            2.0                 NaN                2.0         2.0          1.0\n",
       " 5         6.0         ho_winsor_IMP_DEBTINC        0.0            2.0      1.0  IMP_DEBTINC                                  IMP_DEBTINC: High outlier - winsorize  0.081042            2.0                 2.0                NaN         7.0          1.0\n",
       " 6         7.0    cpy_int_med_imp_IMP_DELINQ        0.0            7.0      1.0   IMP_DELINQ                       IMP_DELINQ: Low missing rate - median imputation  0.068430            1.0                 3.0                NaN         9.0          1.0\n",
       " 7         8.0   ho_dtree_disct10_IMP_DELINQ        1.0            6.0      1.0   IMP_DELINQ                      IMP_DELINQ: High outlier - ten bin decision tr...  0.065238            3.0                 NaN                7.0        11.0          0.0\n",
       " 8         9.0    ho_dtree_disct5_IMP_DELINQ        1.0            5.0      1.0   IMP_DELINQ                      IMP_DELINQ: High outlier - five bin decision t...  0.065238            3.0                 NaN                7.0        11.0          0.0\n",
       " 9        10.0    ho_quan_disct10_IMP_DELINQ        1.0            4.0      1.0   IMP_DELINQ                      IMP_DELINQ: High outlier - robust IQR + ten bi...  0.082688            1.0                 NaN                4.0         5.0          1.0\n",
       " 10       11.0     ho_quan_disct5_IMP_DELINQ        1.0            3.0      1.0   IMP_DELINQ                      IMP_DELINQ: High outlier - robust IQR + five b...  0.082688            1.0                 NaN                4.0         5.0          1.0\n",
       " 11       12.0          ho_winsor_IMP_DELINQ        0.0            2.0      1.0   IMP_DELINQ                                   IMP_DELINQ: High outlier - winsorize  0.068430            1.0                 3.0                NaN         9.0          1.0\n",
       " 12       13.0              grp_rare2_DELINQ        1.0            1.0      1.0       DELINQ                                  DELINQ: Very low entropy - group rare  0.065238            1.0                 NaN                7.0        11.0          1.0\n",
       " 13       14.0               grp_rare2_DEROG        1.0            1.0      1.0        DEROG                                   DEROG: Very low entropy - group rare  0.047825            1.0                 NaN               10.0        14.0          1.0\n",
       "\n",
       "+ Elapsed: 0.001s, user: 0.00041s, sys: 0.000573s, mem: 0.93mb"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.fetch(table = {'name': 'FEATURE_OUT_PY'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"cas-results-key\"><b>&#167; Fetch</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><caption>Selected Rows from Table PIPELINE_OUT_PY</caption>\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"PipelineId\">PipelineId</th>\n",
       "      <th title=\"ModelType\">ModelType</th>\n",
       "      <th title=\"MLType\">MLType</th>\n",
       "      <th title=\"Objective\">Objective</th>\n",
       "      <th title=\"ObjectiveType\">ObjectiveType</th>\n",
       "      <th title=\"Target\">Target</th>\n",
       "      <th title=\"NFeatures\">NFeatures</th>\n",
       "      <th title=\"Feat1Id\">Feat1Id</th>\n",
       "      <th title=\"Feat1IsNom\">Feat1IsNom</th>\n",
       "      <th title=\"Feat2Id\">Feat2Id</th>\n",
       "      <th title=\"Feat2IsNom\">Feat2IsNom</th>\n",
       "      <th title=\"Feat3Id\">Feat3Id</th>\n",
       "      <th title=\"Feat3IsNom\">Feat3IsNom</th>\n",
       "      <th title=\"Feat4Id\">Feat4Id</th>\n",
       "      <th title=\"Feat4IsNom\">Feat4IsNom</th>\n",
       "      <th title=\"Feat5Id\">Feat5Id</th>\n",
       "      <th title=\"Feat5IsNom\">Feat5IsNom</th>\n",
       "      <th title=\"Feat6Id\">Feat6Id</th>\n",
       "      <th title=\"Feat6IsNom\">Feat6IsNom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>binary classification</td>\n",
       "      <td>dtree</td>\n",
       "      <td>0.116296</td>\n",
       "      <td>MCE</td>\n",
       "      <td>BAD</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>binary classification</td>\n",
       "      <td>gradBoost</td>\n",
       "      <td>0.118456</td>\n",
       "      <td>MCE</td>\n",
       "      <td>BAD</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>binary classification</td>\n",
       "      <td>gradBoost</td>\n",
       "      <td>0.139405</td>\n",
       "      <td>MCE</td>\n",
       "      <td>BAD</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>binary classification</td>\n",
       "      <td>dtree</td>\n",
       "      <td>0.144102</td>\n",
       "      <td>MCE</td>\n",
       "      <td>BAD</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>9.0</td>\n",
       "      <td>binary classification</td>\n",
       "      <td>dtree</td>\n",
       "      <td>0.154696</td>\n",
       "      <td>MCE</td>\n",
       "      <td>BAD</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>binary classification</td>\n",
       "      <td>dtree</td>\n",
       "      <td>0.186743</td>\n",
       "      <td>MCE</td>\n",
       "      <td>BAD</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>binary classification</td>\n",
       "      <td>dtree</td>\n",
       "      <td>0.186747</td>\n",
       "      <td>MCE</td>\n",
       "      <td>BAD</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>binary classification</td>\n",
       "      <td>gradBoost</td>\n",
       "      <td>0.199261</td>\n",
       "      <td>MCE</td>\n",
       "      <td>BAD</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>10.0</td>\n",
       "      <td>binary classification</td>\n",
       "      <td>gradBoost</td>\n",
       "      <td>0.199295</td>\n",
       "      <td>MCE</td>\n",
       "      <td>BAD</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>6.0</td>\n",
       "      <td>binary classification</td>\n",
       "      <td>gradBoost</td>\n",
       "      <td>0.199329</td>\n",
       "      <td>MCE</td>\n",
       "      <td>BAD</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-output-area\"></div>\n",
       "<p class=\"cas-results-performance\"><small><span class=\"cas-elapsed\">elapsed 0.000853s</span> &#183; <span class=\"cas-user\">user 0.000349s</span> &#183; <span class=\"cas-sys\">sys 0.000488s</span> &#183; <span class=\"cas-memory\">mem 0.924MB</span></small></p>"
      ],
      "text/plain": [
       "[Fetch]\n",
       "\n",
       " Selected Rows from Table PIPELINE_OUT_PY\n",
       " \n",
       "    PipelineId              ModelType     MLType  Objective ObjectiveType Target  NFeatures  Feat1Id  Feat1IsNom  Feat2Id  Feat2IsNom  Feat3Id  Feat3IsNom  Feat4Id  Feat4IsNom  Feat5Id  Feat5IsNom  Feat6Id  Feat6IsNom\n",
       " 0         1.0  binary classification      dtree   0.116296           MCE    BAD        6.0     13.0         1.0      3.0         1.0      1.0         0.0     10.0         1.0      7.0         0.0     14.0         1.0\n",
       " 1         2.0  binary classification  gradBoost   0.118456           MCE    BAD        6.0     13.0         1.0      3.0         1.0      1.0         0.0     10.0         1.0      7.0         0.0     14.0         1.0\n",
       " 2         4.0  binary classification  gradBoost   0.139405           MCE    BAD        4.0     13.0         1.0      3.0         1.0      7.0         0.0     14.0         1.0      NaN         NaN      NaN         NaN\n",
       " 3         3.0  binary classification      dtree   0.144102           MCE    BAD        4.0     13.0         1.0      3.0         1.0      7.0         0.0     14.0         1.0      NaN         NaN      NaN         NaN\n",
       " 4         9.0  binary classification      dtree   0.154696           MCE    BAD        3.0     13.0         1.0      3.0         1.0     10.0         1.0      NaN         NaN      NaN         NaN      NaN         NaN\n",
       " 5         7.0  binary classification      dtree   0.186743           MCE    BAD        1.0     13.0         1.0      NaN         NaN      NaN         NaN      NaN         NaN      NaN         NaN      NaN         NaN\n",
       " 6         5.0  binary classification      dtree   0.186747           MCE    BAD        1.0     13.0         1.0      NaN         NaN      NaN         NaN      NaN         NaN      NaN         NaN      NaN         NaN\n",
       " 7         8.0  binary classification  gradBoost   0.199261           MCE    BAD        1.0     13.0         1.0      NaN         NaN      NaN         NaN      NaN         NaN      NaN         NaN      NaN         NaN\n",
       " 8        10.0  binary classification  gradBoost   0.199295           MCE    BAD        3.0     13.0         1.0      3.0         1.0     10.0         1.0      NaN         NaN      NaN         NaN      NaN         NaN\n",
       " 9         6.0  binary classification  gradBoost   0.199329           MCE    BAD        1.0     13.0         1.0      NaN         NaN      NaN         NaN      NaN         NaN      NaN         NaN      NaN         NaN\n",
       "\n",
       "+ Elapsed: 0.000853s, user: 0.000349s, sys: 0.000488s, mem: 0.924mb"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.fetch(table = {'name': 'PIPELINE_OUT_PY'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.session.endsession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional SAS Integration with Open Source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](images/MR_10_SASViya_OpenSource.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Available in SAS Studio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](images/MR_11_pythoneditor.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Available within SAS Coding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](images/MR_12_proc_python.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Resources\n",
    "\n",
    "\n",
    "\n",
    "Blog Series\n",
    "- [Getting Started with Python Integration to SAS Viya](https://blogs.sas.com/content/sgf/2020/06/19/getting-started-with-python-integration-to-sas-viya-index/)\n",
    "- [Getting Started with Python Integration to SAS Viya for Predictive Modeling - Index](https://blogs.sas.com/content/sgf/2023/03/20/getting-started-with-python-integration-to-sas-viya-for-predictive-modeling-index/)\n",
    "- [CAS Action! - a series on fundamentals](https://blogs.sas.com/content/sgf/2021/08/06/cas-action-a-series-on-fundamentals/)\n",
    "\n",
    "\n",
    "\n",
    "SAS Documentation\n",
    "- [SAS Cloud Analytic Services: Fundamentals](https://go.documentation.sas.com/doc/en/pgmsascdc/default/casfun/titlepage.htm)\n",
    "- [SWAT Package](https://sassoftware.github.io/python-swat/getting-started.html)\n",
    "- [CAS Actions](https://go.documentation.sas.com/doc/en/pgmsascdc/default/pgmsassyntaxwlcm/home.htm)\n",
    "\n",
    "\n",
    "\n",
    "SAS Courses\n",
    "- [SAS Viya and Python Integration Fundamentals](https://support.sas.com/edu/schedules.html?crs=PIVY&ctry=US)\n",
    "- [SAS Viya and Python Integration for Machine Learning](https://support.sas.com/edu/schedules.html?crs=POSI34&ctry=US)\n",
    "- [High-Performance Data Processing with CASL in SAS Viya](https://support.sas.com/edu/schedules.html?crs=CASL&ctry=US)\n",
    "\n",
    "\n",
    "\n",
    "Additional Resources\n",
    "- SAS Explore 2022 - [Using Python for Data Analytics in SAS Viya](https://www.youtube.com/watch?v=skd9-it5NPU)\n",
    "- Free Webinar - [Ask the Expert Webinar - How Do I Use Python in SAS Viya?](https://www.sas.com/en_us/webinars/use-python-in-sas-viya.html)\n",
    "- YouTube Tutorial - [SAS Tutorial | Python Integration with SAS Viya](https://www.youtube.com/watch?v=6cDU6JGEYSo)\n",
    "- SAS Viya - [Getting Started with the Python Interface of SAS Viya](https://video.sas.com/detail/video/5430217787001/getting-started-with-the-python-interface-of-sas-viya)\n",
    "- SAS Communities - [Loading Data from Python into CAS](https://communities.sas.com/t5/SAS-Communities-Library/Loading-Data-from-Python-into-CAS/ta-p/263567)\n",
    "- SAS Communities - [4 Approaches for Parallel Data Loading to CAS](https://communities.sas.com/t5/SAS-Communities-Library/4-Approaches-for-Parallel-Data-Loading-to-CAS/ta-p/370955)\n",
    "- SAS Paper - [Seriously Serial or Perfectly Parallel Data Transfer with SAS Viya](https://www.sas.com/content/dam/SAS/support/en/sas-global-forum-proceedings/2019/3479-2019.pdf)\n",
    "- SAS Communities - [Hotwire your SWAT inside SAS Studio!](https://communities.sas.com/t5/SAS-Communities-Library/Hotwire-your-SWAT-inside-SAS-Studio/ta-p/835956)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
